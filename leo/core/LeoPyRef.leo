<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: http://leoeditor.com/leo_toc.html -->
<?xml-stylesheet ekr_test ?>
<leo_file xmlns:leo="http://leoeditor.com/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2" tnodes="0" max_tnode_index="0" clone_windows="0"/>
<globals body_outline_ratio="0.5" body_secondary_ratio="0.5">
	<global_window_position top="50" left="50" height="500" width="700"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20051031040240"><vh>Startup</vh>
<v t="ekr.20080412053100.5"><vh>@settings</vh>
<v t="ekr.20160122104332.1"><vh>Buttons</vh>
<v t="ekr.20150507170849.1"><vh>@@button create decorators</vh>
<v t="ekr.20150508063538.1"><vh>create_d</vh></v>
<v t="ekr.20150508071622.1"><vh>create_decorator</vh></v>
<v t="ekr.20150508063412.1"><vh>create_decorators</vh></v>
<v t="ekr.20150508074623.1"><vh>create_fixups</vh></v>
<v t="ekr.20150508063926.1"><vh>find_class</vh></v>
<v t="ekr.20150507174711.1"><vh>find_next_clone</vh></v>
<v t="ekr.20150507175246.1"><vh>munge_lines</vh></v>
<v t="ekr.20150508062944.1"><vh>run</vh></v>
</v>
<v t="ekr.20150509183433.1"><vh>@@button make-decorators2</vh>
<v t="ekr.20150509183433.2"><vh>create_d</vh></v>
<v t="ekr.20150509183433.3"><vh>create_decorator</vh></v>
<v t="ekr.20150509183433.4"><vh>create_decorators V2</vh></v>
<v t="ekr.20150509183832.1"><vh>define_s</vh></v>
<v t="ekr.20150509183433.8"><vh>munge_lines</vh></v>
<v t="ekr.20150509183433.9"><vh>run V2</vh></v>
</v>
<v t="ekr.20150703061709.1"><vh>@button run-pylint</vh></v>
<v t="ekr.20140902155015.18674"><vh>@bool qt-use-scintilla = False</vh></v>
<v t="ekr.20150531102337.1"><vh>@bool tidy-keep-blank-lines = False</vh></v>
<v t="ekr.20150617060607.1"><vh>@bool tidy_autobeautify = False</vh></v>
<v t="ekr.20150502050609.1"><vh>@button backup</vh></v>
<v t="ekr.20150413091056.1"><vh>@button check-clones</vh></v>
<v t="ekr.20131121084830.16362"><vh>@button toggle-debug</vh></v>
</v>
<v t="ekr.20150425145248.1"><vh>@data history-list</vh></v>
<v t="ekr.20140920064112.17946"><vh>@int fts_max_hits = 100</vh></v>
<v t="ekr.20140919093158.17876"><vh>@int max-pre-loaded-body-chars = 0</vh></v>
<v t="ekr.20131111060930.18010"><vh>@shortcuts</vh></v>
<v t="ekr.20140916101314.19538"><vh>@string target_language = python</vh></v>
</v>
<v t="ekr.20140103105930.16446"><vh>@views</vh>
<v t="ekr.20140102162014.16438"><vh>@view added strip_comments keyword arg to two config.getData methods</vh></v>
</v>
<v t="ekr.20140808103117.18035"><vh>@persistence</vh>
<v t="ekr.20140808103117.18036"><vh>@data:@auto ../test/qtui_generate.py</vh>
<v t="ekr.20160306053952.1"><vh>@gnxs</vh></v>
</v>
<v t="ekr.20140808103117.18038"><vh>@data:@auto ../plugins/qt_main.py</vh>
<v t="ekr.20160306053952.2"><vh>@gnxs</vh></v>
</v>
<v t="ekr.20140808103117.18040"><vh>@data:@auto ../plugins/qt_main.ui</vh>
<v t="ekr.20160306053953.1"><vh>@gnxs</vh></v>
</v>
<v t="ekr.20140808103117.18042"><vh>@data:@auto ../plugins/qt_quicksearch.py</vh>
<v t="ekr.20160306053953.2"><vh>@gnxs</vh></v>
</v>
<v t="ekr.20140808103117.18044"><vh>@data:@auto ../plugins/qt_quicksearch.ui</vh>
<v t="ekr.20160306053953.3"><vh>@gnxs</vh></v>
</v>
<v t="ekr.20150604130353.1"><vh>@data:@auto test/unit_tests.py</vh>
<v t="ekr.20150604130353.2"><vh>@gnxs</vh></v>
</v>
</v>
<v t="ekr.20140923085942.17943"><vh>Recent scripts</vh>
<v t="ekr.20140905060158.18560"><vh>Script: change body.x to body.wrapper.x</vh>
<v t="ekr.20140905060158.18561"><vh>test</vh></v>
</v>
<v t="ekr.20140918124632.19450"><vh>Script: print Qt color names</vh></v>
<v t="ekr.20160315161104.1"><vh>@test rt</vh>
<v t="ekr.20160315163533.1"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20150722204300.1"><vh>class HTMLReportTraverser</vh>
<v t="ekr.20150722204300.2"><vh>rt.__init__</vh>
<v t="ekr.20150722204300.3"><vh>define_html_header</vh></v>
</v>
<v t="ekr.20150723094359.1"><vh>rt.code generators</vh>
<v t="ekr.20150723100236.1"><vh>rt.blank</vh></v>
<v t="ekr.20150723100208.1"><vh>rt.clean</vh></v>
<v t="ekr.20150723105702.1"><vh>rt.colon</vh></v>
<v t="ekr.20150723100346.1"><vh>rt.comma &amp; clean_comma</vh></v>
<v t="ekr.20150722204300.21"><vh>rt.doc</vh></v>
<v t="ekr.20150722204300.22"><vh>rt.docstring</vh></v>
<v t="ekr.20150722211115.1"><vh>rt.gen</vh></v>
<v t="ekr.20150722204300.23"><vh>rt.keyword (code generator)</vh></v>
<v t="ekr.20150722204300.24"><vh>rt.name</vh></v>
<v t="ekr.20150723100417.1"><vh>rt.newline</vh></v>
<v t="ekr.20150722204300.26"><vh>rt.op</vh></v>
<v t="ekr.20150723105951.1"><vh>rt.op_name</vh></v>
<v t="ekr.20160315184954.1"><vh>rt.string (code generator)</vh></v>
<v t="ekr.20150722204300.27"><vh>rt.simple_statement</vh></v>
</v>
<v t="ekr.20150722204300.16"><vh>rt.html helpers</vh>
<v t="ekr.20150722204300.17"><vh>rt.attr &amp; text</vh></v>
<v t="ekr.20150722204300.18"><vh>rt.br</vh></v>
<v t="ekr.20150722204300.19"><vh>rt.comment</vh></v>
<v t="ekr.20150722204300.20"><vh>rt.div</vh></v>
<v t="ekr.20150722222149.1"><vh>rt.div_body</vh></v>
<v t="ekr.20150722221101.1"><vh>rt.div_list &amp; div_node</vh></v>
<v t="ekr.20150723095033.1"><vh>rt.end_div</vh></v>
<v t="ekr.20150723095004.1"><vh>rt.end_span</vh></v>
<v t="ekr.20150722221408.1"><vh>rt.keyword_colon</vh></v>
<v t="ekr.20150722204300.5"><vh>rt.link</vh></v>
<v t="ekr.20150722204300.6"><vh>rt.module_link</vh></v>
<v t="ekr.20150722204300.7"><vh>rt.name_link</vh></v>
<v t="ekr.20150722204300.8"><vh>rt.object_name_ref</vh></v>
<v t="ekr.20150722204300.9"><vh>rt.popup</vh></v>
<v t="ekr.20150722204300.28"><vh>rt.span</vh></v>
<v t="ekr.20150722224734.1"><vh>rt.span_list &amp; span_node</vh></v>
<v t="ekr.20150722204300.10"><vh>rt.summary_link</vh></v>
</v>
<v t="ekr.20160315161259.1"><vh>rt.main</vh></v>
<v t="ekr.20150722204300.44"><vh>rt.visit</vh></v>
<v t="ekr.20150722204300.45"><vh>rt.visit_list</vh></v>
<v t="ekr.20150722204300.46"><vh>rt.visitors</vh>
<v t="ekr.20150722204300.49"><vh>rt.Assert</vh></v>
<v t="ekr.20150722204300.50"><vh>rt.Assign</vh></v>
<v t="ekr.20150722204300.51"><vh>rt.Attribute</vh></v>
<v t="ekr.20150722204300.52"><vh>rt.AugAssign</vh></v>
<v t="ekr.20150722204300.53"><vh>rt.BinOp</vh></v>
<v t="ekr.20150722204300.54"><vh>rt.BoolOp</vh></v>
<v t="ekr.20150722204300.55"><vh>rt.Break</vh></v>
<v t="ekr.20150722204300.56"><vh>rt.Call &amp; do_keyword</vh>
<v t="ekr.20150722204300.57"><vh>rt.do_keyword</vh></v>
</v>
<v t="ekr.20150722204300.58"><vh>rt.ClassDef</vh></v>
<v t="ekr.20150722204300.59"><vh>rt.Compare</vh></v>
<v t="ekr.20150722204300.60"><vh>rt.comprehension</vh></v>
<v t="ekr.20150722204300.61"><vh>rt.Continue</vh></v>
<v t="ekr.20150722204300.62"><vh>rt.Delete</vh></v>
<v t="ekr.20150722204300.63"><vh>rt.Dict</vh></v>
<v t="ekr.20150722204300.47"><vh>rt.do_arguments &amp; helpers</vh>
<v t="ekr.20160315182225.1"><vh>rt.arg</vh></v>
<v t="ekr.20150722204300.48"><vh>rt.tuple_parameter</vh></v>
</v>
<v t="ekr.20150722204300.64"><vh>rt.Ellipsis</vh></v>
<v t="ekr.20150722204300.65"><vh>rt.ExceptHandler</vh></v>
<v t="ekr.20150722204300.66"><vh>rt.Exec</vh></v>
<v t="ekr.20150722204300.67"><vh>rt.Expr</vh></v>
<v t="ekr.20150722204300.68"><vh>rt.For</vh></v>
<v t="ekr.20150722204300.69"><vh>rt.FunctionDef</vh></v>
<v t="ekr.20150722204300.70"><vh>rt.GeneratorExp</vh></v>
<v t="ekr.20150722204300.71"><vh>rt.get_import_names</vh></v>
<v t="ekr.20150722204300.72"><vh>rt.Global</vh></v>
<v t="ekr.20150722204300.73"><vh>rt.If</vh></v>
<v t="ekr.20150722204300.74"><vh>rt.IfExp (TernaryOp)</vh></v>
<v t="ekr.20150722204300.75"><vh>rt.Import</vh></v>
<v t="ekr.20150722204300.76"><vh>rt.ImportFrom</vh></v>
<v t="ekr.20160315190818.1"><vh>rt.Index</vh></v>
<v t="ekr.20150722204300.77"><vh>rt.Lambda</vh></v>
<v t="ekr.20150722204300.78"><vh>rt.List</vh></v>
<v t="ekr.20150722204300.79"><vh>rt.ListComp</vh></v>
<v t="ekr.20150722204300.80"><vh>rt.Module</vh></v>
<v t="ekr.20150722204300.81"><vh>rt.Name</vh></v>
<v t="ekr.20160315165109.1"><vh>rt.NameConstant</vh></v>
<v t="ekr.20150722204300.82"><vh>rt.Num</vh></v>
<v t="ekr.20150722204300.83"><vh>rt.Pass</vh></v>
<v t="ekr.20150722204300.84"><vh>rt.Print</vh></v>
<v t="ekr.20150722204300.85"><vh>rt.Raise</vh></v>
<v t="ekr.20150722204300.86"><vh>rt.Return</vh></v>
<v t="ekr.20150722204300.87"><vh>rt.Slice</vh></v>
<v t="ekr.20150722204300.88"><vh>rt.Str</vh></v>
<v t="ekr.20150722204300.89"><vh>rt.Subscript</vh></v>
<v t="ekr.20160315190913.1"><vh>rt.Try (Python 3 only)</vh></v>
<v t="ekr.20150722204300.90"><vh>rt.TryExcept</vh></v>
<v t="ekr.20150722204300.91"><vh>rt.TryFinally</vh></v>
<v t="ekr.20150722204300.92"><vh>rt.Tuple</vh></v>
<v t="ekr.20150722204300.93"><vh>rt.UnaryOp</vh></v>
<v t="ekr.20150722204300.94"><vh>rt.While</vh></v>
<v t="ekr.20150722204300.95"><vh>rt.With</vh></v>
<v t="ekr.20150722204300.96"><vh>rt.Yield</vh></v>
</v>
</v>
</v>
</v>
</v>
<v t="EKR.20040430162943"><vh>Notes</vh>
<v t="ekr.20031218072017.329" descendentVnodeUnknownAttributes="7d71005805000000302e312e3071017d7102285808000000616e6e6f7461746571037d71042858080000007072696f7269747971054d0f27580a000000707269736574646174657106580a000000323031352d30352d3237710775580b0000006c696e65594f666673657471084b0075732e"><vh>@file ../doc/leoNotes.txt</vh></v>
</v>
<v t="ekr.20100120072650.6088"><vh>Projects</vh>
<v t="ekr.20100120072650.6089"><vh>@file ../doc/leoProjects.txt</vh></v>
</v>
<v t="EKR.20040519090151.2"><vh>To do</vh>
<v t="ekr.20100119205347.6015"><vh>@file ../doc/leoToDo.txt</vh></v>
</v>
<v t="ekr.20031218072017.2406"><vh>Code</vh>
<v t="ekr.20140902032918.18591"><vh> About this file</vh>
<v t="ekr.20140831085423.18639"><vh>About widgets and wrappers</vh></v>
<v t="ekr.20140831085423.18630"><vh>Terminology</vh></v>
<v t="ekr.20140831085423.18631"><vh>Official ivars</vh></v>
</v>
<v t="ekr.20031218072017.2604"><vh>Core classes</vh>
<v t="ekr.20031218072017.2608"><vh>@file leoApp.py</vh></v>
<v t="ekr.20141012064706.18389"><vh>@file leoAst.py</vh></v>
<v t="ekr.20150323150718.1"><vh>@file leoAtFile.py</vh></v>
<v t="ekr.20150521115018.1"><vh>@file leoBeautify.py</vh></v>
<v t="ekr.20070227091955.1"><vh>@file leoBridge.py</vh></v>
<v t="ekr.20100208065621.5894"><vh>@file leoCache.py</vh></v>
<v t="ekr.20070317085508.1"><vh>@file leoChapters.py</vh></v>
<v t="ekr.20150605175037.1"><vh>@file leoCheck.py</vh></v>
<v t="ekr.20031218072017.2794"><vh>@file leoColor.py</vh></v>
<v t="ekr.20140827092102.18574"><vh>@file leoColorizer.py</vh></v>
<v t="ekr.20031218072017.2810"><vh>@file leoCommands.py</vh></v>
<v t="ekr.20130925160837.11429"><vh>@file leoConfig.py</vh></v>
<v t="ekr.20160306114544.1"><vh>@file leoExternalFiles.py</vh></v>
<v t="ekr.20031218072017.3018"><vh>@file leoFileCommands.py</vh></v>
<v t="ekr.20031218072017.3093" descendentVnodeUnknownAttributes="7d71005806000000302e31372e3071017d71025808000000616e6e6f7461746571037d710473732e"><vh>@file leoGlobals.py</vh></v>
<v t="ekr.20150514154159.1"><vh>@file leoHistory.py</vh></v>
<v t="ekr.20031218072017.3206"><vh>@file leoImport.py</vh></v>
<v t="ekr.20120401063816.10072"><vh>@file leoIPython.py</vh></v>
<v t="ekr.20031218072017.3320"><vh>@file leoNodes.py</vh></v>
<v t="ekr.20140821055201.18331"><vh>@file leoPersistence.py</vh></v>
<v t="ekr.20031218072017.3439"><vh>@file leoPlugins.py</vh></v>
<v t="ekr.20150419124739.1"><vh>@file leoPrinting.py</vh></v>
<v t="ekr.20061024060248.1"><vh>@file leoPymacs.py</vh></v>
<v t="ekr.20140810053602.18074"><vh>@file leoQt.py</vh></v>
<v t="ekr.20140526082700.18440"><vh>@file leoRope.py</vh></v>
<v t="ekr.20090502071837.3"><vh>@file leoRst.py</vh></v>
<v t="ekr.20120420054855.14241" descendentVnodeUnknownAttributes="7d7100285805000000302e332e3071017d71022858090000007374725f6174696d657103580d000000313331393534393339302e3839710458090000007374725f6374696d657105580c000000313331393439313330362e30710658090000007374725f6d74696d657107580d000000313331393439323330312e35327108755805000000302e332e3371097d710a2858090000007374725f6174696d65710b580d000000313332303433343235372e3336710c58090000007374725f6374696d65710d580c000000313331393436303438332e30710e58090000007374725f6d74696d65710f580d000000313332303432323639302e35347110755805000000302e332e3171117d71122858090000007374725f6174696d657113580c000000313332303432323637302e39711458090000007374725f6374696d657115580c000000313331393436303438332e30711658090000007374725f6d74696d657117580d000000313331393436373033382e32357118755805000000302e332e3271197d711a2858090000007374725f6174696d65711b580d000000313331393436373035302e3438711c58090000007374725f6374696d65711d580c000000313331393436303438332e30711e58090000007374725f6d74696d65711f580d000000313331393436373035302e34387120755805000000302e332e3571217d71222858090000007374725f6174696d657123580d000000313331393634313435352e3937712458090000007374725f6374696d657125580c000000313331393633383634382e30712658090000007374725f6d74696d657127580c000000313331393634313131372e397128755805000000302e332e3471297d712a2858090000007374725f6174696d65712b580c000000313331393634353330362e32712c58090000007374725f6374696d65712d580c000000313331393633383634382e30712e58090000007374725f6d74696d65712f580d000000313331393634313038352e3038713075752e"><vh>@file leoSessions.py</vh></v>
<v t="ekr.20080708094444.1"><vh>@file leoShadow.py</vh></v>
<v t="ekr.20031218072017.3446"><vh>@file leoTangle.py</vh></v>
<v t="ekr.20031218072017.3603"><vh>@file leoUndo.py</vh></v>
<v t="ekr.20131109170017.16504"><vh>@file leoVim.py</vh></v>
</v>
<v t="ekr.20150514035207.1"><vh>Command classes</vh>
<v t="ekr.20150514035943.1"><vh>@file ../commands/baseCommands.py</vh></v>
<v t="ekr.20150514035236.1"><vh>@file ../commands/abbrevCommands.py</vh></v>
<v t="ekr.20150514035559.1"><vh>@file ../commands/bufferCommands.py</vh></v>
<v t="ekr.20150514040100.1"><vh>@file ../commands/controlCommands.py</vh></v>
<v t="ekr.20160316095222.1"
expanded="ekr.20150514063305.121,ekr.20150514063305.160,ekr.20150514063305.176,"><vh>@file ../commands/convertCommands.py</vh></v>
<v t="ekr.20150514040118.1"><vh>@file ../commands/debugCommands.py</vh></v>
<v t="ekr.20150514035813.1"><vh>@file ../commands/editCommands.py</vh></v>
<v t="ekr.20150514041209.1"><vh>@file ../commands/editFileCommands.py</vh></v>
<v t="ekr.20150624112334.1"><vh>@file ../commands/gotoCommands.py</vh></v>
<v t="ekr.20150514040138.1"><vh>@file ../commands/helpCommands.py</vh></v>
<v t="ekr.20150514040140.1"><vh>@file ../commands/keyCommands.py</vh></v>
<v t="ekr.20150514040142.1"><vh>@file ../commands/killBufferCommands.py</vh></v>
<v t="ekr.20150514040144.1"><vh>@file ../commands/macroCommands.py</vh></v>
<v t="ekr.20150514040146.1"><vh>@file ../commands/rectangleCommands.py</vh></v>
<v t="ekr.20150514040234.1"><vh>@file ../commands/registerCommands.py</vh></v>
<v t="ekr.20150514040239.1"><vh>@file ../commands/spellCommands.py</vh></v>
</v>
<v t="ekr.20031218072017.3625"><vh>Gui base classes</vh>
<v t="ekr.20050721093241"><vh>&lt;&lt; about gui classes and gui plugins &gt;&gt;</vh></v>
<v t="ekr.20031218072017.3630"><vh>@file leoCompare.py</vh></v>
<v t="ekr.20060123151617"><vh>@file leoFind.py</vh></v>
<v t="ekr.20031218072017.3655"><vh>@file leoFrame.py</vh></v>
<v t="ekr.20031218072017.3719"><vh>@file leoGui.py</vh></v>
<v t="ekr.20061031131434"><vh>@file leoKeys.py</vh></v>
<v t="ekr.20031218072017.3749"><vh>@file leoMenu.py</vh></v>
</v>
<v t="ekr.20110605121601.17862"><vh>Qt gui</vh>
<v t="ekr.20120419093256.10048"><vh>@file ../plugins/free_layout.py</vh></v>
<v t="ekr.20110605121601.17954"><vh>@file ../plugins/nested_splitter.py</vh></v>
<v t="ekr.20140919181357.24956"><vh>@file ../plugins/qt_big_text.py</vh></v>
<v t="ekr.20110605121601.17996"><vh>@file ../plugins/qt_commands.py</vh></v>
<v t="ekr.20140907103315.18766"><vh>@file ../plugins/qt_events.py</vh></v>
<v t="ekr.20140907123524.18774"><vh>@file ../plugins/qt_frame.py</vh></v>
<v t="ekr.20140907085654.18699"><vh>@file ../plugins/qt_gui.py</vh></v>
<v t="ekr.20140907103315.18777"><vh>@file ../plugins/qt_idle_time.py</vh></v>
<v t="ekr.20140907123524.18777"><vh>@file ../plugins/qt_quickheadlines.py</vh></v>
<v t="ekr.20140831085423.18598"><vh>@file ../plugins/qt_text.py</vh></v>
<v t="ekr.20140907131341.18707"><vh>@file ../plugins/qt_tree.py</vh></v>
<v t="ekr.20110605121601.18002"><vh>@file ../plugins/qtGui.py</vh></v>
<v t="ekr.20110605121601.18695"><vh>QDesigner files</vh>
<v t="ekr.20110605121601.18696"><vh>@auto ../test/qtui_generate.py</vh></v>
<v t="ekr.20110605121601.18698"><vh>@auto ../plugins/qt_main.py</vh></v>
<v t="ekr.20110605121601.18703"><vh>@auto ../plugins/qt_main.ui</vh></v>
<v t="ekr.20110605121601.18704"><vh>@auto ../plugins/qt_quicksearch.py</vh></v>
<v t="ekr.20110605121601.18709"><vh>@auto ../plugins/qt_quicksearch.ui</vh></v>
</v>
</v>
<v t="ekr.20160226082945.1"><vh>PyInstaller</vh>
<v t="ekr.20160124165611.1"><vh>@file ../../launchLeo-unified.spec</vh></v>
</v>
<v t="ekr.20090802181029.5989"><vh>Startup &amp; external files</vh>
<v t="ekr.20150304125314.4"><vh>@clean ../../leo_to_html.xsl</vh>
<v t="ekr.20150304130753.5"><vh>&lt;&lt;style&gt;&gt;</vh></v>
<v t="ekr.20150304130753.6"><vh>&lt;&lt;scripts&gt;&gt;</vh></v>
</v>
<v t="ekr.20150326145530.1"><vh>@clean ../modes/forth.py</vh>
<v t="ekr.20150326145530.2"><vh>&lt;&lt; define mode rules &gt;&gt;</vh></v>
<v t="ekr.20150326145530.3"><vh>&lt;&lt; define mode data &gt;&gt;</vh></v>
<v t="ekr.20150326145530.4"><vh>&lt;&lt; define extendForth class &gt;&gt;</vh>
<v t="ekr.20150326145530.5"><vh>ctor</vh></v>
<v t="ekr.20150326145530.6"><vh>init &amp; helper</vh>
<v t="ekr.20150326145530.7"><vh>splitList</vh></v>
</v>
<v t="ekr.20150326145530.8"><vh>createBracketRules &amp; helper</vh></v>
<v t="ekr.20150326145530.9"><vh>createDefiningWordRules &amp; helper</vh></v>
<v t="ekr.20150326145530.10"><vh>createKeywords</vh></v>
<v t="ekr.20150326145530.11"><vh>createStringRule</vh></v>
<v t="ekr.20150326145530.12"><vh>extendRulesDict</vh></v>
</v>
</v>
<v t="ekr.20160123142722.1"><vh>@clean ../external/make_stub_files.cfg</vh></v>
<v t="ekr.20160315164448.1"><vh>@clean ../external/make_stub_files.py</vh>
<v t="ekr.20160315164542.1"><vh>make_stub_files declarations</vh></v>
<v t="ekr.20160315164542.2"><vh>Top-level functions</vh>
<v t="ekr.20160315164542.3"><vh>dump</vh></v>
<v t="ekr.20160315164542.4"><vh>dump_dict</vh></v>
<v t="ekr.20160315164542.5"><vh>dump_list</vh></v>
<v t="ekr.20160315164542.6"><vh>is_known_type</vh></v>
<v t="ekr.20160315164542.7"><vh>main</vh></v>
<v t="ekr.20160315164542.8"><vh>merge_types</vh></v>
<v t="ekr.20160315164542.9"><vh>pdb</vh></v>
<v t="ekr.20160315164542.10"><vh>reduce_numbers</vh></v>
<v t="ekr.20160315164542.11"><vh>reduce_types</vh></v>
<v t="ekr.20160315164542.12"><vh>show_helper</vh></v>
<v t="ekr.20160315164542.13"><vh>split_types</vh></v>
<v t="ekr.20160315164542.14"><vh>truncate</vh></v>
</v>
<v t="ekr.20160315164542.15"><vh>class AstFormatter</vh>
<v t="ekr.20160315164542.16"><vh># pylint: disable=consider-using-enumerate</vh></v>
<v t="ekr.20160315164542.17"><vh>format</vh></v>
<v t="ekr.20160315164542.18"><vh>visit</vh></v>
<v t="ekr.20160315164542.19"><vh># Contexts...</vh></v>
<v t="ekr.20160315164542.20"><vh>do_ClassDef</vh></v>
<v t="ekr.20160315164542.21"><vh># FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)</vh></v>
<v t="ekr.20160315164542.22"><vh>do_FunctionDef</vh></v>
<v t="ekr.20160315164542.23"><vh>do_Interactive</vh></v>
<v t="ekr.20160315164542.24"><vh>do_Module</vh></v>
<v t="ekr.20160315164542.25"><vh>do_Lambda</vh></v>
<v t="ekr.20160315164542.26"><vh># Expressions...</vh></v>
<v t="ekr.20160315164542.27"><vh>do_Expr</vh></v>
<v t="ekr.20160315164542.28"><vh>do_Expression</vh></v>
<v t="ekr.20160315164542.29"><vh>do_GeneratorExp</vh></v>
<v t="ekr.20160315164542.30"><vh>do_AugLoad</vh></v>
<v t="ekr.20160315164542.31"><vh>do_Del</vh></v>
<v t="ekr.20160315164542.32"><vh>do_Load</vh></v>
<v t="ekr.20160315164542.33"><vh>do_Param</vh></v>
<v t="ekr.20160315164542.34"><vh>do_Store</vh></v>
<v t="ekr.20160315164542.35"><vh># Operands...</vh></v>
<v t="ekr.20160315164542.36"><vh>do_arguments</vh></v>
<v t="ekr.20160315164542.37"><vh># Python 3:</vh></v>
<v t="ekr.20160315164542.38"><vh>do_arg</vh></v>
<v t="ekr.20160315164542.39"><vh># Attribute(expr value, identifier attr, expr_context ctx)</vh></v>
<v t="ekr.20160315164542.40"><vh>do_Attribute</vh></v>
<v t="ekr.20160315164542.41"><vh>do_Bytes</vh></v>
<v t="ekr.20160315164542.42"><vh># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)</vh></v>
<v t="ekr.20160315164542.43"><vh>do_Call</vh></v>
<v t="ekr.20160315164542.44"><vh># keyword = (identifier arg, expr value)</vh></v>
<v t="ekr.20160315164542.45"><vh>do_keyword</vh></v>
<v t="ekr.20160315164542.46"><vh>do_comprehension</vh></v>
<v t="ekr.20160315164542.47"><vh>do_Dict</vh></v>
<v t="ekr.20160315164542.48"><vh>do_Ellipsis</vh></v>
<v t="ekr.20160315164542.49"><vh>do_ExtSlice</vh></v>
<v t="ekr.20160315164542.50"><vh>do_Index</vh></v>
<v t="ekr.20160315164542.51"><vh>do_List</vh></v>
<v t="ekr.20160315164542.52"><vh>do_ListComp</vh></v>
<v t="ekr.20160315164542.53"><vh>do_Name</vh></v>
<v t="ekr.20160315164542.54"><vh>do_NameConstant</vh></v>
<v t="ekr.20160315164542.55"><vh>do_Num</vh></v>
<v t="ekr.20160315164542.56"><vh># Python 2.x only</vh></v>
<v t="ekr.20160315164542.57"><vh>do_Repr</vh></v>
<v t="ekr.20160315164542.58"><vh>do_Slice</vh></v>
<v t="ekr.20160315164542.59"><vh>do_Str</vh></v>
<v t="ekr.20160315164542.60"><vh># Subscript(expr value, slice slice, expr_context ctx)</vh></v>
<v t="ekr.20160315164542.61"><vh>do_Subscript</vh></v>
<v t="ekr.20160315164542.62"><vh>do_Tuple</vh></v>
<v t="ekr.20160315164542.63"><vh># Operators...</vh></v>
<v t="ekr.20160315164542.64"><vh>do_BinOp</vh></v>
<v t="ekr.20160315164542.65"><vh>do_BoolOp</vh></v>
<v t="ekr.20160315164542.66"><vh>do_Compare</vh></v>
<v t="ekr.20160315164542.67"><vh>do_UnaryOp</vh></v>
<v t="ekr.20160315164542.68"><vh>do_IfExp</vh></v>
<v t="ekr.20160315164542.69"><vh># Statements...</vh></v>
<v t="ekr.20160315164542.70"><vh>do_Assert</vh></v>
<v t="ekr.20160315164542.71"><vh>do_Assign</vh></v>
<v t="ekr.20160315164542.72"><vh>do_AugAssign</vh></v>
<v t="ekr.20160315164542.73"><vh>do_Break</vh></v>
<v t="ekr.20160315164542.74"><vh>do_Continue</vh></v>
<v t="ekr.20160315164542.75"><vh>do_Delete</vh></v>
<v t="ekr.20160315164542.76"><vh>do_ExceptHandler</vh></v>
<v t="ekr.20160315164542.77"><vh># Python 2.x only</vh></v>
<v t="ekr.20160315164542.78"><vh>do_Exec</vh></v>
<v t="ekr.20160315164542.79"><vh>do_For</vh></v>
<v t="ekr.20160315164542.80"><vh>do_Global</vh></v>
<v t="ekr.20160315164542.81"><vh>do_If</vh></v>
<v t="ekr.20160315164542.82"><vh>do_Import</vh></v>
<v t="ekr.20160315164542.83"><vh>get_import_names</vh></v>
<v t="ekr.20160315164542.84"><vh>do_ImportFrom</vh></v>
<v t="ekr.20160315164542.85"><vh>do_Pass</vh></v>
<v t="ekr.20160315164542.86"><vh># Python 2.x only</vh></v>
<v t="ekr.20160315164542.87"><vh>do_Print</vh></v>
<v t="ekr.20160315164542.88"><vh>do_Raise</vh></v>
<v t="ekr.20160315164542.89"><vh>do_Return</vh></v>
<v t="ekr.20160315164542.90"><vh>do_TryExcept</vh></v>
<v t="ekr.20160315164542.91"><vh>do_TryFinally</vh></v>
<v t="ekr.20160315164542.92"><vh>do_While</vh></v>
<v t="ekr.20160315164542.93"><vh>do_With</vh></v>
<v t="ekr.20160315164542.94"><vh>do_Yield</vh></v>
<v t="ekr.20160315164542.95"><vh># Utils...</vh></v>
<v t="ekr.20160315164542.96"><vh>kind</vh></v>
<v t="ekr.20160315164542.97"><vh>indent</vh></v>
<v t="ekr.20160315164542.98"><vh>op_name</vh></v>
</v>
<v t="ekr.20160315164542.99"><vh>class AstArgFormatter</vh>
<v t="ekr.20160315164542.100"><vh># Return generic markers to allow better pattern matches.</vh></v>
<v t="ekr.20160315164542.101"><vh>do_BoolOp</vh></v>
<v t="ekr.20160315164542.102"><vh>do_Bytes</vh></v>
<v t="ekr.20160315164542.103"><vh>do_Name</vh></v>
<v t="ekr.20160315164542.104"><vh>do_Num</vh></v>
<v t="ekr.20160315164542.105"><vh>do_Str</vh></v>
</v>
<v t="ekr.20160315164542.106"><vh>class LeoGlobals</vh>
<v t="ekr.20160315164542.107"><vh>class NullObject</vh>
<v t="ekr.20160315164542.108"><vh>__init__</vh></v>
<v t="ekr.20160315164542.109"><vh>__call__</vh></v>
<v t="ekr.20160315164542.110"><vh>__repr__</vh></v>
<v t="ekr.20160315164542.111"><vh>__str__</vh></v>
<v t="ekr.20160315164542.112"><vh>__bool__</vh></v>
<v t="ekr.20160315164542.113"><vh>__nonzero__</vh></v>
<v t="ekr.20160315164542.114"><vh>__delattr__</vh></v>
<v t="ekr.20160315164542.115"><vh>__getattr__</vh></v>
<v t="ekr.20160315164542.116"><vh>__setattr__</vh></v>
</v>
<v t="ekr.20160315164542.117"><vh>_callerName</vh></v>
<v t="ekr.20160315164542.118"><vh>callers</vh></v>
<v t="ekr.20160315164542.119"><vh>cls</vh></v>
<v t="ekr.20160315164542.120"><vh>pdb</vh></v>
<v t="ekr.20160315164542.121"><vh>shortFileName</vh></v>
<v t="ekr.20160315164542.122"><vh>splitLines</vh></v>
<v t="ekr.20160315164542.123"><vh>trace</vh></v>
</v>
<v t="ekr.20160315164542.124"><vh>class Pattern</vh>
<v t="ekr.20160315164542.125"><vh>__init__</vh></v>
<v t="ekr.20160315164542.126"><vh>__eq__</vh></v>
<v t="ekr.20160315164542.127"><vh>__ne__</vh></v>
<v t="ekr.20160315164542.128"><vh>__hash__</vh></v>
<v t="ekr.20160315164542.129"><vh>__repr__</vh></v>
<v t="ekr.20160315164542.130"><vh>__str__ = __repr__</vh></v>
<v t="ekr.20160315164542.131"><vh>is_balanced</vh></v>
<v t="ekr.20160315164542.132"><vh>is_regex</vh></v>
<v t="ekr.20160315164542.133"><vh>all_matches</vh></v>
<v t="ekr.20160315164542.134"><vh>full_balanced_match</vh></v>
<v t="ekr.20160315164542.135"><vh>match_balanced</vh></v>
<v t="ekr.20160315164542.136"><vh>match</vh></v>
<v t="ekr.20160315164542.137"><vh>match_entire_string</vh></v>
<v t="ekr.20160315164542.138"><vh>replace</vh></v>
<v t="ekr.20160315164542.139"><vh>replace_balanced</vh></v>
<v t="ekr.20160315164542.140"><vh>replace_regex</vh></v>
</v>
<v t="ekr.20160315164542.141"><vh>class StandAloneMakeStubFile</vh>
<v t="ekr.20160315164542.142"><vh>__init__</vh></v>
<v t="ekr.20160315164542.143"><vh>finalize</vh></v>
<v t="ekr.20160315164542.144"><vh>make_stub_file</vh></v>
<v t="ekr.20160315164542.145"><vh>run</vh></v>
<v t="ekr.20160315164542.146"><vh>run_all_unit_tests</vh></v>
<v t="ekr.20160315164542.147"><vh>scan_command_line</vh></v>
<v t="ekr.20160315164542.148"><vh>scan_options</vh></v>
<v t="ekr.20160315164542.149"><vh>make_op_name_dict</vh></v>
<v t="ekr.20160315164542.150"><vh>create_parser</vh></v>
<v t="ekr.20160315164542.151"><vh>find_pattern_ops</vh></v>
<v t="ekr.20160315164542.152"><vh>get_config_string</vh></v>
<v t="ekr.20160315164542.153"><vh>init_parser</vh></v>
<v t="ekr.20160315164542.154"><vh>is_section_name</vh></v>
<v t="ekr.20160315164542.155"><vh>make_patterns_dict</vh></v>
<v t="ekr.20160315164542.156"><vh>scan_patterns</vh></v>
</v>
<v t="ekr.20160315164542.157"><vh>class Stub</vh>
<v t="ekr.20160315164542.158"><vh>__init__</vh></v>
<v t="ekr.20160315164542.159"><vh>__eq__</vh></v>
<v t="ekr.20160315164542.160"><vh>__ne__</vh></v>
<v t="ekr.20160315164542.161"><vh>__hash__</vh></v>
<v t="ekr.20160315164542.162"><vh>__repr__</vh></v>
<v t="ekr.20160315164542.163"><vh>__str__</vh></v>
<v t="ekr.20160315164542.164"><vh>level</vh></v>
<v t="ekr.20160315164542.165"><vh>parents</vh></v>
</v>
<v t="ekr.20160315164542.166"><vh>class StubFormatter</vh>
<v t="ekr.20160315164542.167"><vh>__init__</vh></v>
<v t="ekr.20160315164543.1"><vh>matched_d = {}</vh></v>
<v t="ekr.20160315164543.2"><vh>match_all</vh></v>
<v t="ekr.20160315164543.3"><vh>visit</vh></v>
<v t="ekr.20160315164543.4"><vh>trace_visitor</vh></v>
<v t="ekr.20160315164543.5"><vh># StubFormatter visitors for operands...</vh></v>
<v t="ekr.20160315164543.6"><vh>do_Attribute</vh></v>
<v t="ekr.20160315164543.7"><vh># Return generic markers to allow better pattern matches.</vh></v>
<v t="ekr.20160315164543.8"><vh>do_Bytes</vh></v>
<v t="ekr.20160315164543.9"><vh>do_Num</vh></v>
<v t="ekr.20160315164543.10"><vh>do_Str</vh></v>
<v t="ekr.20160315164543.11"><vh>do_Dict</vh></v>
<v t="ekr.20160315164543.12"><vh>do_List</vh></v>
<v t="ekr.20160315164543.13"><vh>seen_names = []</vh></v>
<v t="ekr.20160315164543.14"><vh>do_Name</vh></v>
<v t="ekr.20160315164543.15"><vh>do_Tuple</vh></v>
<v t="ekr.20160315164543.16"><vh># StubFormatter visitors for operators...</vh></v>
<v t="ekr.20160315164543.17"><vh>do_BinOp</vh></v>
<v t="ekr.20160315164543.18"><vh># BoolOp(boolop op, expr* values)</vh></v>
<v t="ekr.20160315164543.19"><vh>do_BoolOp</vh></v>
<v t="ekr.20160315164543.20"><vh># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)</vh></v>
<v t="ekr.20160315164543.21"><vh>do_Call</vh></v>
<v t="ekr.20160315164543.22"><vh># keyword = (identifier arg, expr value)</vh></v>
<v t="ekr.20160315164543.23"><vh>do_keyword</vh></v>
<v t="ekr.20160315164543.24"><vh># Compare(expr left, cmpop* ops, expr* comparators)</vh></v>
<v t="ekr.20160315164543.25"><vh>do_Compare</vh></v>
<v t="ekr.20160315164543.26"><vh># If(expr test, stmt* body, stmt* orelse)</vh></v>
<v t="ekr.20160315164543.27"><vh>do_IfExp</vh></v>
<v t="ekr.20160315164543.28"><vh># Subscript(expr value, slice slice, expr_context ctx)</vh></v>
<v t="ekr.20160315164543.29"><vh>do_Subscript</vh></v>
<v t="ekr.20160315164543.30"><vh># UnaryOp(unaryop op, expr operand)</vh></v>
<v t="ekr.20160315164543.31"><vh>do_UnaryOp</vh></v>
<v t="ekr.20160315164543.32"><vh>do_Return</vh></v>
</v>
<v t="ekr.20160315164543.33"><vh>class StubTraverser</vh>
<v t="ekr.20160315164543.34"><vh>__init__</vh></v>
<v t="ekr.20160315164543.35"><vh>add_stub</vh></v>
<v t="ekr.20160315164543.36"><vh>indent</vh></v>
<v t="ekr.20160315164543.37"><vh>out</vh></v>
<v t="ekr.20160315164543.38"><vh>run</vh></v>
<v t="ekr.20160315164543.39"><vh>output_stubs</vh></v>
<v t="ekr.20160315164543.40"><vh>output_time_stamp</vh></v>
<v t="ekr.20160315164543.41"><vh>update</vh></v>
<v t="ekr.20160315164543.42"><vh>get_stub_file</vh></v>
<v t="ekr.20160315164543.43"><vh>parse_stub_file</vh></v>
<v t="ekr.20160315164543.44"><vh>merge_stubs</vh></v>
<v t="ekr.20160315164543.45"><vh>check_delete</vh></v>
<v t="ekr.20160315164543.46"><vh>flatten_stubs</vh></v>
<v t="ekr.20160315164543.47"><vh>flatten_stubs_helper</vh></v>
<v t="ekr.20160315164543.48"><vh>find_parent_stub</vh></v>
<v t="ekr.20160315164543.49"><vh>find_stub</vh></v>
<v t="ekr.20160315164543.50"><vh>sort_stubs_by_hierarchy</vh></v>
<v t="ekr.20160315164543.51"><vh>trace_stubs</vh></v>
<v t="ekr.20160315164543.52"><vh># ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)</vh></v>
<v t="ekr.20160315164543.53"><vh>visit_ClassDef</vh></v>
<v t="ekr.20160315164543.54"><vh># FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)</vh></v>
<v t="ekr.20160315164543.55"><vh>visit_FunctionDef</vh></v>
<v t="ekr.20160315164543.56"><vh># arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)</vh></v>
<v t="ekr.20160315164543.57"><vh>format_arguments</vh></v>
<v t="ekr.20160315164543.58"><vh>munge_arg</vh></v>
<v t="ekr.20160315164543.59"><vh>format_returns</vh></v>
<v t="ekr.20160315164543.60"><vh>format_return_expressions</vh></v>
<v t="ekr.20160315164543.61"><vh>get_def_name</vh></v>
<v t="ekr.20160315164543.62"><vh>remove_recursive_calls</vh></v>
<v t="ekr.20160315164543.63"><vh>visit_Return</vh></v>
</v>
<v t="ekr.20160315164543.64"><vh>class TestClass</vh>
<v t="ekr.20160315164543.65"><vh># pylint: disable=no-member</vh></v>
<v t="ekr.20160315164543.66"><vh>parse_group</vh></v>
<v t="ekr.20160315164543.67"><vh>return_all</vh></v>
<v t="ekr.20160315164543.68"><vh>return_array</vh></v>
<v t="ekr.20160315164543.69"><vh>return_list</vh></v>
<v t="ekr.20160315164543.70"><vh>return_two_lists</vh></v>
</v>
</v>
<v t="ekr.20160316091132.1"><vh>@clean ../external/py2cs.py</vh>
<v t="ekr.20160316091132.2"><vh>  &lt;&lt; license &gt;&gt; (python_to_coffeescript.py)</vh></v>
<v t="ekr.20160316091132.3"><vh>  &lt;&lt; imports &gt;&gt; (python_to_coffeescript.py)</vh></v>
<v t="ekr.20160316091132.4"><vh>  main</vh></v>
<v t="ekr.20160316091132.5"><vh>  utility functions</vh>
<v t="ekr.20160316091132.6"><vh>dump</vh></v>
<v t="ekr.20160316091132.7"><vh>dump_dict</vh></v>
<v t="ekr.20160316091132.8"><vh>dump_list</vh></v>
<v t="ekr.20160316091132.9"><vh>op_name</vh></v>
<v t="ekr.20160316091132.10"><vh>pdb</vh></v>
<v t="ekr.20160316091132.11"><vh>truncate</vh></v>
</v>
<v t="ekr.20160316091132.12"><vh>class CoffeeScriptTraverser</vh>
<v t="ekr.20160316091132.13"><vh> cv.ctor</vh></v>
<v t="ekr.20160316091132.14"><vh> cv.format</vh></v>
<v t="ekr.20160316091132.15"><vh> cv.indent</vh></v>
<v t="ekr.20160316091132.16"><vh> cv.visit</vh></v>
<v t="ekr.20160316091132.17"><vh>cv.Contexts</vh>
<v t="ekr.20160316091132.18"><vh>cv.ClassDef</vh></v>
<v t="ekr.20160316091132.19"><vh>cv.FunctionDef</vh></v>
<v t="ekr.20160316091132.20"><vh>cv.Interactive</vh></v>
<v t="ekr.20160316091132.21"><vh>cv.Module</vh></v>
<v t="ekr.20160316091132.22"><vh>cv.Lambda</vh></v>
</v>
<v t="ekr.20160316091132.23"><vh>cv.Expressions</vh>
<v t="ekr.20160316091132.24"><vh>cv.Expression</vh></v>
<v t="ekr.20160316091132.25"><vh>cv.GeneratorExp</vh></v>
</v>
<v t="ekr.20160316091132.26"><vh>cv.Operands</vh>
<v t="ekr.20160316091132.27"><vh>cv.arguments</vh></v>
<v t="ekr.20160316091132.28"><vh>cv.arg (Python3 only)</vh></v>
<v t="ekr.20160316091132.29"><vh>cv.Attribute</vh></v>
<v t="ekr.20160316091132.30"><vh>cv.Bytes</vh></v>
<v t="ekr.20160316091132.31"><vh>cv.Call &amp; cv.keyword</vh>
<v t="ekr.20160316091132.32"><vh>cv.keyword</vh></v>
</v>
<v t="ekr.20160316091132.33"><vh>cv.comprehension</vh></v>
<v t="ekr.20160316091132.34"><vh>cv.Dict</vh></v>
<v t="ekr.20160316091132.35"><vh>cv.Ellipsis</vh></v>
<v t="ekr.20160316091132.36"><vh>cv.ExtSlice</vh></v>
<v t="ekr.20160316091132.37"><vh>cv.Index</vh></v>
<v t="ekr.20160316091132.38"><vh>cv.List</vh></v>
<v t="ekr.20160316091132.39"><vh>cv.ListComp</vh></v>
<v t="ekr.20160316091132.40"><vh>cv.Name &amp; cv.NameConstant</vh></v>
<v t="ekr.20160316091132.41"><vh>cv.Num</vh></v>
<v t="ekr.20160316091132.42"><vh>cv.Repr</vh></v>
<v t="ekr.20160316091132.43"><vh>cv.Slice</vh></v>
<v t="ekr.20160316091132.44"><vh>cv.Str</vh></v>
<v t="ekr.20160316091132.45"><vh>cv.Subscript</vh></v>
<v t="ekr.20160316091132.46"><vh>cv.Tuple</vh></v>
</v>
<v t="ekr.20160316091132.47"><vh>cv.Operators</vh>
<v t="ekr.20160316091132.48"><vh>cv.BinOp</vh></v>
<v t="ekr.20160316091132.49"><vh>cv.BoolOp</vh></v>
<v t="ekr.20160316091132.50"><vh>cv.Compare</vh></v>
<v t="ekr.20160316091132.51"><vh>cv.ifExp (ternary operator)</vh></v>
<v t="ekr.20160316091132.52"><vh>cv.UnaryOp</vh></v>
</v>
<v t="ekr.20160316091132.53"><vh>cv.Statements</vh>
<v t="ekr.20160316091132.54"><vh> cv.tail_after_body</vh></v>
<v t="ekr.20160316091132.55"><vh>cv.Assert</vh></v>
<v t="ekr.20160316091132.56"><vh>cv.Assign</vh></v>
<v t="ekr.20160316091132.57"><vh>cv.AugAssign</vh></v>
<v t="ekr.20160316091132.58"><vh>cv.Break</vh></v>
<v t="ekr.20160316091132.59"><vh>cv.Continue</vh></v>
<v t="ekr.20160316091132.60"><vh>cv.Delete</vh></v>
<v t="ekr.20160316091132.61"><vh>cv.ExceptHandler</vh></v>
<v t="ekr.20160316091132.62"><vh>cv.Exec</vh></v>
<v t="ekr.20160316091132.63"><vh>cv.Expr (outer statement)</vh></v>
<v t="ekr.20160316091132.64"><vh>cv.For</vh></v>
<v t="ekr.20160316091132.65"><vh>cv.Global</vh></v>
<v t="ekr.20160316091132.66"><vh>cv.If</vh></v>
<v t="ekr.20160316091132.67"><vh>cv.Import &amp; helper</vh>
<v t="ekr.20160316091132.68"><vh>cv.get_import_names</vh></v>
</v>
<v t="ekr.20160316091132.69"><vh>cv.ImportFrom</vh></v>
<v t="ekr.20160316091132.70"><vh>cv.Pass</vh></v>
<v t="ekr.20160316091132.71"><vh>cv.Print</vh></v>
<v t="ekr.20160316091132.72"><vh>cv.Raise</vh></v>
<v t="ekr.20160316091132.73"><vh>cv.Return</vh></v>
<v t="ekr.20160316091132.74"><vh>cv.Try</vh></v>
<v t="ekr.20160316091132.75"><vh>cv.TryExcept</vh></v>
<v t="ekr.20160316091132.76"><vh>cv.TryFinally</vh></v>
<v t="ekr.20160316091132.77"><vh>cv.While</vh></v>
<v t="ekr.20160316091132.78"><vh>cv.With</vh></v>
<v t="ekr.20160316091132.79"><vh>cv.Yield</vh></v>
</v>
</v>
<v t="ekr.20160316091132.80"><vh>class LeoGlobals</vh>
<v t="ekr.20160316091132.81"><vh>class NullObject (Python Cookbook)</vh></v>
<v t="ekr.20160316091132.82"><vh>class ReadLinesClass</vh></v>
<v t="ekr.20160316091132.83"><vh>g._callerName</vh></v>
<v t="ekr.20160316091132.84"><vh>g.callers</vh></v>
<v t="ekr.20160316091132.85"><vh>g.cls</vh></v>
<v t="ekr.20160316091132.86"><vh>g.computeLeadingWhitespace</vh></v>
<v t="ekr.20160316091132.87"><vh>g.computeLeadingWhitespaceWidth</vh></v>
<v t="ekr.20160316091132.88"><vh>g.isString &amp; isUnicode</vh></v>
<v t="ekr.20160316091132.89"><vh>g.pdb</vh></v>
<v t="ekr.20160316091132.90"><vh>g.shortFileName</vh></v>
<v t="ekr.20160316091132.91"><vh>g.splitLines</vh></v>
<v t="ekr.20160316091132.92"><vh>g.toUnicode</vh></v>
<v t="ekr.20160316091132.93"><vh>g.trace</vh></v>
<v t="ekr.20160316091132.94"><vh>g.u &amp; g.ue</vh></v>
</v>
<v t="ekr.20160316091132.95"><vh>class MakeCoffeeScriptController</vh>
<v t="ekr.20160316091132.96"><vh>mcs.ctor</vh></v>
<v t="ekr.20160316091132.97"><vh>mcs.finalize</vh></v>
<v t="ekr.20160316091132.98"><vh>mcs.make_coffeescript_file</vh></v>
<v t="ekr.20160316091132.99"><vh>mcs.output_time_stamp</vh></v>
<v t="ekr.20160316091132.100"><vh>mcs.run</vh></v>
<v t="ekr.20160316091132.101"><vh>mcs.run_all_unit_tests</vh></v>
<v t="ekr.20160316091132.102"><vh>mcs.scan_command_line</vh></v>
<v t="ekr.20160316091132.103"><vh>mcs.scan_options &amp; helpers</vh>
<v t="ekr.20160316091132.104"><vh>mcs.create_parser</vh></v>
<v t="ekr.20160316091132.105"><vh>mcs.get_config_string</vh></v>
<v t="ekr.20160316091132.106"><vh>mcs.init_parser</vh></v>
<v t="ekr.20160316091132.107"><vh>mcs.is_section_name</vh></v>
</v>
</v>
<v t="ekr.20160316091132.108"><vh>class ParseState</vh></v>
<v t="ekr.20160316091132.109"><vh>class TokenSync</vh>
<v t="ekr.20160316091132.110"><vh> ts.ctor &amp; helpers</vh>
<v t="ekr.20160316091132.111"><vh>ts.make_blank_lines</vh></v>
<v t="ekr.20160316091132.112"><vh>ts.make_ignored_lines</vh></v>
<v t="ekr.20160316091132.113"><vh>ts.make_line_tokens (trace tokens)</vh></v>
<v t="ekr.20160316091132.114"><vh>ts.make_nl_token</vh></v>
<v t="ekr.20160316091132.115"><vh>ts.make_string_tokens</vh></v>
</v>
<v t="ekr.20160316091132.116"><vh>ts.check_strings</vh></v>
<v t="ekr.20160316091132.117"><vh>ts.dump_token</vh></v>
<v t="ekr.20160316091132.118"><vh>ts.is_line_comment</vh></v>
<v t="ekr.20160316091132.119"><vh>ts.join</vh></v>
<v t="ekr.20160316091132.120"><vh>ts.last_node</vh></v>
<v t="ekr.20160316091132.121"><vh>ts.leading_lines</vh></v>
<v t="ekr.20160316091132.122"><vh>ts.leading_string</vh></v>
<v t="ekr.20160316091132.123"><vh>ts.line_at</vh></v>
<v t="ekr.20160316091132.124"><vh>ts.sync_string</vh></v>
<v t="ekr.20160316091132.125"><vh>ts.token_kind/raw_val/val</vh></v>
<v t="ekr.20160316091132.126"><vh>ts.tokens_for_statement</vh></v>
<v t="ekr.20160316091132.127"><vh>ts.trailing_comment</vh></v>
<v t="ekr.20160316091132.128"><vh>ts.trailing_comment_at_lineno</vh></v>
<v t="ekr.20160316091132.129"><vh>ts.trailing_lines</vh></v>
</v>
</v>
<v t="ekr.20160316091152.1"><vh>@clean ../external/py2cs_theory.md</vh>
<v t="ekr.20160316091152.2"><vh>The problem</vh></v>
<v t="ekr.20160316091152.3"><vh>The design</vh></v>
<v t="ekr.20160316091152.4"><vh>Using TokenSync class</vh></v>
<v t="ekr.20160316091152.5"><vh>Summary</vh></v>
</v>
<v t="ekr.20110310091639.14254"><vh>@file ../external/codewise.py</vh></v>
<v t="ekr.20130805134749.12436"><vh>@file ../external/edb.py</vh></v>
<v t="ekr.20120519121124.9919"><vh>@file ../external/leosax.py</vh></v>
<v t="ville.20091010232339.6117"><vh>@file ../external/lproto.py</vh></v>
<v t="ekr.20031218072017.2605"><vh>@file runLeo.py</vh></v>
<v t="ekr.20150304130753.4"><vh>leo-viewer/leo_to_html.xsl</vh></v>
</v>
<v t="ekr.20080730161153.8"><vh>Testing</vh>
<v t="ekr.20100221142603.5638"><vh>@file ../../pylint-leo.py</vh></v>
<v t="ekr.20080730161153.2"><vh>@file leoBridgeTest.py</vh></v>
<v t="ekr.20080730161153.5"><vh>@file leoDynamicTest.py</vh></v>
<v t="ekr.20051104075904" descendentVnodeUnknownAttributes="7d710058010000003071017d71025808000000616e6e6f746174657103285808000000616e6e6f7461746571047d710574710673732e"><vh>@file leoTest.py</vh></v>
</v>
<v t="ekr.20090802181029.5988"><vh>Version</vh>
<v t="ekr.20090717092906.12765"><vh>@file leoVersion.py</vh></v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="EKR.20040430162943"></t>
<t tx="EKR.20040519090151.2"></t>
<t tx="ekr.20031218072017.2406" _bklnk="7d710028580400000074797065710158080000006e6f646552656374710258050000006c696e6b7371035d710458010000007871054b0058010000007971064b00752e"># This file contains almost all of Leo's sources.
# See the "About this file" node for important notes.
@language python
</t>
<t tx="ekr.20031218072017.2604"></t>
<t tx="ekr.20031218072017.3625">&lt;&lt; about gui classes and gui plugins &gt;&gt;
</t>
<t tx="ekr.20050721093241">@nobeautify
@nocolor

The following are notes for anyone who is interested in writing
alternate gui's for Leo.

Rule 1: Leo's core is (or should be) free of gui-specific code.

Core code calls 'gui wrapper methods' defined by gui-specific classes.
The base classes for these gui-specific classes are in the node
Code--&gt;Gui Base classes.

Rule 2: Gui-specific code should be localized.

The @file nodes contained in the node 'Code--&gt;Gui Tkinter classes' in
leoPy.leo contain all of Leo's Tkinter-specific code. Gui plugins
would typically put all similar code in a single file.

Rule 3: Gui-specific code can call gui methods directly.

There are no restrictions about the code in the gui-specific classes.

Rule 4: Gui-specific classes must implement the 'gui wrapper methods'
specified in the gui base classes.

This is the way that gui-specific classes provide gui-specific
services to Leo's core.

The alternative would be to implement all gui-specific commands
directly in the gui-specific code.  But this would be much more work
than needed.  For example, only a few gui-specific wrappers are needed
to implement all commands that deal with body text.  Implementing each
of these commands 'from scratch' would duplicate a lot of code
unnecessarily.

Using the gui wrapper methods is a bit messy for two reasons:

1. It requires defining enough wrappers (both in the base gui classes
   and subclasses) so that all gui-specific services needed by Leo's
   core are available.  Adding a wrapper to a gui base class involves
   adding it to all gui-specific subclasses.  It's easy to forget to
   add a wrapper.  The gui base class defines all wrappers as a
   function that just calls oops().  This prints a warning that the
   wrapper should be defined in a subclass.

2. The original wrappers assumed Tkinter-like indices.  Wrappers that
   were defined later assume Python indices (see Rule 5 below).  The
   newer style wrappers that use Python indices have 'Python' in their
   name.  Having two sets of wrappers is one of the ugliest features
   of the present code.  I find it hard to remember which wrappers
   exist and what exactly they do :-)

Rule 5: Leo's core should use Python indices, not gui-specific
indices.

Leo's core mostly follows this rule: there may be a few exceptions.

A Python index is an int that runs from 0 (beginning of text) to
len(s) (end of text s).  That is, there are exactly len(s) + 1 valid
indices.  In contrast, Tkinter indices run from "1.0" to "x.y" where
text s has x lines and where the length of the last line is y-1.

Two (recently written) functions in leoGlobals.py support conversions
from Python indices to the row/column indices used by Tkinter.

- g.convertPythonIndexToRowCol converts a Python index to a row/column
  index used by Tkinter.

- g.convertRowColToPythonIndex does the reverse.

Important: the first Tkinter index is '1.0', not '0.0', but the row
returned by g.convertPythonIndexToRowCol is zero based, so the code
that actually creates Tkinter indices from row/col must add 1 to the
row.  Similar remarks apply when going in the reverse direction.
</t>
<t tx="ekr.20051031040240"></t>
<t tx="ekr.20080412053100.5">@language rest
</t>
<t tx="ekr.20080730161153.8"></t>
<t tx="ekr.20090802181029.5988"></t>
<t tx="ekr.20090802181029.5989"></t>
<t tx="ekr.20100120072650.6088"></t>
<t tx="ekr.20110605121601.17862"># These files are true plugins, but it is more convenient to put them here.
</t>
<t tx="ekr.20110605121601.18695">@nobeautify
</t>
<t tx="ekr.20131111060930.18010"># Standard bindings...
# run-selected-unit-tests-externally = Alt-4 
# run-marked-unit-tests-externally = Alt-5
# run-marked-unit-tests-locally = Alt-6
run-selected-unit-tests-locally = Alt-4
do-nothing = Alt-5
run-marked-unit-tests-locally = Alt-6
</t>
<t tx="ekr.20131121084830.16362">@language python

# Toggle the settings.
g.app.debug_app = not g.app.debug_app
g.app.debug_widgets = not g.app.debug_widgets
# Report the new settings.
print('g.app.debug_app: %s' % g.app.debug_app)
print('g.app.debug_widgets: %s' % g.app.debug_widgets)
</t>
<t tx="ekr.20140102162014.16438">unl: Code--&gt;Core classes--&gt;@file leoConfig.py--&gt;class LocalConfigManager--&gt;c.config.Getters--&gt;c.config.Getters--&gt;c.config.getData
unl: Code--&gt;Core classes--&gt;@file leoConfig.py--&gt;class GlobalConfigManager--&gt;gcm.Getters...--&gt;gcm.getData &amp; getOutlineData
unl: Code--&gt;Core classes--&gt;@file leoConfig.py--&gt;&lt;&lt; class ParserBaseClass &gt;&gt;--&gt;kind handlers (ParserBaseClass)--&gt;doData
@language rest
The parser for @data nodes, doData, no longer strips *anything*.</t>
<t tx="ekr.20140103105930.16446"></t>
<t tx="ekr.20140808103117.18035"></t>
<t tx="ekr.20140808103117.18036">gnx: ekr.20110605121601.18696
</t>
<t tx="ekr.20140808103117.18038">gnx: ekr.20110605121601.18698
</t>
<t tx="ekr.20140808103117.18040">gnx: ekr.20110605121601.18703
</t>
<t tx="ekr.20140808103117.18042">gnx: ekr.20110605121601.18704
</t>
<t tx="ekr.20140808103117.18044">gnx: ekr.20110605121601.18709
</t>
<t tx="ekr.20140831085423.18630">This outline contains all of Leo's core source code.

Leo's code uses the following conventions throughout:

c:  a commander.
ch: a character.
d:  a dialog or a dict.
f:  an open file.
fn: a file name.
g:  the leoGlobals module.
i, j, k: indices into a string.
p:  a Position.
s:  a string.
t:  a text widget.
u:  an undoer.
w:  a gui widget.
v:  a Vnode
z:  a local temp.

In more limited contexts, the following conventions apply:

si:     a g.ShortcutInfo object.
ks:     a g.KeyStroke object
stroke: a KeyStroke object.

btw:    leoFrame.BaseTextWrapper
stw:    leoFrame.StringTextWrapper

bqtw:   qt_text.BaseQTextWrapper
lqtb:   qt_text.LeoQTextBrowser
qhlw:   qt_text.QHeadlineWrapper
qmbw:   qt_text.QMinibufferWrapper
qlew:   qt_text.QLineEditWrapper
qsciw:  qt_text.QScintiallaWrapper
qtew:   qt_text.QTextEditWrapper</t>
<t tx="ekr.20140831085423.18631">The following 'official' ivars will always exist:

c.frame                 The frame containing the log,body,tree, etc.
c.frame.body            The body pane.
c.frame.body.widget     The gui widget for the body pane.
c.frame.body.wrapper    The high level interface for the body widget.
c.frame.iconBar         The icon bar.
c.frame.log             The log pane.
c.frame.log.widget      The gui widget for the log pane.
c.frame.log.wrapper     The high-level inteface for the log pane.
c.frame.tree            The tree pane.

The following were official ivars that no longer exist:

c.frame.body.bodyCtrl   Use c.frame.body.wrapper instead.
c.frame.log.logCtrl     Use c.frame.log.wrapper instead.
</t>
<t tx="ekr.20140831085423.18639">Here is what you *must know* to understand Leo's core:

1. A **widget** is an actual Qt widget.

Leo's core seldom accesses widgets directly.  Instead...

2. A **wrapper class** defines a standard api that hides the details
   of the underlying gui **text** widgets.

Leo's core uses this api almost exclusively. That is, Leo's core code treats wrappers *as if* they were only text widgets there are!

There is, however, a back door for (hopefully rare!) special cases. All wrapper classes define an official ``widget`` ivar, so core or plugin code can gain access to the real Qt widget using wrapper.widget. Searching for wrapper.widget will find all gui-dependent snippets of code in Leo's core.
</t>
<t tx="ekr.20140902032918.18591">@
@language rest
@wrap

Leo uses a model/view/controller architecture.

- Controller: The Commands class and its helpers in leoCommands.py and leoEditCommands.py.

- Model: The VNode and Position classes in leoNodes.py.

- View: The gui-independent base classes are in the node "Gui Base Classes". The Qt-Specific subclasses are in the node "Qt gui".

**Important**: The general organization of these classes have changed hardly at all in Leo's 20+ year history.  The reason is that what each class does is fairly obvious.  How the gets the job done may have changed drastically, but *that's an internal implementation detail of the class itself*.  This is the crucial design principle that allows Leo's code to remain stable.  *Classes do not know or meddle in the internal details of other classes*.  As a result, nobody, including EKR, needs to remember internal details.
@c
</t>
<t tx="ekr.20140902155015.18674"></t>
<t tx="ekr.20140905060158.18560">'''
A script to replace body.x with body.wrapper.x for all x in the WrapperAPI.

It is *not undoable* to save massive amounts of memory.
Please run on an already-saved .leo file, and take all other reasonable precautions.

If replace is False, it will just report the changes to be made.
'''
import leo.core.leoFrame as leoFrame
replace = False
aList = sorted([z for z in dir(leoFrame.WrapperAPI) if not z.startswith('__')])
nodes = 0
for p in c.all_unique_positions():
    s = p.b
    nodes += 1
    found = False
    for target in aList:
        i = 0
        pattern = 'body.' + target
        while True:
            i = s.find(pattern,i)
            if i == -1:
                break
            if g.match_word(s,i,pattern):
                if not found:
                    print('In node: %s' % p.h)
                    found = True
                i1,i2 = g.getLine(s,i)
                if replace:
                    j = i + len('body.')
                    s = s[:j] + 'wrapper.' + s[j:]
                    print(s[i1:i2+len('wrapper.')].rstrip())
                    i += len('wrapper.') + len(pattern)
                else:
                    print(s[i1:i2].rstrip())
                    i += len(pattern)
            else:
                i += len(pattern)
    if found and replace:
        p.b = s
print('searched %s nodes' % nodes)
</t>
<t tx="ekr.20140905060158.18561">a = c.frame.body.getInsertPoint()

aBody.getInsertPoint()

if 1:
    c.frame.body.setInsertPoint(0)</t>
<t tx="ekr.20140916101314.19538">The default language if no @language or @comment is in effect.

Valid values are (case is ignored):

actionscript,c,csharp,css,cweb,elisp,html,java,latex,
pascal,perl,perlpod,php,plain,plsql,python,rapidq,rebol,shell,tcltk.</t>
<t tx="ekr.20140918124632.19450"># This script prints the list of known Qt names. Qt seems to ignore case.
from leo.core.leoQt import QtGui
aList = sorted([g.u(z) for z in QtGui.QColor().colorNames()])
print('\n'.join(aList))
</t>
<t tx="ekr.20140919093158.17876"></t>
<t tx="ekr.20140920064112.17946"></t>
<t tx="ekr.20140923085942.17943"></t>
<t tx="ekr.20150304125314.4">@tabwidth -2
@killbeautify
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;xsl:stylesheet version="1.0"
xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;

&lt;xsl:output method="html" version="1.0" encoding="UTF-8" indent="yes"/&gt;

&lt;!-- The default setting. Not needed unless there is a strip-space element. --&gt;
  &lt;!-- &lt;xsl:preserve-space elements='leo_file nodes t'/&gt; --&gt;

&lt;xsl:template match ='leo_file'&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;!--
    &lt;link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.9.1/styles/default.min.css"&gt;
    &lt;script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.9.1/highlight.min.js"&gt;&lt;/script&gt;
    --&gt;
    &lt;&lt;style&gt;&gt;
    &lt;&lt;scripts&gt;&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;xsl:apply-templates select='tnodes'/&gt;
    &lt;div class="outlinepane"&gt;
      &lt;!-- &lt;h4&gt;Outline Pane&lt;/h4&gt; --&gt;
      &lt;xsl:apply-templates select='vnodes'/&gt;
    &lt;/div&gt;
    &lt;div class="bodypane"&gt;
      &lt;!-- &lt;h4&gt;Body Pane&lt;/h4&gt; --&gt;
      &lt;pre class="body-text"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
&lt;/xsl:template&gt;

&lt;xsl:template match = 'tnodes'&gt;
&lt;div class="tnodes"&gt;
  &lt;xsl:for-each select = 't'&gt;
    &lt;div class="tnode"&gt;
      &lt;xsl:attribute name="id"&gt;&lt;xsl:value-of select='@tx'/&gt;&lt;/xsl:attribute&gt;
      &lt;xsl:value-of select='.'/&gt;
    &lt;/div&gt;
  &lt;/xsl:for-each&gt;
&lt;/div&gt;
&lt;/xsl:template&gt;

&lt;xsl:template match = 'vnodes'&gt;
  &lt;xsl:for-each select = 'v'&gt;
    &lt;xsl:apply-templates select ='.'/&gt;
  &lt;/xsl:for-each&gt;
&lt;/xsl:template&gt;

&lt;xsl:template match='v'&gt;
  &lt;div class="node"&gt;
    &lt;xsl:attribute name="id"&gt;&lt;xsl:value-of select='@t'/&gt;&lt;/xsl:attribute&gt;
    &lt;xsl:choose&gt;
      &lt;xsl:when test ='./v' &gt;
        &lt;xsl:attribute name="has-children"&gt;1&lt;/xsl:attribute&gt;
        &lt;h1&gt;+ &lt;xsl:value-of select='vh'/&gt;&lt;/h1&gt;
        &lt;xsl:apply-templates select = 'v'/&gt;
      &lt;/xsl:when&gt;
      &lt;xsl:when test ='vh' &gt;
        &lt;h1&gt;- &lt;xsl:value-of select='vh'/&gt;&lt;/h1&gt;
      &lt;/xsl:when&gt;
      &lt;!--
      &lt;xsl:otherwise&gt;
        &lt;h1&gt;- &lt;xsl:value-of select='vh'/&gt;&lt;/h1&gt;
      &lt;/xsl:otherwise&gt;
      --&gt;
    &lt;/xsl:choose&gt;
  &lt;/div&gt;
&lt;/xsl:template&gt;

&lt;/xsl:stylesheet&gt;
</t>
<t tx="ekr.20150304130753.4">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;xsl:stylesheet version="1.0"
xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;

&lt;xsl:output method="html" version="1.0" encoding="UTF-8" indent="yes"/&gt;

&lt;!-- The default setting. Not needed unless there is a strip-space element. --&gt;
  &lt;!-- &lt;xsl:preserve-space elements='leo_file nodes t'/&gt; --&gt;

&lt;xsl:template match ='leo_file'&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;&lt;style&gt;&gt;
    &lt;&lt;scripts&gt;&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;xsl:apply-templates select='tnodes'/&gt;
    &lt;div class="outlinepane"&gt;
      &lt;xsl:apply-templates select='vnodes'/&gt;
    &lt;/div&gt;
    &lt;div class="bodypane"&gt;
      &lt;h1&gt;Body Pane&lt;/h1&gt;
      &lt;pre class="body-text"&gt;body&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
&lt;/xsl:template&gt;

&lt;xsl:template match = 'tnodes'&gt;
&lt;div class="tnodes"&gt;
  &lt;xsl:for-each select = 't'&gt;
    &lt;div class="tnode"&gt;
      &lt;xsl:attribute name="id"&gt;&lt;xsl:value-of select='@tx'/&gt;&lt;/xsl:attribute&gt;
      &lt;xsl:value-of select='.'/&gt;
    &lt;/div&gt;
  &lt;/xsl:for-each&gt;
&lt;/div&gt;
&lt;/xsl:template&gt;

&lt;xsl:template match = 'vnodes'&gt;
  &lt;xsl:for-each select = 'v'&gt;
    &lt;xsl:apply-templates select ='.'/&gt;
  &lt;/xsl:for-each&gt;
&lt;/xsl:template&gt;

&lt;xsl:template match='v'&gt;
  &lt;div class="node"&gt;
    &lt;xsl:attribute name="id"&gt;&lt;xsl:value-of select='@t'/&gt;&lt;/xsl:attribute&gt;
    &lt;h1&gt;&lt;xsl:value-of select='vh'/&gt;&lt;/h1&gt;
    &lt;xsl:if test ='./v' &gt;
      &lt;xsl:apply-templates select = 'v'/&gt;
    &lt;/xsl:if&gt;
  &lt;/div&gt;
&lt;/xsl:template&gt;

&lt;/xsl:stylesheet&gt;
</t>
<t tx="ekr.20150304130753.5">&lt;style&gt;
    /* pre { background:#FFE7C6; } */
    /* Must use h1 for nodes: see below. */
    h1 {
      font-size: 12pt;
      font-style: normal;
      font-weight: normal;
    }
    div.outlinepane {
      position: absolute;
      background: #ffffec; /* Leo yellow */
      top: 10px;
      height: 300px;
      width: 700px;
      overflow: scroll;
      line-height: 0.8;

    }
    div.bodypane {
      position: absolute;
      top: 310px;
      height: 300px;
      width: 700px;
      overflow: scroll;
    }
    div.tnode {
        visibility: hidden;
        height: 0;
    }
    div.node {
        position: relative;
        left: 20px;
    }
    div.node[has-children] &gt; h1 {
        &lt;!-- works --&gt;
        &lt;!-- background: red; --&gt;
    }
&lt;/style&gt;
</t>
<t tx="ekr.20150304130753.6">@language javascript

&lt;script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"&gt;&lt;/script&gt;
&lt;script&gt;

  $(document).ready(function(){
    if (true) {
        // Toggle all but top-level nodes.
        // This requires an indication
        $(".node").toggle()
        $(".outlinepane").children(".node").toggle()
    } else {
        // Toggle all second-level nodes.
        // Safer, until we can see which nodes have children.
        $(".outlinepane").children(".node").children(".node").toggle()
    }
    $("h1").click(function(){
      $(this).parent().children("div.node").toggle();
      // The parent div's id is v.x.
      // Find the tnode div whose id is t.x.
      console.clear();
      parent_id=$(this).parent().attr("id");
      if (parent_id) {
        target=$(this).parent().attr("id").substring(2);
          console.log("clicked:"+$(this).text())
          // console.log("parent:"+$(this).parent())
          // console.log("target:"+target)
        $(".tnode").each(function(){
          console.log($(this).attr("id"))
          target2=$(this).attr("id").substring(2);
          if (target === target2) {
            console.log("found:"+target2)
            // $("pre.body-text").text($(this).text());
            $("code").text($(this).text());
          };
        }); // end .each.
      };
    });
  });
@language html
&lt;/script&gt;
</t>
<t tx="ekr.20150326145530.1"># Hand-written Leo colorizer control file for forth mode.
# This file is in the public domain.
@killbeautify
import leo.core.leoGlobals as g
&lt;&lt; define mode rules &gt;&gt;
&lt;&lt; define mode data &gt;&gt;
&lt;&lt; define extendForth class &gt;&gt;
e = extendForth()

def pre_init_mode(c):
    # g.trace('modes/forth.py',c)
    e.c = c
    e.init()
    e.createKeywords()
    e.createBracketRules()
    e.createDefiningWordRules()
</t>
<t tx="ekr.20150326145530.10">def createKeywords(self):
    '''Create the mode keyword table and
    entries in the rulesDict for the forth_keyword_rule'''
    # global forth_main_keywords_dict
    # global forth_keyword_rule
    table = (
        (self.keywords, 'keyword1'),
      # (self.definingwords,    'keyword2'), # Done in createDefiningWordRules.
        (self.boldwords, 'keyword3'),
        (self.bolditalicwords, 'keyword4'),
        (self.italicwords, 'keyword5'),
        (self.stringwords, 'string'),
    )
    d = forth_main_keywords_dict
    for keywordList, kind in table:
        for z in keywordList:
            # Create the entry in the keyword table.
            if kind == 'string':
                func = self.createStringRule(d, z)
            else:
                func = forth_keyword_rule
            # Always make the entry.
            d[z] = kind
            self.extendRulesDict(ch=z[0], func=func)
</t>
<t tx="ekr.20150326145530.11">def createStringRule(self, d, pair):
    '''Create an entry in d for a string keyword.'''
    aList = pair.split(' ')
    if len(aList) != 2:
        g.trace('can not happen: expecting pair of forth strings:', pair)
        return
    begin, end = aList

    def forth_string_word_rule(colorer, s, i):
        return colorer.match_span(s, i, kind="literal1", begin=begin.strip(), end=end.strip(),
            at_line_start=False, at_whitespace_end=False, at_word_start=True, # Require word.
            delegate="", exclude_match=False,
            no_escape=False, no_line_break=False, no_word_break=False) # Don't require ending word.

    return forth_string_word_rule
</t>
<t tx="ekr.20150326145530.12">def extendRulesDict(self, ch, func):
    global rulesDict
    # Extend the rulesDict entry for the first character of z.
    aList = rulesDict.get(ch, [])
    if func not in aList:
        aList.append(func)
        rulesDict[ch] = aList
    # g.trace(z,kind)
</t>
<t tx="ekr.20150326145530.2"># Rules for forth_main ruleset.

def forth_block_comment_rule(colorer, s, i):
    return colorer.match_span(s, i, kind="comment2", begin="(", end=")",
        at_line_start=False, at_whitespace_end=False, at_word_start=True, # Require word.
        delegate="", exclude_match=False,
        no_escape=False, no_line_break=False, no_word_break=False)

def forth_comment_rule(colorer, s, i):
    return colorer.match_eol_span(s, i, kind="comment1", seq="\\",
        at_line_start=False, at_whitespace_end=False, at_word_start=True, # Require word
        delegate="", exclude_match=False)

def forth_keyword_rule(colorer, s, i):
    return colorer.match_keywords(s, i)

def forth_string_rule(colorer, s, i):
    return colorer.match_span(s, i, kind="literal1", begin="\"", end="\"",
        at_line_start=False, at_whitespace_end=False, at_word_start=True, # Require word
        delegate="", exclude_match=False,
        no_escape=False, no_line_break=False, no_word_break=False)
# ==========================

if 0:

    def forth_rule0(colorer, s, i):
        return colorer.match_eol_span(s, i, kind="comment1", seq="#",
            at_line_start=False, at_whitespace_end=False, at_word_start=False,
            delegate="", exclude_match=False)

    def forth_rule1(colorer, s, i):
        return colorer.match_span(s, i, kind="literal2", begin="\"\"\"", end="\"\"\"",
            at_line_start=False, at_whitespace_end=False, at_word_start=False,
            delegate="", exclude_match=False,
            no_escape=False, no_line_break=False, no_word_break=False)

    def forth_rule2(colorer, s, i):
        return colorer.match_span(s, i, kind="literal2", begin="'''", end="'''",
            at_line_start=False, at_whitespace_end=False, at_word_start=False,
            delegate="", exclude_match=False,
            no_escape=False, no_line_break=False, no_word_break=False)

    def forth_rule3(colorer, s, i):
        return colorer.match_span(s, i, kind="literal1", begin="\"", end="\"",
            at_line_start=False, at_whitespace_end=False, at_word_start=False,
            delegate="", exclude_match=False,
            no_escape=False, no_line_break=False, no_word_break=False)

    def forth_rule4(colorer, s, i):
        return colorer.match_span(s, i, kind="literal1", begin="'", end="'",
            at_line_start=False, at_whitespace_end=False, at_word_start=False,
            delegate="", exclude_match=False,
            no_escape=False, no_line_break=False, no_word_break=False)

    def forth_rule5(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="=",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule6(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="!",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule7(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="&gt;=",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule8(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="&lt;=",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule9(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="+",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule10(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="-",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule11(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="/",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule12(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="*",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule13(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="&gt;",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule14(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="&lt;",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule15(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="%",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule16(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="&amp;",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule17(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="|",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule18(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="^",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule19(colorer, s, i):
        return colorer.match_seq(s, i, kind="operator", seq="~",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, delegate="")

    def forth_rule20(colorer, s, i):
        return colorer.match_mark_previous(s, i, kind="function", pattern="(",
            at_line_start=False, at_whitespace_end=False, at_word_start=False, exclude_match=True)

    def forth_rule21(colorer, s, i):
        return colorer.match_keywords(s, i)
</t>
<t tx="ekr.20150326145530.3"># Properties for forth mode.
properties = {
	# "indentNextLines": "\\s*[^#]{3,}:\\s*(#.*)?",
    "lineComment": "\\",
}
# Attributes dict for forth_main ruleset.
forth_main_attributes_dict = {
    "default": "null",
    "digit_re": "",
	# "escape": "\\",
    "highlight_digits": "false",
    "ignore_case": "false",
    "no_word_sep": "",
}
# Dictionary of attributes dictionaries for forth mode.
attributesDictDict = {
    "forth_main": forth_main_attributes_dict,
}
# Keywords dict for forth_main ruleset.
forth_main_keywords_dict = {} # Created by extendForth class.
# Dictionary of keywords dictionaries for forth mode.
keywordsDictDict = {
    "forth_main": forth_main_keywords_dict,
}
# Rules dict for forth_main ruleset.
# This is extended by extendForth.
rulesDict = {
    '(': [forth_block_comment_rule],
    '\\': [forth_comment_rule],
    '"': [forth_string_rule],
}
# x.rulesDictDict for forth mode.
rulesDictDict = {
    "forth_main": rulesDict,
}
# Import dict for forth mode.
importDict = {}
</t>
<t tx="ekr.20150326145530.4">class extendForth:
    '''A helper class to extend the mode tables from @data forth-x settings.'''
    @others
</t>
<t tx="ekr.20150326145530.5">def __init__(self):
    self.c = None # set by pre_init_mode function.
    # g.trace('modes/forth.py:extendForth')
    # Default forth keywords: extended by @data forth-words
    # Forth words to be rendered in boldface: extended by @data forth-bold-words
    self.boldwords = []
    # Forth bold-italics words: extended by @data forth-bold-italic-words
    # Note: on some boxen, bold italics may show in plain bold.
    self.bolditalicwords = []
    # Forth words that define brackets: extended by @data forth-delimiter-pairs
    self.brackets = [] # Helper: a list of tuples.
    self.brackets1 = []
    self.brackets2 = []
    # Words which define other words: extended by forth-defwords
    self.definingwords = []
    # Forth words to be rendered in italics: extended by forth-italic-words
    self.italicwords = []
    # Default keywords: extended by @data forth-keywords
    self.keywords = []
        # "variable", "constant", "code", "end-code",
        # "dup", "2dup", "swap", "2swap", "drop", "2drop",
        # "r&gt;", "&gt;r", "2r&gt;", "2&gt;r",
        # "if", "else", "then",
        # "begin", "again", "until", "while", "repeat",
        # "v-for", "v-next", "exit",
        # "meta", "host", "target", "picasm", "macro",
        # "needs", "include",
        # "'", "[']",
        # # ":", # Now a defining word.
        # ";",
        # "@", "!", ",", "1+", "+", "-",
        # "&lt;", "&lt;=", "=", "&gt;=", "&gt;",
        # "invert", "and", "or",
    # Forth words which start strings: extended by @data forth-string-word-pairs
    self.stringwords = []
    self.stringwords1 = []
    self.stringwords2 = []
    self.verbose = False # True: tell when extending forth words.
    # g.trace('rulesDict...\n',g.dictToString(rulesDict),tag='rulesDict...')
</t>
<t tx="ekr.20150326145530.6">def init(self):
    '''Set our ivars from settings.'''
    c = self.c
    assert(c)
    table = (
        (self.definingwords, "forth-defwords"),
        (self.brackets, "forth-delimiter-pairs"),
        (self.keywords, "forth-words"),
        (self.stringwords, "forth-string-word-pairs"),
        (self.boldwords, "forth-bold-words"),
        (self.bolditalicwords, "forth-bold-italic-words"),
        (self.italicwords, "forth-italic-words"),
    )
    # Add entries from @data nodes (if they exist) to the corresponding lists.
    for(ivarList, setting) in table:
        extras = []
        aList = c.config.getData(setting)
        if aList:
            for s in aList:
                s = s.strip()
                if s and s[0] != '\\':
                    # g.trace(setting,s)
                    extras.append(s)
            if extras:
                if self.verbose:
                    if not g.app.unitTesting and not g.app.batchMode:
                        g.pr("Found extra forth: %s" % " ".join(extras))
                ivarList.extend(extras)
    # Create brackets1/2 and stringwords1/2 lists.
    table2 = (
        ("brackets", "@data forth-delimiter-pairs"),
        ("stringwords", "@data forth-string-word-pairs"),
    )
    for(ivar, setting) in table2:
        self.splitList(ivar, setting)
    # g.trace('keywords',self.keywords)
</t>
<t tx="ekr.20150326145530.7">def splitList(self, ivar, setting):
    '''Process lines containing pairs of entries
    in a list whose *name* is ivar.
    Put the results in ivars whose names are ivar1 and ivar2.'''
    result1 = []; result2 = []
    aList = getattr(self, ivar)
    # Look for pairs.  Comments have already been removed.
    for s in aList:
        pair = s.split(' ')
        if len(pair) == 2 and pair[0].strip() and pair[1].strip():
            result1.append(pair[0].strip())
            result2.append(pair[1].strip())
        else:
            g.es_print('%s: ignoring line: %s' % (setting, s))
    # Set the ivars.
    name1 = '%s1' % ivar
    name2 = '%s2' % ivar
    setattr(self, name1, result1)
    setattr(self, name2, result2)
    if 0:
        g.trace(name1, getattr(self, name1))
        g.trace(name2, getattr(self, name2))
</t>
<t tx="ekr.20150326145530.8">def createBracketRules(self):
    for z in self.brackets1:
        func = self.createBracketRule(z)
        self.extendRulesDict(ch=z[0], func=func)

def createBracketRule(self, begin):
    i = self.brackets1.index(begin)
    end = self.brackets2[i]

    def forth_bracket_rule(colorer, s, i):
        return colorer.match_span(s, i, kind="bracketRange", begin=begin, end=end,
            at_line_start=False, at_whitespace_end=False, at_word_start=True, # Require word.
            delegate="", exclude_match=False,
            no_escape=False, no_line_break=False, no_word_break=True) # Require word.

    return forth_bracket_rule
</t>
<t tx="ekr.20150326145530.9">def createDefiningWordRules(self):
    for z in self.definingwords:
        func = self.createDefiningWordRule(z)
        self.extendRulesDict(ch=z[0], func=func)

def createDefiningWordRule(self, word):

    def forth_defining_word_rule(colorer, s, i):
        pattern = ''
        return colorer.match_word_and_regexp(s, i,
            kind1="keyword2", # defining word
            word=word,
            kind2="keyword3", # bold
            pattern=r'(\s)*(\S)+',
            at_line_start=False, at_whitespace_end=False, at_word_start=False,
            exclude_match=False)

    return forth_defining_word_rule
</t>
<t tx="ekr.20150413091056.1">'''Warn if leoProjects.txt or leoToDo.txt contain any clones.'''

clones,nodes,seen = 0,0,set()
table = (
  '@file ../doc/leoProjects.txt',
  '@file ../doc/leoToDo.txt',
)

def check_clone(c,p0,root):
    '''Warn if p appears in any @&lt;file&gt; node outside of root's tree.'''
    global nodes,seen
    v = p0.v
    for p in c.all_positions():
        nodes += 1
        if p.v == v:
            # Check *all* ancestors, not just the nearest one.
            for parent in p.self_and_parents():
                nodes += 1
                if parent.isAnyAtFileNode() and parent.v != root.v:
                    if parent.v not in seen:
                        seen.add(parent.v)
                        g.es_print('%s and %s contain clone: %s' % (
                            root.h,parent.h,p0.h))

for h in table:
    root = g.findNodeAnywhere(c,h)
    if root:
        for p in root.self_and_subtree():
            nodes += 1
            if p.isCloned():
                clones += 1
                check_clone(c,p,root)
    else:
        g.es_print('not found',h,color='red')
print('done: %s nodes, %s clones' % (nodes,clones))

@tabwidth -4
@language python
</t>
<t tx="ekr.20150425145248.1">run-pylint
clone-to-at-spot
beautify-tree
cfa-code
sort-lines
# show-data
# test-ptb
check-clones
expand-log-pane
contract-log-pane</t>
<t tx="ekr.20150502050609.1">@language python
'''Save a copy of this file to the Backup directory.'''
theDir,base = g.os_path_split(c.fileName())
path = g.os_path_join('~/Dropbox/','backups','leoPy',base)
c.backup(path)
</t>
<t tx="ekr.20150507170849.1">g.cls()

print('===== Start =====')

class CreateDecorators:
    '''
    A class to create decorators from tables in getPublicCommands.
    
    Note: the node "Found: getPublicCommands" must exist.
    '''
    def __init__(self,c,make_changes):
        self.c = c
        self.fixups = self.create_fixups()
        self.n = 0
        self.n_fail = 0
        self.make_changes=make_changes
        self.suppress = [
            'c.frame.body and c.frame.body.addEditor',
            'cls','cloneFindParents','cycleTabFocus',
            'k and k.keyboardQuit',
            'menuShortcutPlaceHolder','removeBlankLines',
            'saveBuffersKillLeo',
        ]
    @others

CreateDecorators(c,make_changes=False).run()
</t>
<t tx="ekr.20150507174711.1">def find_next_clone(self,p):
    v = p.v
    p = p.copy()
    p.moveToThreadNext()
    wrapped = False
    while 1:
        # g.trace(p.v,p.h)
        if p and p.v == v:
            break
        elif p:
            p.moveToThreadNext()
        elif wrapped:
            break
        else:
            wrapped = True
            p = c.rootPosition()
    return p
</t>
<t tx="ekr.20150507175246.1">def munge_lines(self,root,publicCommands):
    '''Return munged lines of '''
    # print('')
    # g.trace(root.h)
    s = publicCommands.b
    i,j = s.find('{'),s.find('}')
    s = s[i+1:j]
    # print(s)
    lines = sorted([z.strip() for z in g.splitLines(s) if z.strip()])
    lines = [z for z in lines if not z.startswith('#')]
    lines = [z[:z.find('#')] if z.find('#') &gt; -1 else z for z in lines]
    lines = [z.rstrip().rstrip(',') for z in lines]
    lines = [z[1:] for z in lines]
    lines = [z.replace("':",' ') for z in lines]
    # print('\n'.join(lines))
    self.n += len(lines)
    return lines
</t>
<t tx="ekr.20150508062944.1">def run(self):
    '''Top-level code.'''
    self.n = 0
    found = g.findNodeAnywhere(c,'Found: getPublicCommands')
    assert found
    for child in found.children():
        publicCommands = self.find_next_clone(child)
        root = self.find_class(publicCommands)
        if root:
            lines = self.munge_lines(root,publicCommands)
            d = self.create_d(lines,publicCommands)
            self.create_decorators(d,root)
    print('\n%s commands %s failed' % (self.n,self.n_fail))
</t>
<t tx="ekr.20150508063412.1">def create_decorators(self,d,root):
    '''Create decorators for all items in d in root's tree.'''
    # print('***** %s' % root.h)
    if root.h in self.fixups:
        roots = []
        aList = self.fixups.get(root.h)
        for root2_h in aList:
            root2 = g.findNodeAnywhere(self.c,root2_h)
            if root2:
                # g.trace(root.h,'=====&gt;',root2.h)
                roots.append(root2)
            else:
                g.trace('===== not found',root2_h)
    else:
        roots = [root]
    for f_name in sorted(d.keys()):
        found = False
        for root in roots:
            c_name = d.get(f_name)
            found = self.create_decorator(c_name,f_name,root)
            if found: break
        if not found and f_name not in self.suppress:
            print('===== not found: %30s %s' % (root.h,f_name))
            self.n_fail += 1
</t>
<t tx="ekr.20150508063538.1">def create_d(self,lines,publicCommands):
    '''Create a dict. keys are method names; values are command names.'''
    trace = False
    if trace:
        print('')
        g.trace(publicCommands.h)
    d = {}
    for s in lines:
        aList = s.split()
        if len(aList) &gt; 2:
            aList = [aList[0],' '.join(aList[1:])]
        c_name,f_name = aList[0].strip(),aList[1].strip()
        if ' ' not in f_name:
            f_name = f_name.split('.')[-1]
        # if '(' in f_name:
            # f_name = f_name[:f_name.find('(')]
        if trace: g.trace('%45s %s' % (c_name,f_name))
        d [f_name] = c_name
    return d
</t>
<t tx="ekr.20150508063926.1">def find_class(self,p):
    '''Return the position of the class enclosing p.'''
    for p2 in p.parents():
        if p2.h.lower().find('class') &gt; -1 and p2.b.find('class') &gt; -1:
            return p2
    else:
        g.trace('*** no class for p.h')
        return None
</t>
<t tx="ekr.20150508071622.1">def create_decorator(self,c_name,f_name,root):
    '''
    Search root for a definition of f_name.
    If found, insert @cmd(f_name) before the definition.
    '''
    # g.trace('%45s %s' % (c_name,f_name))
    trace = False
    found = False
    decorator = "@cmd('%s')\n" % (c_name)
    for p in root.self_and_subtree():
        changed,result = False,[]
        for s in g.splitLines(p.b):
            if g.match_word(s,0,'def ' + f_name):
                if found:
                    if f_name not in self.suppress:
                        g.trace('duplicate def',f_name)
                else:
                    changed,found = True,True
                    result.append(decorator)
                    # print('%s%s' % (decorator,s))
            result.append(s)
        # if changed and self.make_changes:
            # new_body = ''.join(result)
            # # use git as our undo :-)
            # p.b = new_body
    return found
</t>
<t tx="ekr.20150508074623.1">def create_fixups(self):
    '''
    Return a fixup dict.
    Keys are headlines for classes.
    Values are new headlines of nodes containing the actual class.
    '''
    return {
        'ChapterCommandsClass': ['class ChapterController'],
        'EditCommandsClass': [
            'EditCommandsClass',
            'class Commands',
            'class LeoQtFrame',
            'class LeoBody',
        ],
        'class SearchCommandsClass': ['class LeoFind (LeoFind.py)'],
        'KeyHandlerCommandsClass (add docstrings)': [
            'class KeyHandlerClass',
            'class AutoCompleterClass',
        ]
    }
</t>
<t tx="ekr.20150509183433.1">g.cls()

# Changed files:
# leoApp.py
# leoAtFile.py
# leoCommands.py
# leoFileCommands.py
# leoFrame.py
# leoUndo.py
# qt_frame.py

make_changes = True
    # True, actually make the change

class CreateDecorators:
    '''
    A class to create decorators from tables in getPublicCommands.
    
    Note: the node "Found: getPublicCommands" must exist.
    '''
    def __init__(self):
        self.n = 0
        self.n_fail = 0
        self.s = self.define_s()
    @others

CreateDecorators().run()
</t>
<t tx="ekr.20150509183433.2">def create_d(self,lines):
    '''Create a dict. keys are method names; values are command names.'''
    trace = False
    d = {}
    for s in lines:
        aList = s.split()
        if len(aList) &gt; 2:
            aList = [aList[0],' '.join(aList[1:])]
        c_name,f_name = aList[0].strip(),aList[1].strip()
        if ' ' not in f_name:
            f_name = f_name.split('.')[-1]
        # if '(' in f_name:
            # f_name = f_name[:f_name.find('(')]
        if trace: g.trace('%45s %s' % (c_name,f_name))
        d [f_name] = c_name
    return d
</t>
<t tx="ekr.20150509183433.3">def create_decorator(self,c_name,f_name,root):
    '''
    Search root for a definition of f_name.
    If found, insert @cmd(f_name) before the definition.
    '''
    trace = True
    found = False
    decorator = "@cmd('%s')\n" % (c_name)
    for p in root.self_and_subtree():
        changed,result = False,[]
        for s in g.splitLines(p.b):
            if g.match_word(s,0,'def ' + f_name):
                if found:
                    if f_name not in self.suppress:
                        g.trace('duplicate def',f_name)
                else:
                    changed,found = True,True
                    result.append(decorator)
                    # print('%s%s' % (decorator,s))
            result.append(s)
        if changed and make_changes:
            new_body = ''.join(result)
            print('%40s %s' % (p.h[:40],decorator.rstrip()))
            # use git as our undo :-)
            # p.b = new_body
    return found
</t>
<t tx="ekr.20150509183433.4">def create_decorators(self,d):
    '''Create decorators for all items in d in root's tree.'''
    table = (
        'class Commands', # c.
        'class LeoQtFrame', # f.
        'class LeoFrame', # f.
        'class LeoApp', # g.app.
        '@file leoAtFile.py', # c.atFileCommands
        '@file leoFileCommands.py', # c.fileCommands
        'class Undoer', # c.undoer
    )
    roots = []
    for h in table:
        root = g.findNodeAnywhere(c,h)
        assert root,h
        roots.append(root)
    for f_name in sorted(d.keys()):
        found = False
        for root in roots:
            c_name = d.get(f_name)
            found = self.create_decorator(c_name,f_name,root)
            if found: break
        if not found and f_name not in self.suppress:
            print('===== not found: %s' % (f_name))
            self.n_fail += 1
</t>
<t tx="ekr.20150509183433.8">def munge_lines(self,s):
    '''Return munged lines of s. '''
    lines = sorted([z.strip() for z in g.splitLines(s) if z.strip()])
    lines = [z for z in lines if not z.startswith('#')]
    lines = [z[:z.find('#')] if z.find('#') &gt; -1 else z for z in lines]
    lines = [z.rstrip().rstrip(',') for z in lines]
    lines = [z[1:] for z in lines]
    lines = [z.replace("':",' ') for z in lines]
    self.n += len(lines)
    return lines
</t>
<t tx="ekr.20150509183433.9">def run(self):
    '''Top-level code.'''
    lines = self.munge_lines(self.s)
    d = self.create_d(lines)
    self.create_decorators(d)
    print('%s commands %s failed' % (self.n,self.n_fail))
</t>
<t tx="ekr.20150509183832.1"># 'check-all-python-code':      c.checkAllPythonCode,
# 'check-python-code':          c.checkPythonCode,
# 'extract-python-method':        c.extractPythonMethod,
# 'extract-section':              c.extractSection,
# 'import-at-file':               c.importAtFile,
# 'import-at-root':               c.importAtRoot,
# 'import-cweb-files':            c.importCWEBFiles,
# 'import-derived-file':          c.importDerivedFile,
# 'import-flattened-outline':     c.importFlattenedOutline,
# 'import-noweb-files':           c.importNowebFiles,
# 'mark-changed-roots':           c.markChangedRoots,
# 'mark-clones':                c.markClones,
# 'open-compare-window':        c.openCompareWindow,
# 'open-online-tutorial':       c.leoTutorial,
# 'reformat-body':              c.reformatBody, # 2013/10/02.
def define_s(self):
    return '''
'abort-edit-headline':          f.abortEditLabelCommand,
'about-leo':                    c.about,
'add-comments':                 c.addComments,     
'beautify':                     c.beautifyPythonCode,
'beautify-all':                 c.beautifyAllPythonCode,
'beautify-c':                   c.beautifyCCode,
'beautify-tree':                c.beautifyPythonTree,
'cascade-windows':              f.cascade,
'check-derived-file':           c.atFileCommands.checkDerivedFile,
'check-leo-file':               c.fileCommands.checkLeoFile,
'check-outline':                c.fullCheckOutline,
'clean-recent-files':           c.cleanRecentFiles,
'clear-recent-files':           c.clearRecentFiles,
'clone-node':                   c.clone,
'clone-node-to-last-node':      c.cloneToLastNode,
'close-window':                 c.close,
'contract-all':                 c.contractAllHeadlines,
'contract-all-other-nodes':     c.contractAllOtherNodes,
'contract-node':                c.contractNode,
'contract-or-go-left':          c.contractNodeOrGoToParent,
'contract-parent':              c.contractParent,
'convert-all-blanks':           c.convertAllBlanks,
'convert-all-tabs':             c.convertAllTabs,
'convert-blanks':               c.convertBlanks,
'convert-tabs':                 c.convertTabs,
'copy-node':                    c.copyOutline,
'copy-text':                    f.copyText,
'cut-node':                     c.cutOutline,
'cut-text':                     f.cutText,
'de-hoist':                     c.dehoist,
'delete-comments':              c.deleteComments,
'delete-node':                  c.deleteOutline,
'demote':                       c.demote,
'dump-outline':                 c.dumpOutline,
'edit-headline':                c.editHeadline,
'end-edit-headline':            f.endEditLabelCommand,
'equal-sized-panes':            f.equalSizedPanes,
'execute-script':               c.executeScript,
'exit-leo':                     g.app.onQuit,
'expand-all':                   c.expandAllHeadlines,
'expand-all-subheads':          c.expandAllSubheads,
'expand-ancestors-only':        c.expandOnlyAncestorsOfNode,
'expand-and-go-right':          c.expandNodeAndGoToFirstChild,
'expand-next-level':            c.expandNextLevel,
'expand-node':                  c.expandNode,
'expand-or-go-right':           c.expandNodeOrGoToFirstChild,
'expand-prev-level':            c.expandPrevLevel,
'expand-to-level-1':            c.expandLevel1,
'expand-to-level-2':            c.expandLevel2,
'expand-to-level-3':            c.expandLevel3,
'expand-to-level-4':            c.expandLevel4,
'expand-to-level-5':            c.expandLevel5,
'expand-to-level-6':            c.expandLevel6,
'expand-to-level-7':            c.expandLevel7,
'expand-to-level-8':            c.expandLevel8,
'expand-to-level-9':            c.expandLevel9,
'export-headlines':             c.exportHeadlines,
'extract':                      c.extract,
'extract-names':                c.extractSectionNames,
'find-next-clone':              c.findNextClone,
'flatten-outline':              c.flattenOutline,
'flatten-outline-to-node':      c.flattenOutlineToNode,
'go-back':                      c.goPrevVisitedNode,
'go-forward':                   c.goNextVisitedNode,
'goto-first-node':              c.goToFirstNode,
'goto-first-sibling':           c.goToFirstSibling,
'goto-first-visible-node':      c.goToFirstVisibleNode,
'goto-last-node':               c.goToLastNode,
'goto-last-sibling':            c.goToLastSibling,
'goto-last-visible-node':       c.goToLastVisibleNode,
'goto-next-changed':            c.goToNextDirtyHeadline,
'goto-next-clone':              c.goToNextClone,
'goto-next-history-node':       c.goToNextHistory,
'goto-next-marked':             c.goToNextMarkedHeadline,
'goto-next-node':               c.selectThreadNext,
'goto-next-sibling':            c.goToNextSibling,
'goto-next-visible':            c.selectVisNext,
'goto-parent':                  c.goToParent,
'goto-prev-history-node':       c.goToPrevHistory,
'goto-prev-node':               c.selectThreadBack,
'goto-prev-sibling':            c.goToPrevSibling,
'goto-prev-visible':            c.selectVisBack,
'hide-invisibles':              c.hideInvisibles,
'hoist':                        c.hoist,
'import-file':                  c.importAnyFile,
'indent-region':                c.indentBody,
'insert-body-time':             c.insertBodyTime,
'insert-child':                 c.insertChild,
'insert-node':                  c.insertHeadline,
'insert-node-before':           c.insertHeadlineBefore,
'mark':                         c.markHeadline,
'mark-changed-items':           c.markChangedHeadlines,
'mark-subheads':                c.markSubheads,
'match-brackets':               c.findMatchingBracket,
'minimize-all':                 f.minimizeAll,
'move-outline-down':            c.moveOutlineDown,
'move-outline-left':            c.moveOutlineLeft,
'move-outline-right':           c.moveOutlineRight,
'move-outline-up':              c.moveOutlineUp,
'new':                          c.new,
'open-cheat-sheet-leo':         c.openCheatSheet,
'open-leoDocs-leo':             c.leoDocumentation,
'open-leoPlugins-leo':          c.openLeoPlugins,
'open-leoSettings-leo':         c.openLeoSettings,
'open-local-settings':          c.selectAtSettingsNode,
'open-myLeoSettings-leo':       c.openMyLeoSettings,
'open-offline-tutorial':        f.leoHelp,
'open-online-home':             c.leoHome,
'open-online-toc':              c.openLeoTOC,
'open-online-tutorials':        c.openLeoTutorials,
'open-online-videos':           c.openLeoVideos,
'open-outline':                 c.open,
'open-python-window':           c.openPythonWindow,
'open-quickstart-leo':          c.leoQuickStart,
'open-scripts-leo':             c.openLeoScripts,
'open-users-guide':             c.openLeoUsersGuide,
'open-with':                    c.openWith,
'outline-to-cweb':              c.outlineToCWEB,
'outline-to-noweb':             c.outlineToNoweb,
'paste-node':                   c.pasteOutline,
'paste-retaining-clones':       c.pasteOutlineRetainingClones,
'paste-text':                   f.pasteText,
'pretty-print-all-python-code': c.prettyPrintAllPythonCode,
'pretty-print-python-code':     c.prettyPrintPythonCode,
'promote':                      c.promote,
'read-at-auto-nodes':           c.readAtAutoNodes,
'read-at-file-nodes':           c.readAtFileNodes,
'read-at-shadow-nodes':         c.readAtShadowNodes,
'read-file-into-node':          c.readFileIntoNode,
'read-outline-only':            c.readOutlineOnly,
'redo':                         c.undoer.redo,
'reformat-paragraph':           c.reformatParagraph,
'refresh-from-disk':            c.refreshFromDisk,
'remove-sentinels':             c.removeSentinels,
'resize-to-screen':             f.resizeToScreen,
'revert':                       c.revert,
'save-all':                     c.saveAll,
'save-file':                    c.save,
'save-file-as':                 c.saveAs,
'save-file-as-unzipped':        c.saveAsUnzipped,
'save-file-as-zipped':          c.saveAsZipped,
'save-file-to':                 c.saveTo,
'set-colors':                   c.colorPanel,
'set-font':                     c.fontPanel,
'settings':                     c.preferences,
'show-invisibles':              c.showInvisibles,
'sort-children':                c.sortChildren,
'sort-recent-files':            c.sortRecentFiles,
'sort-siblings':                c.sortSiblings,
'tangle':                       c.tangle,
'tangle-all':                   c.tangleAll,
'tangle-marked':                c.tangleMarked,
'toggle-active-pane':           f.toggleActivePane,
'toggle-angle-brackets':        c.toggleAngleBrackets,
'toggle-invisibles':            c.toggleShowInvisibles,
'toggle-sparse-move':           c.toggleSparseMove,
'toggle-split-direction':       f.toggleSplitDirection,
'undo':                         c.undoer.undo,
'unformat-paragraph':           c.unformatParagraph,
'unindent-region':              c.dedentBody,
'unmark-all':                   c.unmarkAll,
'untangle':                     c.untangle,
'untangle-all':                 c.untangleAll,
'untangle-marked':              c.untangleMarked,
'weave':                        c.weave,
'write-at-auto-nodes':          c.atFileCommands.writeAtAutoNodes,
'write-at-file-nodes':          c.fileCommands.writeAtFileNodes,
'write-at-shadow-nodes':        c.fileCommands.writeAtShadowNodes,
'write-dirty-at-auto-nodes':    c.atFileCommands.writeDirtyAtAutoNodes,
'write-dirty-at-file-nodes':    c.fileCommands.writeDirtyAtFileNodes,
'write-dirty-at-shadow-nodes':  c.fileCommands.writeDirtyAtShadowNodes,
'write-file-from-node':         c.writeFileFromNode,
'write-missing-at-file-nodes':  c.fileCommands.writeMissingAtFileNodes,
'write-outline-only':           c.fileCommands.writeOutlineOnly,
'''
</t>
<t tx="ekr.20150514035207.1"></t>
<t tx="ekr.20150531102337.1"></t>
<t tx="ekr.20150604130353.1">gnx: ekr.20150604130223.363
</t>
<t tx="ekr.20150604130353.2"></t>
<t tx="ekr.20150617060607.1"></t>
<t tx="ekr.20150703061709.1">@language python

'''myLeoSettings.py: save the outline and run the pylint command'''

# print('@button run-pylint: %s' % c.shortFileName())
if c.isChanged():
    c.save()
c.k.simulateCommand('pylint')
</t>
<t tx="ekr.20150722204300.1">class HTMLReportTraverser:
    '''
    Create html reports from an AST tree.

    Inspired by Paul Boddie.

    This version writes all html to a global code list.
    
    At present, this code does not show comments.
    The TokenSync class is probably the best way to do this.
    '''
    # To do: revise report-traverser-debug.css.
    # pylint: disable=no-self-argument
    @others
</t>
<t tx="ekr.20150722204300.10">def summary_link(rt, module_name, full_name, name, classes=None):

    return rt.name_link(
        "%s-summary" % module_name,
        full_name, name,
        classes)
</t>
<t tx="ekr.20150722204300.16"></t>
<t tx="ekr.20150722204300.17">def attr(rt, s):
    return rt.text(s).replace("'", "&amp;apos;").replace('"', "&amp;quot;")

def text(rt, s):
    return s.replace("&amp;", "&amp;amp;").replace("&lt;", "&amp;lt;").replace("&gt;", "&amp;gt;")
</t>
<t tx="ekr.20150722204300.18">def br(rt):
    return '\n&lt;br /&gt;'
</t>
<t tx="ekr.20150722204300.19">def comment(rt, comment):

    rt.span('comment')
    rt.gen('# ' + comment)
    rt.end_span('comment')
    rt.newline()
</t>
<t tx="ekr.20150722204300.2">def __init__(rt, debug=False):
    '''Ctor for the NewHTMLReportTraverser class.'''
    rt.code_list = []
    rt.debug = debug
    rt.div_stack = []
        # A check to ensure matching div/end_div.
    rt.last_doc = None
    # List of divs &amp; spans to generate...
    rt.enable_list = [
        'body', 'class', 'doc', 'function',
        'keyword', 'name', 'statement'
    ]
    # Formatting stuff...
    debug_css = 'report-traverser-debug.css'
    plain_css = 'report-traverser.css'
    rt.css_fn = debug_css if debug else plain_css
    rt.html_footer = '\n&lt;/body&gt;\n&lt;/html&gt;\n'
    rt.html_header = rt.define_html_header()
</t>
<t tx="ekr.20150722204300.20">def div(rt, class_name, extra=None, wrap=False):
    '''Generate the start of a div element.'''
    if class_name in rt.enable_list:
        if class_name:
            full_class_name = class_name if wrap else class_name + ' nowrap'
        rt.newline()
        if class_name and extra:
            rt.gen("&lt;div class='%s' %s&gt;" % (full_class_name, extra))
        elif class_name:
            rt.newline()
            rt.gen("&lt;div class='%s'&gt;" % (full_class_name))
        else:
            assert not extra
            rt.gen("&lt;div&gt;")
    rt.div_stack.append(class_name)

</t>
<t tx="ekr.20150722204300.21"># Called by ClassDef &amp; FunctionDef visitors.

def doc(rt, node):
    doc = ast.get_docstring(node)
    if doc:
        rt.docstring(doc)
        rt.last_doc = doc # Attempt to suppress duplicate.
</t>
<t tx="ekr.20150722204300.22">def docstring(rt, s):
    rt.gen("&lt;pre class='doc'&gt;")
    rt.gen('"""')
    rt.gen(rt.text(textwrap.dedent(s.replace('"""', '\\"\\"\\"'))))
    rt.gen('"""')
    rt.gen("&lt;/pre&gt;")
</t>
<t tx="ekr.20150722204300.23">def keyword(rt, name):

    rt.blank()
    rt.span('keyword')
    rt.gen(name)
    rt.end_span('keyword')
    rt.blank()
</t>
<t tx="ekr.20150722204300.24">def name(rt, name):
    
    # Div would put each name on a separate line.
    # span messes up whitespace, for now.
    # rt.span('name')
    rt.gen(name)
    # rt.end_span('name')
</t>
<t tx="ekr.20150722204300.26">def op(rt, op_name, leading=False, trailing=True):

    if leading:
        rt.blank()
    # rt.span('operation')
    # rt.span('operator')
    rt.gen(rt.text(op_name))
    # rt.end_span('operator')
    if trailing:
        rt.blank()
    # rt.end_span('operation')
</t>
<t tx="ekr.20150722204300.27">def simple_statement(rt, name):

    class_name = '%s nowrap' % name
    rt.div(class_name)
    rt.keyword(name)
    rt.end_div(class_name)
</t>
<t tx="ekr.20150722204300.28">def span(rt, class_name, wrap=False):

    if class_name in rt.enable_list:
        rt.newline()
        if class_name:
            full_class_name = class_name if wrap else class_name + ' nowrap'
            rt.gen("&lt;span class='%s'&gt;" % (full_class_name))
        else:
            rt.gen('&lt;span&gt;')
        # rt.newline()
    rt.div_stack.append(class_name)
</t>
<t tx="ekr.20150722204300.3">def define_html_header(rt):
    # Use string catenation to avoid using g.adjustTripleString.
    return (
        '&lt;?xml version="1.0" encoding="iso-8859-15"?&gt;\n'
        '&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"\n'
        '"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;\n'
        '&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;\n'
        '&lt;head&gt;\n'
        '  &lt;title&gt;%(title)s&lt;/title&gt;\n'
        '  &lt;link rel="stylesheet" type="text/css" href="%(css-fn)s" /&gt;\n'
        '&lt;/head&gt;\n&lt;body&gt;'
    )
</t>
<t tx="ekr.20150722204300.44">def visit(rt, node):
    """Walk a tree of AST nodes."""
    assert isinstance(node, ast.AST), node.__class__.__name__
    method_name = 'do_' + node.__class__.__name__
    method = getattr(rt, method_name)
    method(node)
</t>
<t tx="ekr.20150722204300.45">def visit_list(rt, aList, sep=None):
    # pylint: disable=arguments-differ
    if aList:
        for z in aList:
            rt.visit(z)
            rt.gen(sep)
        rt.clean(sep)
            
</t>
<t tx="ekr.20150722204300.46"></t>
<t tx="ekr.20150722204300.47"># arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def do_arguments(rt, node):

    assert isinstance(node, ast.arguments), node
    first_default = len(node.args) - len(node.defaults)
    for n, arg in enumerate(node.args):
        if isinstance(arg, (list,tuple)):
            rt.tuple_parameter(arg)
        else:
            rt.visit(arg)
        if n &gt;= first_default:
            default = node.defaults[n - first_default]
            rt.gen("=")
            rt.visit(default)
        rt.comma()
    if getattr(node, 'vararg', None):
        rt.gen('*')
        rt.gen(rt.name(node.vararg))
        rt.comma()
    if getattr(node, 'kwarg', None):
        rt.gen('**')
        rt.gen(rt.name(node.kwarg))
        rt.comma()
    rt.clean_comma()
</t>
<t tx="ekr.20150722204300.48">def tuple_parameter(rt, node):
    
    assert isinstance(node, (list, tuple)), node
    rt.gen("(")
    for param in node:
        if isinstance(param, tuple):
            rt.tuple_parameter(param)
        else:
            rt.visit(param)
    rt.gen(")")
</t>
<t tx="ekr.20150722204300.49"># Assert(expr test, expr? msg)

def do_Assert(rt, node):

    rt.div('statement')
    rt.keyword("assert")
    rt.visit(node.test)
    if node.msg:
        rt.comma()
        rt.visit(node.msg)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.5">def link(rt, class_name, href, a_text):\

    return "&lt;a class='%s' href='%s'&gt;%s&lt;/a&gt;" % (
        class_name, href, a_text)
</t>
<t tx="ekr.20150722204300.50">def do_Assign(rt, node):

    rt.div('statement')
    for z in node.targets:
        rt.visit(z)
        rt.op('=', leading=True, trailing=True)
    rt.visit(node.value)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.51"># Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(rt, node):

    rt.visit(node.value)
    rt.gen('.')
    rt.gen(node.attr)
</t>
<t tx="ekr.20150722204300.52">#  AugAssign(expr target, operator op, expr value)

def do_AugAssign(rt, node):

    op_name = rt.op_name(node.op)
    rt.div('statement')
    rt.visit(node.target)
    rt.op(op_name, leading=True)
    rt.visit(node.value)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.53">def do_BinOp(rt, node):

    op_name = rt.op_name(node.op)
    # rt.span(op_name)
    rt.visit(node.left)
    rt.op(op_name, leading=True)
    rt.visit(node.right)
    # rt.end_span(op_name)
</t>
<t tx="ekr.20150722204300.54">def do_BoolOp(rt, node):

    op_name = rt.op_name(node.op).strip()
    rt.span(op_name)
    for i, node2 in enumerate(node.values):
        if i &gt; 0:
            rt.keyword(op_name)
        rt.visit(node2)
    rt.end_span(op_name)
</t>
<t tx="ekr.20150722204300.55">def do_Break(rt, node):

    rt.simple_statement('break')
</t>
<t tx="ekr.20150722204300.56"># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(rt, node):

    # rt.span("callfunc")
    rt.visit(node.func)
    # rt.span("call")
    rt.gen('(')
    rt.visit_list(node.args, sep=',')
    if node.keywords:
        rt.visit_list(node.keywords, sep=',')
    if getattr(node, 'starargs', None):
        rt.op('*', trailing=False)
        rt.visit(node.starargs)
        rt.comma()
    if getattr(node, 'kwargs', None):
        rt.op('**', trailing=False)
        rt.visit(node.kwargs)
        rt.comma()
    rt.clean_comma()
    rt.gen(')')
    # rt.end_span('call')
    # rt.end_span('callfunc')
</t>
<t tx="ekr.20150722204300.57"># keyword = (identifier arg, expr value)
# keyword arguments supplied to call

def do_keyword(rt, node):

    rt.span('keyword-arg')
    rt.gen(node.arg)
    rt.blank()
    rt.gen('=')
    rt.blank()
    rt.visit(node.value)
    rt.end_span('keyword-arg')
</t>
<t tx="ekr.20150722204300.58"># ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

def do_ClassDef(rt, node):

    rt.div('class')
    rt.keyword("class")
    rt.gen(node.name) # Always a string.
    if node.bases:
        rt.gen('(')
        rt.visit_list(node.bases, sep=', ')
        rt.gen(')')
    rt.colon()
    rt.div('body')
    rt.doc(node)
    rt.visit_list(node.body)
    rt.end_div('body')
    rt.end_div('class')
</t>
<t tx="ekr.20150722204300.59">def do_Compare(rt, node):

    assert len(node.ops) == len(node.comparators)
    # rt.span('compare')
    rt.visit(node.left)
    for i in range(len(node.ops)):
        op_name = rt.op_name(node.ops[i])
        rt.op(op_name, leading=True)
        rt.visit(node.comparators[i])
    # rt.end_span('compare')
</t>
<t tx="ekr.20150722204300.6">def module_link(rt, module_name, classes=None):

    return rt.link(
        class_name=classes or 'name',
        href='%s.xhtml' % module_name,
        a_text=rt.text(module_name))
</t>
<t tx="ekr.20150722204300.60"># comprehension = (expr target, expr iter, expr* ifs)

def do_comprehension(rt, node):

    rt.visit(node.target)
    rt.keyword('in')
    # rt.span('collection')
    rt.visit(node.iter)
    if node.ifs:
        rt.keyword('if')
        # rt.span_list("conditional", node.ifs, sep=' ')
        for z in node.ifs:
            rt.visit(z)
            rt.blank()
        rt.clean(' ')
    # rt.end_span('collection')
</t>
<t tx="ekr.20150722204300.61">def do_Continue(rt, node):

    rt.simple_statement('continue')
</t>
<t tx="ekr.20150722204300.62">def do_Delete(rt, node):

    rt.div('statement')
    rt.keyword('del')
    if node.targets:
        rt.visit_list(node.targets, sep=',')
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.63">def do_Dict(rt, node):

    assert len(node.keys) == len(node.values)
    # rt.span('dict')
    rt.gen('{')
    for i in range(len(node.keys)):
        rt.visit(node.keys[i])
        rt.colon()
        rt.visit(node.values[i])
        rt.comma()
    rt.clean_comma()
    rt.gen('}')
    # rt.end_span('dict')
</t>
<t tx="ekr.20150722204300.64">def do_Ellipsis(rt, node):

    rt.gen('...')
</t>
<t tx="ekr.20150722204300.65">def do_ExceptHandler(rt, node):

    rt.div('excepthandler')
    rt.keyword("except")
    if not node.type:
        rt.clean(' ')
    if node.type:
        rt.visit(node.type)
    if node.name:
        rt.keyword('as')
        rt.visit(node.name)
    rt.colon()
    rt.div_body(node.body)
    rt.end_div('excepthandler')
</t>
<t tx="ekr.20150722204300.66"># Python 2.x only.

def do_Exec(rt, node):

    rt.div('statement')
    rt.keyword('exec')
    rt.visit(node.body)
    if node.globals:
        rt.comma()
        rt.visit(node.globals)
    if node.locals:
        rt.comma()
        rt.visit(node.locals)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.67">def do_Expr(rt, node):

    rt.div_node('expr', node.value)
</t>
<t tx="ekr.20150722204300.68"># For(expr target, expr iter, stmt* body, stmt* orelse)

def do_For(rt, node):

    rt.div('statement')
    rt.keyword("for")
    rt.visit(node.target)
    rt.keyword("in")
    rt.visit(node.iter)
    rt.colon()
    rt.div_body(node.body)
    if node.orelse:
        rt.keyword('else')
        rt.colon()
        rt.div_body(node.orelse)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.69">def do_FunctionDef(rt, node):

    rt.div('function', extra='id="%s"' % node.name)
    rt.keyword("def")
    rt.name(node.name)
    rt.gen('(')
    rt.visit(node.args)
    rt.gen(')')
    rt.colon()
    rt.div('body')
    rt.doc(node)
    rt.visit_list(node.body)
    rt.end_div('body')
    rt.end_div('function')
</t>
<t tx="ekr.20150722204300.7">def name_link(rt, module_name, full_name, name, classes=None):

    return rt.link(
        class_name=classes or "specific-ref",
        href='%s.xhtml#%s' % (module_name, rt.attr(full_name)),
        a_text=rt.text(name))
</t>
<t tx="ekr.20150722204300.70">def do_GeneratorExp(rt, node):

    # rt.span('genexpr')
    rt.gen('(')
    if node.elt:
        rt.visit(node.elt)
    rt.keyword('for')
    # rt.span_node('item', node.elt)
    rt.visit(node.elt)
    # rt.span_list('generators', node.generators)
    rt.visit_list(node.generators)
    rt.gen(')')
    # rt.end_span('genexpr')
</t>
<t tx="ekr.20150722204300.71">def get_import_names(rt, node):
    '''Return a list of the the full file names in the import statement.'''
    result = []
    for ast2 in node.names:
        if isinstance(ast2, ast.alias):
            data = ast2.name, ast2.asname
            result.append(data)
        else:
            g.trace('unsupported node in Import.names list', ast.__class__.__name__)
    return result
</t>
<t tx="ekr.20150722204300.72">def do_Global(rt, node):

    rt.div('statement')
    rt.keyword("global")
    for z in node.names:
        rt.gen(z)
        rt.comma()
    rt.clean_comma()
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.73"># If(expr test, stmt* body, stmt* orelse)

def do_If(rt, node, elif_flag=False):

    rt.div('statement')
    rt.keyword('elif' if elif_flag else 'if')
    rt.visit(node.test)
    rt.colon()
    rt.div_body(node.body)
    if node.orelse:
        node1 = node.orelse[0]
        if isinstance(node1, ast.If) and len(node.orelse) == 1:
            rt.do_If(node1, elif_flag=True)
        else:
            rt.keyword('else')
            rt.colon()
            rt.div_body(node.orelse)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.74"># IfExp(expr test, expr body, expr orelse)

def do_IfExp(rt, node):

    # rt.span('ifexp')
    rt.visit(node.body)
    rt.keyword('if')
    rt.visit(node.test)
    rt.keyword('else')
    rt.visit(node.orelse)
    # rt.end_span('ifexp')
</t>
<t tx="ekr.20150722204300.75">def do_Import(rt, node):

    rt.div('statement')
    rt.keyword("import")
    for name, alias in rt.get_import_names(node):
        rt.name(name) # rt.gen(rt.module_link(name))
        if alias:
            rt.keyword("as")
            rt.name(alias)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.76">def do_ImportFrom(rt, node):

    rt.div('statement')
    rt.keyword("from")
    rt.gen(rt.module_link(node.module))
    rt.keyword("import")
    for name, alias in rt.get_import_names(node):
        rt.name(name)
        if alias:
            rt.keyword("as")
            rt.name(alias)
        rt.comma()
    rt.clean_comma()
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.77">def do_Lambda(rt, node):

    # rt.span('lambda')
    rt.keyword('lambda')
    rt.visit(node.args)
    rt.comma()
    rt.span_node("code", node.body)
    # rt.end_span('lambda')
</t>
<t tx="ekr.20150722204300.78"># List(expr* elts, expr_context ctx)

def do_List(rt, node):

    # rt.span('list')
    rt.gen('[')
    if node.elts:
        for z in node.elts:
            rt.visit(z)
            rt.comma()
        rt.clean_comma()
    rt.gen(']')
    # rt.end_span('list')
</t>
<t tx="ekr.20150722204300.79"># ListComp(expr elt, comprehension* generators)

def do_ListComp(rt, node):

    # rt.span('listcomp')
    rt.gen('[')
    if node.elt:
        rt.visit(node.elt)
    rt.keyword('for')
    # rt.span('ifgenerators')
    rt.visit_list(node.generators)
    rt.gen(']')
    # rt.end_span('ifgenerators')
    # rt.end_span('listcomp')
</t>
<t tx="ekr.20150722204300.8">def object_name_ref(rt, module, obj, name=None, classes=None):
    """
    Link to the definition for 'module' using 'obj' with the optional 'name'
    used as the label (instead of the name of 'obj'). The optional 'classes'
    can be used to customise the CSS classes employed.
    """
    return rt.name_link(
        module.full_name(),
        obj.full_name(),
        name or obj.name, classes)
</t>
<t tx="ekr.20150722204300.80">def do_Module(rt, node):

    rt.doc(node)
    rt.visit_list(node.body)
</t>
<t tx="ekr.20150722204300.81">def do_Name(rt, node):
    
    rt.name(node.id)
</t>
<t tx="ekr.20150722204300.82">def do_Num(rt, node):

    rt.gen(rt.text(repr(node.n)))
</t>
<t tx="ekr.20150722204300.83">def do_Pass(rt, node):

    rt.simple_statement('pass')
</t>
<t tx="ekr.20150722204300.84"># Print(expr? dest, expr* values, bool nl)

def do_Print(rt, node):

    rt.div('statement')
    rt.keyword("print")
    rt.gen('(')
    if node.dest:
        rt.op('&gt;&gt;\n')
        rt.visit(node.dest)
        rt.comma()
        rt.newline()
        if node.values:
            for z in node.values:
                rt.visit(z)
                rt.comma()
                rt.newline()
    rt.clean('\n')
    rt.clean_comma()
    rt.gen(')')
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.85">def do_Raise(rt, node):

    rt.div('statement')
    rt.keyword("raise")
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.86">def do_Return(rt, node):

    rt.div('statement')
    rt.keyword("return")
    if node.value:
        rt.visit(node.value)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.87">def do_Slice(rt, node):

    # rt.span("slice")
    if node.lower:
        rt.visit(node.lower)
    rt.colon()
    if node.upper:
        rt.visit(node.upper)
    if node.step:
        rt.colon()
        rt.visit(node.step)
    # rt.end_span("slice")
</t>
<t tx="ekr.20150722204300.88">def do_Str(rt, node):
    '''This represents a string constant.'''

    def clean(s):
        return s.replace(' ','').replace('\n','').replace('"','').replace("'",'')
        
    assert g.isString(node.s)
    if rt.last_doc and clean(rt.last_doc) == clean(node.s):
        # Already seen.
        rt.last_doc = None
    else:
        rt.string(node.s)
</t>
<t tx="ekr.20150722204300.89">def do_Subscript(rt, node):

    # rt.span("subscript")
    rt.visit(node.value)
    rt.gen('[')
    rt.visit(node.slice)
    rt.gen(']')
    # rt.end_span("subscript")
</t>
<t tx="ekr.20150722204300.9">def popup(rt, classes, aList):

    rt.span_list(classes or 'popup', aList)
</t>
<t tx="ekr.20150722204300.90">def do_TryExcept(rt, node):

    rt.div('statement')
    rt.keyword('try')
    rt.colon()
    rt.div_list('body', node.body)
    if node.orelse:
        rt.keyword('else')
        rt.colon()
        rt.div_body(node.orelse)
    rt.div_body(node.handlers)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.91">def do_TryFinally(rt, node):

    rt.div('statement')
    rt.keyword('try')
    rt.colon()
    rt.div_body(node.body)
    rt.keyword('finally')
    rt.colon()
    rt.div_body(node.final.body)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.92"># Tuple(expr* elts, expr_context ctx)

def do_Tuple(rt, node):

    # rt.span('tuple')
    rt.gen('(')
    for z in node.elts or []:
        # g.trace(z)
        rt.visit(z)
        rt.comma()
    rt.clean_comma()
    rt.gen(')')
    # rt.end_span('tuple')
</t>
<t tx="ekr.20150722204300.93">def do_UnaryOp(rt, node):

    op_name = rt.op_name(node.op).strip()
    # rt.span(op_name)
    rt.op(op_name, trailing=False)
    rt.visit(node.operand)
    # rt.end_span(op_name)
</t>
<t tx="ekr.20150722204300.94">def do_While(rt, node):

    rt.div('statement')
    rt.div(None)
    rt.keyword("while")
    rt.visit(node.test)
    rt.colon()
    rt.end_div(None)
    rt.div_list('body', node.body)
    if node.orelse:
        rt.keyword('else')
        rt.colon()
        rt.div_body(node.orelse)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.95"># With(expr context_expr, expr? optional_vars, stmt* body)

def do_With(rt, node):

    context_expr = getattr(node, 'context_expr', None)
    optional_vars = getattr(node, 'optional_vars', None)
    rt.div('statement')
    # rt.div(None)
    rt.keyword('with')
    if context_expr:
        rt.visit(context_expr)
    if optional_vars:
        rt.keyword('as')
        rt.visit_list(optional_vars)
    rt.colon()
    # rt.end_div(None)
    rt.div_body(node.body)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722204300.96">def do_Yield(rt, node):

    rt.div('statement')
    rt.keyword('yield')
    rt.visit(node.value)
    rt.end_div('statement')
</t>
<t tx="ekr.20150722211115.1">def gen(rt, s):
    '''Append s to the global code list.'''
    if s:
        rt.code_list.append(s)
</t>
<t tx="ekr.20150722221101.1">def div_list(rt, class_name, aList, sep=None):

    rt.div(class_name)
    rt.visit_list(aList, sep=sep)
    rt.end_div(class_name)

def div_node(rt, class_name, node):

    rt.div(class_name)
    rt.visit(node)
    rt.end_div(class_name)
</t>
<t tx="ekr.20150722221408.1"># def keyword_colon(rt, keyword):

    # rt.keyword(keyword)
    # rt.colon()
</t>
<t tx="ekr.20150722222149.1">def div_body(rt, aList):
    if aList:
        rt.div_list('body', aList)
</t>
<t tx="ekr.20150722224734.1">def span_list(rt, class_name, aList, sep=None):

    rt.span(class_name)
    rt.visit_list(aList, sep=sep)
    rt.end_span(class_name)

def span_node(rt, class_name, node):

    rt.span(class_name)
    rt.visit(node)
    rt.end_span(class_name)
</t>
<t tx="ekr.20150723094359.1"></t>
<t tx="ekr.20150723095004.1">def end_span(rt, class_name):

    if class_name in rt.enable_list:
        rt.gen('&lt;/span&gt;')
        rt.newline()
    class_name2 = rt.div_stack.pop()
    assert class_name2 == class_name, (class_name2, class_name)
</t>
<t tx="ekr.20150723095033.1">def end_div(rt, class_name):

    if class_name in rt.enable_list:
        # rt.newline()
        rt.gen('&lt;/div&gt;')
        # rt.newline()
    class_name2 = rt.div_stack.pop()
    assert class_name2 == class_name, (class_name2, class_name)
</t>
<t tx="ekr.20150723100208.1">def clean(rt, s):
    '''Remove s from the code list.'''
    s2 = rt.code_list[-1]
    if s2 == s:
        rt.code_list.pop()
</t>
<t tx="ekr.20150723100236.1">def blank(rt):
    '''Insert a single blank.'''
    rt.clean(' ')
    if rt.code_list[-1] not in ' \n':
        rt.gen(' ')
</t>
<t tx="ekr.20150723100346.1">def comma(rt):
    
    rt.clean(' ')
    rt.gen(', ')
    
def clean_comma(rt):

    rt.clean(', ')
</t>
<t tx="ekr.20150723100417.1">def newline(rt):

    rt.clean(' ')
    rt.clean('\n')
    rt.clean(' ')
    rt.gen('\n')
</t>
<t tx="ekr.20150723105702.1">def colon(rt):

    rt.clean('\n')
    rt.clean(' ')
    rt.clean('\n')
    rt.gen(':')
</t>
<t tx="ekr.20150723105951.1">@nobeautify

def op_name (rt, node,strict=True):
    '''Return the print name of an operator node.'''
    d = {
        # Binary operators.
        'Add':       '+',
        'BitAnd':    '&amp;',
        'BitOr':     '|',
        'BitXor':    '^',
        'Div':       '/',
        'FloorDiv':  '//',
        'LShift':    '&lt;&lt;',
        'Mod':       '%',
        'Mult':      '*',
        'Pow':       '**',
        'RShift':    '&gt;&gt;',
        'Sub':       '-',
        # Boolean operators.
        'And':   ' and ',
        'Or':    ' or ',
        # Comparison operators
        'Eq':    '==',
        'Gt':    '&gt;',
        'GtE':   '&gt;=',
        'In':    ' in ',
        'Is':    ' is ',
        'IsNot': ' is not ',
        'Lt':    '&lt;',
        'LtE':   '&lt;=',
        'NotEq': '!=',
        'NotIn': ' not in ',
        # Context operators.
        'AugLoad':  '&lt;AugLoad&gt;',
        'AugStore': '&lt;AugStore&gt;',
        'Del':      '&lt;Del&gt;',
        'Load':     '&lt;Load&gt;',
        'Param':    '&lt;Param&gt;',
        'Store':    '&lt;Store&gt;',
        # Unary operators.
        'Invert':   '~',
        'Not':      ' not ',
        'UAdd':     '+',
        'USub':     '-',
    }
    kind = node.__class__.__name__
    name = d.get(kind, kind)
    if strict: assert name, kind
    return name
</t>
<t tx="ekr.20160122104332.1"></t>
<t tx="ekr.20160123142722.1"># An example configuration file for make_stub_files.py.
# By default, this is ~/stubs/make_stub_files.cfg.
# Can be changed using the --config=path command-line option.

[Global]

files:

    # Files to be used *only* if no files are given on the command line.
    # glob.glob wildcards are supported.

    # c:/leo.repo/leo-editor/leo/core/leoAst.py
    # c:/leo.repo/leo-editor/leo/core/*.py
    # c:/leo.repo/leo-editor/plugins/*.py

output_directory: ~/stubs

prefix_lines:
    # Lines to be inserted at the start of each stub file.
    from typing import TypeVar, Iterable, Tuple
    T = TypeVar('T', int, float, complex)

[Def Name Patterns]

[General Patterns]
</t>
<t tx="ekr.20160226082945.1"></t>
<t tx="ekr.20160306053952.1">gnx: ekr.20160301134754.1
unl: qtui_generate declarations
</t>
<t tx="ekr.20160306053952.2">gnx: ekr.20160301134754.2
unl: qt_main declarations
gnx: ekr.20160301134754.3
unl: class Ui_MainWindow
gnx: ekr.20160301134754.4
unl: class Ui_MainWindow--&gt;setupUi
gnx: ekr.20160301134754.5
unl: class Ui_MainWindow--&gt;retranslateUi
</t>
<t tx="ekr.20160306053953.1"></t>
<t tx="ekr.20160306053953.2">gnx: ekr.20160301134754.6
unl: qt_quicksearch declarations
gnx: ekr.20160301134754.7
unl: class Ui_LeoQuickSearchWidget
gnx: ekr.20160301134754.8
unl: class Ui_LeoQuickSearchWidget--&gt;setupUi
gnx: ekr.20160301134754.9
unl: class Ui_LeoQuickSearchWidget--&gt;retranslateUi
</t>
<t tx="ekr.20160306053953.3"></t>
<t tx="ekr.20160315161104.1">&lt;&lt; imports &gt;&gt;
g.cls()
if c.isChanged(): c.save()
@others
path = g.os_path_finalize_join(g.app.loadDir,
    '..', 'test', 'report_test.py') # 'leoAst.py')
assert g.os_path_exists(path), path
fn = g.shortFileName(path)
source = open(path, 'r').read()
node = ast.parse(source, filename=fn, mode='exec')
s = HTMLReportTraverser(debug=True).main(fn, node)
out_fn = g.os_path_finalize_join(g.app.loadDir, '..', 'test', 
    'HTMLReportTraverser_test.html')
open(out_fn, 'w').write(s)
# print('%s %s' % (len(s), out_fn))
os.startfile(out_fn)
# os.system('ed ' + out_fn)</t>
<t tx="ekr.20160315161259.1">def main(rt, fn, node):
    '''Return a report for the given ast node as a string.'''
    rt.gen(rt.html_header % {
            'css-fn': rt.css_fn,
            'title': 'Module: %s' % fn
        })
    rt.parent = None
    rt.parents = [None]
    rt.visit(node)
    rt.gen(rt.html_footer)
    return ''.join(rt.code_list)
</t>
<t tx="ekr.20160315163533.1">import leo.core.leoAst as leoAst
import ast
import os
import xml.sax.saxutils as saxutils
import textwrap
# Needed only for the script version
AstFullTraverser = leoAst.AstFullTraverser</t>
<t tx="ekr.20160315164448.1">@language python
@tabwidth -4
@others
g = LeoGlobals() # For ekr.
if __name__ == "__main__":
    main()
</t>
<t tx="ekr.20160315164542.1">#!/usr/bin/env python
'''
This script makes a stub (.pyi) file in the output directory for each
source file listed on the command line (wildcard file names are supported).

For full details, see README.md.

This file is in the public domain.
'''
import ast
from collections import OrderedDict
    # Requires Python 2.7 or above. Without OrderedDict
    # the configparser will give random order for patterns.
try:
    import ConfigParser as configparser # Python 2
except ImportError:
    import configparser # Python 3
import glob
import optparse
import os
import re
import sys
import time
try:
    import StringIO as io # Python 2
except ImportError:
    import io # Python 3


</t>
<t tx="ekr.20160315164542.10">def reduce_numbers(aList):
    '''
    Return aList with all number types in aList replaced by the most
    general numeric type in aList.
    '''
    found = None
    numbers = ('number', 'complex', 'float', 'long', 'int')
    for kind in numbers:
        for z in aList:
            if z == kind:
                found = kind
                break
        if found:
            break
    if found:
        assert found in numbers, found
        aList = [z for z in aList if z not in numbers]
        aList.append(found)
    return aList

</t>
<t tx="ekr.20160315164542.100">
# Return generic markers to allow better pattern matches.

</t>
<t tx="ekr.20160315164542.101">def do_BoolOp(self, node): # Python 2.x only.
    return 'bool'

</t>
<t tx="ekr.20160315164542.102">def do_Bytes(self, node): # Python 3.x only.
    return 'bytes' # return str(node.s)

</t>
<t tx="ekr.20160315164542.103">def do_Name(self, node):
    return 'bool' if node.id in ('True', 'False') else node.id

</t>
<t tx="ekr.20160315164542.104">def do_Num(self, node):
    return 'number' # return repr(node.n)

</t>
<t tx="ekr.20160315164542.105">def do_Str(self, node):
    '''This represents a string constant.'''
    return 'str' # return repr(node.s)


</t>
<t tx="ekr.20160315164542.106">class LeoGlobals:
    '''A class supporting g.pdb and g.trace for compatibility with Leo.'''
    @others
</t>
<t tx="ekr.20160315164542.107">
class NullObject:
    """
    An object that does nothing, and does it very well.
    From the Python cookbook, recipe 5.23
    """
    @others
</t>
<t tx="ekr.20160315164542.108">def __init__(self, *args, **keys): pass
</t>
<t tx="ekr.20160315164542.109">def __call__(self, *args, **keys): return self
</t>
<t tx="ekr.20160315164542.11">def reduce_types(aList, name=None, trace=False):
    '''
    Return a string containing the reduction of all types in aList.
    The --trace-reduce command-line option sets trace=True.
    If present, name is the function name or class_name.method_name.
    '''
    trace = False or trace
    
    def show(s, known=True):
        '''Bind the arguments to show_helper.'''
        return show_helper(aList[:], known, name, s, trace)

    while None in aList:
        aList.remove(None)
    if not aList:
        return show('None')
    r = sorted(set(aList))
    if not all([is_known_type(z) for z in r]):
        return show('Any', known=False)
    elif len(r) == 1:
        return show(r[0])
    if 'None' in r:
        kind = 'Optional'
        while 'None' in r:
            r.remove('None')
        return show('Optional[%s]' % r[0])
    r = reduce_numbers(r)
    if len(r) == 1:
        return show(r[0])
    else:
        return show('Union[%s]' % (', '.join(sorted(r))))

</t>
<t tx="ekr.20160315164542.110">def __repr__(self): return "NullObject"
</t>
<t tx="ekr.20160315164542.111">def __str__(self): return "NullObject"
</t>
<t tx="ekr.20160315164542.112">def __bool__(self): return False
</t>
<t tx="ekr.20160315164542.113">def __nonzero__(self): return 0
</t>
<t tx="ekr.20160315164542.114">def __delattr__(self, attr): return self
</t>
<t tx="ekr.20160315164542.115">def __getattr__(self, attr): return self
</t>
<t tx="ekr.20160315164542.116">def __setattr__(self, attr, val): return self

</t>
<t tx="ekr.20160315164542.117">def _callerName(self, n=1, files=False):
    # print('_callerName: %s %s' % (n,files))
    try: # get the function name from the call stack.
        f1 = sys._getframe(n) # The stack frame, n levels up.
        code1 = f1.f_code # The code object
        name = code1.co_name
        if name == '__init__':
            name = '__init__(%s,line %s)' % (
                self.shortFileName(code1.co_filename), code1.co_firstlineno)
        if files:
            return '%s:%s' % (self.shortFileName(code1.co_filename), name)
        else:
            return name # The code name
    except ValueError:
        # print('g._callerName: ValueError',n)
        return '' # The stack is not deep enough.
    except Exception:
        # es_exception()
        return '' # "&lt;no caller name&gt;"

</t>
<t tx="ekr.20160315164542.118">def callers(self, n=4, count=0, excludeCaller=True, files=False):
    '''Return a list containing the callers of the function that called g.callerList.

    If the excludeCaller keyword is True (the default), g.callers is not on the list.

    If the files keyword argument is True, filenames are included in the list.
    '''
    # sys._getframe throws ValueError in both cpython and jython if there are less than i entries.
    # The jython stack often has less than 8 entries,
    # so we must be careful to call g._callerName with smaller values of i first.
    result = []
    i = 3 if excludeCaller else 2
    while 1:
        s = self._callerName(i, files=files)
        # print(i,s)
        if s:
            result.append(s)
        if not s or len(result) &gt;= n: break
        i += 1
    result.reverse()
    if count &gt; 0: result = result[: count]
    sep = '\n' if files else ','
    return sep.join(result)

</t>
<t tx="ekr.20160315164542.119">def cls(self):
    '''Clear the screen.'''
    if sys.platform.lower().startswith('win'):
        os.system('cls')

</t>
<t tx="ekr.20160315164542.12">def show_helper(aList, known, name, s, trace):
    '''Show the result of the reduction.'''
    s = s.strip()
    if trace and (not known or len(aList) &gt; 1):
        if name:
            if name.find('.') &gt; -1:
                context = ''.join(name.split('.')[1:])
            else:
                context = name
        else:
            context = g.callers(3).split(',')[0].strip()
        context = truncate(context, 26)
        known = '' if known else '? '
        pattern = sorted(set([z.replace('\n',' ') for z in aList]))
        pattern = '[%s]' % truncate(', '.join(pattern), 53-2)
        print('reduce_types: %-26s %53s ==&gt; %s%s' % (context, pattern, known, s))
            # widths above match the corresponding indents in match_all and match.
    return s

</t>
<t tx="ekr.20160315164542.120">def pdb(self):
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()

</t>
<t tx="ekr.20160315164542.121">def shortFileName(self,fileName, n=None):
    if n is None or n &lt; 1:
        return os.path.basename(fileName)
    else:
        return '/'.join(fileName.replace('\\', '/').split('/')[-n:])

</t>
<t tx="ekr.20160315164542.122">def splitLines(self, s):
    '''Split s into lines, preserving trailing newlines.'''
    return s.splitlines(True) if s else []

</t>
<t tx="ekr.20160315164542.123">def trace(self, *args, **keys):
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.trace(caller_level=2, *args, **keys)
    except ImportError:
        print(args, keys)


</t>
<t tx="ekr.20160315164542.124">class Pattern(object):
    '''
    A class representing regex or balanced patterns.
    
    Sample matching code, for either kind of pattern:
        
        for m in reversed(pattern.all_matches(s)):
            s = pattern.replace(m, s)
    '''
    @others
</t>
<t tx="ekr.20160315164542.125">
def __init__ (self, find_s, repl_s=''):
    '''Ctor for the Pattern class.'''
    self.find_s = find_s
    self.repl_s = repl_s
    if self.is_regex():
        self.regex = re.compile(find_s)
    elif self.is_balanced():
        self.regex = None
    else:
        # Escape all dangerous characters.
        result = []
        for ch in find_s:
            if ch == '_' or ch.isalnum():
                result.append(ch)
            else:
                result.append('\\'+ch)
        self.regex = re.compile(''.join(result))

</t>
<t tx="ekr.20160315164542.126">def __eq__(self, obj):
    """Return True if two Patterns are equivalent."""
    if isinstance(obj, Pattern):
        return self.find_s == obj.find_s and self.repl_s == obj.repl_s
    else:
        return NotImplemented

</t>
<t tx="ekr.20160315164542.127">def __ne__(self, obj):
    """Return True if two Patterns are not equivalent."""
    return not self.__eq__(obj)

</t>
<t tx="ekr.20160315164542.128">def __hash__(self):
    '''Pattern.__hash__'''
    return len(self.find_s) + len(self.repl_s)

</t>
<t tx="ekr.20160315164542.129">def __repr__(self):
    '''Pattern.__repr__'''
    return '%s: %s' % (self.find_s, self.repl_s)
    
</t>
<t tx="ekr.20160315164542.13">def split_types(s):
    '''Split types on *outer level* commas.'''
    aList, i1, level = [], 0, 0
    for i, ch in enumerate(s):
        if ch == '[':
            level += 1
        elif ch == ']':
            level -= 1
        elif ch == ',' and level == 0:
            aList.append(s[i1:i])
            i1 = i+1
    aList.append(s[i1:].strip())
    return aList

</t>
<t tx="ekr.20160315164542.130">__str__ = __repr__

</t>
<t tx="ekr.20160315164542.131">def is_balanced(self):
    '''Return True if self.find_s is a balanced pattern.'''
    s = self.find_s
    if s.endswith('*'):
        return True
    for pattern in ('(*)', '[*]', '{*}'):
        if s.find(pattern) &gt; -1:
            return True
    return False

</t>
<t tx="ekr.20160315164542.132">def is_regex(self):
    '''
    Return True if self.find_s is a regular pattern.
    For now a kludgy convention suffices.
    '''
    return self.find_s.endswith('$')
        # A dollar sign is not valid in any Python expression.

</t>
<t tx="ekr.20160315164542.133">def all_matches(self, s):
    '''
    Return a list of match objects for all matches in s.
    These are regex match objects or (start, end) for balanced searches.
    '''
    trace = False
    if self.is_balanced():
        aList, i = [], 0
        while i &lt; len(s):
            progress = i
            j = self.full_balanced_match(s, i)
            if j is None:
                i += 1
            else:
                aList.append((i,j),)
                i = j
            assert progress &lt; i
        return aList
    else:
        return list(self.regex.finditer(s))

</t>
<t tx="ekr.20160315164542.134">def full_balanced_match(self, s, i):
    '''Return the index of the end of the match found at s[i:] or None.'''
    i1 = i
    trace = False
    if trace: g.trace(self.find_s, s[i:].rstrip())
    pattern = self.find_s
    j = 0 # index into pattern
    while i &lt; len(s) and j &lt; len(pattern) and pattern[j] in ('*', s[i]):
        progress = i
        if pattern[j:j+3] in ('(*)', '[*]', '{*}'):
            delim = pattern[j]
            i = self.match_balanced(delim, s, i)
            j += 3
        elif j == len(pattern)-1 and pattern[j] == '*':
            # A trailing * matches the rest of the string.
            j += 1
            i = len(s)
            break
        else:
            i += 1
            j += 1
        assert progress &lt; i
    found = i &lt;= len(s) and j == len(pattern)
    if trace and found:
        g.trace('%s -&gt; %s' % (pattern, s[i1:i]))
    return i if found else None

</t>
<t tx="ekr.20160315164542.135">def match_balanced(self, delim, s, i):
    '''
    delim == s[i] and delim is in '([{'
    Return the index of the end of the balanced parenthesized string, or len(s)+1.
    '''
    trace = False
    assert s[i] == delim, s[i]
    assert delim in '([{'
    delim2 = ')]}'['([{'.index(delim)]
    assert delim2 in ')]}'
    i1, level = i, 0
    while i &lt; len(s):
        progress = i
        ch = s[i]
        i += 1
        if ch == delim:
            level += 1
        elif ch == delim2:
            level -= 1
            if level == 0:
                if trace: g.trace('found: %s' % s[i1:i])
                return i
        assert progress &lt; i
    # Unmatched: a syntax error.
    print('***** unmatched %s in %s' % (delim, s))
    return len(s) + 1

</t>
<t tx="ekr.20160315164542.136">def match(self, s, trace=False):
    '''
    Perform the match on the entire string if possible.
    Return (found, new s)
    '''
    trace = False or trace
    caller = g.callers(2).split(',')[0].strip()
        # The caller of match_all.
    s1 = truncate(s,40)
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        if j is None:
            return False, s
        else:
            start, end = 0, len(s)
            s = self.replace_balanced(s, start, end)
            if trace:
                g.trace('%-16s %30s %40s ==&gt; %s' % (caller, self, s1, s))
            return True, s
    else:
        m = self.regex.match(s)
        if m and m.group(0) == s:
            s = self.replace_regex(m, s)
            if trace:
                g.trace('%-16s %30s %30s ==&gt; %s' % (caller, self, s1, s))
            return True, s
        else:
            return False, s

</t>
<t tx="ekr.20160315164542.137">def match_entire_string(self, s):
    '''Return True if s matches self.find_s'''
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        return j is not None
    else:
        m = self.regex.match(s)
        return m and m.group(0) == s

</t>
<t tx="ekr.20160315164542.138">def replace(self, m, s):
    '''Perform any kind of replacement.'''
    if self.is_balanced():
        start, end = m
        return self.replace_balanced(s, start, end)
    else:
        return self.replace_regex(m, s)

</t>
<t tx="ekr.20160315164542.139">def replace_balanced(self, s1, start, end):
    '''
    Use m (returned by all_matches) to replace s by the string implied by repr_s.
    Within repr_s, * star matches corresponding * in find_s
    '''
    trace = False
    s = s1[start:end]
    f, r = self.find_s, self.repl_s
    i1 = f.find('(*)')
    i2 = f.find('[*]')
    i3 = f.find('{*}')
    if -1 == i1 == i2 == i3:
        return s1[:start] + r + s1[end:]
    j = r.find('*')
    if j == -1:
        return s1[:start] + r + s1[end:]
    i = min([z for z in [i1, i2, i3] if z &gt; -1])
    assert i &gt; -1 # i is an index into f AND s
    delim = f[i]
    if trace: g.trace('head', s[:i], f[:i])
    assert s[:i] == f[:i], (s[:i], f[:i])
    if trace: g.trace('delim',delim)
    k = self.match_balanced(delim, s, i)
    s_star = s[i+1:k-1]
    if trace: g.trace('s_star',s_star)
    repl = r[:j] + s_star + r[j+1:]
    if trace: g.trace('repl',self.repl_s,'==&gt;',repl)
    return s1[:start] + repl + s1[end:]

</t>
<t tx="ekr.20160315164542.14">def truncate(s, n):
    '''Return s truncated to n characters.'''
    return s if len(s) &lt;= n else s[:n-3] + '...'


</t>
<t tx="ekr.20160315164542.140">def replace_regex(self, m, s):
    '''Do the replacement in s specified by m.'''
    s = self.repl_s
    for i in range(9):
        group = '\\%s' % i
        if s.find(group) &gt; -1:
            # g.trace(i, m.group(i))
            s = s.replace(group, m.group(i))
    return s


</t>
<t tx="ekr.20160315164542.141">class StandAloneMakeStubFile:
    '''
    A class to make Python stub (.pyi) files in the ~/stubs directory for
    every file mentioned in the [Source Files] section of
    ~/stubs/make_stub_files.cfg.
    '''
    @others
</t>
<t tx="ekr.20160315164542.142">
def __init__ (self):
    '''Ctor for StandAloneMakeStubFile class.'''
    self.options = {}
    # Ivars set on the command line...
    self.config_fn = None
        # self.finalize('~/stubs/make_stub_files.cfg')
    self.enable_unit_tests = False
    self.files = [] # May also be set in the config file.
    # Ivars set in the config file...
    self.output_fn = None
    self.output_directory = self.finalize('.')
        # self.finalize('~/stubs')
    self.overwrite = False
    self.prefix_lines = []
    self.trace_matches = False
    self.trace_patterns = False
    self.trace_reduce = False
    self.trace_visitors = False
    self.update_flag = False
    self.verbose = False # Trace config arguments.
    self.warn = False
    # Pattern lists, set by config sections...
    self.section_names = (
        'Global', 'Def Name Patterns', 'General Patterns')
    self.def_patterns = [] # [Def Name Patterns]
    self.general_patterns = [] # [General Patterns]
    self.names_dict = {}
    self.op_name_dict = self.make_op_name_dict()
    self.patterns_dict = {}

</t>
<t tx="ekr.20160315164542.143">def finalize(self, fn):
    '''Finalize and regularize a filename.'''
    fn = os.path.expanduser(fn)
    fn = os.path.abspath(fn)
    fn = os.path.normpath(fn)
    return fn

</t>
<t tx="ekr.20160315164542.144">def make_stub_file(self, fn):
    '''
    Make a stub file in ~/stubs for all source files mentioned in the
    [Source Files] section of ~/stubs/make_stub_files.cfg
    '''
    if not fn.endswith('.py'):
        print('not a python file', fn)
        return
    if not os.path.exists(fn):
        print('not found', fn)
        return
    base_fn = os.path.basename(fn)
    out_fn = os.path.join(self.output_directory, base_fn)
    out_fn = out_fn[:-3] + '.pyi'
    self.output_fn = os.path.normpath(out_fn)
    s = open(fn).read()
    node = ast.parse(s,filename=fn,mode='exec')
    StubTraverser(controller=self).run(node)

</t>
<t tx="ekr.20160315164542.145">def run(self):
    '''
    Make stub files for all files.
    Do nothing if the output directory does not exist.
    '''
    if self.enable_unit_tests:
        self.run_all_unit_tests()
    if self.files:
        dir_ = self.output_directory
        if dir_:
            if os.path.exists(dir_):
                for fn in self.files:
                    self.make_stub_file(fn)
            else:
                print('output directory not found: %s' % dir_)
        else:
            print('no output directory')
    elif not self.enable_unit_tests:
        print('no input files')

</t>
<t tx="ekr.20160315164542.146">def run_all_unit_tests(self):
    '''Run all unit tests in the make_stub_files/test directory.'''
    import unittest
    loader = unittest.TestLoader()
    suite = loader.discover(os.path.abspath('.'),
                            pattern='test*.py',
                            top_level_dir=None)
    unittest.TextTestRunner(verbosity=1).run(suite)

</t>
<t tx="ekr.20160315164542.147">def scan_command_line(self):
    '''Set ivars from command-line arguments.'''
    # This automatically implements the --help option.
    usage = "usage: make_stub_files.py [options] file1, file2, ..."
    parser = optparse.OptionParser(usage=usage)
    add = parser.add_option
    add('-c', '--config', dest='fn',
        help='full path to configuration file')
    add('-d', '--dir', dest='dir',
        help='full path to the output directory')
    add('-o', '--overwrite', action='store_true', default=False,
        help='overwrite existing stub (.pyi) files')
    add('-t', '--test', action='store_true', default=False,
        help='run unit tests on startup')
    add('--trace-matches', action='store_true', default=False,
        help='trace Pattern.matches')
    add('--trace-patterns', action='store_true', default=False,
        help='trace pattern creation')
    add('--trace-reduce', action='store_true', default=False,
        help='trace st.reduce_types')
    add('--trace-visitors', action='store_true', default=False,
        help='trace visitor methods')
    add('-u', '--update', action='store_true', default=False,
        help='update stubs in existing stub file')
    add('-v', '--verbose', action='store_true', default=False,
        help='verbose output in .pyi file')
    add('-w', '--warn', action='store_true', default=False,
        help='warn about unannotated args')
    # Parse the options
    options, args = parser.parse_args()
    # Handle the options...
    self.enable_unit_tests=options.test
    self.overwrite = options.overwrite
    self.trace_matches = options.trace_matches
    self.trace_patterns = options.trace_patterns
    self.trace_reduce = options.trace_reduce
    self.trace_visitors = options.trace_visitors
    self.update_flag = options.update
    self.verbose = options.verbose
    self.warn = options.warn
    if options.fn:
        self.config_fn = options.fn
    if options.dir:
        dir_ = options.dir
        dir_ = self.finalize(dir_)
        if os.path.exists(dir_):
            self.output_directory = dir_
        else:
            print('--dir: directory does not exist: %s' % dir_)
            print('exiting')
            sys.exit(1)
    # If any files remain, set self.files.
    if args:
        args = [self.finalize(z) for z in args]
        if args:
            self.files = args

</t>
<t tx="ekr.20160315164542.148">def scan_options(self):
    '''Set all configuration-related ivars.'''
    trace = False
    if not self.config_fn:
        return
    self.parser = parser = self.create_parser()
    s = self.get_config_string()
    self.init_parser(s)
    if self.files:
        files_source = 'command-line'
        files = self.files
    elif parser.has_section('Global'):
        files_source = 'config file'
        files = parser.get('Global', 'files')
        files = [z.strip() for z in files.split('\n') if z.strip()]
    else:
        return
    files2 = []
    for z in files:
        files2.extend(glob.glob(self.finalize(z)))
    self.files = [z for z in files2 if z and os.path.exists(z)]
    if trace:
        print('Files (from %s)...\n' % files_source)
        for z in self.files:
            print(z)
        print('')
    if 'output_directory' in parser.options('Global'):
        s = parser.get('Global', 'output_directory')
        output_dir = self.finalize(s)
        if os.path.exists(output_dir):
            self.output_directory = output_dir
            if self.verbose:
                print('output directory: %s\n' % output_dir)
        else:
            print('output directory not found: %s\n' % output_dir)
            self.output_directory = None # inhibit run().
    if 'prefix_lines' in parser.options('Global'):
        prefix = parser.get('Global', 'prefix_lines')
        self.prefix_lines = prefix.split('\n')
            # The parser does not preserve leading whitespace.
        if trace:
            print('Prefix lines...\n')
            for z in self.prefix_lines:
                print(z)
            print('')
    self.def_patterns = self.scan_patterns('Def Name Patterns')
    self.general_patterns = self.scan_patterns('General Patterns')
    self.make_patterns_dict()

</t>
<t tx="ekr.20160315164542.149">def make_op_name_dict(self):
    '''
    Make a dict whose keys are operators ('+', '+=', etc),
    and whose values are lists of values of ast.Node.__class__.__name__.
    '''
    d = {
        '.':   ['Attr',],
        '(*)': ['Call', 'Tuple',],
        '[*]': ['List', 'Subscript',],
        '{*}': ['???',],
        ### 'and': 'BoolOp',
        ### 'or':  'BoolOp',
    }
    for op in (
        '+', '-', '*', '/', '%', '**', '&lt;&lt;',
        '&gt;&gt;', '|', '^', '&amp;', '//',
    ):
        d[op] = ['BinOp',]
    for op in (
        '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=',
        'is', 'is not', 'in', 'not in',
    ):
        d[op] = ['Compare',]
    return d

</t>
<t tx="ekr.20160315164542.15">class AstFormatter:
    '''
    A class to recreate source code from an AST.
    
    This does not have to be perfect, but it should be close.
    '''
    @others
</t>
<t tx="ekr.20160315164542.150">def create_parser(self):
    '''Create a RawConfigParser and return it.'''
    parser = configparser.RawConfigParser(dict_type=OrderedDict)
        # Requires Python 2.7
    parser.optionxform = str
    return parser

</t>
<t tx="ekr.20160315164542.151">def find_pattern_ops(self, pattern):
    '''Return a list of operators in pattern.find_s.'''
    trace = False or self.trace_patterns
    if pattern.is_regex():
        return []
            # The special characters in the regex
            # do not correspond to Python operators!
    d = self.op_name_dict
    keys1, keys2, keys3, keys9 = [], [], [], []
    for op in d:
        aList = d.get(op)
        if op.replace(' ','').isalnum():
            # an alpha op, like 'not, 'not in', etc.
            keys9.append(op)
        elif len(op) == 3:
            keys3.append(op)
        elif len(op) == 2:
            keys2.append(op)
        elif len(op) == 1:
            keys1.append(op)
        else:
            g.trace('bad op', op)
    ops = []
    s = s1 = pattern.find_s
    for aList in (keys3, keys2, keys1):
        for op in aList:
            # Must match word here!
            if s.find(op) &gt; -1:
                s = s.replace(op, '')
                ops.append(op)
    # Handle the keys9 list very carefully.
    for op in keys9:
        target = ' %s ' % op
        if s.find(target) &gt; -1:
            ops.append(op)
            break # Only one match allowed.
            
    if trace and ops: g.trace(s1, ops)
    return ops

</t>
<t tx="ekr.20160315164542.152">def get_config_string(self):
    
    fn = self.finalize(self.config_fn)
    if os.path.exists(fn):
        if self.verbose:
            print('\nconfiguration file: %s\n' % fn)
        f = open(fn, 'r')
        s = f.read()
        f.close()
        return s
    else:
        print('\nconfiguration file not found: %s' % fn)
        return ''
    

</t>
<t tx="ekr.20160315164542.153">def init_parser(self, s):
    '''Add double back-slashes to all patterns starting with '['.'''
    trace = False
    if not s: return
    aList = []
    for s in s.split('\n'):
        if self.is_section_name(s):
            aList.append(s)
        elif s.strip().startswith('['):
            aList.append(r'\\'+s[1:])
            if trace: g.trace('*** escaping:',s)
        else:
            aList.append(s)
    s = '\n'.join(aList)+'\n'
    if trace: g.trace(s)
    file_object = io.StringIO(s)
    self.parser.readfp(file_object)

</t>
<t tx="ekr.20160315164542.154">def is_section_name(self, s):
    
    def munge(s):
        return s.strip().lower().replace(' ','')
    
    s = s.strip()
    if s.startswith('[') and s.endswith(']'):
        s = munge(s[1:-1])
        for s2 in self.section_names:
            if s == munge(s2):
                return True
    return False

</t>
<t tx="ekr.20160315164542.155">def make_patterns_dict(self):
    '''Assign all patterns to the appropriate ast.Node.'''
    trace = False or self.trace_patterns
    for pattern in self.general_patterns:
        ops = self.find_pattern_ops(pattern)
        if ops:
            for op in ops:
                # Add the pattern to op's list.
                op_names = self.op_name_dict.get(op)
                for op_name in op_names:
                    aList = self.patterns_dict.get(op_name, [])
                    aList.append(pattern)
                    self.patterns_dict[op_name] = aList
        else:
            # Enter the name in self.names_dict.
            name = pattern.find_s
            # Special case for 'number'
            if name == 'number':
                aList = self.patterns_dict.get('Num', [])
                aList.append(pattern)
                self.patterns_dict['Num'] = aList
            elif name in self.names_dict:
                g.trace('duplicate pattern', pattern)
            else:
                self.names_dict [name] = pattern.repl_s
    if 0:
        g.trace('names_dict...')
        for z in sorted(self.names_dict):
            print('  %s: %s' % (z, self.names_dict.get(z)))
    if 0:
        g.trace('patterns_dict...')
        for z in sorted(self.patterns_dict):
            aList = self.patterns_dict.get(z)
            print(z)
            for pattern in sorted(aList):
                print('  '+repr(pattern))
    # Note: retain self.general_patterns for use in argument lists.

</t>
<t tx="ekr.20160315164542.156">def scan_patterns(self, section_name):
    '''Parse the config section into a list of patterns, preserving order.'''
    trace = False or self.trace_patterns
    parser = self.parser
    aList = []
    if parser.has_section(section_name):
        seen = set()
        for key in parser.options(section_name):
            value = parser.get(section_name, key)
            # A kludge: strip leading \\ from patterns.
            if key.startswith(r'\\'):
                key = '[' + key[2:]
                if trace: g.trace('removing escapes', key)
            if key in seen:
                g.trace('duplicate key', key)
            else:
                seen.add(key)
                aList.append(Pattern(key, value))
        if trace:
            g.trace('%s...\n' % section_name)
            for z in aList:
                print(z)
            print('')
    # elif trace:
        # print('no section: %s' % section_name)
        # print(parser.sections())
        # print('')
    return aList


</t>
<t tx="ekr.20160315164542.157">class Stub(object):
    '''
    A class representing all the generated stub for a class or def.
    stub.full_name should represent the complete context of a def.
    '''
    @others
</t>
<t tx="ekr.20160315164542.158">
def __init__(self, kind, name, parent=None, stack=None):
    '''Stub ctor. Equality depends only on full_name and kind.'''
    self.children = []
    self.full_name = '%s.%s' % ('.'.join(stack), name) if stack else name
    self.kind = kind
    self.name = name
    self.out_list = []
    self.parent = parent
    self.stack = stack # StubTraverser.context_stack.
    if stack:
        assert stack[-1] == parent.name, (stack[-1], parent.name)
    if parent:
        assert isinstance(parent, Stub)
        parent.children.append(self)

</t>
<t tx="ekr.20160315164542.159">def __eq__(self, obj):
    '''
    Stub.__eq__. Return whether two stubs refer to the same method.
    Do *not* test parent links. That would interfere with --update logic.
    '''
    if isinstance(obj, Stub):
        return self.full_name == obj.full_name and self.kind == obj.kind
    else:
        return NotImplemented

</t>
<t tx="ekr.20160315164542.16"># pylint: disable=consider-using-enumerate

# Entries...

</t>
<t tx="ekr.20160315164542.160">def __ne__(self, obj):
    """Stub.__ne__"""
    return not self.__eq__(obj)

</t>
<t tx="ekr.20160315164542.161">def __hash__(self):
    '''Stub.__hash__. Equality depends *only* on full_name and kind.'''
    return len(self.kind) + sum([ord(z) for z in self.full_name])

</t>
<t tx="ekr.20160315164542.162">def __repr__(self):
    '''Stub.__repr__.'''
    return 'Stub: %s %s' % (id(self), self.full_name)
    
</t>
<t tx="ekr.20160315164542.163">def __str__(self):
    '''Stub.__repr__.'''
    return 'Stub: %s' % self.full_name

</t>
<t tx="ekr.20160315164542.164">def level(self):
    '''Return the number of parents.'''
    return len(self.parents())
    
</t>
<t tx="ekr.20160315164542.165">def parents(self):
    '''Return a list of this stub's parents.'''
    return self.full_name.split('.')[:-1]


</t>
<t tx="ekr.20160315164542.166">class StubFormatter (AstFormatter):
    '''
    Formats an ast.Node and its descendants,
    making pattern substitutions in Name and operator nodes.
    '''
    @others
</t>
<t tx="ekr.20160315164542.167">
def __init__(self, controller, traverser):
    '''Ctor for StubFormatter class.'''
    self.controller = x = controller
    self.traverser = traverser
        # 2016/02/07: to give the formatter access to the class_stack.
    self.def_patterns = x.def_patterns
    self.general_patterns = x.general_patterns
    self.names_dict = x.names_dict
    self.patterns_dict = x.patterns_dict
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose

</t>
<t tx="ekr.20160315164542.17">def format(self, node):
    '''Format the node (or list of nodes) and its descendants.'''
    self.level = 0
    val = self.visit(node)
    return val and val.strip() or ''

</t>
<t tx="ekr.20160315164542.18">def visit(self, node):
    '''Return the formatted version of an Ast node, or list of Ast nodes.'''
    if isinstance(node, (list, tuple)):
        return ','.join([self.visit(z) for z in node])
    elif node is None:
        return 'None'
    else:
        assert isinstance(node, ast.AST), node.__class__.__name__
        method_name = 'do_' + node.__class__.__name__
        method = getattr(self, method_name)
        s = method(node)
        # pylint: disable=unidiomatic-typecheck
        assert type(s) == type('abc'), (node, type(s))
        return s

</t>
<t tx="ekr.20160315164542.19"># Contexts...

# ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

</t>
<t tx="ekr.20160315164542.2"># Top-level functions

</t>
<t tx="ekr.20160315164542.20">def do_ClassDef(self, node):
    result = []
    name = node.name # Only a plain string is valid.
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if bases:
        result.append(self.indent('class %s(%s):\n' % (name, ','.join(bases))))
    else:
        result.append(self.indent('class %s:\n' % name))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.21"># FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)

</t>
<t tx="ekr.20160315164542.22">def do_FunctionDef(self, node):
    '''Format a FunctionDef node.'''
    result = []
    if node.decorator_list:
        for z in node.decorator_list:
            result.append('@%s\n' % self.visit(z))
    name = node.name # Only a plain string is valid.
    args = self.visit(node.args) if node.args else ''
    result.append(self.indent('def %s(%s):\n' % (name, args)))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.23">def do_Interactive(self, node):
    for z in node.body:
        self.visit(z)

</t>
<t tx="ekr.20160315164542.24">def do_Module(self, node):
    assert 'body' in node._fields
    result = ''.join([self.visit(z) for z in node.body])
    return result # 'module:\n%s' % (result)

</t>
<t tx="ekr.20160315164542.25">def do_Lambda(self, node):
    return self.indent('lambda %s: %s' % (
        self.visit(node.args),
        self.visit(node.body)))

</t>
<t tx="ekr.20160315164542.26"># Expressions...

</t>
<t tx="ekr.20160315164542.27">def do_Expr(self, node):
    '''An outer expression: must be indented.'''
    return self.indent('%s\n' % self.visit(node.value))

</t>
<t tx="ekr.20160315164542.28">def do_Expression(self, node):
    '''An inner expression: do not indent.'''
    return '%s\n' % self.visit(node.body)

</t>
<t tx="ekr.20160315164542.29">def do_GeneratorExp(self, node):
    elt = self.visit(node.elt) or ''
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens] # Kludge: probable bug.
    return '&lt;gen %s for %s&gt;' % (elt, ','.join(gens))

</t>
<t tx="ekr.20160315164542.3">def dump(title, s=None):
    if s:
        print('===== %s...\n%s\n' % (title, s.rstrip()))
    else:
        print('===== %s...\n' % title)

</t>
<t tx="ekr.20160315164542.30">def do_AugLoad(self, node):
    return 'AugLoad'

</t>
<t tx="ekr.20160315164542.31">def do_Del(self, node):
    return 'Del'

</t>
<t tx="ekr.20160315164542.32">def do_Load(self, node):
    return 'Load'

</t>
<t tx="ekr.20160315164542.33">def do_Param(self, node):
    return 'Param'

</t>
<t tx="ekr.20160315164542.34">def do_Store(self, node):
    return 'Store'

</t>
<t tx="ekr.20160315164542.35"># Operands...

# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

</t>
<t tx="ekr.20160315164542.36">def do_arguments(self, node):
    '''Format the arguments node.'''
    kind = self.kind(node)
    assert kind == 'arguments', kind
    args = [self.visit(z) for z in node.args]
    defaults = [self.visit(z) for z in node.defaults]
    # Assign default values to the last args.
    args2 = []
    n_plain = len(args) - len(defaults)
    for i in range(len(args)):
        if i &lt; n_plain:
            args2.append(args[i])
        else:
            args2.append('%s=%s' % (args[i], defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name: args2.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name: args2.append('**' + name)
    return ','.join(args2)

</t>
<t tx="ekr.20160315164542.37"># Python 3:
# arg = (identifier arg, expr? annotation)

</t>
<t tx="ekr.20160315164542.38">def do_arg(self, node):
    return node.arg

</t>
<t tx="ekr.20160315164542.39"># Attribute(expr value, identifier attr, expr_context ctx)

</t>
<t tx="ekr.20160315164542.4">def dump_dict(title, d):
    '''Dump a dictionary with a header.'''
    dump(title)
    for z in sorted(d):
        print('%30s %s' % (z, d.get(z)))
    print('')

</t>
<t tx="ekr.20160315164542.40">def do_Attribute(self, node):
    return '%s.%s' % (
        self.visit(node.value),
        node.attr) # Don't visit node.attr: it is always a string.

</t>
<t tx="ekr.20160315164542.41">def do_Bytes(self, node): # Python 3.x only.
    return str(node.s)

</t>
<t tx="ekr.20160315164542.42"># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

</t>
<t tx="ekr.20160315164542.43">def do_Call(self, node):
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z] # Kludge: Defensive coding.
    return '%s(%s)' % (func, ','.join(args))

</t>
<t tx="ekr.20160315164542.44"># keyword = (identifier arg, expr value)

</t>
<t tx="ekr.20160315164542.45">def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)

</t>
<t tx="ekr.20160315164542.46">def do_comprehension(self, node):
    result = []
    name = self.visit(node.target) # A name.
    it = self.visit(node.iter) # An attribute.
    result.append('%s in %s' % (name, it))
    ifs = [self.visit(z) for z in node.ifs]
    if ifs:
        result.append(' if %s' % (''.join(ifs)))
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.47">def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        # result.append('{\n' if keys else '{')
        result.append('{')
        items = []
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
        # result.append(',\n'.join(items))
        # result.append('\n}' if keys else '}')
    else:
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.48">def do_Ellipsis(self, node):
    return '...'

</t>
<t tx="ekr.20160315164542.49">def do_ExtSlice(self, node):
    return ':'.join([self.visit(z) for z in node.dims])

</t>
<t tx="ekr.20160315164542.5">def dump_list(title, aList):
    '''Dump a list with a header.'''
    dump(title)
    for z in aList:
        print(z)
    print('')

</t>
<t tx="ekr.20160315164542.50">def do_Index(self, node):
    return self.visit(node.value)

</t>
<t tx="ekr.20160315164542.51">def do_List(self, node):
    # Not used: list context.
    # self.visit(node.ctx)
    elts = [self.visit(z) for z in node.elts]
    elst = [z for z in elts if z] # Defensive.
    return '[%s]' % ','.join(elts)

</t>
<t tx="ekr.20160315164542.52">def do_ListComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens] # Kludge: probable bug.
    return '%s for %s' % (elt, ''.join(gens))

</t>
<t tx="ekr.20160315164542.53">def do_Name(self, node):
    return node.id

</t>
<t tx="ekr.20160315164542.54">def do_NameConstant(self, node): # Python 3 only.
    s = repr(node.value)
    return 'bool' if s in ('True', 'False') else s

</t>
<t tx="ekr.20160315164542.55">def do_Num(self, node):
    return repr(node.n)

</t>
<t tx="ekr.20160315164542.56"># Python 2.x only

</t>
<t tx="ekr.20160315164542.57">def do_Repr(self, node):
    return 'repr(%s)' % self.visit(node.value)

</t>
<t tx="ekr.20160315164542.58">def do_Slice(self, node):
    lower, upper, step = '', '', ''
    if getattr(node, 'lower', None) is not None:
        lower = self.visit(node.lower)
    if getattr(node, 'upper', None) is not None:
        upper = self.visit(node.upper)
    if getattr(node, 'step', None) is not None:
        step = self.visit(node.step)
    if step:
        return '%s:%s:%s' % (lower, upper, step)
    else:
        return '%s:%s' % (lower, upper)

</t>
<t tx="ekr.20160315164542.59">def do_Str(self, node):
    '''This represents a string constant.'''
    return repr(node.s)

</t>
<t tx="ekr.20160315164542.6">def is_known_type(s):
    '''
    Return True if s is nothing but a single known type.
    Recursively test inner types in square brackets.
    '''
    trace = False
    s1 = s
    s = s.strip()
    table = (
        # None,
        'None', 
        'complex', 'float', 'int', 'long', 'number',
        'dict', 'list', 'tuple',
        'bool', 'bytes', 'str', 'unicode',
    )
    for s2 in table:
        if s2 == s:
            return True
        elif Pattern(s2+'(*)', s).match_entire_string(s):
            return True
    if s.startswith('[') and s.endswith(']'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('(') and s.endswith(')'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('{') and s.endswith('}'):
        return True ### Not yet.
        # inner = s[1:-1]
        # return is_known_type(inner) if inner else True
    table = (
        # Pep 484: https://www.python.org/dev/peps/pep-0484/
        # typing module: https://docs.python.org/3/library/typing.html
        'AbstractSet', 'Any', 'AnyMeta', 'AnyStr',
        'BinaryIO', 'ByteString',
        'Callable', 'CallableMeta', 'Container',
        'Dict', 'Final', 'Generic', 'GenericMeta', 'Hashable',
        'IO', 'ItemsView', 'Iterable', 'Iterator',
        'KT', 'KeysView', 'List',
        'Mapping', 'MappingView', 'Match',
        'MutableMapping', 'MutableSequence', 'MutableSet',
        'NamedTuple', 'Optional', 'OptionalMeta',
        # 'POSIX', 'PY2', 'PY3',
        'Pattern', 'Reversible',
        'Sequence', 'Set', 'Sized',
        'SupportsAbs', 'SupportsFloat', 'SupportsInt', 'SupportsRound',
        'T', 'TextIO', 'Tuple', 'TupleMeta',
        'TypeVar', 'TypingMeta',
        'Undefined', 'Union', 'UnionMeta',
        'VT', 'ValuesView', 'VarBinding',
    )
    for s2 in table:
        if s2 == s:
            return True
        pattern = Pattern(s2+'[*]', s)
        if pattern.match_entire_string(s):
            # Look inside the square brackets.
            brackets = s[len(s2):]
            assert brackets and brackets[0] == '[' and brackets[-1] == ']'
            s3 = brackets[1:-1]
            if s3:
                return all([is_known_type(z.strip())
                    for z in split_types(s3)])
            else:
                return True
    if trace: g.trace('Fail:', s1)
    return False

</t>
<t tx="ekr.20160315164542.60"># Subscript(expr value, slice slice, expr_context ctx)

</t>
<t tx="ekr.20160315164542.61">def do_Subscript(self, node):
    value = self.visit(node.value)
    the_slice = self.visit(node.slice)
    return '%s[%s]' % (value, the_slice)

</t>
<t tx="ekr.20160315164542.62">def do_Tuple(self, node):
    elts = [self.visit(z) for z in node.elts]
    return '(%s)' % ', '.join(elts)

</t>
<t tx="ekr.20160315164542.63"># Operators...

</t>
<t tx="ekr.20160315164542.64">def do_BinOp(self, node):
    return '%s%s%s' % (
        self.visit(node.left),
        self.op_name(node.op),
        self.visit(node.right))

</t>
<t tx="ekr.20160315164542.65">def do_BoolOp(self, node):
    op_name = self.op_name(node.op)
    values = [self.visit(z) for z in node.values]
    return op_name.join(values)

</t>
<t tx="ekr.20160315164542.66">def do_Compare(self, node):
    result = []
    lt = self.visit(node.left)
    ops = [self.op_name(z) for z in node.ops]
    comps = [self.visit(z) for z in node.comparators]
    result.append(lt)
    if len(ops) == len(comps):
        for i in range(len(ops)):
            result.append('%s%s' % (ops[i], comps[i]))
    else:
        print('can not happen: ops', repr(ops), 'comparators', repr(comps))
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.67">def do_UnaryOp(self, node):
    return '%s%s' % (
        self.op_name(node.op),
        self.visit(node.operand))

</t>
<t tx="ekr.20160315164542.68">def do_IfExp(self, node):
    return '%s if %s else %s ' % (
        self.visit(node.body),
        self.visit(node.test),
        self.visit(node.orelse))

</t>
<t tx="ekr.20160315164542.69"># Statements...

</t>
<t tx="ekr.20160315164542.7">def main():
    '''
    The driver for the stand-alone version of make-stub-files.
    All options come from ~/stubs/make_stub_files.cfg.
    '''
    # g.cls()
    controller = StandAloneMakeStubFile()
    controller.scan_command_line()
    controller.scan_options()
    controller.run()
    print('done')

</t>
<t tx="ekr.20160315164542.70">def do_Assert(self, node):
    test = self.visit(node.test)
    if getattr(node, 'msg', None):
        message = self.visit(node.msg)
        return self.indent('assert %s, %s' % (test, message))
    else:
        return self.indent('assert %s' % test)

</t>
<t tx="ekr.20160315164542.71">def do_Assign(self, node):
    return self.indent('%s=%s\n' % (
        '='.join([self.visit(z) for z in node.targets]),
        self.visit(node.value)))

</t>
<t tx="ekr.20160315164542.72">def do_AugAssign(self, node):
    return self.indent('%s%s=%s\n' % (
        self.visit(node.target),
        self.op_name(node.op), # Bug fix: 2013/03/08.
        self.visit(node.value)))

</t>
<t tx="ekr.20160315164542.73">def do_Break(self, node):
    return self.indent('break\n')

</t>
<t tx="ekr.20160315164542.74">def do_Continue(self, node):
    return self.indent('continue\n')

</t>
<t tx="ekr.20160315164542.75">def do_Delete(self, node):
    targets = [self.visit(z) for z in node.targets]
    return self.indent('del %s\n' % ','.join(targets))

</t>
<t tx="ekr.20160315164542.76">def do_ExceptHandler(self, node):
    result = []
    result.append(self.indent('except'))
    if getattr(node, 'type', None):
        result.append(' %s' % self.visit(node.type))
    if getattr(node, 'name', None):
        if isinstance(node.name, ast.AST):
            result.append(' as %s' % self.visit(node.name))
        else:
            result.append(' as %s' % node.name) # Python 3.x.
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.77"># Python 2.x only

</t>
<t tx="ekr.20160315164542.78">def do_Exec(self, node):
    body = self.visit(node.body)
    args = [] # Globals before locals.
    if getattr(node, 'globals', None):
        args.append(self.visit(node.globals))
    if getattr(node, 'locals', None):
        args.append(self.visit(node.locals))
    if args:
        return self.indent('exec %s in %s\n' % (
            body, ','.join(args)))
    else:
        return self.indent('exec %s\n' % (body))

</t>
<t tx="ekr.20160315164542.79">def do_For(self, node):
    result = []
    result.append(self.indent('for %s in %s:\n' % (
        self.visit(node.target),
        self.visit(node.iter))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.8">def merge_types(a1, a2):
    '''
    a1 and a2 may be strings or lists.
    return a list containing both of them, flattened, without duplicates.
    '''
    # Not used at present, and perhaps never.
    # Only useful if visitors could return either lists or strings.
    assert a1 is not None
    assert a2 is not None
    r1 = a1 if isinstance(a1, (list, tuple)) else [a1]
    r2 = a2 if isinstance(a2, (list, tuple)) else [a2]
    return sorted(set(r1 + r2))

</t>
<t tx="ekr.20160315164542.80">def do_Global(self, node):
    return self.indent('global %s\n' % (
        ','.join(node.names)))

</t>
<t tx="ekr.20160315164542.81">def do_If(self, node):
    result = []
    result.append(self.indent('if %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.82">def do_Import(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('import %s\n' % (
        ','.join(names)))

</t>
<t tx="ekr.20160315164542.83">def get_import_names(self, node):
    '''Return a list of the the full file names in the import statement.'''
    result = []
    for ast2 in node.names:
        if self.kind(ast2) == 'alias':
            data = ast2.name, ast2.asname
            result.append(data)
        else:
            print('unsupported kind in Import.names list', self.kind(ast2))
    return result

</t>
<t tx="ekr.20160315164542.84">def do_ImportFrom(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('from %s import %s\n' % (
        node.module,
        ','.join(names)))

</t>
<t tx="ekr.20160315164542.85">def do_Pass(self, node):
    return self.indent('pass\n')

</t>
<t tx="ekr.20160315164542.86"># Python 2.x only

</t>
<t tx="ekr.20160315164542.87">def do_Print(self, node):
    vals = []
    for z in node.values:
        vals.append(self.visit(z))
    if getattr(node, 'dest', None):
        vals.append('dest=%s' % self.visit(node.dest))
    if getattr(node, 'nl', None):
        vals.append('nl=%s' % node.nl)
    return self.indent('print(%s)\n' % (
        ','.join(vals)))

</t>
<t tx="ekr.20160315164542.88">def do_Raise(self, node):
    args = []
    for attr in ('type', 'inst', 'tback'):
        if getattr(node, attr, None) is not None:
            args.append(self.visit(getattr(node, attr)))
    if args:
        return self.indent('raise %s\n' % (
            ','.join(args)))
    else:
        return self.indent('raise\n')

</t>
<t tx="ekr.20160315164542.89">def do_Return(self, node):
    if node.value:
        return self.indent('return %s\n' % (
            self.visit(node.value)))
    else:
        return self.indent('return\n')

</t>
<t tx="ekr.20160315164542.9">def pdb(self):
    '''Invoke a debugger during unit testing.'''
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()

</t>
<t tx="ekr.20160315164542.90">def do_TryExcept(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.91">def do_TryFinally(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append(self.indent('finally:\n'))
    for z in node.finalbody:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.92">def do_While(self, node):
    result = []
    result.append(self.indent('while %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.93">def do_With(self, node):
    result = []
    result.append(self.indent('with '))
    if hasattr(node, 'context_expression'):
        result.append(self.visit(node.context_expresssion))
    vars_list = []
    if hasattr(node, 'optional_vars'):
        try:
            for z in node.optional_vars:
                vars_list.append(self.visit(z))
        except TypeError: # Not iterable.
            vars_list.append(self.visit(node.optional_vars))
    result.append(','.join(vars_list))
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append('\n')
    return ''.join(result)

</t>
<t tx="ekr.20160315164542.94">def do_Yield(self, node):
    if getattr(node, 'value', None):
        return self.indent('yield %s\n' % (
            self.visit(node.value)))
    else:
        return self.indent('yield\n')

</t>
<t tx="ekr.20160315164542.95"># Utils...

</t>
<t tx="ekr.20160315164542.96">def kind(self, node):
    '''Return the name of node's class.'''
    return node.__class__.__name__

</t>
<t tx="ekr.20160315164542.97">def indent(self, s):
    return '%s%s' % (' ' * 4 * self.level, s)

</t>
<t tx="ekr.20160315164542.98">def op_name (self,node,strict=True):
    '''Return the print name of an operator node.'''
    d = {
        # Binary operators. 
        'Add':       '+',
        'BitAnd':    '&amp;',
        'BitOr':     '|',
        'BitXor':    '^',
        'Div':       '/',
        'FloorDiv':  '//',
        'LShift':    '&lt;&lt;',
        'Mod':       '%',
        'Mult':      '*',
        'Pow':       '**',
        'RShift':    '&gt;&gt;',
        'Sub':       '-',
        # Boolean operators.
        'And':   ' and ',
        'Or':    ' or ',
        # Comparison operators
        'Eq':    '==',
        'Gt':    '&gt;',
        'GtE':   '&gt;=',
        'In':    ' in ',
        'Is':    ' is ',
        'IsNot': ' is not ',
        'Lt':    '&lt;',
        'LtE':   '&lt;=',
        'NotEq': '!=',
        'NotIn': ' not in ',
        # Context operators.
        'AugLoad':  '&lt;AugLoad&gt;',
        'AugStore': '&lt;AugStore&gt;',
        'Del':      '&lt;Del&gt;',
        'Load':     '&lt;Load&gt;',
        'Param':    '&lt;Param&gt;',
        'Store':    '&lt;Store&gt;',
        # Unary operators.
        'Invert':   '~',
        'Not':      ' not ',
        'UAdd':     '+',
        'USub':     '-',
    }
    name = d.get(self.kind(node),'&lt;%s&gt;' % node.__class__.__name__)
    if strict: assert name,self.kind(node)
    return name


</t>
<t tx="ekr.20160315164542.99">class AstArgFormatter (AstFormatter):
    '''
    Just like the AstFormatter class, except it prints the class
    names of constants instead of actual values.
    '''
    @others
</t>
<t tx="ekr.20160315164543.1">matched_d = {}

</t>
<t tx="ekr.20160315164543.10">def do_Str(self, node):
    '''This represents a string constant.'''
    return 'str' # return repr(node.s)

</t>
<t tx="ekr.20160315164543.11">def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        result.append('{')
        items = []
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
    else:
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    # return ''.join(result)
    return 'Dict[%s]' % ''.join(result)

</t>
<t tx="ekr.20160315164543.12">def do_List(self, node):
    '''StubFormatter.List.'''
    elts = [self.visit(z) for z in node.elts]
    elst = [z for z in elts if z] # Defensive.
    # g.trace('=====',elts)
    return 'List[%s]' % ', '.join(elts)

</t>
<t tx="ekr.20160315164543.13">seen_names = []

</t>
<t tx="ekr.20160315164543.14">def do_Name(self, node):
    '''StubFormatter ast.Name visitor.'''
    trace = False
    d = self.names_dict
    name = d.get(node.id, node.id)
    s = 'bool' if name in ('True', 'False') else name
    if trace and node.id not in self.seen_names:
        self.seen_names.append(node.id)
        if d.get(node.id):
            g.trace(node.id, '==&gt;', d.get(node.id))
        elif node.id == 'aList':
            g.trace('**not found**', node.id)
    return s

</t>
<t tx="ekr.20160315164543.15">def do_Tuple(self, node):
    '''StubFormatter.Tuple.'''
    elts = [self.visit(z) for z in node.elts]
    if 1:
        return 'Tuple[%s]' % ', '.join(elts)
    else:
        s = '(%s)' % ', '.join(elts)
        return self.match_all(node, s)
    # return 'Tuple[%s]' % ', '.join(elts)

</t>
<t tx="ekr.20160315164543.16"># StubFormatter visitors for operators...

# BinOp(expr left, operator op, expr right)

</t>
<t tx="ekr.20160315164543.17">def do_BinOp(self, node):
    '''StubFormatter.BinOp visitor.'''
    trace = False or self.trace_reduce ; verbose = False
    numbers = ['number', 'complex', 'float', 'long', 'int',]
    op = self.op_name(node.op)
    lhs = self.visit(node.left)
    rhs = self.visit(node.right)
    if op.strip() in ('is', 'is not', 'in', 'not in'):
        s = 'bool'
    elif lhs == rhs:
        s = lhs
            # Perhaps not always right,
            # but it is correct for Tuple, List, Dict.
    elif lhs in numbers and rhs in numbers:
        s = reduce_types([lhs, rhs], trace=trace)
            # reduce_numbers would be wrong: it returns a list.
    elif lhs == 'str' and op in '%+*':
        # str + any implies any is a string.
        s = 'str'
    else:
        if trace and verbose and lhs == 'str':
            g.trace('***** unknown string op', lhs, op, rhs)
        # Fall back to the base-class behavior.
        s = '%s%s%s' % (
            self.visit(node.left),
            op,
            self.visit(node.right))
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s

</t>
<t tx="ekr.20160315164543.18"># BoolOp(boolop op, expr* values)

</t>
<t tx="ekr.20160315164543.19">def do_BoolOp(self, node): # Python 2.x only.
    '''StubFormatter.BoolOp visitor for 'and' and 'or'.'''
    trace = False or self.trace_reduce
    op = self.op_name(node.op)
    values = [self.visit(z).strip() for z in node.values]
    s = reduce_types(values, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s

</t>
<t tx="ekr.20160315164543.2">def match_all(self, node, s):
    '''Match all the patterns for the given node.'''
    trace = False or self.trace_matches
    d = self.matched_d
    name = node.__class__.__name__
    s1 = truncate(s, 40)
    caller = g.callers(2).split(',')[1].strip()
        # The direct caller of match_all.
    for pattern in self.patterns_dict.get(name, []):
        found, s = pattern.match(s,trace=False)
        if found:
            if trace:
                aList = d.get(name, [])
                if pattern not in aList:
                    aList.append(pattern)
                    d [name] = aList
                    print('match_all:    %-12s %26s %40s ==&gt; %s' % (caller, pattern, s1, s))
            break
    return s

</t>
<t tx="ekr.20160315164543.20"># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

</t>
<t tx="ekr.20160315164543.21">def do_Call(self, node):
    '''StubFormatter.Call visitor.'''
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z] # Kludge: Defensive coding.
    # Explicit pattern:
    if func in ('dict', 'list', 'set', 'tuple',):
        s = '%s[%s]' % (func.capitalize(), ', '.join(args))
    else:
        s = '%s(%s)' % (func, ', '.join(args))
    s = self.match_all(node, s)
    self.trace_visitor(node, 'call', s)
    return s

</t>
<t tx="ekr.20160315164543.22"># keyword = (identifier arg, expr value)

</t>
<t tx="ekr.20160315164543.23">def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)

</t>
<t tx="ekr.20160315164543.24"># Compare(expr left, cmpop* ops, expr* comparators)

</t>
<t tx="ekr.20160315164543.25">def do_Compare(self, node):
    '''
    StubFormatter ast.Compare visitor for these ops:
    '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=', 'is', 'is not', 'in', 'not in',
    '''
    s = 'bool' # Correct regardless of arguments.
    ops = ','.join([self.op_name(z) for z in node.ops])
    self.trace_visitor(node, ops, s)
    return s

</t>
<t tx="ekr.20160315164543.26"># If(expr test, stmt* body, stmt* orelse)

</t>
<t tx="ekr.20160315164543.27">def do_IfExp(self, node):
    '''StubFormatterIfExp (ternary operator).'''
    trace = False or self.trace_reduce
    aList = [
        self.match_all(node, self.visit(node.body)),
        self.match_all(node, self.visit(node.orelse)),
    ]
    s = reduce_types(aList, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, 'if', s)
    return s

</t>
<t tx="ekr.20160315164543.28"># Subscript(expr value, slice slice, expr_context ctx)

</t>
<t tx="ekr.20160315164543.29">def do_Subscript(self, node):
    '''StubFormatter.Subscript.'''
    s = '%s[%s]' % (
        self.visit(node.value),
        self.visit(node.slice))
    s = self.match_all(node, s)
    self.trace_visitor(node, '[]', s)
    return s

</t>
<t tx="ekr.20160315164543.3">def visit(self, node):
    '''StubFormatter.visit: supports --verbose tracing.'''
    s = AstFormatter.visit(self, node)
    # if self.verbose:
        # g.trace('%12s %s' % (node.__class__.__name__,s))
    return s

</t>
<t tx="ekr.20160315164543.30"># UnaryOp(unaryop op, expr operand)

</t>
<t tx="ekr.20160315164543.31">def do_UnaryOp(self, node):
    '''StubFormatter.UnaryOp for unary +, -, ~ and 'not' operators.'''
    op = self.op_name(node.op)
    s = 'bool' if op.strip() is 'not' else self.visit(node.operand)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s

</t>
<t tx="ekr.20160315164543.32">def do_Return(self, node):
    '''
    StubFormatter ast.Return vsitor.
    Return only the return expression itself.
    '''
    s = AstFormatter.do_Return(self, node)
    assert s.startswith('return'), repr(s)
    return s[len('return'):].strip()


</t>
<t tx="ekr.20160315164543.33">class StubTraverser (ast.NodeVisitor):
    '''
    An ast.Node traverser class that outputs a stub for each class or def.
    Names of visitors must start with visit_. The order of traversal does
    not matter, because so few visitors do anything.
    '''
    @others
</t>
<t tx="ekr.20160315164543.34">
def __init__(self, controller):
    '''Ctor for StubTraverser class.'''
    self.controller = x = controller
        # A StandAloneMakeStubFile instance.
    # Internal state ivars...
    self.class_name_stack = []
    self.context_stack = []
    sf = StubFormatter(controller=controller,traverser=self)
    self.format = sf.format
    self.arg_format = AstArgFormatter().format
    self.level = 0
    self.output_file = None
    self.parent_stub = None
    self.raw_format = AstFormatter().format
    self.returns = []
    self.stubs_dict = {}
        # Keys are stub.full_name's.  Values are stubs.
    self.warn_list = []
    # Copies of controller ivars...
    self.output_fn = x.output_fn
    self.overwrite = x.overwrite
    self.prefix_lines = x.prefix_lines
    self.update_flag = x.update_flag
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
    self.warn = x.warn
    # Copies of controller patterns...
    self.def_patterns = x.def_patterns
    self.names_dict = x.names_dict
    self.general_patterns = x.general_patterns
    self.patterns_dict = x.patterns_dict
    

</t>
<t tx="ekr.20160315164543.35">def add_stub(self, d, stub):
    '''Add the stub to d, checking that it does not exist.'''
    trace = False ; verbose = False
    key = stub.full_name
    assert key
    if key in d:
        caller = g.callers(2).split(',')[1]
        g.trace('Ignoring duplicate entry for %s in %s' % (stub, caller))
    else:
        d [key] = stub
        if trace and verbose:
            caller = g.callers(2).split(',')[1]
            g.trace('%17s %s' % (caller, stub.full_name))
        elif trace:
            g.trace(stub.full_name)

</t>
<t tx="ekr.20160315164543.36">def indent(self, s):
    '''Return s, properly indented.'''
    # This version of indent *is* used.
    return '%s%s' % (' ' * 4 * self.level, s)

</t>
<t tx="ekr.20160315164543.37">def out(self, s):
    '''Output the string to the console or the file.'''
    s = self.indent(s)
    if self.parent_stub:
        self.parent_stub.out_list.append(s)
    elif self.output_file:
        self.output_file.write(s+'\n')
    else:
        print(s)

</t>
<t tx="ekr.20160315164543.38">def run(self, node):
    '''StubTraverser.run: write the stubs in node's tree to self.output_fn.'''
    fn = self.output_fn
    dir_ = os.path.dirname(fn)
    if os.path.exists(fn) and not self.overwrite:
        print('file exists: %s' % fn)
    elif not dir_ or os.path.exists(dir_):
        t1 = time.clock()
        # Delayed output allows sorting.
        self.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
        for z in self.prefix_lines or []:
            self.parent_stub.out_list.append(z)
        self.visit(node)
            # Creates parent_stub.out_list.
        if self.update_flag:
            self.parent_stub = self.update(fn, new_root=self.parent_stub)
        if 1:
            self.output_file = open(fn, 'w')
            self.output_time_stamp()
            self.output_stubs(self.parent_stub)
            self.output_file.close()
            self.output_file = None
            self.parent_stub = None
        t2 = time.clock()
        print('wrote: %s in %4.2f sec' % (fn, t2 - t1))
    else:
        print('output directory not not found: %s' % dir_)

</t>
<t tx="ekr.20160315164543.39">def output_stubs(self, stub):
    '''Output this stub and all its descendants.'''
    for s in stub.out_list or []:
        # Indentation must be present when an item is added to stub.out_list.
        if self.output_file:
            self.output_file.write(s.rstrip()+'\n')
        else:
            print(s)
    # Recursively print all children.
    for child in stub.children:
        self.output_stubs(child)

</t>
<t tx="ekr.20160315164543.4">def trace_visitor(self, node, op, s):
    '''Trace node's visitor.'''
    if self.trace_visitors:
        caller = g.callers(2).split(',')[1]
        s1 = AstFormatter().format(node).strip()
        print('%12s op %-6s: %s ==&gt; %s' % (caller, op.strip(), s1, s))

</t>
<t tx="ekr.20160315164543.40">def output_time_stamp(self):
    '''Put a time-stamp in the output file.'''
    if self.output_file:
        self.output_file.write('# make_stub_files: %s\n' %
            time.strftime("%a %d %b %Y at %H:%M:%S"))

</t>
<t tx="ekr.20160315164543.41">def update(self, fn, new_root):
    '''
    Merge the new_root tree with the old_root tree in fn (a .pyi file).

    new_root is the root of the stub tree from the .py file.
    old_root (read below) is the root of stub tree from the .pyi file.
    
    Return old_root, or new_root if there are any errors.
    '''
    trace = False ; verbose = False
    s = self.get_stub_file(fn)
    if not s or not s.strip():
        return new_root
    if '\t' in s:
        # Tabs in stub files make it impossible to parse them reliably.
        g.trace('Can not update stub files containing tabs.')
        return new_root
    # Read old_root from the .pyi file.
    old_d, old_root = self.parse_stub_file(s, root_name='&lt;old-stubs&gt;')
    if old_root:
        # Merge new stubs into the old tree.
        if trace and verbose:
            print(self.trace_stubs(old_root, header='old_root'))
            print(self.trace_stubs(new_root, header='new_root'))
        print('***** updating stubs from %s *****' % fn)
        self.merge_stubs(self.stubs_dict.values(), old_root, new_root)
        if trace:
            print(self.trace_stubs(old_root, header='updated_root'))
        return old_root
    else:
        return new_root

</t>
<t tx="ekr.20160315164543.42">def get_stub_file(self, fn):
    '''Read the stub file into s.'''
    if os.path.exists(fn):
        try:
            s = open(fn, 'r').read()
        except Exception:
            print('--update: error reading %s' % fn)
            s = None
        return s
    else:
        print('--update: not found: %s' % fn)
        return None

</t>
<t tx="ekr.20160315164543.43">def parse_stub_file(self, s, root_name):
    '''
    Parse s, the contents of a stub file, into a tree of Stubs.
    
    Parse by hand, so that --update can be run with Python 2.
    '''
    trace = False
    assert '\t' not in s
    d = {}
    root = Stub(kind='root', name=root_name)
    indent_stack = [-1] # To prevent the root from being popped.
    stub_stack = [root]
    lines = []
    pat = re.compile(r'^([ ]*)(def|class)\s+([a-zA-Z_]+)(.*)')
    for line in g.splitLines(s):
        m = pat.match(line)
        if m:
            indent, kind, name, rest = (
                len(m.group(1)), m.group(2), m.group(3), m.group(4))
            old_indent = indent_stack[-1]
            # Terminate any previous lines.
            old_stub = stub_stack[-1]
            old_stub.out_list.extend(lines)
            if trace:
                for s in lines:
                    g.trace('  '+s.rstrip())
            lines = [line]
            # Adjust the stacks.
            if indent == old_indent:
                stub_stack.pop()
            elif indent &gt; old_indent:
                indent_stack.append(indent)
            else: # indent &lt; old_indent
                # The indent_stack can't underflow because
                # indent &gt;= 0 and indent_stack[0] &lt; 0
                assert indent &gt;= 0
                while indent &lt;= indent_stack[-1]:
                    indent_stack.pop()
                    old_stub = stub_stack.pop()
                    assert old_stub != root
                indent_stack.append(indent)
            # Create and push the new stub *after* adjusting the stacks.
            assert stub_stack
            parent = stub_stack[-1]
            stack = [z.name for z in stub_stack[1:]]
            parent = stub_stack[-1]
            stub = Stub(kind, name, parent, stack)
            self.add_stub(d, stub)
            stub_stack.append(stub)
            if trace:
                g.trace('%s%5s %s %s' % (' '*indent, kind, name, rest))
        else:
            parent = stub_stack[-1]
            lines.append(line)
    # Terminate the last stub.
    old_stub = stub_stack[-1]
    old_stub.out_list.extend(lines)
    if trace:
        for s in lines:
            g.trace('  '+s.rstrip())
    return d, root

</t>
<t tx="ekr.20160315164543.44">def merge_stubs(self, new_stubs, old_root, new_root, trace=False):
    '''
    Merge the new_stubs *list* into the old_root *tree*.
    - new_stubs is a list of Stubs from the .py file.
    - old_root is the root of the stubs from the .pyi file.
    - new_root is the root of the stubs from the .py file.
    '''
    trace = False or trace ; verbose = False
    # Part 1: Delete old stubs do *not* exist in the *new* tree.
    aList = self.check_delete(new_stubs,
                              old_root,
                              new_root,
                              trace and verbose)
        # Checks that all ancestors of deleted nodes will be deleted.
    aList = list(reversed(self.sort_stubs_by_hierarchy(aList)))
        # Sort old stubs so that children are deleted before parents.
    if trace and verbose:
        dump_list('ordered delete list', aList)
    for stub in aList:
        if trace: g.trace('deleting  %s' % stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.remove(stub)
        assert not self.find_stub(stub, old_root), stub
    # Part 2: Insert new stubs that *not* exist in the *old* tree.
    aList = [z for z in new_stubs if not self.find_stub(z, old_root)]
    aList = self.sort_stubs_by_hierarchy(aList)
        # Sort new stubs so that parents are created before children.
    for stub in aList:
        if trace: g.trace('inserting %s' % stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.append(stub)
        assert self.find_stub(stub, old_root), stub

</t>
<t tx="ekr.20160315164543.45">def check_delete(self, new_stubs, old_root, new_root, trace):
    '''Return a list of nodes that can be deleted.'''
    old_stubs = self.flatten_stubs(old_root)
    old_stubs.remove(old_root)
    aList = [z for z in old_stubs if z not in new_stubs]
    if trace:
        dump_list('old_stubs', old_stubs)
        dump_list('new_stubs', new_stubs)
        dump_list('to-be-deleted stubs', aList)
    delete_list = []
    # Check that all parents of to-be-delete nodes will be deleted.
    for z in aList:
        z1 = z
        for i in range(20):
            z = z.parent
            if not z:
                g.trace('can not append: new root not found', z)
                break
            elif z == old_root:
                # if trace: g.trace('can delete', z1)
                delete_list.append(z1)
                break
            elif z not in aList:
                g.trace("can not delete %s because of %s" % (z1, z))
                break
        else:
            g.trace('can not happen: parent loop')
    if trace:
        dump_list('delete_list', delete_list)
    return delete_list

</t>
<t tx="ekr.20160315164543.46">def flatten_stubs(self, root):
    '''Return a flattened list of all stubs in root's tree.'''
    aList = [root]
    for child in root.children:
        self.flatten_stubs_helper(child, aList)
    return aList
        
</t>
<t tx="ekr.20160315164543.47">def flatten_stubs_helper(self, root, aList):
    '''Append all stubs in root's tree to aList.'''
    aList.append(root)
    for child in root.children:
        self.flatten_stubs_helper(child, aList)

</t>
<t tx="ekr.20160315164543.48">def find_parent_stub(self, stub, root):
    '''Return stub's parent **in root's tree**.'''
    return self.find_stub(stub.parent, root) if stub.parent else None

</t>
<t tx="ekr.20160315164543.49">def find_stub(self, stub, root):
    '''Return the stub **in root's tree** that matches stub.'''
    if stub == root: # Must use Stub.__eq__!
        return root # not stub!
    for child in root.children:
        stub2 = self.find_stub(stub, child)
        if stub2: return stub2
    return None

</t>
<t tx="ekr.20160315164543.5"># StubFormatter visitors for operands...

# Attribute(expr value, identifier attr, expr_context ctx)

attrs_seen = []

</t>
<t tx="ekr.20160315164543.50">def sort_stubs_by_hierarchy(self, stubs1):
    '''
    Sort the list of Stubs so that parents appear before all their
    descendants.
    '''
    stubs, result = stubs1[:], []
    for i in range(50):
        if stubs:
            # Add all stubs with i parents to the results.
            found = [z for z in stubs if z.level() == i]
            result.extend(found)
            for z in found:
                stubs.remove(z)
        else:
            return result
    g.trace('can not happen: unbounded stub levels.')
    return [] # Abort the merge.

</t>
<t tx="ekr.20160315164543.51">def trace_stubs(self, stub, aList=None, header=None, level=-1):
    '''Return a trace of the given stub and all its descendants.'''
    indent = ' '*4*max(0,level)
    if level == -1:
        aList = ['===== %s...\n' % (header) if header else '']
    for s in stub.out_list:
        aList.append('%s%s' % (indent, s.rstrip()))
    for child in stub.children:
        self.trace_stubs(child, level=level+1, aList=aList)
    if level == -1:
        return '\n'.join(aList) + '\n'

</t>
<t tx="ekr.20160315164543.52"># ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

</t>
<t tx="ekr.20160315164543.53">def visit_ClassDef(self, node):
    
    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.parent_stub = Stub('class', node.name,old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.class_name_stack.append(node.name)
    self.context_stack.append(node.name)
    if self.trace_matches or self.trace_reduce:
        print('\nclass %s\n' % node.name)
    # Format...
    if not node.name.startswith('_'):
        if node.bases:
            s = '(%s)' % ', '.join([self.format(z) for z in node.bases])
        else:
            s = ''
        self.out('class %s%s:' % (node.name, s))
    # Visit...
    self.level += 1
    for z in node.body:
        self.visit(z)
    self.context_stack.pop()
    self.class_name_stack.pop()
    self.level -= 1
    self.parent_stub = old_stub

</t>
<t tx="ekr.20160315164543.54"># FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)

</t>
<t tx="ekr.20160315164543.55">def visit_FunctionDef(self, node):

    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.parent_stub = Stub('def', node.name, old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.returns = []
    self.level += 1
    self.context_stack.append(node.name)
    for z in node.body:
        self.visit(z)
    self.context_stack.pop()
    self.level -= 1
    # Format *after* traversing
    # if self.trace_matches or self.trace_reduce:
        # if not self.class_name_stack:
            # print('def %s\n' % node.name)
    self.out('def %s(%s) -&gt; %s' % (
        node.name,
        self.format_arguments(node.args),
        self.format_returns(node)))
    self.parent_stub = old_stub

</t>
<t tx="ekr.20160315164543.56"># arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

</t>
<t tx="ekr.20160315164543.57">def format_arguments(self, node):
    '''
    Format the arguments node.
    Similar to AstFormat.do_arguments, but it is not a visitor!
    '''
    assert isinstance(node,ast.arguments), node
    args = [self.raw_format(z) for z in node.args]
    defaults = [self.raw_format(z) for z in node.defaults]
    # Assign default values to the last args.
    result = []
    n_plain = len(args) - len(defaults)
    # pylint: disable=consider-using-enumerate
    for i in range(len(args)):
        s = self.munge_arg(args[i])
        if i &lt; n_plain:
            result.append(s)
        else:
            result.append('%s=%s' % (s, defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name:
        if hasattr(ast, 'arg'): # python 3:
            name = self.raw_format(name)
        result.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name:
        if hasattr(ast, 'arg'): # python 3:
            name = self.raw_format(name)
        result.append('**' + name)
    return ', '.join(result)

</t>
<t tx="ekr.20160315164543.58">def munge_arg(self, s):
    '''Add an annotation for s if possible.'''
    if s == 'self':
        return s
    for pattern in self.general_patterns:
        if pattern.match_entire_string(s):
            return '%s: %s' % (s, pattern.repl_s)
    if self.warn and s not in self.warn_list:
        self.warn_list.append(s)
        print('no annotation for %s' % s)
    return s + ': Any'

</t>
<t tx="ekr.20160315164543.59">def format_returns(self, node):
    '''
    Calculate the return type:
    - Return None if there are no return statements.
    - Patterns in [Def Name Patterns] override all other patterns.
    - Otherwise, return a list of return values.
    '''
    trace = False
    name = self.get_def_name(node)
    raw = [self.raw_format(z) for z in self.returns]
    r = [self.format(z) for z in self.returns]
        # Allow StubFormatter.do_Return to do the hack.
    # Step 1: Return None if there are no return statements.
    if trace and self.returns:
        g.trace('name: %s r:\n%s' % (name, r))
    if not [z for z in self.returns if z.value != None]:
        return 'None: ...'
    # Step 2: [Def Name Patterns] override all other patterns.
    for pattern in self.def_patterns:
        found, s = pattern.match(name)
        if found:
            if trace:
                g.trace('*name pattern %s: %s -&gt; %s' % (
                    pattern.find_s, name, s))
            return s + ': ...'
    # Step 3: remove recursive calls.
    raw, r = self.remove_recursive_calls(name, raw, r)
    # Step 4: Calculate return types.
    return self.format_return_expressions(name, raw, r)

</t>
<t tx="ekr.20160315164543.6">def do_Attribute(self, node):
    '''StubFormatter.do_Attribute.'''
    trace = False
    s = '%s.%s' % (
        self.visit(node.value),
        node.attr) # Don't visit node.attr: it is always a string.
    s2 = self.names_dict.get(s)
    if trace and s2 and s2 not in self.attrs_seen:
        self.attrs_seen.append(s2)
        g.trace(s, '==&gt;', s2)
    return s2 or s

</t>
<t tx="ekr.20160315164543.60">def format_return_expressions(self, name, raw_returns, reduced_returns):
    '''
    aList is a list of maximally reduced return expressions.
    For each expression e in Alist:
    - If e is a single known type, add e to the result.
    - Otherwise, add Any # e to the result.
    Return the properly indented result.
    '''
    assert len(raw_returns) == len(reduced_returns)
    lws =  '\n' + ' '*4
    n = len(raw_returns)
    known = all([is_known_type(e) for e in reduced_returns])
    if not known or self.verbose:
        # First, generate the return lines.
        aList = []
        for i in range(n):
            e, raw = reduced_returns[i], raw_returns[i]
            known = ' ' if is_known_type(e) else '?'
            aList.append('# %s %s: %s' % (' ', i, raw))
            aList.append('# %s %s: return %s' % (known, i, e))
        results = ''.join([lws + self.indent(z) for z in aList])
        # Put the return lines in their proper places.
        if known:
            s = reduce_types(reduced_returns,
                             name=name,
                             trace=self.trace_reduce)
            return s + ': ...' + results
        else:
            return 'Any: ...' + results
    else:
        s = reduce_types(reduced_returns,
                         name=name,
                         trace=self.trace_reduce) 
        return s + ': ...'

</t>
<t tx="ekr.20160315164543.61">def get_def_name(self, node):
    '''Return the representaion of a function or method name.'''
    if self.class_name_stack:
        name = '%s.%s' % (self.class_name_stack[-1], node.name)
        # All ctors should return None
        if node.name == '__init__':
            name = 'None'
    else:
        name = node.name
    return name

</t>
<t tx="ekr.20160315164543.62">def remove_recursive_calls(self, name, raw, reduced):
    '''Remove any recursive calls to name from both lists.'''
    # At present, this works *only* if the return is nothing but the recursive call.
    assert len(raw) == len(reduced)
    pattern = Pattern('%s(*)' % name)
    n = len(reduced)
    raw_result, reduced_result = [], []
    for i in range(n):
        if pattern.match_entire_string(reduced[i]):
            g.trace('****', name, pattern, reduced[i])
        else:
            raw_result.append(raw[i])
            reduced_result.append(reduced[i])
    return raw_result, reduced_result

</t>
<t tx="ekr.20160315164543.63">def visit_Return(self, node):

    self.returns.append(node)
        # New: return the entire node, not node.value.


</t>
<t tx="ekr.20160315164543.64">class TestClass:
    '''
    A class containing constructs that have caused difficulties.
    This is in the make_stub_files directory, not the test directory.
    '''
    @others
</t>
<t tx="ekr.20160315164543.65"># pylint: disable=no-member
# pylint: disable=undefined-variable
# pylint: disable=no-self-argument
# pylint: disable=no-method-argument

</t>
<t tx="ekr.20160315164543.66">def parse_group(group):
    if len(group) &gt;= 3 and group[-2] == 'as':
        del group[-2:]
    ndots = 0
    i = 0
    while len(group) &gt; i and group[i].startswith('.'):
        ndots += len(group[i])
        i += 1
    assert ''.join(group[:i]) == '.'*ndots, group
    del group[:i]
    assert all(g == '.' for g in group[1::2]), group
    return ndots, os.sep.join(group[::2])

</t>
<t tx="ekr.20160315164543.67">def return_all(self):
    return all([is_known_type(z) for z in s3.split(',')])
    # return all(['abc'])

</t>
<t tx="ekr.20160315164543.68">def return_array():
    return f(s[1:-1])

</t>
<t tx="ekr.20160315164543.69">def return_list(self, a):
    return [a]

</t>
<t tx="ekr.20160315164543.7"># Return generic markers to allow better pattern matches.

</t>
<t tx="ekr.20160315164543.70">def return_two_lists(s):
    if 1:
        return aList
    else:
        return list(self.regex.finditer(s))
</t>
<t tx="ekr.20160315164543.8">def do_Bytes(self, node): # Python 3.x only.
    return 'bytes' # return str(node.s)

</t>
<t tx="ekr.20160315164543.9">def do_Num(self, node):
    # make_patterns_dict treats 'number' as a special case.
    # return self.names_dict.get('number', 'number')
    return 'number' # return repr(node.n)

</t>
<t tx="ekr.20160315165109.1">def do_NameConstant(rt, node): # Python 3 only.

    rt.name(repr(node.value))
</t>
<t tx="ekr.20160315182225.1"># Python 3:
# arg = (identifier arg, expr? annotation)

def do_arg(rt, node):
    
    rt.gen(node.arg)
    # if hasattr(node, expr):
        # pass
</t>
<t tx="ekr.20160315184954.1">def string(rt, s):

    s = repr(s.strip().strip())
    s = saxutils.escape(s)
    rt.gen(s)
</t>
<t tx="ekr.20160315190818.1">def do_Index(rt, node):

    rt.visit(node.value)
</t>
<t tx="ekr.20160315190913.1"># Python 3 only: Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(rt, node):

    rt.div('statement')
    rt.keyword('try')
    rt.colon()
    rt.div_list('body', node.body)
    for z in node.handlers:
        rt.visit(z)
    for z in node.orelse:
        rt.visit(z)
    if node.finalbody:
        rt.keyword('finally')
        rt.colon()
        rt.div_list('body', node.finalbody)
    rt.end_div('statement')
</t>
<t tx="ekr.20160316091132.1">#!/usr/bin/env python
'''
This script makes a coffeescript file for every python source file listed
on the command line (wildcard file names are supported).

For full details, see README.md.

Released under the MIT License.

Written by Edward K. Ream.
'''
&lt;&lt; license &gt;&gt;
&lt;&lt; imports &gt;&gt;
isPython3 = sys.version_info &gt;= (3, 0, 0)
@others

g = LeoGlobals() # For ekr.
if __name__ == "__main__":
    main()
# A final comment for testing.
</t>
<t tx="ekr.20160316091132.10">
def pdb(self):
    '''Invoke a debugger during unit testing.'''
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()
</t>
<t tx="ekr.20160316091132.100">
def run(self):
    '''
    Make stub files for all files.
    Do nothing if the output directory does not exist.
    '''
    if self.enable_unit_tests:
        self.run_all_unit_tests()
    if self.files:
        dir_ = self.output_directory
        if dir_:
            if os.path.exists(dir_):
                for fn in self.files:
                    self.make_coffeescript_file(fn)
            else:
                print('output directory not found: %s' % dir_)
        else:
            print('no output directory')
    elif not self.enable_unit_tests:
        print('no input files')
</t>
<t tx="ekr.20160316091132.101">
def run_all_unit_tests(self):
    '''Run all unit tests in the python-to-coffeescript/test directory.'''
    import unittest
    loader = unittest.TestLoader()
    suite = loader.discover(os.path.abspath('.'),
                            pattern='test*.py',
                            top_level_dir=None)
    unittest.TextTestRunner(verbosity=1).run(suite)
</t>
<t tx="ekr.20160316091132.102">
def scan_command_line(self):
    '''Set ivars from command-line arguments.'''
    # This automatically implements the --help option.
    usage = "usage: python_to_coffeescript.py [options] file1, file2, ..."
    parser = optparse.OptionParser(usage=usage)
    add = parser.add_option
    add('-c', '--config', dest='fn',
        help='full path to configuration file')
    add('-d', '--dir', dest='dir',
        help='full path to the output directory')
    add('-o', '--overwrite', action='store_true', default=False,
        help='overwrite existing .coffee files')
    # add('-t', '--test', action='store_true', default=False,
        # help='run unit tests on startup')
    add('-v', '--verbose', action='store_true', default=False,
        help='verbose output')
    # Parse the options
    options, args = parser.parse_args()
    # Handle the options...
    # self.enable_unit_tests = options.test
    self.overwrite = options.overwrite
    if options.fn:
        self.config_fn = options.fn
    if options.dir:
        dir_ = options.dir
        dir_ = self.finalize(dir_)
        if os.path.exists(dir_):
            self.output_directory = dir_
        else:
            print('--dir: directory does not exist: %s' % dir_)
            print('exiting')
            sys.exit(1)
    # If any files remain, set self.files.
    if args:
        args = [self.finalize(z) for z in args]
        if args:
            self.files = args
</t>
<t tx="ekr.20160316091132.103">
def scan_options(self):
    '''Set all configuration-related ivars.'''
    trace = False
    if not self.config_fn:
        return
    self.parser = parser = self.create_parser()
    s = self.get_config_string()
    self.init_parser(s)
    if self.files:
        files_source = 'command-line'
        files = self.files
    elif parser.has_section('Global'):
        files_source = 'config file'
        files = parser.get('Global', 'files')
        files = [z.strip() for z in files.split('\n') if z.strip()]
    else:
        return
    files2 = []
    for z in files:
        files2.extend(glob.glob(self.finalize(z)))
    self.files = [z for z in files2 if z and os.path.exists(z)]
    if trace:
        print('Files (from %s)...\n' % files_source)
        for z in self.files:
            print(z)
        print('')
    if 'output_directory' in parser.options('Global'):
        s = parser.get('Global', 'output_directory')
        output_dir = self.finalize(s)
        if os.path.exists(output_dir):
            self.output_directory = output_dir
            if self.verbose:
                print('output directory: %s\n' % output_dir)
        else:
            print('output directory not found: %s\n' % output_dir)
            self.output_directory = None # inhibit run().
    if 'prefix_lines' in parser.options('Global'):
        prefix = parser.get('Global', 'prefix_lines')
        self.prefix_lines = prefix.split('\n')
            # The parser does not preserve leading whitespace.
        if trace:
            print('Prefix lines...\n')
            for z in self.prefix_lines:
                print(z)
            print('')
    #
    # self.def_patterns = self.scan_patterns('Def Name Patterns')
    # self.general_patterns = self.scan_patterns('General Patterns')
    # self.make_patterns_dict()
</t>
<t tx="ekr.20160316091132.104">
def create_parser(self):
    '''Create a RawConfigParser and return it.'''
    parser = configparser.RawConfigParser()
    parser.optionxform = str
    return parser
</t>
<t tx="ekr.20160316091132.105">
def get_config_string(self):
    fn = self.finalize(self.config_fn)
    if os.path.exists(fn):
        if self.verbose:
            print('\nconfiguration file: %s\n' % fn)
        f = open(fn, 'r')
        s = f.read()
        f.close()
        return s
    else:
        print('\nconfiguration file not found: %s' % fn)
        return ''
</t>
<t tx="ekr.20160316091132.106">
def init_parser(self, s):
    '''Add double back-slashes to all patterns starting with '['.'''
    trace = False
    if not s: return
    aList = []
    for s in s.split('\n'):
        if self.is_section_name(s):
            aList.append(s)
        elif s.strip().startswith('['):
            aList.append(r'\\' + s[1:])
            if trace: g.trace('*** escaping:', s)
        else:
            aList.append(s)
    s = '\n'.join(aList) + '\n'
    if trace: g.trace(s)
    file_object = io.StringIO(s)
    self.parser.readfp(file_object)
</t>
<t tx="ekr.20160316091132.107">
def is_section_name(self, s):

    def munge(s):
        return s.strip().lower().replace(' ', '')

    s = s.strip()
    if s.startswith('[') and s.endswith(']'):
        s = munge(s[1: -1])
        for s2 in self.section_names:
            if s == munge(s2):
                return True
    return False
</t>
<t tx="ekr.20160316091132.108">

class ParseState(object):
    '''A class representing items parse state stack.'''

    def __init__(self, kind, value):
        self.kind = kind
        self.value = value

    def __repr__(self):
        return 'State: %10s %s' % (self.kind, repr(self.value))

    __str__ = __repr__
</t>
<t tx="ekr.20160316091132.109">

class TokenSync(object):
    '''A class to sync and remember tokens.'''
    # To do: handle comments, line breaks...
    @others
</t>
<t tx="ekr.20160316091132.11">
def truncate(s, n):
    '''Return s truncated to n characters.'''
    return s if len(s) &lt;= n else s[:n-3] + '...'
</t>
<t tx="ekr.20160316091132.110">
def __init__(self, s, tokens):
    '''Ctor for TokenSync class.'''
    assert isinstance(tokens, list) # Not a generator.
    self.s = s
    self.first_leading_line = None
    self.lines = [z.rstrip() for z in g.splitLines(s)]
    # Order is important from here on...
    self.nl_token = self.make_nl_token()
    self.line_tokens = self.make_line_tokens(tokens)
    self.blank_lines = self.make_blank_lines()
    self.string_tokens = self.make_string_tokens()
    self.ignored_lines = self.make_ignored_lines()
</t>
<t tx="ekr.20160316091132.111">
def make_blank_lines(self):
    '''Return of list of line numbers of blank lines.'''
    result = []
    for i, aList in enumerate(self.line_tokens):
        # if any([self.token_kind(z) == 'nl' for z in aList]):
        if len(aList) == 1 and self.token_kind(aList[0]) == 'nl':
            result.append(i)
    return result
</t>
<t tx="ekr.20160316091132.112">
def make_ignored_lines(self):
    '''
    Return a copy of line_tokens containing ignored lines,
    that is, full-line comments or blank lines.
    These are the lines returned by leading_lines().
    '''
    result = []
    for i, aList in enumerate(self.line_tokens):
        for z in aList:
            if self.is_line_comment(z):
                result.append(z)
                break
        else:
            if i in self.blank_lines:
                result.append(self.nl_token)
            else:
                result.append(None)
    assert len(result) == len(self.line_tokens)
    for i, aList in enumerate(result):
        if aList:
            self.first_leading_line = i
            break
    else:
        self.first_leading_line = len(result)
    return result
</t>
<t tx="ekr.20160316091132.113">
def make_line_tokens(self, tokens):
    '''
    Return a list of lists of tokens for each list in self.lines.
    The strings in self.lines may end in a backslash, so care is needed.
    '''
    trace = False
    n, result = len(self.lines), []
    for i in range(0, n+1):
        result.append([])
    for token in tokens:
        t1, t2, t3, t4, t5 = token
        kind = token_module.tok_name[t1].lower()
        srow, scol = t3
        erow, ecol = t4
        line = erow-1 if kind == 'string' else srow-1 
        result[line].append(token)
        if trace: g.trace('%3s %s' % (line, self.dump_token(token)))
    assert len(self.lines) + 1 == len(result), len(result)
    return result
</t>
<t tx="ekr.20160316091132.114">
def make_nl_token(self):
    '''Return a newline token with '\n' as both val and raw_val.'''
    t1 = token_module.NEWLINE
    t2 = '\n'
    t3 = (0, 0) # Not used.
    t4 = (0, 0) # Not used.
    t5 = '\n'
    return t1, t2, t3, t4, t5
</t>
<t tx="ekr.20160316091132.115">
def make_string_tokens(self):
    '''Return a copy of line_tokens containing only string tokens.'''
    result = []
    for aList in self.line_tokens:
        result.append([z for z in aList if self.token_kind(z) == 'string'])
    assert len(result) == len(self.line_tokens)
    return result
</t>
<t tx="ekr.20160316091132.116">
def check_strings(self):
    '''Check that all strings have been consumed.'''
    # g.trace(len(self.string_tokens))
    for i, aList in enumerate(self.string_tokens):
        if aList:
            g.trace('warning: line %s. unused strings: %s' % (i, aList))</t>
<t tx="ekr.20160316091132.117">
def dump_token(self, token, verbose=False):
    '''Dump the token. It is either a string or a 5-tuple.'''
    if g.isString(token):
        return token
    else:
        t1, t2, t3, t4, t5 = token
        kind = g.toUnicode(token_module.tok_name[t1].lower())
        raw_val = g.toUnicode(t5)
        val = g.toUnicode(t2)
        if verbose:
            return 'token: %10s %r' % (kind, val)
        else:
            return val
</t>
<t tx="ekr.20160316091132.118">
def is_line_comment(self, token):
    '''Return True if the token represents a full-line comment.'''
    t1, t2, t3, t4, t5 = token
    kind = token_module.tok_name[t1].lower()
    raw_val = t5
    return kind == 'comment' and raw_val.lstrip().startswith('#')
</t>
<t tx="ekr.20160316091132.119">
def join(self, aList, sep=','):
    '''return the items of the list joined by sep string.'''
    tokens = []
    for i, token in enumerate(aList or []):
        tokens.append(token)
        if i &lt; len(aList) -1:
            tokens.append(sep)
    return tokens
</t>
<t tx="ekr.20160316091132.12">

class CoffeeScriptTraverser(object):
    '''A class to convert python sources to coffeescript sources.'''
    # pylint: disable=consider-using-enumerate
    @others
</t>
<t tx="ekr.20160316091132.120">
def last_node(self, node):
    '''Return the node of node's tree with the largest lineno field.'''

    class LineWalker(ast.NodeVisitor):
        
        def __init__ (self):
            '''Ctor for LineWalker class.'''
            self.node = None
            self.lineno = -1
            
        def visit(self, node):
            '''LineWalker.visit.'''
            if hasattr(node, 'lineno'):
                if node.lineno &gt; self.lineno:
                    self.lineno = node.lineno
                    self.node = node
            if isinstance(node, list):
                for z in node:
                    self.visit(z)
            else:
                self.generic_visit(node)
 
    w = LineWalker()
    w.visit(node)
    return w.node
            </t>
<t tx="ekr.20160316091132.121">
def leading_lines(self, node):
    '''Return a list of the preceding comment and blank lines'''
    # This can be called on arbitrary nodes.
    trace = False
    leading = []
    if hasattr(node, 'lineno'):
        i, n = self.first_leading_line, node.lineno
        while i &lt; n:
            token = self.ignored_lines[i]
            if token:
                s = self.token_raw_val(token).rstrip()+'\n'
                leading.append(s)
                if trace: g.trace('%11s: %s' % (i, s.rstrip()))
            i += 1
        self.first_leading_line = i
    return leading
</t>
<t tx="ekr.20160316091132.122">
def leading_string(self, node):
    '''Return a string containing all lines preceding node.'''
    return ''.join(self.leading_lines(node))</t>
<t tx="ekr.20160316091132.123">
def line_at(self, node, continued_lines=True):
    '''Return the lines at the node, possibly including continuation lines.'''
    n = getattr(node, 'lineno', None)
    if n is None:
        return '&lt;no line&gt; for %s' % node.__class__.__name__
    elif continued_lines:
        aList, n = [], n-1
        while n &lt; len(self.lines):
            s = self.lines[n]
            if s.endswith('\\'):
                aList.append(s[:-1])
                n += 1
            else:
                aList.append(s)
                break
        return ''.join(aList)
    else:
        return self.lines[n-1]
</t>
<t tx="ekr.20160316091132.124">
def sync_string(self, node):
    '''Return the spelling of the string at the given node.'''
    # g.trace('%-10s %2s: %s' % (' ', node.lineno, self.line_at(node)))
    n = node.lineno
    tokens = self.string_tokens[n-1]
    if tokens:
        token = tokens.pop(0)
        self.string_tokens[n-1] = tokens
        return self.token_val(token)
    else:
        g.trace('===== underflow', n, node.s)
        return node.s
</t>
<t tx="ekr.20160316091132.125">
def token_kind(self, token):
    '''Return the token's type.'''
    t1, t2, t3, t4, t5 = token
    return g.toUnicode(token_module.tok_name[t1].lower())

def token_raw_val(self, token):
    '''Return the value of the token.'''
    t1, t2, t3, t4, t5 = token
    return g.toUnicode(t5)
    
def token_val(self, token):
    '''Return the raw value of the token.'''
    t1, t2, t3, t4, t5 = token
    return g.toUnicode(t2)
</t>
<t tx="ekr.20160316091132.126">
def tokens_for_statement(self, node):
    
    assert isinstance(node, ast.AST), node
    name = node.__class__.__name__
    if hasattr(node, 'lineno'):
        tokens = self.line_tokens[node.lineno-1]
        g.trace(' '.join([self.dump_token(z) for z in tokens]))
    else:
        g.trace('no lineno', name)

    
    
</t>
<t tx="ekr.20160316091132.127">
def trailing_comment(self, node):
    '''
    Return a string containing the trailing comment for the node, if any.
    The string always ends with a newline.
    '''
    if hasattr(node, 'lineno'):
        return self.trailing_comment_at_lineno(node.lineno)
    else:
        g.trace('no lineno', node.__class__.__name__, g.callers())
        return '\n'
</t>
<t tx="ekr.20160316091132.128">
def trailing_comment_at_lineno(self, lineno):
    '''Return any trailing comment at the given node.lineno.'''
    trace = False
    tokens = self.line_tokens[lineno-1]
    for token in tokens:
        if self.token_kind(token) == 'comment':
            raw_val = self.token_raw_val(token).rstrip()
            if not raw_val.strip().startswith('#'):
                val = self.token_val(token).rstrip()
                s = ' %s\n' % val
                if trace: g.trace(lineno, s.rstrip(), g.callers())
                return s
    return '\n'</t>
<t tx="ekr.20160316091132.129">
def trailing_lines(self):
    '''return any remaining ignored lines.'''
    trace = False
    trailing = []
    i = self.first_leading_line
    while i &lt; len(self.ignored_lines):
        token = self.ignored_lines[i]
        if token:
            s = self.token_raw_val(token).rstrip()+'\n'
            trailing.append(s)
            if trace: g.trace('%11s: %s' % (i, s.rstrip()))
        i += 1
    self.first_leading_line = i
    return trailing
</t>
<t tx="ekr.20160316091132.13">
def __init__(self, controller):
    '''Ctor for CoffeeScriptFormatter class.'''
    self.controller = controller
    self.class_stack = []
    # Redirection. Set in format.
    self.sync_string = None
    self.last_node = None
    self.leading_lines = None
    self.leading_string = None
    self.tokens_for_statement = None
    self.trailing_comment = None
    self.trailing_comment_at_lineno = None
    </t>
<t tx="ekr.20160316091132.14">
def format(self, node, s, tokens):
    '''Format the node (or list of nodes) and its descendants.'''
    self.level = 0
    self.sync = sync = TokenSync(s, tokens)
    # Create aliases here for convenience.
    self.sync_string = sync.sync_string
    self.last_node = sync.last_node
    self.leading_lines = sync.leading_lines
    self.leading_string = sync.leading_string
    self.tokens_for_statment = sync.tokens_for_statement
    self.trailing_comment = sync.trailing_comment
    self.trailing_comment_at_lineno = sync.trailing_comment_at_lineno
    # Compute the result.
    val = self.visit(node)
    sync.check_strings()
    # if isinstance(val, list): # testing:
        # val = ' '.join(val)
    val += ''.join(sync.trailing_lines())
    return val or ''
</t>
<t tx="ekr.20160316091132.15">
def indent(self, s):
    '''Return s, properly indented.'''
    # assert not s.startswith('\n'), (g.callers(), repr(s))
    n = 0
    while s and s.startswith('\n'):
        n += 1
        s = s[1:]
    return '%s%s%s' % ('\n' * n, ' ' * 4 * self.level, s)
</t>
<t tx="ekr.20160316091132.16">
def visit(self, node):
    '''Return the formatted version of an Ast node, or list of Ast nodes.'''
    name = node.__class__.__name__
    if isinstance(node, (list, tuple)):
        return ', '.join([self.visit(z) for z in node])
    elif node is None:
        return 'None'
    else:
        assert isinstance(node, ast.AST), name
        method = getattr(self, 'do_' + name)
        s = method(node)
        if isPython3:
            assert isinstance(s, str)
        else:
            assert isinstance(s, (str, unicode))
        return s
</t>
<t tx="ekr.20160316091132.17">
#
# CoffeeScriptTraverser contexts...
#</t>
<t tx="ekr.20160316091132.18">
# ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

def do_ClassDef(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    name = node.name # Only a plain string is valid.
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if bases:
        s = 'class %s extends %s' % (name, ', '.join(bases))
    else:
        s = 'class %s' % name
    result.append(self.indent(s + tail))
    self.class_stack.append(name)
    for i, z in enumerate(node.body):
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    self.class_stack.pop()
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.19">
# FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)

def do_FunctionDef(self, node):
    '''Format a FunctionDef node.'''
    result = self.leading_lines(node)
    if node.decorator_list:
        for z in node.decorator_list:
            tail = self.trailing_comment(z)
            s = '@%s' % self.visit(z)
            result.append(self.indent(s + tail))
    name = node.name # Only a plain string is valid.
    args = self.visit(node.args) if node.args else ''
    args = [z.strip() for z in args.split(',')]
    if self.class_stack and args and args[0] == '@':
        args = args[1:]
    args = ', '.join(args)
    args = '(%s) ' % args if args else ''
    # result.append('\n')
    tail = self.trailing_comment(node)
    sep = ': ' if self.class_stack else ' = '
    s = '%s%s%s-&gt;%s' % (name, sep, args, tail)
    result.append(self.indent(s))
    for i, z in enumerate(node.body):
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.2">@nocolor-node
@
All parts of this script are distributed under the following copyright. This is intended to be the same as the MIT license, namely that this script is absolutely free, even for commercial use, including resale. There is no GNU-like "copyleft" restriction. This license is compatible with the GPL.

**Copyright 2016 by Edward K. Ream. All Rights Reserved.**

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

**THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.**
</t>
<t tx="ekr.20160316091132.20">
def do_Interactive(self, node):
    for z in node.body:
        self.visit(z)
</t>
<t tx="ekr.20160316091132.21">
def do_Module(self, node):

    return ''.join([self.visit(z) for z in node.body])
</t>
<t tx="ekr.20160316091132.22">
def do_Lambda(self, node):
    return self.indent('lambda %s: %s' % (
        self.visit(node.args),
        self.visit(node.body)))
</t>
<t tx="ekr.20160316091132.23">
#
# CoffeeScriptTraverser expressions...
#
</t>
<t tx="ekr.20160316091132.24">
def do_Expression(self, node):
    '''An inner expression: do not indent.'''
    return '%s\n' % self.visit(node.body)
</t>
<t tx="ekr.20160316091132.25">
def do_GeneratorExp(self, node):
    elt = self.visit(node.elt) or ''
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens] # Kludge: probable bug.
    return '&lt;gen %s for %s&gt;' % (elt, ','.join(gens))
</t>
<t tx="ekr.20160316091132.26">
#
# CoffeeScriptTraverser operands...
#</t>
<t tx="ekr.20160316091132.27">
# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def do_arguments(self, node):
    '''Format the arguments node.'''
    assert isinstance(node, ast.arguments)
    args = [self.visit(z) for z in node.args]
    defaults = [self.visit(z) for z in node.defaults]
    # Assign default values to the last args.
    args2 = []
    n_plain = len(args) - len(defaults)
    for i in range(len(args)):
        if i &lt; n_plain:
            args2.append(args[i])
        else:
            args2.append('%s=%s' % (args[i], defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name:
        # pylint: disable=no-member
        if isPython3 and isinstance(name, ast.arg):
            name = name.arg
        args2.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name:
        # pylint: disable=no-member
        if isPython3 and isinstance(name, ast.arg):
            name = name.arg
        args2.append('**' + name)
    return ','.join(args2)
</t>
<t tx="ekr.20160316091132.28">
# Python 3:
# arg = (identifier arg, expr? annotation)

def do_arg(self, node):
    return node.arg
</t>
<t tx="ekr.20160316091132.29">
# Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):
    
    # Don't visit node.attr: it is always a string.
    val = self.visit(node.value)
    val = '@' if val == '@' else val + '.'
    return val + node.attr
</t>
<t tx="ekr.20160316091132.3">import ast
import glob
import optparse
import os
import sys
import time
import token as token_module
import tokenize
import types
try:
    import ConfigParser as configparser # Python 2
except ImportError:
    import configparser # Python 3
try:
    import StringIO as io # Python 2
except ImportError:
    import io # Python 3
</t>
<t tx="ekr.20160316091132.30">
def do_Bytes(self, node): # Python 3.x only.
    return str(node.s)
</t>
<t tx="ekr.20160316091132.31">
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z] # Kludge: Defensive coding.
    s = '%s(%s)' % (func, ','.join(args))
    return s
</t>
<t tx="ekr.20160316091132.32">
# keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)
</t>
<t tx="ekr.20160316091132.33">
def do_comprehension(self, node):
    result = []
    name = self.visit(node.target) # A name.
    it = self.visit(node.iter) # An attribute.
    result.append('%s in %s' % (name, it))
    ifs = [self.visit(z) for z in node.ifs]
    if ifs:
        result.append(' if %s' % (''.join(ifs)))
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.34">
def do_Dict(self, node):
    assert len(node.keys) == len(node.values)
    items, result = [], []
    result.append('{')
    self.level += 1
    for i, key in enumerate(node.keys):
        head = self.leading_lines(key)
            # Prevents leading lines from being handled again.
        head = [z for z in head if z.strip()]
            # Ignore blank lines.
        if head:
            items.extend('\n'+''.join(head))
        tail = self.trailing_comment(node.values[i])
        key = self.visit(node.keys[i])
        value = self.visit(node.values[i])
        s = '%s:%s%s' % (key, value, tail)
        items.append(self.indent(s))
    self.level -= 1
    result.extend(items)
    if items:
        result.append(self.indent('}'))
    else:
        result.append('}')
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.35">
def do_Ellipsis(self, node):
    return '...'
</t>
<t tx="ekr.20160316091132.36">
def do_ExtSlice(self, node):
    return ':'.join([self.visit(z) for z in node.dims])
</t>
<t tx="ekr.20160316091132.37">
def do_Index(self, node):
    return self.visit(node.value)
</t>
<t tx="ekr.20160316091132.38">
def do_List(self, node):
    # Not used: list context.
    # self.visit(node.ctx)
    elts = [self.visit(z) for z in node.elts]
    elst = [z for z in elts if z] # Defensive.
    return '[%s]' % ','.join(elts)
</t>
<t tx="ekr.20160316091132.39">
def do_ListComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens] # Kludge: probable bug.
    return '%s for %s' % (elt, ''.join(gens))
</t>
<t tx="ekr.20160316091132.4">
def main():
    '''
    The driver for the stand-alone version of make-stub-files.
    All options come from ~/stubs/make_stub_files.cfg.
    '''
    # g.cls()
    controller = MakeCoffeeScriptController()
    controller.scan_command_line()
    controller.scan_options()
    controller.run()
    print('done')
</t>
<t tx="ekr.20160316091132.40">
def do_Name(self, node):
    return '@' if node.id == 'self' else node.id

def do_NameConstant(self, node): # Python 3 only.
    s = repr(node.value)
    return 'bool' if s in ('True', 'False') else s
</t>
<t tx="ekr.20160316091132.41">
def do_Num(self, node):
    return repr(node.n)
</t>
<t tx="ekr.20160316091132.42">
# Python 2.x only

def do_Repr(self, node):
    return 'repr(%s)' % self.visit(node.value)
</t>
<t tx="ekr.20160316091132.43">
def do_Slice(self, node):
    lower, upper, step = '', '', ''
    if getattr(node, 'lower', None) is not None:
        lower = self.visit(node.lower)
    if getattr(node, 'upper', None) is not None:
        upper = self.visit(node.upper)
    if getattr(node, 'step', None) is not None:
        step = self.visit(node.step)
    if step:
        return '%s:%s:%s' % (lower, upper, step)
    else:
        return '%s:%s' % (lower, upper)
</t>
<t tx="ekr.20160316091132.44">
def do_Str(self, node):
    '''A string constant, including docstrings.'''
    if hasattr(node, 'lineno'):
        # Do *not* handle leading lines here.
        # leading = self.leading_string(node)
        return self.sync_string(node)
    else:
        g.trace('==== no lineno', node.s)
        return node.s
</t>
<t tx="ekr.20160316091132.45">
# Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    value = self.visit(node.value)
    the_slice = self.visit(node.slice)
    return '%s[%s]' % (value, the_slice)
</t>
<t tx="ekr.20160316091132.46">
def do_Tuple(self, node):
    elts = [self.visit(z) for z in node.elts]
    return '(%s)' % ', '.join(elts)
</t>
<t tx="ekr.20160316091132.47">
#
# CoffeeScriptTraverser operators...
#</t>
<t tx="ekr.20160316091132.48">
def do_BinOp(self, node):
    return '%s%s%s' % (
        self.visit(node.left),
        op_name(node.op),
        self.visit(node.right))
</t>
<t tx="ekr.20160316091132.49">
def do_BoolOp(self, node):
    values = [self.visit(z) for z in node.values]
    return op_name(node.op).join(values)
</t>
<t tx="ekr.20160316091132.5">
#
# Utility functions...
#</t>
<t tx="ekr.20160316091132.50">
def do_Compare(self, node):
    result = []
    lt = self.visit(node.left)
    ops = [op_name(z) for z in node.ops]
    comps = [self.visit(z) for z in node.comparators]
    result.append(lt)
    if len(ops) == len(comps):
        for i in range(len(ops)):
            result.append('%s%s' % (ops[i], comps[i]))
    else:
        print('can not happen: ops', repr(ops), 'comparators', repr(comps))
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.51">
def do_IfExp(self, node):
    return '%s if %s else %s ' % (
        self.visit(node.body),
        self.visit(node.test),
        self.visit(node.orelse))
</t>
<t tx="ekr.20160316091132.52">
def do_UnaryOp(self, node):
    return '%s%s' % (
        op_name(node.op),
        self.visit(node.operand))
</t>
<t tx="ekr.20160316091132.53">
#
# CoffeeScriptTraverser statements...
#</t>
<t tx="ekr.20160316091132.54">
def tail_after_body(self, body, aList, result):
    '''
    Return the tail of the 'else' or 'finally' statement following the given body.
    aList is the node.orelse or node.finalbody list.
    '''
    node = self.last_node(body)
    if node:
        max_n = node.lineno
        leading = self.leading_lines(aList[0])
        if leading:
            result.extend(leading)
            max_n += len(leading)
        tail = self.trailing_comment_at_lineno(max_n + 1)
    else:
        tail = '\n'
    return tail
</t>
<t tx="ekr.20160316091132.55">
def do_Assert(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    test = self.visit(node.test)
    if getattr(node, 'msg', None) is not None:
        s = 'assert %s, %s' % (test, self.visit(node.msg))
    else:
        s = 'assert %s' % test
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.56">
def do_Assign(self, node):

    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    s = '%s=%s' % (
        '='.join([self.visit(z) for z in node.targets]),
        self.visit(node.value))
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.57">
def do_AugAssign(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    s = '%s%s=%s' % (
        self.visit(node.target),
        op_name(node.op),
        self.visit(node.value))
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.58">
def do_Break(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    return head + self.indent('break') + tail
</t>
<t tx="ekr.20160316091132.59">
def do_Continue(self, node):
    
    head = self.leading_lines(node)
    tail = self.trailing_comment(node)
    return head + self.indent('continue') + tail
</t>
<t tx="ekr.20160316091132.6">
def dump(title, s=None):
    if s:
        print('===== %s...\n%s\n' % (title, s.rstrip()))
    else:
        print('===== %s...\n' % title)
</t>
<t tx="ekr.20160316091132.60">
def do_Delete(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    targets = [self.visit(z) for z in node.targets]
    s = 'del %s' % ','.join(targets)
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.61">
def do_ExceptHandler(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    result.append(self.indent('except'))
    if getattr(node, 'type', None):
        result.append(' %s' % self.visit(node.type))
    if getattr(node, 'name', None):
        if isinstance(node.name, ast.AST):
            result.append(' as %s' % self.visit(node.name))
        else:
            result.append(' as %s' % node.name) # Python 3.x.
    result.append(':' + tail)
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.62">
# Python 2.x only

def do_Exec(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    body = self.visit(node.body)
    args = [] # Globals before locals.
    if getattr(node, 'globals', None):
        args.append(self.visit(node.globals))
    if getattr(node, 'locals', None):
        args.append(self.visit(node.locals))
    if args:
        s = 'exec %s in %s' % (body, ','.join(args))
    else:
        s = 'exec %s' % body
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.63">
def do_Expr(self, node):
    '''An outer expression: must be indented.'''
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    s = '%s' % self.visit(node.value)
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.64">
def do_For(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'for %s in %s:' % (
        self.visit(node.target),
        self.visit(node.iter))
    result.append(self.indent(s + tail))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        tail = self.tail_after_body(node.body, node.orelse, result)
        result.append(self.indent('else:' + tail))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.65">
def do_Global(self, node):
    
    head = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'global %s' % ','.join(node.names)
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.66">
def do_If(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'if %s:%s' % (self.visit(node.test), tail)
    result.append(self.indent(s))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        tail = self.tail_after_body(node.body, node.orelse, result)
        result.append(self.indent('else:' + tail))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.67">
def do_Import(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    s = 'pass # import %s' % ','.join(names)
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.68">
def get_import_names(self, node):
    '''Return a list of the the full file names in the import statement.'''
    result = []
    for ast2 in node.names:
        assert isinstance(ast2, ast.alias)
        data = ast2.name, ast2.asname
        result.append(data)
    return result
</t>
<t tx="ekr.20160316091132.69">
def do_ImportFrom(self, node):

    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    s = 'pass # from %s import %s' % (node.module, ','.join(names))
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.7">
def dump_dict(title, d):
    '''Dump a dictionary with a header.'''
    dump(title)
    for z in sorted(d):
        print('%30s %s' % (z, d.get(z)))
    print('')
</t>
<t tx="ekr.20160316091132.70">
def do_Pass(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    return head + self.indent('pass') + tail
</t>
<t tx="ekr.20160316091132.71">
# Python 2.x only

def do_Print(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    vals = []
    for z in node.values:
        vals.append(self.visit(z))
    if getattr(node, 'dest', None) is not None:
        vals.append('dest=%s' % self.visit(node.dest))
    if getattr(node, 'nl', None) is not None:
        if node.nl == 'False':
            vals.append('nl=%s' % node.nl)
    s = 'print(%s)' % ','.join(vals)
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.72">
def do_Raise(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    args = []
    for attr in ('type', 'inst', 'tback'):
        if getattr(node, attr, None) is not None:
            args.append(self.visit(getattr(node, attr)))
    s = 'raise %s' % ', '.join(args) if args else 'raise'
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.73">
def do_Return(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    if node.value:
        s = 'return %s' % self.visit(node.value).strip()
    else:
        s = 'return'
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.74">
# Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(self, node): # Python 3

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'try' + tail
    result.append(self.indent(s))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        tail = self.trailing_comment(node.orelse)
        result.append(self.indent('else:' + tail))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    if node.finalbody:
        tail = self.trailing_comment(node.finalbody)
        s = 'finally:' + tail
        result.append(self.indent(s))
        for z in node.finalbody:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.75">
def do_TryExcept(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'try:' + tail
    result.append(self.indent(s))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        tail = self.trailing_comment(node.orelse)
        s = 'else:' + tail
        result.append(self.indent(s))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.76">
def do_TryFinally(self, node):
    
    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    result.append(self.indent('try:' + tail))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    tail = self.tail_after_body(node.body, node.finalbody, result)
    result.append(self.indent('finally:' + tail))
    for z in node.finalbody:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.77">
def do_While(self, node):
    
    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'while %s:' % self.visit(node.test)
    result.append(self.indent(s + tail))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        tail = self.trailing_comment(node)
        result.append(self.indent('else:' + tail))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160316091132.78">
def do_With(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    result.append(self.indent('with '))
    if hasattr(node, 'context_expression'):
        result.append(self.visit(node.context_expresssion))
    vars_list = []
    if hasattr(node, 'optional_vars'):
        try:
            for z in node.optional_vars:
                vars_list.append(self.visit(z))
        except TypeError: # Not iterable.
            vars_list.append(self.visit(node.optional_vars))
    result.append(','.join(vars_list))
    result.append(':' + tail)
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result) + tail
</t>
<t tx="ekr.20160316091132.79">
def do_Yield(self, node):
    
    head = self.leading_string(node)
    tail = self.trailing_comment(node)
    if getattr(node, 'value', None) is not None:
        s = 'yield %s' % self.visit(node.value)
    else:
        s ='yield'
    return head + self.indent(s) + tail
</t>
<t tx="ekr.20160316091132.8">
def dump_list(title, aList):
    '''Dump a list with a header.'''
    dump(title)
    for z in aList:
        print(z)
    print('')
</t>
<t tx="ekr.20160316091132.80">

class LeoGlobals(object):
    '''A class supporting g.pdb and g.trace for compatibility with Leo.'''
    @others
</t>
<t tx="ekr.20160316091132.81">

class NullObject:
    """
    An object that does nothing, and does it very well.
    From the Python cookbook, recipe 5.23
    """
    def __init__(self, *args, **keys): pass
    def __call__(self, *args, **keys): return self
    def __repr__(self): return "NullObject"
    def __str__(self): return "NullObject"
    def __bool__(self): return False
    def __nonzero__(self): return 0
    def __delattr__(self, attr): return self
    def __getattr__(self, attr): return self
    def __setattr__(self, attr, val): return self
</t>
<t tx="ekr.20160316091132.82">

class ReadLinesClass:
    """A class whose next method provides a readline method for Python's tokenize module."""

    def __init__(self, s):
        self.lines = s.splitlines(True) if s else []
            # g.splitLines(s)
        self.i = 0

    def next(self):
        if self.i &lt; len(self.lines):
            line = self.lines[self.i]
            self.i += 1
        else:
            line = ''
        # g.trace(repr(line))
        return line

    __next__ = next
</t>
<t tx="ekr.20160316091132.83">
def _callerName(self, n=1, files=False):
    # print('_callerName: %s %s' % (n,files))
    try: # get the function name from the call stack.
        f1 = sys._getframe(n) # The stack frame, n levels up.
        code1 = f1.f_code # The code object
        name = code1.co_name
        if name == '__init__':
            name = '__init__(%s,line %s)' % (
                self.shortFileName(code1.co_filename), code1.co_firstlineno)
        if files:
            return '%s:%s' % (self.shortFileName(code1.co_filename), name)
        else:
            return name # The code name
    except ValueError:
        # print('g._callerName: ValueError',n)
        return '' # The stack is not deep enough.
    except Exception:
        # es_exception()
        return '' # "&lt;no caller name&gt;"
</t>
<t tx="ekr.20160316091132.84">
def callers(self, n=4, count=0, excludeCaller=True, files=False):
    '''Return a list containing the callers of the function that called g.callerList.

    If the excludeCaller keyword is True (the default), g.callers is not on the list.

    If the files keyword argument is True, filenames are included in the list.
    '''
    # sys._getframe throws ValueError in both cpython and jython if there are less than i entries.
    # The jython stack often has less than 8 entries,
    # so we must be careful to call g._callerName with smaller values of i first.
    result = []
    i = 3 if excludeCaller else 2
    while 1:
        s = self._callerName(i, files=files)
        # print(i,s)
        if s:
            result.append(s)
        if not s or len(result) &gt;= n: break
        i += 1
    result.reverse()
    if count &gt; 0: result = result[: count]
    sep = '\n' if files else ','
    return sep.join(result)
</t>
<t tx="ekr.20160316091132.85">
def cls(self):
    '''Clear the screen.'''
    if sys.platform.lower().startswith('win'):
        os.system('cls')
</t>
<t tx="ekr.20160316091132.86">
def computeLeadingWhitespace(self, width, tab_width):
    '''Returns optimized whitespace corresponding to width with the indicated tab_width.'''
    if width &lt;= 0:
        return ""
    elif tab_width &gt; 1:
        tabs = int(width / tab_width)
        blanks = int(width % tab_width)
        return ('\t' * tabs) + (' ' * blanks)
    else: # Negative tab width always gets converted to blanks.
        return (' ' * width)
</t>
<t tx="ekr.20160316091132.87">
def computeLeadingWhitespaceWidth(self, s, tab_width):
    '''Returns optimized whitespace corresponding to width with the indicated tab_width.'''
    w = 0
    for ch in s:
        if ch == ' ':
            w += 1
        elif ch == '\t':
            w += (abs(tab_width) - (w % abs(tab_width)))
        else:
            break
    return w
</t>
<t tx="ekr.20160316091132.88">
def isString(self, s):
    '''Return True if s is any string, but not bytes.'''
    if isPython3:
        return type(s) == type('a')
    else:
        return type(s) in types.StringTypes

def isUnicode(self, s):
    '''Return True if s is a unicode string.'''
    if isPython3:
        return type(s) == type('a')
    else:
        return type(s) == types.UnicodeType
</t>
<t tx="ekr.20160316091132.89">
def pdb(self):
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()
</t>
<t tx="ekr.20160316091132.9">
def op_name(node,strict=True):
    '''Return the print name of an operator node.'''
    d = {
        # Binary operators. 
        'Add':       '+',
        'BitAnd':    '&amp;',
        'BitOr':     '|',
        'BitXor':    '^',
        'Div':       '/',
        'FloorDiv':  '//',
        'LShift':    '&lt;&lt;',
        'Mod':       '%',
        'Mult':      '*',
        'Pow':       '**',
        'RShift':    '&gt;&gt;',
        'Sub':       '-',
        # Boolean operators.
        'And':   ' and ',
        'Or':    ' or ',
        # Comparison operators
        'Eq':    '==',
        'Gt':    '&gt;',
        'GtE':   '&gt;=',
        'In':    ' in ',
        'Is':    ' is ',
        'IsNot': ' is not ',
        'Lt':    '&lt;',
        'LtE':   '&lt;=',
        'NotEq': '!=',
        'NotIn': ' not in ',
        # Context operators.
        'AugLoad':  '&lt;AugLoad&gt;',
        'AugStore': '&lt;AugStore&gt;',
        'Del':      '&lt;Del&gt;',
        'Load':     '&lt;Load&gt;',
        'Param':    '&lt;Param&gt;',
        'Store':    '&lt;Store&gt;',
        # Unary operators.
        'Invert':   '~',
        'Not':      ' not ',
        'UAdd':     '+',
        'USub':     '-',
    }
    kind = node.__class__.__name__
    name = d.get(kind,'&lt;%s&gt;' % kind)
    if strict: assert name, kind
    return name
</t>
<t tx="ekr.20160316091132.90">
def shortFileName(self, fileName, n=None):
    if n is None or n &lt; 1:
        return os.path.basename(fileName)
    else:
        return '/'.join(fileName.replace('\\', '/').split('/')[-n:])
</t>
<t tx="ekr.20160316091132.91">
def splitLines(self, s):
    '''Split s into lines, preserving trailing newlines.'''
    return s.splitlines(True) if s else []
</t>
<t tx="ekr.20160316091132.92">
def toUnicode(self, s, encoding='utf-8', reportErrors=False):
    '''Connvert a non-unicode string with the given encoding to unicode.'''
    trace = False
    if g.isUnicode(s):
        return s
    if not encoding:
        encoding = 'utf-8'
    # These are the only significant calls to s.decode in Leo.
    # Tracing these calls directly yields thousands of calls.
    # Never call g.trace here!
    try:
        s = s.decode(encoding, 'strict')
    except UnicodeError:
        s = s.decode(encoding, 'replace')
        if trace or reportErrors:
            g.trace(g.callers())
            print("toUnicode: Error converting %s... from %s encoding to unicode" % (
                s[: 200], encoding))
    except AttributeError:
        if trace:
            print('toUnicode: AttributeError!: %s' % s)
        # May be a QString.
        s = g.u(s)
    if trace and encoding == 'cp1252':
        print('toUnicode: returns %s' % s)
    return s
</t>
<t tx="ekr.20160316091132.93">
def trace(self, *args, **keys):
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.trace(caller_level=2, *args, **keys)
    except ImportError:
        print(args, keys)
</t>
<t tx="ekr.20160316091132.94">
if isPython3:

    def u(self, s):
        return s

    def ue(self, s, encoding):
        return s if g.isUnicode(s) else str(s, encoding)

else:

    def u(self, s):
        return unicode(s)

    def ue(self, s, encoding):
        return unicode(s, encoding)
</t>
<t tx="ekr.20160316091132.95">

class MakeCoffeeScriptController(object):
    '''The controller class for python_to_coffeescript.py.'''

    @others
</t>
<t tx="ekr.20160316091132.96">
def __init__(self):
    '''Ctor for MakeCoffeeScriptController class.'''
    self.options = {}
    # Ivars set on the command line...
    self.config_fn = None
    self.enable_unit_tests = False
    self.files = [] # May also be set in the config file.
    self.section_names = ('Global',)
    # Ivars set in the config file...
    self.output_directory = self.finalize('.')
    self.overwrite = False
    self.verbose = False # Trace config arguments.
</t>
<t tx="ekr.20160316091132.97">
def finalize(self, fn):
    '''Finalize and regularize a filename.'''
    fn = os.path.expanduser(fn)
    fn = os.path.abspath(fn)
    fn = os.path.normpath(fn)
    return fn
</t>
<t tx="ekr.20160316091132.98">
def make_coffeescript_file(self, fn):
    '''
    Make a stub file in the output directory for all source files mentioned
    in the [Source Files] section of the configuration file.
    '''
    if not fn.endswith('.py'):
        print('not a python file', fn)
        return
    if not os.path.exists(fn):
        print('not found', fn)
        return
    base_fn = os.path.basename(fn)
    out_fn = os.path.join(self.output_directory, base_fn)
    out_fn = os.path.normpath(out_fn)
    out_fn = out_fn[: -3] + '.coffee'
    dir_ = os.path.dirname(out_fn)
    if os.path.exists(out_fn) and not self.overwrite:
        print('file exists: %s' % out_fn)
    elif not dir_ or os.path.exists(dir_):
        t1 = time.clock()
        s = open(fn).read()
        readlines = g.ReadLinesClass(s).next
        tokens = list(tokenize.generate_tokens(readlines))
        # s = CoffeeScriptTokenizer(controller=self).format(tokens)
        node = ast.parse(s, filename=fn, mode='exec')
        s = CoffeeScriptTraverser(controller=self).format(node, s, tokens)
        f = open(out_fn, 'w')
        self.output_time_stamp(f)
        f.write(s)
        f.close()
        print('wrote: %s' % out_fn)
    else:
        print('output directory not not found: %s' % dir_)
</t>
<t tx="ekr.20160316091132.99">
def output_time_stamp(self, f):
    '''Put a time-stamp in the output file f.'''
    f.write('# python_to_coffeescript: %s\n' %
        time.strftime("%a %d %b %Y at %H:%M:%S"))
</t>
<t tx="ekr.20160316091152.1">@language rest
@wrap

This is the theory of operation document for py2cs.py. The most interesting aspect of this script is the TokenSync class. This class provides a reliable way of associating tokenizer tokens with ast nodes.

@others



</t>
<t tx="ekr.20160316091152.2">
### The problem

The initial version of py2cs.py (the script) used only tokens. This solved all token-related problems, but made parsing difficult. Alas, it is [difficult](http://stackoverflow.com/questions/16748029/how-to-get-source-corresponding-to-a-python-ast-node) to associate tokens with ast nodes.

The script needs the following token-related data:

- The **ignored lines** (comment lines and blank lines) that precede any statement.

- The **trailing comment** strings that might follow any line.

- Optionally, the **line breaks** occurring within lines. At present, this script does not preserve such breaks, and it's probably not worth doing. Indeed, automatically breaking long lines seems more useful, especially considering that coffeescript lines may be substantially shorter than the corresponding python lines.

- The **exact spelling** of all strings.

The [ast_utils module](
https://bitbucket.org/plas/thonny/src/3b71fda7ac0b66d5c475f7a668ffbdc7ae48c2b5/thonny/ast_utils.py?at=master) purports to solve this problem with convoluted adjustments to the col_offset field. This approach is subject to subtle Python bugs, and subtle differences between Python 2 and Python 3. There is a better way...
</t>
<t tx="ekr.20160316091152.3">
### Design

The main idea is to use *only* the ast.lineno fields and the tokenizer module to recreate token data. The design assumes only that both the ast.lineno field and Python's tokenizer module are solid. This is a much more reasonable assumption than assuming that the col_offset field always tells the truth. In short, this design *ignores* the ast.col_offset field.

At startup, the TokenSync ctor assigns all the incoming tokens to various lists.  These lists are indexed by lineno:

    ts.line_tokens[i]: all the tokens on line i
    ts.string_tokens[i]: all string tokens on line i
    st.ignored_lines: the blank or comment line on line i
    
It is very easy to create these lists. The code does not depend on any arcane details.

#### Recovering the exact spelling of stings.

ts.synch_string returns the *next* string on the line. Here it is, stripped of defensive code:

    def sync_string(self, node):
        '''Return the spelling of the string at the given node.'''
        tokens = self.string_tokens[node.lineno-1]
        token = tokens.pop(0)
        self.string_tokens[node.lineno-1] = tokens
        return self.token_val(token)
       
Stripped of defensive code, the do_Str visitor is just:

    def do_Str(self, node):
        '''A string constant, including docstrings.'''
        return self.sync_string(node)
        
#### Recovering otherwise ignored nodes

**ts.leading_lines(node)** returns a list of otherwise ignored lines that
precede the node's line that have not already been returned.
**ts.leading_string(node)** is a convenience method that returns ''.join(ts.leading_lines(node)). The visitors of the CoffeeScriptTraverser class show how to use these methods.
</t>
<t tx="ekr.20160316091152.4">
### Using the TokenSync class

The present code is driven by ast trees, but each visitor of the CoffeeScriptTraverser class takes care to preserve **otherwise-ignored tokens**. These are tokens that would otherwise be ignored: namely blank lines and comments, both entire-line comments and trailing comments.

The visitor for each statement intersperses otherwise ignored tokens using calls to the TokenSync class.  The simplest cases are like this:

    def do_Break(self, node):
        head = self.leading_string(node)
        tail = self.trailing_comment(node)
        return head + self.indent('break') + tail

The leading_string and trailing_comment methods simply redirect to the corresponding methods in the TokenSync class.  Saves a bit of typing. Compound statements are a bit more bother, but not overly so. For example:

    def do_If(self, node):
   
        result = self.leading_lines(node)
        tail = self.trailing_comment(node)
        s = 'if %s:%s' % (self.visit(node.test), tail)
        result.append(self.indent(s))
        for z in node.body:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
        if node.orelse:
            tail = self.tail_after_body(node.body, node.orelse, result)
            result.append(self.indent('else:' + tail))
            for z in node.orelse:
                self.level += 1
                result.append(self.visit(z))
                self.level -= 1
        return ''.join(result)

The line:

        tail = self.tail_after_body(node.body, node.orelse, result)

is a hack needed to compensate for the lack of an actual ast.Else node.
</t>
<t tx="ekr.20160316091152.5">
### Summary

The TokenSync class is, a new, elegant, unexpected and happy development. It is a relatively easy-to-use helper that allows parser-based code to preserve data that is not easily accessible in parse trees.

The TokenSync class avoids [problems with the col_offset field](
http://stackoverflow.com/questions/16748029/how-to-get-source-corresponding-to-a-python-ast-node) in ast nodes. The TokenSync class depends only on the ast.lineno field and the tokenize module. We can expect it to be rock solid.

Edward K. Ream  
February 20 to 25, 2016
</t>
</tnodes>
</leo_file>
