#@+leo-ver=5-thin
#@+node:ekr.20100120072650.6089: * @file leoProjects.txt
#@+all
#@+node:ekr.20101127152442.5916: ** Testing
#@+node:ekr.20110601190157.19176: *3* Pylint
@nocolor-node

************* Module leo.core.leoCommands
WRONG: E1101:3443:Commands.rp_get_args: Instance of 'Commands' has no 'editCommands' member
#@+node:ekr.20101028131948.5858: *3* Pylint errors for minor plugins
@killcolor

************* Module leo.plugins.geotag
E1101: 64:geotag_Controller.__del__: Instance of 'geotag_Controller' has no 'handlers' member


************* Module leo.plugins.graphed
W0511:366: FIXME
W0511:377: FIXME no handlers?


************* Module leo.plugins.groupOperations
E0602: 77:init: Undefined variable 'sets'
W0601:192:initImages: Global variable 'groupOpPI' undefined at the module level
W0601:193:initImages: Global variable 'bullseyePI' undefined at the module level
W0601:194:initImages: Global variable 'copyPI' undefined at the module level
W0601:195:initImages: Global variable 'clonePI' undefined at the module level
W0601:196:initImages: Global variable 'movePI' undefined at the module level
W0601:197:initImages: Global variable 'move_arrowPI' undefined at the module level
W0601:198:initImages: Global variable 'copy_arrowPI' undefined at the module level
W0601:199:initImages: Global variable 'clone_arrowPI' undefined at the module level
W0601:200:initImages: Global variable 'markSpotPI' undefined at the module level
W0601:201:initImages: Global variable 'markForPI' undefined at the module level
W0601:202:initImages: Global variable 'operateOnMarkedPI' undefined at the module level
W0601:203:initImages: Global variable 'clearMarksPI' undefined at the module level
W0601:204:initImages: Global variable 'transferFromPI' undefined at the module level
W0611: 31: Unused import copy
W0611: 32: Unused import base64


************* Module leo.plugins.leoupdate
W0105: 61: String statement has no effect
E0602: 72:init: Undefined variable 'sets'
W0601: 96:onCreate: Global variable 'thePluginController' undefined at the module level
W0601:103:topLevelMenu: Global variable 'thePluginController' undefined at the module level
E1101:143:LeoUpdater.showManagerDialog.HandlerDialog.initLocalCollection: Instance of 'HandlerDialog' has no 'c' member
E1101:161:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'remote_plugin_list' member
E1101:162:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'messagebar' member
E1101:166:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'messagebar' member
E1101:170:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'plugin_list' member
E1101:171:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'plugin_list' member
E1101:173:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'remote_plugin_list' member
E1101:174:LeoUpdater.showManagerDialog.HandlerDialog.installPlugin: Instance of 'HandlerDialog' has no 'messagebar' member
W0611: 30: Unused import glob
W0611: 29: Unused import sys
W0611: 28: Unused import re


************* Module leo.plugins.mod_labels
W0311:118: Bad indentation. Found 3 spaces, expected 4
W0311:119: Bad indentation. Found 6 spaces, expected 8
W0311:126: Bad indentation. Found 6 spaces, expected 8
W0311:128: Bad indentation. Found 3 spaces, expected 4
W0311:129: Bad indentation. Found 6 spaces, expected 8
W0311:133: Bad indentation. Found 3 spaces, expected 4
W0311:134: Bad indentation. Found 6 spaces, expected 8
W0311:135: Bad indentation. Found 6 spaces, expected 8
W0311:140: Bad indentation. Found 6 spaces, expected 8
W0311:142: Bad indentation. Found 3 spaces, expected 4
W0311:143: Bad indentation. Found 6 spaces, expected 8
W0311:206: Bad indentation. Found 20 spaces, expected 16
W0311:207: Bad indentation. Found 20 spaces, expected 16
W0311:208: Bad indentation. Found 20 spaces, expected 16
W0311:209: Bad indentation. Found 28 spaces, expected 20
W0311:210: Bad indentation. Found 20 spaces, expected 16
W0311:212: Bad indentation. Found 20 spaces, expected 16
W0311:226: Bad indentation. Found 20 spaces, expected 16
W0311:228: Bad indentation. Found 20 spaces, expected 16
W0311:236: Bad indentation. Found 20 spaces, expected 16
E1123:542:labelsController.label_to_subnode: Passing unexpected keyword argument 'p' in function call
E1120:542:labelsController.label_to_subnode: No value passed for parameter 'v' in function call
E1101:571:labelsController.subnode_to_label: Instance of 'labelsController' has no 'get_labellist_for_node' member
E0602:579:labelsController.subnode_to_label: Undefined variable 'v'
E0602:605:labelsController.subnode_to_label: Undefined variable 'labels'
E0602:606:labelsController.subnode_to_label: Undefined variable 'v'
E0602:606:labelsController.subnode_to_label: Undefined variable 'labels'
E0602:611:labelsController.subnode_to_label: Undefined variable 'v'
E1120:623:labelsController.subnodes_to_label: No value passed for parameter 'title' in function call
E0602:673:labelsController.subnodes_to_labels: Undefined variable 'v'
W0611: 39: Unused import leoAtFile
W0611: 40: Unused import leoCommands
W0611: 53: Unused import os


************* Module leo.plugins.newButtons
E1101:249:UIHelperClass.addWidgets: Instance of 'FlatOptionMenu' has no 'pack' member
E1111:362:HelperForm.formCommit: Assigning to function call which doesn't return


************* Module leo.plugins.nodeActions
W0312: 63: Found indentation with tabs instead of spaces
W0312: 64: Found indentation with tabs instead of spaces
W0312: 65: Found indentation with tabs instead of spaces
W0312: 66: Found indentation with tabs instead of spaces
W0312: 67: Found indentation with tabs instead of spaces
W0312: 68: Found indentation with tabs instead of spaces
W0311: 72: Bad indentation. Found 3 spaces, expected 4
W0311: 81: Bad indentation. Found 3 spaces, expected 4
W0311: 83: Bad indentation. Found 3 spaces, expected 4
W0311: 84: Bad indentation. Found 6 spaces, expected 8
W0311: 87: Bad indentation. Found 3 spaces, expected 4
W0311: 88: Bad indentation. Found 3 spaces, expected 4
W0311: 89: Bad indentation. Found 6 spaces, expected 8
W0311: 92: Bad indentation. Found 3 spaces, expected 4
W0311: 93: Bad indentation. Found 3 spaces, expected 4
W0311: 94: Bad indentation. Found 6 spaces, expected 8
W0311: 96: Bad indentation. Found 3 spaces, expected 4
W0311: 98: Bad indentation. Found 6 spaces, expected 8
W0311: 99: Bad indentation. Found 6 spaces, expected 8
W0311:101: Bad indentation. Found 6 spaces, expected 8
W0311:104: Bad indentation. Found 9 spaces, expected 12
W0311:105: Bad indentation. Found 12 spaces, expected 16
W0311:108: Bad indentation. Found 9 spaces, expected 12
W0311:109: Bad indentation. Found 12 spaces, expected 16
W0311:111: Bad indentation. Found 9 spaces, expected 12
W0311:112: Bad indentation. Found 9 spaces, expected 12
W0311:113: Bad indentation. Found 12 spaces, expected 16
W0311:116: Bad indentation. Found 9 spaces, expected 12
W0311:117: Bad indentation. Found 9 spaces, expected 12
W0311:118: Bad indentation. Found 12 spaces, expected 16
W0311:119: Bad indentation. Found 9 spaces, expected 12
W0311:120: Bad indentation. Found 12 spaces, expected 16
W0311:122: Bad indentation. Found 9 spaces, expected 12
W0311:123: Bad indentation. Found 9 spaces, expected 12
W0311:124: Bad indentation. Found 9 spaces, expected 12
W0311:125: Bad indentation. Found 12 spaces, expected 16
W0311:127: Bad indentation. Found 9 spaces, expected 12
W0311:128: Bad indentation. Found 9 spaces, expected 12
W0311:129: Bad indentation. Found 12 spaces, expected 16
W0311:133: Bad indentation. Found 9 spaces, expected 12
W0311:137: Bad indentation. Found 9 spaces, expected 12
W0311:138: Bad indentation. Found 9 spaces, expected 12
W0311:139: Bad indentation. Found 9 spaces, expected 12
W0311:141: Bad indentation. Found 12 spaces, expected 16
W0311:142: Bad indentation. Found 12 spaces, expected 16
W0311:143: Bad indentation. Found 15 spaces, expected 20
W0311:145: Bad indentation. Found 15 spaces, expected 20
W0311:146: Bad indentation. Found 15 spaces, expected 20
W0311:147: Bad indentation. Found 18 spaces, expected 24
W0311:151: Bad indentation. Found 9 spaces, expected 12
W0311:152: Bad indentation. Found 12 spaces, expected 16
W0311:153: Bad indentation. Found 9 spaces, expected 12
W0311:154: Bad indentation. Found 12 spaces, expected 16
W0311:155: Bad indentation. Found 9 spaces, expected 12
W0311:156: Bad indentation. Found 12 spaces, expected 16
W0311:157: Bad indentation. Found 15 spaces, expected 20
W0311:158: Bad indentation. Found 12 spaces, expected 16
W0311:159: Bad indentation. Found 15 spaces, expected 20
W0311:162: Bad indentation. Found 12 spaces, expected 16
W0311:163: Bad indentation. Found 15 spaces, expected 20
W0311:165: Bad indentation. Found 18 spaces, expected 24
W0311:166: Bad indentation. Found 18 spaces, expected 24
W0311:167: Bad indentation. Found 18 spaces, expected 24
W0311:168: Bad indentation. Found 18 spaces, expected 24
W0311:169: Bad indentation. Found 21 spaces, expected 28
W0311:171: Bad indentation. Found 12 spaces, expected 16
W0311:173: Bad indentation. Found 12 spaces, expected 16
W0311:175: Bad indentation. Found 12 spaces, expected 16
W0311:176: Bad indentation. Found 15 spaces, expected 20
W0311:177: Bad indentation. Found 9 spaces, expected 12
W0311:178: Bad indentation. Found 12 spaces, expected 16
W0311:179: Bad indentation. Found 15 spaces, expected 20
W0311:182: Bad indentation. Found 6 spaces, expected 8
W0311:184: Bad indentation. Found 9 spaces, expected 12
W0311:185: Bad indentation. Found 12 spaces, expected 16
W0311:186: Bad indentation. Found 9 spaces, expected 12
W0311:187: Bad indentation. Found 6 spaces, expected 8
W0311:189: Bad indentation. Found 9 spaces, expected 12
W0311:190: Bad indentation. Found 12 spaces, expected 16
W0311:191: Bad indentation. Found 9 spaces, expected 12
W0311:192: Bad indentation. Found 6 spaces, expected 8
W0311:194: Bad indentation. Found 9 spaces, expected 12
W0311:195: Bad indentation. Found 12 spaces, expected 16
W0311:196: Bad indentation. Found 9 spaces, expected 12
W0311:197: Bad indentation. Found 3 spaces, expected 4
W0311:199: Bad indentation. Found 6 spaces, expected 8
W0311:200: Bad indentation. Found 9 spaces, expected 12
W0311:201: Bad indentation. Found 6 spaces, expected 8
W0311:205: Bad indentation. Found 3 spaces, expected 4
W0311:206: Bad indentation. Found 3 spaces, expected 4
W0311:207: Bad indentation. Found 7 spaces, expected 8
W0311:208: Bad indentation. Found 7 spaces, expected 8
W0311:209: Bad indentation. Found 7 spaces, expected 8
W0311:210: Bad indentation. Found 7 spaces, expected 8
W0311:212: Bad indentation. Found 7 spaces, expected 8
W0311:213: Bad indentation. Found 11 spaces, expected 12
W0311:214: Bad indentation. Found 11 spaces, expected 12
W0311:215: Bad indentation. Found 7 spaces, expected 8
W0311:216: Bad indentation. Found 11 spaces, expected 12
W0311:222: Bad indentation. Found 11 spaces, expected 12
W0311:224: Bad indentation. Found 11 spaces, expected 12
W0311:225: Bad indentation. Found 15 spaces, expected 16
W0311:226: Bad indentation. Found 15 spaces, expected 16
W0311:227: Bad indentation. Found 7 spaces, expected 8
W0311:229: Bad indentation. Found 11 spaces, expected 12
W0311:230: Bad indentation. Found 15 spaces, expected 16
W0311:231: Bad indentation. Found 15 spaces, expected 16
W0311:232: Bad indentation. Found 11 spaces, expected 12
W0311:233: Bad indentation. Found 11 spaces, expected 12
W0311:235: Bad indentation. Found 7 spaces, expected 8


************* Module leo.plugins.pie_menus
E1101:104:PieMenu.drawString: Instance of 'PieMenu' has no 'l4' member
E1101:104:PieMenu.drawString: Instance of 'PieMenu' has no 'l4' member
E0602:134:PieMenu.construct: Undefined variable 'l1'
E0602:138:PieMenu.construct: Undefined variable 'l1'
E0602:142:PieMenu.construct: Undefined variable 'l1'
E0602:147:PieMenu.construct: Undefined variable 'l1'
E0602:151:PieMenu.construct: Undefined variable 'l1'
E0602:166:PieMenu.construct: Undefined variable 'l1'
E0602:179:PieMenu.construct: Undefined variable 'l3'
E0602:185:PieMenu.construct: Undefined variable 'l3'
E0602:192:PieMenu.construct: Undefined variable 'l3'
E0602:200:PieMenu.construct: Undefined variable 'l2'
E0602:206:PieMenu.construct: Undefined variable 'l2'
E0602:212:PieMenu.construct: Undefined variable 'l2'
E0602:219:PieMenu.construct: Undefined variable 'l2'
E0602:225:PieMenu.construct: Undefined variable 'l2'
E0602:233:PieMenu.construct: Undefined variable 'l4'
E0602:239:PieMenu.construct: Undefined variable 'l4'
E0602:246:PieMenu.construct: Undefined variable 'l4'
E0602:254:PieMenu.construct: Undefined variable 'l5'
E0602:262:PieMenu.construct: Undefined variable 'l6'
E0602:270:PieMenu.construct: Undefined variable 'l7'
E0602:276:PieMenu.construct: Undefined variable 'l7'
E0602:282:PieMenu.construct: Undefined variable 'l7'
E1101:381:PieMenu.clean: Instance of 'PieMenu' has no 'l1' member
E1101:382:PieMenu.clean: Instance of 'PieMenu' has no 'l2' member
E1101:383:PieMenu.clean: Instance of 'PieMenu' has no 'l3' member
E1101:384:PieMenu.clean: Instance of 'PieMenu' has no 'l4' member
E1101:385:PieMenu.clean: Instance of 'PieMenu' has no 'l5' member
E1101:386:PieMenu.clean: Instance of 'PieMenu' has no 'l6' member
E1101:387:PieMenu.clean: Instance of 'PieMenu' has no 'l7' member
E1101:433:PieMenu.draw: Instance of 'PieMenu' has no 'l1' member
E1101:434:PieMenu.draw: Instance of 'PieMenu' has no 'l3' member
E1101:435:PieMenu.draw: Instance of 'PieMenu' has no 'l2' member
E1101:436:PieMenu.draw: Instance of 'PieMenu' has no 'l4' member
E1101:437:PieMenu.draw: Instance of 'PieMenu' has no 'l5' member
E1101:438:PieMenu.draw: Instance of 'PieMenu' has no 'l6' member
E1101:439:PieMenu.draw: Instance of 'PieMenu' has no 'l7' member
E1101:440:PieMenu.draw: Instance of 'PieMenu' has no 'l1' member
E1101:441:PieMenu.draw: Instance of 'PieMenu' has no 'l3' member
E1101:442:PieMenu.draw: Instance of 'PieMenu' has no 'l2' member
E1101:443:PieMenu.draw: Instance of 'PieMenu' has no 'l4' member
E1101:444:PieMenu.draw: Instance of 'PieMenu' has no 'l5' member
E1101:445:PieMenu.draw: Instance of 'PieMenu' has no 'l6' member
E1101:446:PieMenu.draw: Instance of 'PieMenu' has no 'l7' member


************* Module leo.plugins.read_only_nodes
E0611: 73: No name 'parse' in module 'urllib'
E0602:201:FTPurl.read: Undefined variable 'sys'
E0602:235:FTPurl.write: Undefined variable 'sys'
E0213:239:FTPurl.seek: Method should have "self" as first argument
E0602:240:FTPurl.seek: Undefined variable 'self'
E0211:242:FTPurl.flush: Method has no argument
E0602:256:FTPurl.dir: Undefined variable 'sys'
W0601:290:enable_body: Global variable 'insertOnTime' undefined at the module level
W0601:290:enable_body: Global variable 'insertOffTime' undefined at the module level
W0601:300:disable_body: Global variable 'insertOnTime' undefined at the module level
W0601:300:disable_body: Global variable 'insertOffTime' undefined at the module level


************* Module leo.plugins.rClick
W0511:633: TODO:
E1101:958:pluginController.getButtonHandlers: Instance of 'pluginController' has no 'button_handlers' member
E1101:1587:pluginController.findButtonCommandClass.doCommand: Instance of 'findButtonCommandClass' has no 'data' member
W0611:662: Unused import ImageTk
W0611:661: Unused import Image


************* Module leo.plugins.searchbar
W0311:100: Bad indentation. Found 9 spaces, expected 8
W0107:125:onPreCreate: Unnecessary pass statement
E1101:205:SearchbarEntryWidget.__init__: Instance of 'SearchbarEntryWidget' has no 'bg' member
E1101:211:SearchbarEntryWidget.__init__: Instance of 'SearchbarEntryWidget' has no 'labelText' member
E1101:213:SearchbarEntryWidget.__init__: Instance of 'SearchbarEntryWidget' has no 'command' member
E1103:216:SearchbarEntryWidget.__init__: Instance of 'stringTextWidget' has no 'pack' member (but some types could not be inferred)
E1101:270:SearchbarEntryWidget.detachWidget: Instance of 'SearchbarEntryWidget' has no 'leoIconBar' member
E1101:275:SearchbarEntryWidget.detachWidget: Instance of 'SearchbarEntryWidget' has no 'leoIconBar' member
E1101:299:SearchbarEntryWidget.onTextChanged: Instance of 'SearchbarEntryWidget' has no 'slave' member
E1101:309:SearchbarEntryWidget.onRightClick: Instance of 'SearchbarEntryWidget' has no 'entry_menu' member
E1101:316:SearchbarEntryWidget.onReturn: Instance of 'SearchbarEntryWidget' has no 'command' member
W0107:460:pluginController.toggleSearchbarCommandClass.doCommand: Unnecessary pass statement
W0611: 48: Unused import sys
W0611: 56: Unused import ImageTk
W0611: 55: Unused import Image
W0611: 47: Unused import re
W0611: 49: Unused import os


************* Module leo.plugins.searchbox
E1101:245:QuickFind.__init__: Class 'leoTkinterFrame' has no 'leoTkTextWidget' member
E1103:280:QuickFind.init_s_ctrl: Instance of 'searchWidget' has no 'mark_set' member (but some types could not be inferred)
E1103:282:QuickFind.init_s_ctrl: Instance of 'searchWidget' has no 'toGuiIndex' member (but some types could not be inferred)
E1103:283:QuickFind.init_s_ctrl: Instance of 'searchWidget' has no 'mark_set' member (but some types could not be inferred)


************* Module leo.plugins.templates
W0601:100:initImages: Global variable 'templatePI' undefined at the module level
W0601:101:initImages: Global variable 'tempwizPI' undefined at the module level
E0602:210:getTemplateDialog: Undefined variable 'bs'
E0602:211:getTemplateDialog: Undefined variable 'hs'


************* Module leo.plugins.toolbar
W0511:749: FIXME:
W0511:829: TODO: not ready yet
E1103:487:ToolbarTkinterFrame.getIconButton: Instance of 'tkIconBarClass' has no 'getButton' member (but some types could not be inferred)
E1103:487:ToolbarTkinterFrame.getIconButton: Instance of 'nullIconBarClass' has no 'getButton' member (but some types could not be inferred)
W0221:491:ToolbarTkinterFrame.addIconWidget: Arguments number differs from overridden method
W0221:499:ToolbarTkinterFrame.clearIconBar: Arguments number differs from overridden method
E1101:503:ToolbarTkinterFrame.clearIconBar: Instance of 'ToolbarTkinterFrame' has no 'iconBars' member
W0221:505:ToolbarTkinterFrame.createIconBar: Arguments number differs from overridden method
E1101:519:ToolbarTkinterFrame.createIconBar: Instance of 'ToolbarTkinterFrame' has no 'iconBars' member
E1101:525:ToolbarTkinterFrame.createIconBar: Instance of 'ToolbarTkinterFrame' has no 'iconBars' member
E1101:528:ToolbarTkinterFrame.createIconBar: Instance of 'ToolbarTkinterFrame' has no 'iconBars' member
W0221:540:ToolbarTkinterFrame.hideIconBar: Arguments number differs from overridden method
E1101:544:ToolbarTkinterFrame.hideIconBar: Instance of 'ToolbarTkinterFrame' has no 'iconBars' member
E1103:562:ToolbarTkinterFrame.getIconWidgetFrame: Instance of 'tkIconBarClass' has no 'getWidgetFrame' member (but some types could not be inferred)
E1103:562:ToolbarTkinterFrame.getIconWidgetFrame: Instance of 'nullIconBarClass' has no 'getWidgetFrame' member (but some types could not be inferred)
E1101:580:ToolbarTkinterFrame.getToolbarFrame: Instance of 'ToolbarTkinterFrame' has no 'toolBar' member
E1101:643:ToolbarIconWidgetFrame.detachWidget: Instance of 'ToolbarIconWidgetFrame' has no 'leoIconBar' member
E1101:648:ToolbarIconWidgetFrame.detachWidget: Instance of 'ToolbarIconWidgetFrame' has no 'leoIconBar' member
E1101:858:ToolbarIconButton.detachWidget: Instance of 'ToolbarIconButton' has no 'leoIconBar' member
E1101:863:ToolbarIconButton.detachWidget: Instance of 'ToolbarIconButton' has no 'leoIconBar' member
E1101:995:ToolbarIconButton.setCommand: Instance of 'ToolbarIconButton' has no 'config' member
E1101:1031:ToolbarScriptButton.__init__.<lambda>: Instance of 'ToolbarScriptButton' has no 'invoke' member
W0221:1253:ToolbarScriptingController.executeScriptFromButton: Arguments number differs from overridden method
W0221:1338:ToolbarScriptingController.createScriptButtonIconButton: Arguments number differs from overridden method
E1103:1360:ToolbarScriptingController.createScriptButtonIconButton: Instance of 'ToolbarScriptButton' has no 'configure' member (but some types could not be inferred)
W0221:1362:ToolbarScriptingController.addScriptButtonCommand: Arguments number differs from overridden method
W0221:1840:ToolbarTkIconBarClass.addWidget: Arguments number differs from overridden method
W0221:2016:ToolbarTkIconBarClass.pack: Arguments number differs from overridden method


============ xcc
W0312:233: Found indentation with tabs instead of spaces
W0312:406: Found indentation with tabs instead of spaces
W0312:408: Found indentation with tabs instead of spaces
W0312:409: Found indentation with tabs instead of spaces
W0312:410: Found indentation with tabs instead of spaces
W0312:412: Found indentation with tabs instead of spaces
W0312:413: Found indentation with tabs instead of spaces
W0312:417: Found indentation with tabs instead of spaces
W0312:418: Found indentation with tabs instead of spaces
W0312:423: Found indentation with tabs instead of spaces
W0312:424: Found indentation with tabs instead of spaces
W0312:425: Found indentation with tabs instead of spaces
W0312:469: Found indentation with tabs instead of spaces
W0312:471: Found indentation with tabs instead of spaces
W0312:473: Found indentation with tabs instead of spaces
W0312:474: Found indentation with tabs instead of spaces
W0312:475: Found indentation with tabs instead of spaces
W0312:478: Found indentation with tabs instead of spaces
W0312:479: Found indentation with tabs instead of spaces
W0312:494: Found indentation with tabs instead of spaces
W0312:495: Found indentation with tabs instead of spaces
W0312:496: Found indentation with tabs instead of spaces
W0312:498: Found indentation with tabs instead of spaces
W0312:499: Found indentation with tabs instead of spaces
W0312:503: Found indentation with tabs instead of spaces
W0312:504: Found indentation with tabs instead of spaces
W0312:505: Found indentation with tabs instead of spaces
W0312:506: Found indentation with tabs instead of spaces
W0312:507: Found indentation with tabs instead of spaces
W0312:508: Found indentation with tabs instead of spaces
W0312:512: Found indentation with tabs instead of spaces
W0312:513: Found indentation with tabs instead of spaces
W0312:514: Found indentation with tabs instead of spaces
W0312:515: Found indentation with tabs instead of spaces
W0312:517: Found indentation with tabs instead of spaces
W0312:521: Found indentation with tabs instead of spaces
W0312:525: Found indentation with tabs instead of spaces
W0312:526: Found indentation with tabs instead of spaces
W0312:527: Found indentation with tabs instead of spaces
W0312:528: Found indentation with tabs instead of spaces
W0312:532: Found indentation with tabs instead of spaces
W0312:533: Found indentation with tabs instead of spaces
W0312:536: Found indentation with tabs instead of spaces
W0312:537: Found indentation with tabs instead of spaces
W0312:538: Found indentation with tabs instead of spaces
W0312:539: Found indentation with tabs instead of spaces
W0312:540: Found indentation with tabs instead of spaces
W0312:542: Found indentation with tabs instead of spaces
W0312:556: Found indentation with tabs instead of spaces
W0312:557: Found indentation with tabs instead of spaces
W0511:169: XXX to XxxClass.
W0511:521: TODO: ","Add import code in ImportFiles function!")
W0511:3342: TODO: Support precompiled header auto creation/inclusion."""
W0511:3663: TODO: send a WATCHTASK if breaked
E0602:339:OnStart2: Undefined variable 'XCC_INITED'
E0602:341:OnStart2: Undefined variable 'InitXcc'
E1101:418:linPause: Module 'os' has no 'kill' member
E0601:423:AddText: Using variable 'c' before assignment
E0602:424:AddText: Undefined variable 'LeoBody'
E0602:425:AddText: Undefined variable 'LeoBody'
E0602:474:DecompressIcon: Undefined variable 'Excetion'
E0602:475:DecompressIcon: Undefined variable 'Traceback'
E0602:536:ReplaceVars: Undefined variable 'NAME'
E0602:537:ReplaceVars: Undefined variable 'EXT'
E0602:538:ReplaceVars: Undefined variable 'ABS_PATH'
E0602:539:ReplaceVars: Undefined variable 'REL_PATH'
E0602:540:ReplaceVars: Undefined variable 'SRC_EXT'
E1121:677:controllerClass.onIdle: Too many positional arguments for function call
E1121:730:controllerClass.onQuit: Too many positional arguments for function call
E0211:816:controllerClass.UpdateProcess: Method has no argument
E0601:818:controllerClass.UpdateProcess: Using variable 'cc' before assignment
E0602:820:controllerClass.UpdateProcess: Undefined variable 'self'
E0211:995:controllerClass.sGetExecInfo: Method has no argument
E0602:997:controllerClass.sGetExecInfo: Undefined variable 'self'
E0602:1023:controllerClass.sGoToError: Undefined variable 'CPL'
E1101:1181:controllerClass.sSetText: Instance of 'controllerClass' has no 'setBodyText' member
E0602:1181:controllerClass.sSetText: Undefined variable 'SELECTED_NODE'
E1101:1187:controllerClass.sAddText: Instance of 'controllerClass' has no 'setBodyText' member
E0602:1187:controllerClass.sAddText: Undefined variable 'SELECTED_NODE'
E1120:1252:controllerClass.aStop: No value passed for parameter 'pid' in function call
E0602:1268:controllerClass.aStepIn: Undefined variable 'DBG'
E0602:1283:controllerClass.aStepOver: Undefined variable 'DBG'
E0602:1298:controllerClass.aStepOut: Undefined variable 'DBG'
E1120:1311:controllerClass.aPause: No value passed for parameter 'pid' in function call
E1101:1345:controllerClass.aSetText: Instance of 'controllerClass' has no 'setBodyText' member
E0602:1345:controllerClass.aSetText: Undefined variable 'ACTIVE_NODE'
E1101:1351:controllerClass.aAddText: Instance of 'controllerClass' has no 'ACTIVE_NOD' member
E1101:1352:controllerClass.aAddText: Instance of 'controllerClass' has no 'setBodyText' member
E0602:1355:controllerClass.aAddText: Undefined variable 'LeoBodyText'
E1101:1382:controllerClass.Compile: Instance of 'controllerClass' has no 'ProcessClass' member
E1101:1389:controllerClass.Compile: Instance of 'controllerClass' has no 'ProcessList' member
E1101:1404:controllerClass.CplCmd: Instance of 'controllerClass' has no 'ReplaceVars' member
E0602:1443:controllerClass.CplCmd: Undefined variable 'CPL'
E1101:1460:controllerClass.Debug: Instance of 'controllerClass' has no 'GetDebugInfo' member
E1101:1469:controllerClass.Debug: Instance of 'controllerClass' has no 'ProcessList' member
E1101:1476:controllerClass.DbgCmd: Instance of 'controllerClass' has no 'ReplaceVars' member
E1121:1486:controllerClass.Execute: Too many positional arguments for function call
E1101:1498:controllerClass.Execute: Instance of 'controllerClass' has no 'ProcessList' member
E1101:1510:controllerClass.CplStart: Instance of 'controllerClass' has no 'VProcessList' member
E1101:1590:controllerClass.DbgStart: Instance of 'controllerClass' has no 'ProcessList' member
E0602:1610:controllerClass.DbgStart: Undefined variable 'DBG'
E0602:1617:controllerClass.DbgStart: Undefined variable 'DBG'
E0213:1619:controllerClass.DbgOut: Method should have "self" as first argument
E0602:1623:controllerClass.DbgOut: Undefined variable 'self'
E0602:1628:controllerClass.DbgOut: Undefined variable 'OutBuff'
E1101:1707:controllerClass.ProgStart: Instance of 'controllerClass' has no 'ProcessList' member
E0602:1722:controllerClass.ProgOut: Undefined variable 'ExtractLines'
E0602:1722:controllerClass.ProgOut: Undefined variable 'OutBuff'
E0602:1739:controllerClass.ProgErr: Undefined variable 'ExtractLines'
E0602:1739:controllerClass.ProgErr: Undefined variable 'ErrBuff'
E0602:1775:DBGTASK.__init__: Undefined variable 'DBG_SD'
E0602:1777:DBGTASK.__init__: Undefined variable 'DBG_SD'
E1101:1783:DBGTASK.Send: Instance of 'DBGTASK' has no 'Command' member
E1101:1784:DBGTASK.Send: Instance of 'DBGTASK' has no 'aWrite' member
E1101:1784:DBGTASK.Send: Instance of 'DBGTASK' has no 'Command' member
E1101:1785:DBGTASK.Send: Instance of 'DBGTASK' has no 'DBG_SD' member
E0602:1861:BREAKTASK.__init__: Undefined variable 'aGet'
E0602:1863:BREAKTASK.__init__: Undefined variable 'DBG'
E0602:1865:BREAKTASK.__init__: Undefined variable 'Waning'
E0602:1870:BREAKTASK.__init__: Undefined variable 'DBG'
E0602:1884:BREAKTASK.Send: Undefined variable 'NAME'
E0602:1885:BREAKTASK.Send: Undefined variable 'aWrite'
E0602:1887:BREAKTASK.Send: Undefined variable 'DBG_SD'
E0602:1888:BREAKTASK.Send: Undefined variable 'DBG_RD'
E0602:1900:BREAKTASK.Receive: Undefined variable 'aAddText'
E0602:1952:WATCHTASK.__init__: Undefined variable 'cc'
E0602:1954:WATCHTASK.__init__: Undefined variable 'cc'
E0602:1958:WATCHTASK.__init__: Undefined variable 'cc'
E0602:1959:WATCHTASK.__init__: Undefined variable 'ccWatcher'
E0602:1962:WATCHTASK.__init__: Undefined variable 'DBG_SD'
W0601:1972:WATCHTASK.Cancel: Global variable 'WATCH_TASK' undefined at the module level
E0602:1973:WATCHTASK.Cancel: Undefined variable 'DBG_SD'
E0602:1974:WATCHTASK.Cancel: Undefined variable 'DBG_SD'
E0602:1975:WATCHTASK.Cancel: Undefined variable 'DBG_RD'
E0602:1976:WATCHTASK.Cancel: Undefined variable 'DBG_RD'
E0602:1977:WATCHTASK.Cancel: Undefined variable 'PROMPT_RD'
E0602:1978:WATCHTASK.Cancel: Undefined variable 'PROMPT_RD'
E0602:1980:WATCHTASK.Cancel: Undefined variable 'Watcher'
E0602:1986:WATCHTASK.Send: Undefined variable 'Watcher'
E0602:1988:WATCHTASK.Send: Undefined variable 'aWrite'
E0602:1988:WATCHTASK.Send: Undefined variable 'DBG'
E0602:1989:WATCHTASK.Send: Undefined variable 'DBG_SD'
E0602:1990:WATCHTASK.Send: Undefined variable 'DBG_RD'
E0602:1991:WATCHTASK.Send: Undefined variable 'PROMPT_RD'
E0602:1996:WATCHTASK.Receive: Undefined variable 'DBG_PROMPT'
W0601:2000:WATCHTASK.OnPrompt: Global variable 'WATCH_TASK' undefined at the module level
E0602:2002:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2008:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2013:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2014:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2017:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2018:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2020:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2023:WATCHTASK.OnPrompt: Undefined variable 'DBG_SD'
E0602:2025:WATCHTASK.OnPrompt: Undefined variable 'Watcher'
E0602:2028:WATCHTASK.OnPrompt: Undefined variable 'PROMPT_RD'
E0602:2029:WATCHTASK.OnPrompt: Undefined variable 'DBG_RD'
E0602:2104:BREAKIDTASK.Send: Undefined variable 'aWrite'
E0602:2105:BREAKIDTASK.Send: Undefined variable 'DBG_SD'
E0602:2106:BREAKIDTASK.Send: Undefined variable 'DBG_RD'
E0602:2557:ConfigClass.CplPageClass.Browse: Undefined variable 'e'
E0602:2697:ConfigClass.DbgPageClass.Browse: Undefined variable 'e'
E0602:3538:ToolbarClass.SyncDisplayToError: Undefined variable 'BreakBar'
E0602:3539:ToolbarClass.SyncDisplayToError: Undefined variable 'BreakBar'
E0602:3544:ToolbarClass.SyncDisplayToError: Undefined variable 'INSERT'
E0602:3557:ToolbarClass.SyncDisplayToError: Undefined variable 'c'
W0601:3561:ToolbarClass.SetError: Global variable 'PARSE_ERROR' undefined at the module level
W0601:3561:ToolbarClass.SetError: Global variable 'PARSE_ERROR_NODE' undefined at the module level
E0602:3593:ToolbarClass.Refresh: Undefined variable 'ACTIVE_NODE'
E0602:3613:WatcherClass.__init__: Undefined variable 'c'
E0602:3634:WatcherClass.__init__: Undefined variable 'c'
E0602:3635:WatcherClass.__init__: Undefined variable 'c'
E0602:3636:WatcherClass.__init__: Undefined variable 'c'
E0602:3637:WatcherClass.__init__: Undefined variable 'c'
E0602:3687:WatcherClass.OnDelete: Undefined variable 'sGet'
W0221:3799:BreakbarClass.yview: Arguments number differs from overridden method
E0602:3849:BreakbarClass.OnCut: Undefined variable 'LeoFrame'
E0602:3853:BreakbarClass.OnPaste: Undefined variable 'LeoFrame'
E1101:3858:BreakbarClass.OnRightClick: Instance of 'BreakbarClass' has no 'c' member
E0602:3859:BreakbarClass.OnRightClick: Undefined variable 'Menu'
E0602:3876:BreakbarClass.OnLeftClick: Undefined variable 'cGet'
E0602:3878:BreakbarClass.OnLeftClick: Undefined variable 'CHILD_NODE'
E0602:3891:BreakbarClass.OnLeftClick: Undefined variable 'SEL'
E0602:3895:BreakbarClass.AddNodeBreak: Undefined variable 'cGet'
E0602:3898:BreakbarClass.DeleteNodeBreak: Undefined variable 'cGet'
E0602:3903:BreakbarClass.ClearNodeBreaks: Undefined variable 'cSet'
E0602:4013:BreakbarClass.BreaksFromTags: Undefined variable 'CHILD_EXT'
E0602:4013:BreakbarClass.BreaksFromTags: Undefined variable 'CHILD_LINE'
E0602:4019:BreakbarClass.AddBreak: Undefined variable 'sGet'
E0602:4060:BreakbarClass.DeleteNodeBreaks: Undefined variable 'cGet'
E0602:4064:BreakbarClass.DeleteNodeBreaks: Undefined variable 'CHILD_EXT'
E0602:4064:BreakbarClass.DeleteNodeBreaks: Undefined variable 'CHILD_LINE'
E1101:4066:BreakbarClass.DeleteNodeBreaks: Instance of 'BreakbarClass' has no 'DeleteDbgBreaks' member
E0602:4068:BreakbarClass.DeleteNodeBreaks: Undefined variable 'cSelect'
E0602:4360:CppParserClass.FUNCRULE.DeclareFunc: Undefined variable 'ToolBar'
E0602:4378:CppParserClass.FUNCRULE.DefineFunc: Undefined variable 'ToolBar'
E0602:4516:CppParserClass.CLASSRULE.OnMatch: Undefined variable 'ToolBar'
E1101:4706:CppParserClass.Docum: Instance of 'CppParserClass' has no 'CURRENT_DOC_LINE' member
E0602:4730:CppParserClass.SetRealBodyDestination: Undefined variable 'EXT'
E1101:4799:CppParserClass.CppParse: Instance of 'CppParserClass' has no 'cc' member
E1102:4826:CppParserClass.CppParse: self.OnStart is not callable
E0602:4833:CppParserClass.CppParse: Undefined variable 'NAME'
E1102:4839:CppParserClass.CppParse: self.OnEnd is not callable
E1101:4852:CppParserClass.ParseNode: Instance of 'CppParserClass' has no 'cc' member
E0602:4942:WriterClass.OnWriteStart: Undefined variable 'REL_PATH'
E0602:4943:WriterClass.OnWriteStart: Undefined variable 'REL_PATH'
E0602:4943:WriterClass.OnWriteStart: Undefined variable 'NAME'
E0602:4945:WriterClass.OnWriteStart: Undefined variable 'NAME'
E0602:4948:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4949:WriterClass.OnWriteStart: Undefined variable 'sAddText'
E0602:4953:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4954:WriterClass.OnWriteStart: Undefined variable 'sAddText'
E0602:4959:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4959:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4960:WriterClass.OnWriteStart: Undefined variable 'sAddText'
E0602:4960:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4961:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4964:WriterClass.OnWriteStart: Undefined variable 'EXT'
E0602:4965:WriterClass.OnWriteStart: Undefined variable 'sAddText'
E0602:5011:BreakFinderClass.__init__: Undefined variable 'controllerSELECTED_NODE'
E0602:5011:BreakFinderClass.__init__: Undefined variable 'controllerEXT'
E0602:5027:BreakFinderClass.OnFindStart: Undefined variable 'sSet'
E0602:5028:BreakFinderClass.OnFindStart: Undefined variable 'sGet'
E0602:5034:BreakFinderClass.OnFindEnd: Undefined variable 'sSet'
E0602:5053:BreakFinderClass.BreakDef: Undefined variable 'SRC_EXT'
W0611:206: Unused import tkSimpleDialog
W0611:207: Unused import base64
W0611:203: Unused import beep


************* Module leo.plugins.active_path
W0108:122:attachToCommander.<lambda>: Lambda may not be necessary
E1101:397:openDir: Generator 'walk' has no 'next' member


************* Module leo.plugins.attrib_edit
W0311:817: Bad indentation. Found 3 spaces, expected 4
W0311:820: Bad indentation. Found 3 spaces, expected 4
W0311:823: Bad indentation. Found 3 spaces, expected 4
W0311:826: Bad indentation. Found 3 spaces, expected 4
W0311:829: Bad indentation. Found 3 spaces, expected 4
W0511:290: FIXME type_ = {True: '_view', False: '_edit'}[readonly]
W0511:305: FIXME self.attrPaths.add(tuple(ns))
E1101:666:attrib_edit_Controller.JUNKrecSearch: Instance of 'attrib_edit_Controller' has no 'recSearch' member
E1101:670:attrib_edit_Controller.JUNKrecSearch: Instance of 'attrib_edit_Controller' has no 'typeMap' member
E1101:672:attrib_edit_Controller.JUNKrecSearch: Instance of 'attrib_edit_Controller' has no 'typeMap' member
W0611:119: Unused import os
W0611:116: Unused import re


************* Module leo.plugins.backlink
W0511: 21: TODO
E1101:143:backlinkTkUI.updateTkTab: Instance of 'backlinkTkUI' has no 'c' member
E1101:148:backlinkTkUI.updateTkTabInt: Instance of 'backlinkTkUI' has no 'c' member
E1123:159:backlinkTkUI.updateTkTabInt: Passing unexpected keyword argument 'optional' in function call
E1101:167:backlinkTkUI.updateTkTabInt: Instance of 'backlinkTkUI' has no 'vnode' member
E1101:168:backlinkTkUI.updateTkTabInt: Instance of 'backlinkTkUI' has no 'vnodePosition' member
E1101:169:backlinkTkUI.updateTkTabInt: Instance of 'backlinkTkUI' has no 'c' member
E1123:177:backlinkTkUI.updateTkTabInt: Passing unexpected keyword argument 'optional' in function call
E1101:184:backlinkTkUI.updateTkTabInt.delLink: Instance of 'backlinkTkUI' has no 'deleteLink' member
E1103:647:backlinkController.showMenu: Instance of 'unitTestGui' has no 'killPopupMenu' member (but some types could not be inferred)
E1103:647:backlinkController.showMenu: Instance of 'nullGui' has no 'killPopupMenu' member (but some types could not be inferred)
E1103:709:backlinkController.showMenu: Instance of 'unitTestGui' has no 'postPopupMenu' member (but some types could not be inferred)
E1103:709:backlinkController.showMenu: Instance of 'nullGui' has no 'postPopupMenu' member (but some types could not be inferred)
W0101:785:backlinkController.vnodePosition: Unreachable code
E1101:788:backlinkController.vnodePosition: Instance of 'backlinkController' has no 'positions' member
E1101:789:backlinkController.vnodePosition: Instance of 'backlinkController' has no 'positions' member
E1101:803:backlinkController.vnodePosition: Instance of 'backlinkController' has no 'positions' member


************* Module leo.plugins.cursesGui
W0311: 84: Bad indentation. Found 2 spaces, expected 4
W0311: 85: Bad indentation. Found 4 spaces, expected 8
W0311: 87: Bad indentation. Found 2 spaces, expected 4
W0311: 92: Bad indentation. Found 2 spaces, expected 4
W0311: 93: Bad indentation. Found 4 spaces, expected 8
W0311: 95: Bad indentation. Found 4 spaces, expected 8
W0311: 96: Bad indentation. Found 4 spaces, expected 8
W0311: 99: Bad indentation. Found 2 spaces, expected 4
W0311:103: Bad indentation. Found 6 spaces, expected 8
W0311:105: Bad indentation. Found 2 spaces, expected 4
W0311:106: Bad indentation. Found 4 spaces, expected 8
W0311:107: Bad indentation. Found 4 spaces, expected 8
W0311:108: Bad indentation. Found 4 spaces, expected 8
W0311:110: Bad indentation. Found 2 spaces, expected 4
W0311:111: Bad indentation. Found 4 spaces, expected 8
W0311:114: Bad indentation. Found 2 spaces, expected 4
W0311:115: Bad indentation. Found 4 spaces, expected 8
W0311:117: Bad indentation. Found 2 spaces, expected 4
W0311:118: Bad indentation. Found 4 spaces, expected 8
W0311:120: Bad indentation. Found 2 spaces, expected 4
W0311:122: Bad indentation. Found 6 spaces, expected 8
W0311:124: Bad indentation. Found 6 spaces, expected 8
W0311:126: Bad indentation. Found 2 spaces, expected 4
W0311:127: Bad indentation. Found 4 spaces, expected 8
W0311:129: Bad indentation. Found 2 spaces, expected 4
W0311:130: Bad indentation. Found 4 spaces, expected 8
W0311:132: Bad indentation. Found 2 spaces, expected 4
W0311:133: Bad indentation. Found 4 spaces, expected 8
W0311:135: Bad indentation. Found 4 spaces, expected 8
W0311:137: Bad indentation. Found 4 spaces, expected 8
W0311:138: Bad indentation. Found 4 spaces, expected 8
W0311:140: Bad indentation. Found 4 spaces, expected 8
W0311:142: Bad indentation. Found 4 spaces, expected 8
W0311:143: Bad indentation. Found 6 spaces, expected 12
W0311:144: Bad indentation. Found 4 spaces, expected 8
W0311:146: Bad indentation. Found 2 spaces, expected 4
W0311:147: Bad indentation. Found 4 spaces, expected 8
W0311:149: Bad indentation. Found 2 spaces, expected 4
W0311:150: Bad indentation. Found 4 spaces, expected 8
W0311:152: Bad indentation. Found 2 spaces, expected 4
W0311:153: Bad indentation. Found 4 spaces, expected 8
W0311:155: Bad indentation. Found 4 spaces, expected 8
W0311:156: Bad indentation. Found 4 spaces, expected 8
W0311:158: Bad indentation. Found 4 spaces, expected 8
W0311:161: Bad indentation. Found 6 spaces, expected 12
W0311:162: Bad indentation. Found 8 spaces, expected 16
W0311:163: Bad indentation. Found 6 spaces, expected 12
W0311:164: Bad indentation. Found 6 spaces, expected 12
W0311:167: Bad indentation. Found 6 spaces, expected 12
W0311:169: Bad indentation. Found 6 spaces, expected 12
W0311:170: Bad indentation. Found 8 spaces, expected 16
W0311:171: Bad indentation. Found 6 spaces, expected 12
W0311:172: Bad indentation. Found 10 spaces, expected 16
W0311:174: Bad indentation. Found 2 spaces, expected 4
W0311:176: Bad indentation. Found 4 spaces, expected 8
W0311:177: Bad indentation. Found 6 spaces, expected 12
W0311:178: Bad indentation. Found 4 spaces, expected 8
W0311:179: Bad indentation. Found 6 spaces, expected 12
W0311:180: Bad indentation. Found 4 spaces, expected 8
W0311:181: Bad indentation. Found 6 spaces, expected 12
W0311:182: Bad indentation. Found 4 spaces, expected 8
W0311:183: Bad indentation. Found 6 spaces, expected 12
W0311:184: Bad indentation. Found 8 spaces, expected 16
W0311:185: Bad indentation. Found 6 spaces, expected 12
W0311:186: Bad indentation. Found 6 spaces, expected 12
W0311:187: Bad indentation. Found 8 spaces, expected 16
W0311:188: Bad indentation. Found 6 spaces, expected 12
W0311:189: Bad indentation. Found 8 spaces, expected 16
W0311:190: Bad indentation. Found 6 spaces, expected 12
W0311:191: Bad indentation. Found 8 spaces, expected 16
W0311:192: Bad indentation. Found 4 spaces, expected 8
W0311:193: Bad indentation. Found 6 spaces, expected 12
W0311:194: Bad indentation. Found 4 spaces, expected 8
W0311:195: Bad indentation. Found 6 spaces, expected 12
W0311:197: Bad indentation. Found 2 spaces, expected 4
W0311:198: Bad indentation. Found 4 spaces, expected 8
W0311:199: Bad indentation. Found 6 spaces, expected 12
W0311:200: Bad indentation. Found 4 spaces, expected 8
W0311:206: Bad indentation. Found 2 spaces, expected 4
W0311:208: Bad indentation. Found 4 spaces, expected 8
W0311:210: Bad indentation. Found 4 spaces, expected 8
W0311:213: Bad indentation. Found 2 spaces, expected 4
W0311:215: Bad indentation. Found 4 spaces, expected 8
W0311:217: Bad indentation. Found 4 spaces, expected 8
W0311:218: Bad indentation. Found 4 spaces, expected 8
W0311:219: Bad indentation. Found 4 spaces, expected 8
W0311:221: Bad indentation. Found 4 spaces, expected 8
W0311:222: Bad indentation. Found 4 spaces, expected 8
W0311:223: Bad indentation. Found 4 spaces, expected 8
W0311:236: Bad indentation. Found 2 spaces, expected 4
W0311:237: Bad indentation. Found 2 spaces, expected 4
W0311:239: Bad indentation. Found 2 spaces, expected 4
W0311:240: Bad indentation. Found 6 spaces, expected 8
W0311:242: Bad indentation. Found 2 spaces, expected 4
W0311:243: Bad indentation. Found 4 spaces, expected 8
W0311:245: Bad indentation. Found 4 spaces, expected 8
W0311:246: Bad indentation. Found 4 spaces, expected 8
W0311:247: Bad indentation. Found 4 spaces, expected 8
W0311:248: Bad indentation. Found 4 spaces, expected 8
W0311:250: Bad indentation. Found 4 spaces, expected 8
W0311:251: Bad indentation. Found 6 spaces, expected 12
W0311:253: Bad indentation. Found 4 spaces, expected 8
W0311:254: Bad indentation. Found 4 spaces, expected 8
W0311:257: Bad indentation. Found 4 spaces, expected 8
W0311:260: Bad indentation. Found 4 spaces, expected 8
W0311:262: Bad indentation. Found 2 spaces, expected 4
W0311:264: Bad indentation. Found 2 spaces, expected 4
W0311:265: Bad indentation. Found 4 spaces, expected 8
W0311:267: Bad indentation. Found 2 spaces, expected 4
W0311:268: Bad indentation. Found 4 spaces, expected 8
W0311:270: Bad indentation. Found 2 spaces, expected 4
W0311:271: Bad indentation. Found 4 spaces, expected 8
W0311:273: Bad indentation. Found 4 spaces, expected 8
W0311:274: Bad indentation. Found 4 spaces, expected 8
W0311:276: Bad indentation. Found 4 spaces, expected 8
W0311:277: Bad indentation. Found 4 spaces, expected 8
W0311:279: Bad indentation. Found 4 spaces, expected 8
W0311:280: Bad indentation. Found 8 spaces, expected 12
W0311:281: Bad indentation. Found 12 spaces, expected 16
W0311:282: Bad indentation. Found 12 spaces, expected 16
W0311:283: Bad indentation. Found 12 spaces, expected 16
W0311:284: Bad indentation. Found 12 spaces, expected 16
W0311:285: Bad indentation. Found 12 spaces, expected 16
W0311:291: Bad indentation. Found 4 spaces, expected 8
W0311:292: Bad indentation. Found 4 spaces, expected 8
W0311:293: Bad indentation. Found 4 spaces, expected 8
W0311:295: Bad indentation. Found 4 spaces, expected 8
W0311:296: Bad indentation. Found 4 spaces, expected 8
W0311:298: Bad indentation. Found 2 spaces, expected 4
W0311:299: Bad indentation. Found 2 spaces, expected 4
W0311:305: Bad indentation. Found 2 spaces, expected 4
W0311:306: Bad indentation. Found 4 spaces, expected 8
W0311:308: Bad indentation. Found 4 spaces, expected 8
W0311:310: Bad indentation. Found 4 spaces, expected 8
W0311:311: Bad indentation. Found 4 spaces, expected 8
W0311:314: Bad indentation. Found 2 spaces, expected 4
W0311:317: Bad indentation. Found 4 spaces, expected 8
W0311:321: Bad indentation. Found 2 spaces, expected 4
W0311:322: Bad indentation. Found 2 spaces, expected 4
W0311:324: Bad indentation. Found 2 spaces, expected 4
W0311:326: Bad indentation. Found 4 spaces, expected 8
W0311:327: Bad indentation. Found 4 spaces, expected 8
W0311:328: Bad indentation. Found 4 spaces, expected 8
W0311:329: Bad indentation. Found 4 spaces, expected 8
W0311:333: Bad indentation. Found 2 spaces, expected 4
W0311:338: Bad indentation. Found 2 spaces, expected 4
W0311:339: Bad indentation. Found 4 spaces, expected 8
W0311:340: Bad indentation. Found 4 spaces, expected 8
W0311:341: Bad indentation. Found 4 spaces, expected 8
W0311:343: Bad indentation. Found 2 spaces, expected 4
W0311:344: Bad indentation. Found 4 spaces, expected 8
W0311:345: Bad indentation. Found 4 spaces, expected 8
W0311:346: Bad indentation. Found 6 spaces, expected 12
W0311:347: Bad indentation. Found 4 spaces, expected 8
W0311:353: Bad indentation. Found 2 spaces, expected 4
W0311:354: Bad indentation. Found 4 spaces, expected 8
W0311:355: Bad indentation. Found 4 spaces, expected 8
W0311:356: Bad indentation. Found 4 spaces, expected 8
W0311:357: Bad indentation. Found 4 spaces, expected 8
W0311:359: Bad indentation. Found 2 spaces, expected 4
W0311:360: Bad indentation. Found 4 spaces, expected 8
W0311:366: Bad indentation. Found 2 spaces, expected 4
W0311:367: Bad indentation. Found 4 spaces, expected 8
W0311:374: Bad indentation. Found 2 spaces, expected 4
W0311:377: Bad indentation. Found 6 spaces, expected 8
W0311:378: Bad indentation. Found 6 spaces, expected 8
W0311:381: Bad indentation. Found 6 spaces, expected 8
W0311:383: Bad indentation. Found 2 spaces, expected 4
W0311:385: Bad indentation. Found 4 spaces, expected 8
W0311:387: Bad indentation. Found 4 spaces, expected 8
W0311:389: Bad indentation. Found 4 spaces, expected 8
W0311:391: Bad indentation. Found 2 spaces, expected 4
W0311:393: Bad indentation. Found 4 spaces, expected 8
W0311:398: Bad indentation. Found 4 spaces, expected 8
W0311:399: Bad indentation. Found 4 spaces, expected 8
W0311:400: Bad indentation. Found 4 spaces, expected 8
W0311:402: Bad indentation. Found 2 spaces, expected 4
W0311:406: Bad indentation. Found 4 spaces, expected 8
W0311:407: Bad indentation. Found 8 spaces, expected 12
W0311:408: Bad indentation. Found 4 spaces, expected 8
W0311:412: Bad indentation. Found 2 spaces, expected 4
W0311:417: Bad indentation. Found 4 spaces, expected 8
W0311:421: Bad indentation. Found 4 spaces, expected 8
W0311:422: Bad indentation. Found 6 spaces, expected 12
W0311:424: Bad indentation. Found 4 spaces, expected 8
W0311:425: Bad indentation. Found 4 spaces, expected 8
W0311:426: Bad indentation. Found 4 spaces, expected 8
W0311:427: Bad indentation. Found 4 spaces, expected 8
W0311:430: Bad indentation. Found 4 spaces, expected 8
W0311:431: Bad indentation. Found 4 spaces, expected 8
W0311:433: Bad indentation. Found 2 spaces, expected 4
W0311:434: Bad indentation. Found 4 spaces, expected 8
W0311:436: Bad indentation. Found 2 spaces, expected 4
W0311:438: Bad indentation. Found 4 spaces, expected 8
W0311:440: Bad indentation. Found 2 spaces, expected 4
W0311:441: Bad indentation. Found 4 spaces, expected 8
W0311:443: Bad indentation. Found 4 spaces, expected 8
W0311:444: Bad indentation. Found 6 spaces, expected 12
W0311:446: Bad indentation. Found 6 spaces, expected 12
W0311:447: Bad indentation. Found 8 spaces, expected 16
W0311:448: Bad indentation. Found 6 spaces, expected 12
W0311:450: Bad indentation. Found 6 spaces, expected 12
W0311:451: Bad indentation. Found 6 spaces, expected 12
W0311:452: Bad indentation. Found 6 spaces, expected 12
W0311:454: Bad indentation. Found 6 spaces, expected 12
W0311:455: Bad indentation. Found 8 spaces, expected 16
W0311:456: Bad indentation. Found 6 spaces, expected 12
W0311:458: Bad indentation. Found 8 spaces, expected 16
W0311:459: Bad indentation. Found 8 spaces, expected 16
W0311:460: Bad indentation. Found 10 spaces, expected 20
W0311:461: Bad indentation. Found 14 spaces, expected 24
W0311:462: Bad indentation. Found 8 spaces, expected 16
W0311:464: Bad indentation. Found 6 spaces, expected 12
W0311:465: Bad indentation. Found 8 spaces, expected 16
W0311:466: Bad indentation. Found 6 spaces, expected 12
W0311:467: Bad indentation. Found 8 spaces, expected 16
W0311:469: Bad indentation. Found 6 spaces, expected 12
W0311:470: Bad indentation. Found 6 spaces, expected 12
W0311:471: Bad indentation. Found 8 spaces, expected 16
W0311:472: Bad indentation. Found 8 spaces, expected 16
W0311:473: Bad indentation. Found 6 spaces, expected 12
W0311:474: Bad indentation. Found 8 spaces, expected 16
W0311:475: Bad indentation. Found 6 spaces, expected 12
W0311:476: Bad indentation. Found 8 spaces, expected 16
W0311:483: Bad indentation. Found 2 spaces, expected 4
W0311:484: Bad indentation. Found 4 spaces, expected 8
W0311:486: Bad indentation. Found 2 spaces, expected 4
W0311:487: Bad indentation. Found 4 spaces, expected 8
W0311:489: Bad indentation. Found 2 spaces, expected 4
W0311:490: Bad indentation. Found 4 spaces, expected 8
W0311:493: Bad indentation. Found 2 spaces, expected 4
W0311:494: Bad indentation. Found 2 spaces, expected 4
W0311:496: Bad indentation. Found 2 spaces, expected 4
W0311:504: Bad indentation. Found 2 spaces, expected 4
W0311:505: Bad indentation. Found 4 spaces, expected 8
W0311:507: Bad indentation. Found 2 spaces, expected 4
W0311:508: Bad indentation. Found 4 spaces, expected 8
W0311:510: Bad indentation. Found 2 spaces, expected 4
W0311:511: Bad indentation. Found 4 spaces, expected 8
W0311:512: Bad indentation. Found 6 spaces, expected 12
W0311:514: Bad indentation. Found 2 spaces, expected 4
W0311:515: Bad indentation. Found 4 spaces, expected 8
W0311:517: Bad indentation. Found 2 spaces, expected 4
W0311:518: Bad indentation. Found 4 spaces, expected 8
W0311:519: Bad indentation. Found 6 spaces, expected 12
W0311:522: Bad indentation. Found 2 spaces, expected 4
W0311:524: Bad indentation. Found 4 spaces, expected 8
W0311:526: Bad indentation. Found 4 spaces, expected 8
W0311:528: Bad indentation. Found 2 spaces, expected 4
W0311:531: Bad indentation. Found 4 spaces, expected 8
W0311:532: Bad indentation. Found 4 spaces, expected 8
W0311:534: Bad indentation. Found 4 spaces, expected 8
W0311:538: Bad indentation. Found 4 spaces, expected 8
W0311:541: Bad indentation. Found 2 spaces, expected 4
W0311:542: Bad indentation. Found 4 spaces, expected 8
W0311:544: Bad indentation. Found 2 spaces, expected 4
W0311:545: Bad indentation. Found 4 spaces, expected 8
W0311:547: Bad indentation. Found 2 spaces, expected 4
W0311:550: Bad indentation. Found 4 spaces, expected 8
W0311:551: Bad indentation. Found 4 spaces, expected 8
W0311:553: Bad indentation. Found 2 spaces, expected 4
W0311:555: Bad indentation. Found 4 spaces, expected 8
W0311:557: Bad indentation. Found 6 spaces, expected 12
W0311:558: Bad indentation. Found 8 spaces, expected 16
W0311:559: Bad indentation. Found 6 spaces, expected 12
W0311:560: Bad indentation. Found 8 spaces, expected 16
W0311:562: Bad indentation. Found 6 spaces, expected 12
W0311:568: Bad indentation. Found 6 spaces, expected 12
W0311:570: Bad indentation. Found 6 spaces, expected 12
W0311:571: Bad indentation. Found 8 spaces, expected 16
W0511: 21: TODO >>
W0511: 22: TODO >>
W0511: 43: TODO >>
W0511: 97: TODO leoTkinterFrame finishCreate g.app.windowList.append(f) - use that?
W0511:319: TODO Tkinter onBodyChanged undo call and many others. =(
W0511:529: TODO Much more here: there's four hooks and all sorts of other things called in the TK version. 
W0221:267:textFrame.setTopGeometry: Arguments number differs from overridden method
W0221:391:textLeoMenu.new_menu: Arguments number differs from overridden method
W0221:412:textLeoMenu.add_command: Arguments number differs from overridden method
W0221:436:textLeoMenu.delete_range: Arguments number differs from overridden method
W0221:514:textTree.redraw: Arguments number differs from overridden method
W0221:517:textTree.redraw_now: Arguments number differs from overridden method
W0221:541:textTree.editLabel: Arguments number differs from overridden method


************* Module leo.plugins.dtest
W0611: 30: Unused import leoPlugins


************* Module leo.plugins.leo_interface
W0311: 42: Bad indentation. Found 3 spaces, expected 4
W0311: 43: Bad indentation. Found 6 spaces, expected 8
W0311: 47: Bad indentation. Found 3 spaces, expected 4
W0311: 48: Bad indentation. Found 6 spaces, expected 8
W0311: 59: Bad indentation. Found 3 spaces, expected 4
W0311: 66: Bad indentation. Found 3 spaces, expected 4
W0311: 67: Bad indentation. Found 7 spaces, expected 8
W0311: 70: Bad indentation. Found 3 spaces, expected 4
W0311: 71: Bad indentation. Found 7 spaces, expected 8
W0311: 72: Bad indentation. Found 7 spaces, expected 8
W0311: 75: Bad indentation. Found 3 spaces, expected 4
W0311: 76: Bad indentation. Found 7 spaces, expected 8
W0311: 79: Bad indentation. Found 3 spaces, expected 4
W0311: 80: Bad indentation. Found 7 spaces, expected 8
W0311: 81: Bad indentation. Found 11 spaces, expected 12
W0311: 84: Bad indentation. Found 3 spaces, expected 4
W0311: 85: Bad indentation. Found 7 spaces, expected 8
W0311: 86: Bad indentation. Found 7 spaces, expected 8
W0311: 87: Bad indentation. Found 11 spaces, expected 12
W0311: 88: Bad indentation. Found 7 spaces, expected 8
W0311: 89: Bad indentation. Found 7 spaces, expected 8
W0311: 92: Bad indentation. Found 3 spaces, expected 4
W0311: 93: Bad indentation. Found 7 spaces, expected 8
W0311: 94: Bad indentation. Found 7 spaces, expected 8
W0311: 95: Bad indentation. Found 7 spaces, expected 8
W0311: 96: Bad indentation. Found 7 spaces, expected 8
W0311: 97: Bad indentation. Found 7 spaces, expected 8
W0311: 98: Bad indentation. Found 11 spaces, expected 12
W0311: 99: Bad indentation. Found 7 spaces, expected 8
W0311:100: Bad indentation. Found 7 spaces, expected 8
W0311:101: Bad indentation. Found 11 spaces, expected 12
W0311:102: Bad indentation. Found 7 spaces, expected 8
W0311:103: Bad indentation. Found 7 spaces, expected 8
W0311:104: Bad indentation. Found 7 spaces, expected 8
W0311:105: Bad indentation. Found 11 spaces, expected 12
W0311:108: Bad indentation. Found 3 spaces, expected 4
W0311:109: Bad indentation. Found 7 spaces, expected 8
W0311:110: Bad indentation. Found 7 spaces, expected 8
W0311:111: Bad indentation. Found 7 spaces, expected 8
W0311:112: Bad indentation. Found 7 spaces, expected 8
W0311:113: Bad indentation. Found 7 spaces, expected 8
W0311:114: Bad indentation. Found 11 spaces, expected 12
W0311:115: Bad indentation. Found 7 spaces, expected 8
W0311:120: Bad indentation. Found 3 spaces, expected 4
W0311:121: Bad indentation. Found 5 spaces, expected 8
W0311:130: Bad indentation. Found 3 spaces, expected 4
W0311:135: Bad indentation. Found 3 spaces, expected 4
W0311:136: Bad indentation. Found 6 spaces, expected 8
W0311:140: Bad indentation. Found 3 spaces, expected 4
W0311:141: Bad indentation. Found 6 spaces, expected 8
W0311:145: Bad indentation. Found 3 spaces, expected 4
W0311:146: Bad indentation. Found 7 spaces, expected 8
W0311:149: Bad indentation. Found 3 spaces, expected 4
W0311:150: Bad indentation. Found 7 spaces, expected 8
W0311:151: Bad indentation. Found 7 spaces, expected 8
W0311:154: Bad indentation. Found 3 spaces, expected 4
W0311:155: Bad indentation. Found 7 spaces, expected 8
W0311:156: Bad indentation. Found 7 spaces, expected 8
W0311:157: Bad indentation. Found 7 spaces, expected 8
W0311:158: Bad indentation. Found 7 spaces, expected 8
W0311:161: Bad indentation. Found 3 spaces, expected 4
W0311:162: Bad indentation. Found 7 spaces, expected 8
W0311:165: Bad indentation. Found 7 spaces, expected 8
W0311:170: Bad indentation. Found 7 spaces, expected 8
W0311:171: Bad indentation. Found 7 spaces, expected 8
W0311:172: Bad indentation. Found 7 spaces, expected 8
W0311:173: Bad indentation. Found 10 spaces, expected 12
W0311:174: Bad indentation. Found 10 spaces, expected 12
W0311:175: Bad indentation. Found 7 spaces, expected 8
W0311:176: Bad indentation. Found 7 spaces, expected 8
W0311:179: Bad indentation. Found 3 spaces, expected 4
W0311:180: Bad indentation. Found 7 spaces, expected 8
W0311:181: Bad indentation. Found 11 spaces, expected 12
W0311:184: Bad indentation. Found 3 spaces, expected 4
W0311:185: Bad indentation. Found 6 spaces, expected 8
W0311:186: Bad indentation. Found 9 spaces, expected 12
W0311:187: Bad indentation. Found 9 spaces, expected 12
W0311:188: Bad indentation. Found 9 spaces, expected 12
W0311:189: Bad indentation. Found 6 spaces, expected 8
W0311:190: Bad indentation. Found 9 spaces, expected 12
W0311:194: Bad indentation. Found 3 spaces, expected 4
W0311:195: Bad indentation. Found 7 spaces, expected 8
W0311:202: Bad indentation. Found 3 spaces, expected 4
W0311:203: Bad indentation. Found 7 spaces, expected 8
W0311:206: Bad indentation. Found 3 spaces, expected 4
W0311:207: Bad indentation. Found 7 spaces, expected 8
W0311:210: Bad indentation. Found 3 spaces, expected 4
W0311:211: Bad indentation. Found 7 spaces, expected 8
W0311:214: Bad indentation. Found 3 spaces, expected 4
W0311:215: Bad indentation. Found 7 spaces, expected 8
W0311:224: Bad indentation. Found 3 spaces, expected 4
W0311:233: Bad indentation. Found 3 spaces, expected 4
W0311:234: Bad indentation. Found 3 spaces, expected 4
W0311:237: Bad indentation. Found 3 spaces, expected 4
W0311:238: Bad indentation. Found 7 spaces, expected 8
W0311:239: Bad indentation. Found 7 spaces, expected 8
W0311:240: Bad indentation. Found 7 spaces, expected 8
W0311:241: Bad indentation. Found 7 spaces, expected 8
W0311:242: Bad indentation. Found 7 spaces, expected 8
W0311:245: Bad indentation. Found 3 spaces, expected 4
W0311:246: Bad indentation. Found 7 spaces, expected 8
W0311:249: Bad indentation. Found 3 spaces, expected 4
W0311:250: Bad indentation. Found 7 spaces, expected 8
W0311:253: Bad indentation. Found 7 spaces, expected 8
W0311:254: Bad indentation. Found 11 spaces, expected 12
W0311:257: Bad indentation. Found 3 spaces, expected 4
W0311:258: Bad indentation. Found 7 spaces, expected 8
W0311:261: Bad indentation. Found 3 spaces, expected 4
W0311:262: Bad indentation. Found 6 spaces, expected 8
W0311:263: Bad indentation. Found 6 spaces, expected 8
W0311:264: Bad indentation. Found 9 spaces, expected 12
W0311:269: Bad indentation. Found 9 spaces, expected 12
W0311:270: Bad indentation. Found 9 spaces, expected 12
W0311:271: Bad indentation. Found 12 spaces, expected 16
W0311:272: Bad indentation. Found 12 spaces, expected 16
W0311:273: Bad indentation. Found 12 spaces, expected 16
W0311:274: Bad indentation. Found 12 spaces, expected 16
W0311:275: Bad indentation. Found 15 spaces, expected 20
W0311:276: Bad indentation. Found 12 spaces, expected 16
W0311:277: Bad indentation. Found 12 spaces, expected 16
W0311:278: Bad indentation. Found 9 spaces, expected 12
W0311:279: Bad indentation. Found 9 spaces, expected 12
W0311:280: Bad indentation. Found 9 spaces, expected 12
W0311:281: Bad indentation. Found 9 spaces, expected 12
W0311:282: Bad indentation. Found 6 spaces, expected 8
W0311:283: Bad indentation. Found 6 spaces, expected 8
W0311:284: Bad indentation. Found 9 spaces, expected 12
W0311:285: Bad indentation. Found 9 spaces, expected 12
W0311:288: Bad indentation. Found 3 spaces, expected 4
W0311:289: Bad indentation. Found 6 spaces, expected 8
W0311:290: Bad indentation. Found 6 spaces, expected 8
W0311:291: Bad indentation. Found 9 spaces, expected 12
W0311:294: Bad indentation. Found 3 spaces, expected 4
W0311:295: Bad indentation. Found 7 spaces, expected 8
W0311:298: Bad indentation. Found 3 spaces, expected 4
W0311:299: Bad indentation. Found 7 spaces, expected 8
W0311:302: Bad indentation. Found 3 spaces, expected 4
W0311:303: Bad indentation. Found 7 spaces, expected 8
W0311:306: Bad indentation. Found 3 spaces, expected 4
W0311:307: Bad indentation. Found 7 spaces, expected 8
W0311:311: Bad indentation. Found 3 spaces, expected 4
W0311:312: Bad indentation. Found 7 spaces, expected 8
W0311:315: Bad indentation. Found 3 spaces, expected 4
W0311:316: Bad indentation. Found 6 spaces, expected 8
W0311:322: Bad indentation. Found 3 spaces, expected 4
W0311:336: Bad indentation. Found 3 spaces, expected 4
W0311:337: Bad indentation. Found 6 spaces, expected 8
W0311:338: Bad indentation. Found 6 spaces, expected 8
W0311:342: Bad indentation. Found 3 spaces, expected 4
W0311:343: Bad indentation. Found 6 spaces, expected 8
W0311:350: Bad indentation. Found 3 spaces, expected 4
W0311:351: Bad indentation. Found 6 spaces, expected 8
W0601:173:leo_file.gen1: Global variable 'vnode_count' undefined at the module level
W0601:186:leo_file.gen_vnodes: Global variable 'allvnodes' undefined at the module level
W0601:186:leo_file.gen_vnodes: Global variable 'vnode_stack' undefined at the module level
W0105:268:leo_node.gen_vnodes: String statement has no effect
W0601:278:leo_node.gen_vnodes: Global variable 'vnode_count' undefined at the module level


************* Module leo.plugins.leo_pdf
E0602:322:Bunch.__setitem__: Undefined variable 'operator'
E0602:326:Bunch.__getitem__: Undefined variable 'operator'
W0105:344:Writer: String statement has no effect
W0105:372:Writer: String statement has no effect


************* Module leo.plugins.leoOPML
E1101:241:opmlFileCommandsClass.putOPMLHeader: Instance of 'opmlFileCommandsClass' has no 'opml_write_leo_globals_attributes' member
E1101:278:opmlFileCommandsClass.putOPMLNode: Instance of 'opmlFileCommandsClass' has no 'opml_write_leo_details' member
E1101:294:opmlFileCommandsClass.putOPMLNode: Instance of 'opmlFileCommandsClass' has no 'opml_write_body_text' member
E1101:295:opmlFileCommandsClass.putOPMLNode: Instance of 'opmlFileCommandsClass' has no 'opml_use_outline_elements' member
E1101:373:opmlFileCommandsClass.uAAttributes: Instance of 'opmlFileCommandsClass' has no 'opml_write_ua_attributes' member
E1101:375:opmlFileCommandsClass.uAAttributes: Instance of 'opmlFileCommandsClass' has no 'opml_expand_ua_dictionary' member
E1101:377:opmlFileCommandsClass.uAAttributes: Instance of 'opmlFileCommandsClass' has no 'opml_skip_ua_dictionary_blanks' member
E1101:485:opmlController.createVnode: Module 'leo.core.leoNodes' has no 'tnode' member
E1101:489:opmlController.createVnode: Instance of 'vnode' has no 't' member
W0221:887:contentHandler.ignorableWhitespace: Arguments number differs from overridden method


************* Module leo.plugins.leoremote
W0611: 45: Unused import sys


************* Module leo.plugins.lineNumbers
E1121: 48:init.putLineNumberDirective: Too many positional arguments for function call


************* Module leo.plugins.macros
This is a real error.
E1103:130:paramClass.parameterize: Instance of 'unitTestGui' has no 'getInsertPoint' member (but some types could not be inferred)
E1103:130:paramClass.parameterize: Instance of 'nullGui' has no 'getInsertPoint' member (but some types could not be inferred)


************* Module leo.plugins.mod_autosave
W0311: 85: Bad indentation. Found 9 spaces, expected 8
W0611: 24: Unused import os


************* Module leo.plugins.mod_leo2ascd
E1120:133:GetAscFilename: No value passed for parameter 'vnode' in function call
E1120:353:WriteTreeOfCurrentNode: No value passed for parameter 'vnode' in function call
E1120:368:WriteAll: No value passed for parameter 'vnode' in function call
E1120:427: No value passed for parameter 'c' in function call


************* Module leo.plugins.mod_speedups
W0611: 30: Unused import leoPlugins
W0611: 52: Unused import leo


************* Module leo.plugins.nav_buttons
W0311:347: Bad indentation. Found 11 spaces, expected 12


************* Module leo.plugins.nodeActions
W0312: 63: Found indentation with tabs instead of spaces
W0312: 64: Found indentation with tabs instead of spaces
W0312: 65: Found indentation with tabs instead of spaces
W0312: 66: Found indentation with tabs instead of spaces
W0312: 67: Found indentation with tabs instead of spaces
W0312: 68: Found indentation with tabs instead of spaces
W0311: 72: Bad indentation. Found 3 spaces, expected 4
W0311: 81: Bad indentation. Found 3 spaces, expected 4
W0311: 83: Bad indentation. Found 3 spaces, expected 4
W0311: 84: Bad indentation. Found 6 spaces, expected 8
W0311: 87: Bad indentation. Found 3 spaces, expected 4
W0311: 88: Bad indentation. Found 3 spaces, expected 4
W0311: 89: Bad indentation. Found 6 spaces, expected 8
W0311: 92: Bad indentation. Found 3 spaces, expected 4
W0311: 93: Bad indentation. Found 3 spaces, expected 4
W0311: 94: Bad indentation. Found 6 spaces, expected 8
W0311: 96: Bad indentation. Found 3 spaces, expected 4
W0311: 98: Bad indentation. Found 6 spaces, expected 8
W0311: 99: Bad indentation. Found 6 spaces, expected 8
W0311:101: Bad indentation. Found 6 spaces, expected 8
W0311:104: Bad indentation. Found 9 spaces, expected 12
W0311:105: Bad indentation. Found 12 spaces, expected 16
W0311:108: Bad indentation. Found 9 spaces, expected 12
W0311:109: Bad indentation. Found 12 spaces, expected 16
W0311:111: Bad indentation. Found 9 spaces, expected 12
W0311:112: Bad indentation. Found 9 spaces, expected 12
W0311:113: Bad indentation. Found 12 spaces, expected 16
W0311:116: Bad indentation. Found 9 spaces, expected 12
W0311:117: Bad indentation. Found 9 spaces, expected 12
W0311:118: Bad indentation. Found 12 spaces, expected 16
W0311:119: Bad indentation. Found 9 spaces, expected 12
W0311:120: Bad indentation. Found 12 spaces, expected 16
W0311:122: Bad indentation. Found 9 spaces, expected 12
W0311:123: Bad indentation. Found 9 spaces, expected 12
W0311:124: Bad indentation. Found 9 spaces, expected 12
W0311:125: Bad indentation. Found 12 spaces, expected 16
W0311:127: Bad indentation. Found 9 spaces, expected 12
W0311:128: Bad indentation. Found 9 spaces, expected 12
W0311:129: Bad indentation. Found 12 spaces, expected 16
W0311:133: Bad indentation. Found 9 spaces, expected 12
W0311:137: Bad indentation. Found 9 spaces, expected 12
W0311:138: Bad indentation. Found 9 spaces, expected 12
W0311:139: Bad indentation. Found 9 spaces, expected 12
W0311:141: Bad indentation. Found 12 spaces, expected 16
W0311:142: Bad indentation. Found 12 spaces, expected 16
W0311:143: Bad indentation. Found 15 spaces, expected 20
W0311:145: Bad indentation. Found 15 spaces, expected 20
W0311:146: Bad indentation. Found 15 spaces, expected 20
W0311:147: Bad indentation. Found 18 spaces, expected 24
W0311:151: Bad indentation. Found 9 spaces, expected 12
W0311:152: Bad indentation. Found 12 spaces, expected 16
W0311:153: Bad indentation. Found 9 spaces, expected 12
W0311:154: Bad indentation. Found 12 spaces, expected 16
W0311:155: Bad indentation. Found 9 spaces, expected 12
W0311:156: Bad indentation. Found 12 spaces, expected 16
W0311:157: Bad indentation. Found 15 spaces, expected 20
W0311:158: Bad indentation. Found 12 spaces, expected 16
W0311:159: Bad indentation. Found 15 spaces, expected 20
W0311:162: Bad indentation. Found 12 spaces, expected 16
W0311:163: Bad indentation. Found 15 spaces, expected 20
W0311:165: Bad indentation. Found 18 spaces, expected 24
W0311:166: Bad indentation. Found 18 spaces, expected 24
W0311:167: Bad indentation. Found 18 spaces, expected 24
W0311:168: Bad indentation. Found 18 spaces, expected 24
W0311:169: Bad indentation. Found 21 spaces, expected 28
W0311:171: Bad indentation. Found 12 spaces, expected 16
W0311:173: Bad indentation. Found 12 spaces, expected 16
W0311:175: Bad indentation. Found 12 spaces, expected 16
W0311:176: Bad indentation. Found 15 spaces, expected 20
W0311:177: Bad indentation. Found 9 spaces, expected 12
W0311:178: Bad indentation. Found 12 spaces, expected 16
W0311:179: Bad indentation. Found 15 spaces, expected 20
W0311:182: Bad indentation. Found 6 spaces, expected 8
W0311:184: Bad indentation. Found 9 spaces, expected 12
W0311:185: Bad indentation. Found 12 spaces, expected 16
W0311:186: Bad indentation. Found 9 spaces, expected 12
W0311:187: Bad indentation. Found 6 spaces, expected 8
W0311:189: Bad indentation. Found 9 spaces, expected 12
W0311:190: Bad indentation. Found 12 spaces, expected 16
W0311:191: Bad indentation. Found 9 spaces, expected 12
W0311:192: Bad indentation. Found 6 spaces, expected 8
W0311:194: Bad indentation. Found 9 spaces, expected 12
W0311:195: Bad indentation. Found 12 spaces, expected 16
W0311:196: Bad indentation. Found 9 spaces, expected 12
W0311:197: Bad indentation. Found 3 spaces, expected 4
W0311:199: Bad indentation. Found 6 spaces, expected 8
W0311:200: Bad indentation. Found 9 spaces, expected 12
W0311:201: Bad indentation. Found 6 spaces, expected 8
W0311:205: Bad indentation. Found 3 spaces, expected 4
W0311:206: Bad indentation. Found 3 spaces, expected 4
W0311:207: Bad indentation. Found 7 spaces, expected 8
W0311:208: Bad indentation. Found 7 spaces, expected 8
W0311:209: Bad indentation. Found 7 spaces, expected 8
W0311:210: Bad indentation. Found 7 spaces, expected 8
W0311:212: Bad indentation. Found 7 spaces, expected 8
W0311:213: Bad indentation. Found 11 spaces, expected 12
W0311:214: Bad indentation. Found 11 spaces, expected 12
W0311:215: Bad indentation. Found 7 spaces, expected 8
W0311:216: Bad indentation. Found 11 spaces, expected 12
W0311:222: Bad indentation. Found 11 spaces, expected 12
W0311:224: Bad indentation. Found 11 spaces, expected 12
W0311:225: Bad indentation. Found 15 spaces, expected 16
W0311:226: Bad indentation. Found 15 spaces, expected 16
W0311:227: Bad indentation. Found 7 spaces, expected 8
W0311:229: Bad indentation. Found 11 spaces, expected 12
W0311:230: Bad indentation. Found 15 spaces, expected 16
W0311:231: Bad indentation. Found 15 spaces, expected 16
W0311:232: Bad indentation. Found 11 spaces, expected 12
W0311:233: Bad indentation. Found 11 spaces, expected 12
W0311:235: Bad indentation. Found 7 spaces, expected 8


************* Module leo.plugins.nodebar
W0601:183:initImages: Global variable 'clonePI' undefined at the module level
W0601:184:initImages: Global variable 'copyPI' undefined at the module level
W0601:185:initImages: Global variable 'cutPI' undefined at the module level
W0601:186:initImages: Global variable 'dehoistPI' undefined at the module level
W0601:187:initImages: Global variable 'deletePI' undefined at the module level
W0601:188:initImages: Global variable 'demotePI' undefined at the module level
W0601:189:initImages: Global variable 'hoistPI' undefined at the module level
W0601:190:initImages: Global variable 'insertPI' undefined at the module level
W0601:191:initImages: Global variable 'movedownPI' undefined at the module level
W0601:192:initImages: Global variable 'moveleftPI' undefined at the module level
W0601:193:initImages: Global variable 'moverightPI' undefined at the module level
W0601:194:initImages: Global variable 'moveupPI' undefined at the module level
W0601:195:initImages: Global variable 'nodedownPI' undefined at the module level
W0601:196:initImages: Global variable 'nodeleftPI' undefined at the module level
W0601:197:initImages: Global variable 'noderightPI' undefined at the module level
W0601:198:initImages: Global variable 'nodeupPI' undefined at the module level
W0601:199:initImages: Global variable 'pastePI' undefined at the module level
W0601:200:initImages: Global variable 'pasteclonePI' undefined at the module level
W0601:201:initImages: Global variable 'promotePI' undefined at the module level
W0601:202:initImages: Global variable 'questionPI' undefined at the module level
W0601:203:initImages: Global variable 'sortchildrenPI' undefined at the module level
W0601:204:initImages: Global variable 'sortsiblingsPI' undefined at the module level
W0611: 21: Unused import weakref


************* Module leo.plugins.pretty_print
W0233: 52:myPrettyPrinter.__init__: __init__ method from a non direct base class 'myPrettyPrinter' is called
E0602: 62:myPrettyPrinter.putNormalToken: Undefined variable 'token'
E0602:188:myPrettyPrinter.doOp: Undefined variable 'keyword'
E0602:223:myPrettyPrinter.doOp: Undefined variable 'string'
E0602:223:myPrettyPrinter.doOp: Undefined variable 'string'


************* Module leo.plugins.quickMove
W0311:220: Bad indentation. Found 16 spaces, expected 12
W0311:225: Bad indentation. Found 16 spaces, expected 12
E1101:220:quickMove.__init__: Module 'leo.core.leoGlobals' has no 'tree_popup_handlers' member
E1101:225:quickMove.__del__: Module 'leo.core.leoGlobals' has no 'tree_popup_handlers' member
W0611:106: Unused import types


************* Module leo.plugins.quicksearch
W0301:222: Unnecessary semicolon
W0301:240: Unnecessary semicolon
W0604: 73: Using the global statement at the module level
W0611: 42: Unused import QListWidget


************* Module leo.plugins.rClickBasePluginClasses
E1101:134:pluginCommandClass.preDoCommand: Instance of 'pluginCommandClass' has no 'doCommand' member
E1101:260:basePluginController.getPublicCommands: Instance of 'basePluginController' has no 'commandList' member
E1101:267:basePluginController.getPublicCommands: Instance of 'basePluginController' has no 'commandPrefix' member
E1101:272:basePluginController.getPublicCommands: Instance of 'basePluginController' has no 'commandPrefix' member
E1101:310:basePluginController.getCommandList: Instance of 'basePluginController' has no 'commandList' member
E1101:318:basePluginController.setDefaultContextMenus: Instance of 'basePluginController' has no 'defaultContextMenus' member


************* Module leo.plugins.run_nodes
E1120:210:OnQuit: No value passed for parameter 'c' in function call


************* Module leo.plugins.rst3
E1120:263:runUnitTests: No value passed for parameter 'headline' in function call
E1120:1017:rstClass.initOptionsFromSettings: No value passed for parameter 'tag' in function call


************* Module leo.plugins.scrolledmessage
W0311:407: Bad indentation. Found 12 spaces, expected 8
W0311:408: Bad indentation. Found 12 spaces, expected 8
W0311:410: Bad indentation. Found 12 spaces, expected 8
W0311:411: Bad indentation. Found 12 spaces, expected 8
E1101:289:ScrolledMessageDialog.doActionOutlineShow: Instance of 'ScrolledMessageDialog' has no 'name' member
W0107:314:ScrolledMessageDialog.doActionAbout: Unnecessary pass statement
E1101:318:ScrolledMessageDialog.doActionRST3: Instance of 'LeoApp' has no 'pluginsController' member
E1101:532:ScrolledMessageDialog.updateDialog: Instance of 'ScrolledMessageDialog' has no 'label' member
E1101:533:ScrolledMessageDialog.updateDialog: Instance of 'ScrolledMessageDialog' has no 'label' member
E1101:539:ScrolledMessageDialog.updateDialog: Instance of 'ScrolledMessageDialog' has no 'title' member
E0211:543:ScrolledMessageDialog.afterDrawHandler: Method has no argument
E0602:613:ScrolledMessageController.afterRedrawHandler: Undefined variable 'dialogs'
E1120:614:ScrolledMessageController.afterRedrawHandler: No value passed for parameter 'tag' in function call
E1120:614:ScrolledMessageController.afterRedrawHandler: No value passed for parameter 'keywords' in function call
W0611: 91: Unused import inspect


************* Module leo.plugins.todo
E1101: 58:init: Module 'leo.core.leoGlobals' has no 'tree_popup_handlers' member
E0102:260:todoController.addPopupMenu.func: function already defined line 251
E0213:307:todoController.redrawer: Method should have "self" as first argument
E1102:312:todoController.redrawer.new: fn is not callable
E0213:322:todoController.projectChanger: Method should have "self" as first argument
E1102:325:todoController.projectChanger.new: fn is not callable

************* Module leo.plugins.toolbar
E1103:487:ToolbarTkinterFrame.getIconButton: Instance of 'tkIconBarClass' has no 'getButton' member (but some types could not be inferred)
E1103:487:ToolbarTkinterFrame.getIconButton: Instance of 'nullIconBarClass' has no 'getButton' member (but some types could not be inferred)
E1103:562:ToolbarTkinterFrame.getIconWidgetFrame: Instance of 'tkIconBarClass' has no 'getWidgetFrame' member (but some types could not be inferred)
E1103:562:ToolbarTkinterFrame.getIconWidgetFrame: Instance of 'nullIconBarClass' has no 'getWidgetFrame' member (but some types could not be inferred)
E1103:1360:ToolbarScriptingController.createScriptButtonIconButton: Instance of 'ToolbarScriptButton' has no 'configure' member (but some types could not be inferred)


************* Module leo.external.ipy_leo
W0601: 30:init_ipython: Global variable 'ip' undefined at the module level
W0107: 90:es: Unnecessary pass statement
W0108:231:LeoNode.<lambda>: Lambda may not be necessary
W1001:398:LeoWorkbook: Use of "property" on an old style class
E1101:438:workbook_complete: Function 'dispatch' has no 'when_type' member
E1101:438:workbook_complete: Function 'complete_object' has no 'when_type' member
E1101:589:edit_macro: Function 'edit_object_in_leo' has no 'when_type' member
W0601:749:lleo_f: Global variable '_request_immediate_connect' undefined at the module level


************* Module leo.external.lproto
E1101:137:LProtoClient.__init__: Module 'socket' has no 'AF_UNIX' member
#@+node:ekr.20100907092144.5901: *3* Unit tests
# These are intended to be temporary tests,
# to be copied eventually to unitTest.leo
#@+node:ekr.20100907115157.5905: *4* @ignore
#@+node:ekr.20100208095423.5940: *5* @test leoCache
import leo.core.leoCache as leoCache

cacher = leoCache.cacher(c)

if 0:
    import os
    os.system('cls')

assert cacher.test()
#@+node:ekr.20100906165118.5915: *5* @test leoInkCommands
ic = c.inkscapeCommands
screenshot = r'c:\leo.repo\inkcall\some_screen_shot.png'
template_fn = r'c:\leo.repo\inkcall\template.svg'
png_fn = r'c:\leo.repo\inkcall\output.png'
svg_fn = r'c:\leo.repo\inkcall\temp.svg'
callouts = [
        "This goes here",
        "These are those, but slightly longer",
        "Then you pull this, but this text needs to be longer for testing",]
ic.run(
    screenshot,
    callouts=callouts,
    numbers=[2,4,17],
    edit_flag = True, # True: call inkscape to edit the working file.
    png_fn=png_fn, # Optional: Name of output png file.
    svg_fn=svg_fn, # Optional: Name of working svg file.
    template_fn=template_fn, # Optional: Name of template svg file.
)
#@+node:ekr.20110621074459.14908: ** 4.9.1
#@+node:ekr.20110730093802.15134: *3* Bugs
#@+node:ekr.20110621074459.14904: *4* Fixed ancient hanger in paste-retaining-clones
@nocolor-node

https://bugs.launchpad.net/leo-editor/+bug/800157

In a new file containing only a "NewHeadline" and that being selected, execute:

copy-node
insert-child
<<enter>>
undo
paste-retaining-clones

Leo's UI freezes and loops forever with 100% CPU.

Note: If one does not undo, Leo prints "Invalid paste: nodes may not descend
from themselves". I guess the undo circumvents such a check. However, that
should not be the case, as paste-retaining-clones inserts the clones _after_ and
not as children of the selected node "NewHeadline".

I guess that the undo forgets to set the selection back to "NewHeadline", so
that Leo tries to insert the clones after the undone child node - therefore as
child of "NewHeadline".

====================

EKR: only getLeoOutlineFromClipboar calls checkPaste.
#@+node:ekr.20031218072017.1551: *5* pasteOutline
# To cut and paste between apps, just copy into an empty body first, then copy to Leo's clipboard.

def pasteOutline(self,event=None,reassignIndices=True):

    '''Paste an outline into the present outline from the clipboard.
    Nodes do *not* retain their original identify.'''

    c = self ; u = c.undoer ; current = c.p
    s = g.app.gui.getTextFromClipboard()
    pasteAsClone = not reassignIndices
    undoType = g.choose(reassignIndices,'Paste Node','Paste As Clone')

    c.endEditing()

    if not s or not c.canPasteOutline(s):
        return # This should never happen.

    isLeo = g.match(s,0,g.app.prolog_prefix_string)
    vnodeInfoDict = {}
    if pasteAsClone:
        << remember all data for undo/redo Paste As Clone >>
    # create a *position* to be pasted.

    if isLeo:
        pasted = c.fileCommands.getLeoOutlineFromClipboard(s,reassignIndices)
    else:
        pasted = c.importCommands.convertMoreStringToOutlineAfter(s,current)

    if not pasted: return

    copiedBunchList = []
    if pasteAsClone:
        << put only needed info in copiedBunchList >>
    undoData = u.beforeInsertNode(current,
        pasteAsClone=pasteAsClone,copiedBunchList=copiedBunchList)

    c.validateOutline()
    c.selectPosition(pasted)
    pasted.setDirty()
    c.setChanged(True)
    # paste as first child if back is expanded.
    back = pasted.back()
    if back and back.hasChildren() and back.isExpanded():
        # 2011/06/21: fixed hanger: test back.hasChildren().
        pasted.moveToNthChildOf(back,0)
    # c.setRootPosition()

    if pasteAsClone:
        # Set dirty bits for ancestors of *all* pasted nodes.
        # Note: the setDescendentsDirty flag does not do what we want.
        for p in pasted.self_and_subtree():
            p.setAllAncestorAtFileNodesDirty(
                setDescendentsDirty=False)

    u.afterInsertNode(pasted,undoType,undoData)
    c.redraw(pasted)
    c.recolor()
#@+node:ekr.20050418084539: *6* << remember all data for undo/redo Paste As Clone >>
@

We don't know yet which nodes will be affected by the paste, so we remember
everything. This is expensive, but foolproof.

The alternative is to try to remember the 'before' values of tnodes in the
fileCommands read logic. Several experiments failed, and the code is very ugly.
In short, it seems wise to do things the foolproof way.

@c

for v in c.all_unique_nodes():
    if v not in vnodeInfoDict:
        vnodeInfoDict[v] = g.Bunch(
            v=v,head=v.headString(),body=v.b)
#@+node:ekr.20050418084539.2: *6* << put only needed info in copiedBunchList >>
# Create a dict containing only copied tnodes.
copiedVnodeDict = {}
for p in pasted.self_and_subtree():
    if p.v not in copiedVnodeDict:
        copiedVnodeDict[p.v] = p.v

# g.trace(list(copiedVnodeDict.keys()))

for v in vnodeInfoDict:
    bunch = vnodeInfoDict.get(v)
    if copiedVnodeDict.get(v):
        copiedBunchList.append(bunch)

# g.trace('copiedBunchList',copiedBunchList)
#@+node:ekr.20110705101348.14898: *4* Fixed bug in p.setAllAncestorAtFileNodesDirty
@language rest

The code that marks descendant @<file> nodes dirty now tests
p2.isAnyAtFileNode().  The old code tested p2.isAtThinFileNode().
#@+node:ekr.20040303214038: *5* p.setAllAncestorAtFileNodesDirty
def setAllAncestorAtFileNodesDirty (self,setDescendentsDirty=False):

    trace = False and not g.unitTesting
    verbose = False
    p = self
    dirtyVnodeList = []

    # Calculate all nodes that are joined to p or parents of such nodes.
    nodes = p.findAllPotentiallyDirtyNodes()

    if setDescendentsDirty:
        # N.B. Only mark _direct_ descendents of nodes.
        # Using the findAllPotentiallyDirtyNodes algorithm would mark way too many nodes.
        for p2 in p.subtree():
            # Only @thin nodes need to be marked.
            if p2.v not in nodes and p2.isAnyAtFileNode():
                    # Bug fix: 2011/07/05: was p2.isAtThinFileNode():
                nodes.append(p2.v)

    if trace and verbose:
        for v in nodes:
            print (v.isDirty(),v.isAnyAtFileNode(),v)

    dirtyVnodeList = [v for v in nodes
        if not v.isDirty() and v.isAnyAtFileNode()]
    changed = len(dirtyVnodeList) > 0

    for v in dirtyVnodeList:
        v.setDirty()

    if trace: g.trace("position",dirtyVnodeList,g.callers(5))

    return dirtyVnodeList
#@+node:ekr.20110717110529.14970: *4* Removed timer hack from double-click code
#@+node:tbrown.20090219095555.61: *5* g.handleUrlInUrlNode
def handleUrlInUrlNode(url, c=None, p=None):
    
    # Note 1: the UNL plugin has its own notion of what a good url is.

    # Note 2: tree.OnIconDoubleClick now uses the body text of an @url
    #         node if it exists.

    if g.unitTesting: return
    << check the url; return if bad >>
    << pass the url to the web browser >>
#@+node:tbrown.20090219095555.62: *6* << check the url; return if bad >>
@ A valid url is (according to D.T.Hein):

3 or more lowercase alphas, followed by,
one ':', followed by,
one or more of: (excludes !"#;<>[\]^`|)
  $%&'()*+,-./0-9:=?@A-Z_a-z{}~
followed by one of: (same as above, except no minus sign or comma).
  $%&'()*+/0-9:=?@A-Z_a-z}~
@c

# urlPattern = "[a-z]{3,}:[\$-:=?-Z_a-z{}~]+[\$-+\/-:=?-Z_a-z}~]"

if not url or len(url) == 0:
    g.es("no url following @url")
    return

# Add http:// if required.
# if not re.match('^([a-z]{3,}:)',url):
#     url = 'http://' + url
# if not re.match(urlPattern,url):
#     g.es("invalid url:",url)
#     return
#@+node:tbrown.20090219095555.63: *6* << pass the url to the web browser >>
@ Most browsers should handle the following urls:
  ftp://ftp.uu.net/public/whatever.
  http://localhost/MySiteUnderDevelopment/index.html
  file://home/me/todolist.html
@c

try:
    
    parsed = urlparse(url)
    
    leo_path = parsed.path
    if parsed.netloc:
        leo_path = os.path.join(parsed.netloc, parsed.path)
        # "readme.txt" gets parsed into .netloc...
    
    if c and parsed.scheme in ('', 'file'):
        
        # local UNLs like "node-->subnode", "-->node", and "#node"
        if '-->' in parsed.path:
            g.recursiveUNLSearch(parsed.path.split("-->"), c)
            return
        if not parsed.path and parsed.fragment:
            g.recursiveUNLSearch(parsed.fragment.split("-->"), c)
            return

        # leo aware path
        leo_path = os.path.expanduser(leo_path)
        leo_path = g.os_path_expandExpression(leo_path, c=c)
        if p and not os.path.isabs(leo_path):
            leo_path = os.path.normpath(
                os.path.join(c.getNodePath(p), leo_path))

        # .leo file
        if leo_path.lower().endswith('.leo') and os.path.exists(leo_path):
            # 2011/07/28: Immediately end editing, so that
            # typing in the new window works properly.
            c.endEditing()
            c.redraw_now()
            ok,frame = g.openWithFileName(leo_path, c)
            
            # with UNL after path
            if ok and parsed.fragment:
                g.recursiveUNLSearch(parsed.fragment.split("-->"), frame.c)
                
            if ok:
                frame.c.bringToFront()
                return
                
    if parsed.scheme in ('', 'file'):
        if os.path.exists(leo_path):
            g.os_startfile(leo_path)
            return
        if parsed.scheme == 'file':
            g.es("File '%s' does not exist"%leo_path)
            return
        
    import webbrowser
    # Mozilla throws a weird exception, then opens the file!
    try: webbrowser.open(url)
    except: pass
    
except:
    g.es("exception opening",url)
    g.es_exception()
#@+node:tbrown.20110219154422.37469: *5* recursiveUNLSearch
def recursiveUNLSearch(unlList, c, depth=0, p=None, maxdepth=0, maxp=None):
    """try and move to unl in the commander c
    
    NOTE: maxdepth is max depth seen in recursion so far, not a limit on
          how fast we will recurse.  So it should default to 0 (zero).
    """

    def moveToP(c, p):
        c.expandAllAncestors(p) # 2009/11/07
        c.selectPosition(p)
        c.redraw()
        c.frame.bringToFront()  # doesn't seem to work

    if depth == 0:
        nds = c.rootPosition().self_and_siblings()
        unlList = [i for i in unlList if i.strip()]
        # drop empty parts so "-->node name" works
    else:
        nds = p.children()

    for i in nds:

        if unlList[depth] == i.h:

            if depth+1 == len(unlList):  # found it
                moveToP(c, i)
                return True, maxdepth, maxp
            else:
                if maxdepth < depth+1:
                    maxdepth = depth+1
                    maxp = i.copy()
                found, maxdepth, maxp = g.recursiveUNLSearch(unlList, c, depth+1, i, maxdepth, maxp)
                if found:
                    return found, maxdepth, maxp
                # else keep looking through nds

    if depth == 0 and maxp:  # inexact match
        moveToP(c, maxp)
        g.es('Partial UNL match')

    return False, maxdepth, maxp
#@+node:ekr.20031218072017.2312: *5* tree.OnIconDoubleClick (@url) & helper
# Several plugins handle url's, especially UNL.py.

def OnIconDoubleClick (self,p):

    # Note: "icondclick" hooks handled by vnode callback routine.

    c = self.c
    s = p.h.strip()
    if g.match_word(s,0,"@url"): 
        if p.b.strip():
            lines = p.b.split('\n',1)
            url = lines and lines[0].strip() or ''
        else:
            url = s[4:].strip()
        # g.trace(url,g.callers())

        if not g.doHook("@url1",c=c,p=p,v=p,url=url):
            g.handleUrlInUrlNode(url, c=c, p=p)
        g.doHook("@url2",c=c,p=p,v=p)

    return # (for Tk) 'break' # 11/19/06
#@+node:ekr.20110605121601.18406: *5* qtTree.initAfterLoad
def initAfterLoad (self):

    '''Do late-state inits.'''

    # Called by Leo's core.

    c = self.c ; frame = c.frame
    w = c.frame.top ; tw = self.treeWidget

    if not leoQtTree.callbacksInjected:
        leoQtTree.callbacksInjected = True
        self.injectCallbacks() # A base class method.

    w.connect(self.treeWidget,QtCore.SIGNAL(
            "itemDoubleClicked(QTreeWidgetItem*, int)"),
        self.onItemDoubleClicked)

    w.connect(self.treeWidget,QtCore.SIGNAL(
            "itemClicked(QTreeWidgetItem*, int)"),
        self.onItemClicked)

    w.connect(self.treeWidget,QtCore.SIGNAL(
            "itemSelectionChanged()"),
        self.onTreeSelect)

    # We don't need this.  Hooray!
    # w.connect(self.treeWidget,QtCore.SIGNAL(
            # "itemChanged(QTreeWidgetItem*, int)"),
        # self.onItemChanged)

    w.connect(self.treeWidget,QtCore.SIGNAL(
            "itemCollapsed(QTreeWidgetItem*)"),
        self.onItemCollapsed)

    w.connect(self.treeWidget,QtCore.SIGNAL(
            "itemExpanded(QTreeWidgetItem*)"),
        self.onItemExpanded)

    w.connect(self.treeWidget, QtCore.SIGNAL(
            "customContextMenuRequested(QPoint)"),
        self.onContextMenu)

    self.ev_filter = leoQtEventFilter(c,w=self,tag='tree')
    tw.installEventFilter(self.ev_filter)

    # 2010/01/24: Do not set this here.
    # The read logic sets c.changed to indicate nodes have changed.
    # c.setChanged(False)
#@+node:ekr.20110605121601.17896: *5* onItemClicked (nativeTree)
def onItemClicked (self,item,col,auto_edit=False):

    # This is called after an item is selected.
    trace = False and not g.unitTesting ; verbose = False

    if self.busy(): return

    c = self.c
    # if trace: g.trace(self.traceItem(item),g.callers(4))
    try:
        self.selecting = True
        p = self.item2position(item)
        auto_edit = self.prev_v == p.v
        if p:
            # auto_edit = self.prev_v == p.v
            if trace: g.trace('auto_edit',auto_edit,p.h)
            self.prev_v = p.v
            event = None
            if g.doHook("iconclick1",c=c,p=p,v=p,event=event) is None:
                pass
                # if c.positionExists(p): c.selectPosition(p) # 2011/03/07
                # c.frame.tree.OnIconDoubleClick(p) # Call the base class method.
            g.doHook("iconclick2",c=c,p=p,v=p,event=event)
        else:
            auto_edit = None
            g.trace('*** no p')

        # 2011/05/27: click here is like ctrl-g.
        c.k.keyboardQuit(setFocus=False)
        c.treeWantsFocus() # 2011/05/08: Focus must stay in the tree!
        c.outerUpdate()
        # 2011/06/01: A second *single* click on a selected node
        # enters editing state.
        if auto_edit and self.auto_edit:
            e,wrapper = self.createTreeEditorForItem(item)
    finally:
        self.selecting = False
#@+node:ekr.20110605121601.17897: *5* onItemDoubleClicked (nativeTree)
def onItemDoubleClicked (self,item,col):

    trace = False and not g.unitTesting
    verbose = False

    if self.busy(): return

    c = self.c

    if trace: g.trace(col,self.traceItem(item))

    try:
        self.selecting = True

        e,wrapper = self.createTreeEditorForItem(item)
        if e:
            wrapper.setEditorColors(c.k.insert_mode_bg_color,'(not used)')
        else:
            g.trace('*** no e')

        p = self.item2position(item)
        
    # 2011/07/28: End the lockout here, not at the end.
    # This allows g.handleUrlInUrlNode to end editing properly.
    finally:
        self.selecting = False
        
    if p:
        event = None
        if g.doHook("icondclick1",c=c,p=p,v=p,event=event) is None:
            c.frame.tree.OnIconDoubleClick(p) # Call the base class method.
        g.doHook("icondclick2",c=c,p=p,v=p,event=event)
    else:
        g.trace('*** no p')

    c.outerUpdate()
#@+node:ekr.20110726130504.15081: *4* Fixed double-click problem
@nocolor-node

CAUTION: new double click handling code

http://groups.google.com/group/leo-editor/browse_thread/thread/dbd63b9b38911906

The problem isn't single/double, but double click not stopping the
event processing.  It has the correct form:

if g.doHook('doubleClick1') is None:
   do-normal-double-click-stuff
g.doHook('doubleClick2')

but I think some other route through the code, or additional processing
of the event means that even thought the handler registered on
doubleClick1 returns non-None, the node goes into headline edit mode,
with focus.

This is bad, because the doubleClick1 on an @url node attempts to
select and raise a different commander (tab), so now you're looking at
one commander but focus is in another, so what you type trashes the
headline in the original commander.

The timer shouldn't be needed - a 'doubleClick1' hook which returns
non-None should stop the headline going into edit mode.  If you can
make that be the case, all is well.
#@+node:ekr.20110605121601.17894: *5* onIconBoxDoubleClick
def onIconBoxDoubleClick (self,event,p=None):

    if self.busy(): return

    c = self.c
    if not p: p = c.p

    if not g.doHook("icondclick1",c=c,p=p,v=p,event=event):
        self.endEditLabel()
        self.OnIconDoubleClick(p) # Call the method in the base class.

    g.doHook("icondclick2",c=c,p=p,v=p,event=event)

    c.outerUpdate()
#@+node:ekr.20031218072017.2312: *5* tree.OnIconDoubleClick (@url) & helper
# Several plugins handle url's, especially UNL.py.

def OnIconDoubleClick (self,p):

    # Note: "icondclick" hooks handled by vnode callback routine.

    c = self.c
    s = p.h.strip()
    if g.match_word(s,0,"@url"): 
        if p.b.strip():
            lines = p.b.split('\n',1)
            url = lines and lines[0].strip() or ''
        else:
            url = s[4:].strip()
        # g.trace(url,g.callers())

        if not g.doHook("@url1",c=c,p=p,v=p,url=url):
            g.handleUrlInUrlNode(url, c=c, p=p)
        g.doHook("@url2",c=c,p=p,v=p)

    return # (for Tk) 'break' # 11/19/06
#@+node:ekr.20100908125007.6018: *5* doPlugins
# This is the default g.app.hookFunction.

def doPlugins(self,tag,keywords):

    if g.app.killed:
        return

    if tag in ('start1','open0'):
        self.loadHandlers(tag,keywords)

    return self.doHandlersForTag(tag,keywords)
#@+node:ekr.20110605121601.17897: *5* onItemDoubleClicked (nativeTree)
def onItemDoubleClicked (self,item,col):

    trace = False and not g.unitTesting
    verbose = False

    if self.busy(): return

    c = self.c

    if trace: g.trace(col,self.traceItem(item))

    try:
        self.selecting = True

        e,wrapper = self.createTreeEditorForItem(item)
        if e:
            wrapper.setEditorColors(c.k.insert_mode_bg_color,'(not used)')
        else:
            g.trace('*** no e')

        p = self.item2position(item)
        
    # 2011/07/28: End the lockout here, not at the end.
    # This allows g.handleUrlInUrlNode to end editing properly.
    finally:
        self.selecting = False
        
    if p:
        event = None
        if g.doHook("icondclick1",c=c,p=p,v=p,event=event) is None:
            c.frame.tree.OnIconDoubleClick(p) # Call the base class method.
        g.doHook("icondclick2",c=c,p=p,v=p,event=event)
    else:
        g.trace('*** no p')

    c.outerUpdate()
#@+node:ekr.20110605121601.18420: *5* createTreeEditorForItem (leoQtTree)
def createTreeEditorForItem(self,item):

    trace = False and not g.unitTesting

    w = self.treeWidget
    w.setCurrentItem(item) # Must do this first.
    w.editItem(item)
    e = w.itemWidget(item,0)
    e.setObjectName('headline')
    wrapper = self.connectEditorWidget(e,item)
    
    if trace: g.trace(e,wrapper)

    return e,wrapper
#@+node:ekr.20110728112148.6735: *4* Fixed url focus issues
#@+node:ekr.20110605121601.17897: *5* onItemDoubleClicked (nativeTree)
def onItemDoubleClicked (self,item,col):

    trace = False and not g.unitTesting
    verbose = False

    if self.busy(): return

    c = self.c

    if trace: g.trace(col,self.traceItem(item))

    try:
        self.selecting = True

        e,wrapper = self.createTreeEditorForItem(item)
        if e:
            wrapper.setEditorColors(c.k.insert_mode_bg_color,'(not used)')
        else:
            g.trace('*** no e')

        p = self.item2position(item)
        
    # 2011/07/28: End the lockout here, not at the end.
    # This allows g.handleUrlInUrlNode to end editing properly.
    finally:
        self.selecting = False
        
    if p:
        event = None
        if g.doHook("icondclick1",c=c,p=p,v=p,event=event) is None:
            c.frame.tree.OnIconDoubleClick(p) # Call the base class method.
        g.doHook("icondclick2",c=c,p=p,v=p,event=event)
    else:
        g.trace('*** no p')

    c.outerUpdate()
#@+node:tbrown.20090219095555.61: *5* g.handleUrlInUrlNode
def handleUrlInUrlNode(url, c=None, p=None):
    
    # Note 1: the UNL plugin has its own notion of what a good url is.

    # Note 2: tree.OnIconDoubleClick now uses the body text of an @url
    #         node if it exists.

    if g.unitTesting: return
    << check the url; return if bad >>
    << pass the url to the web browser >>
#@+node:tbrown.20090219095555.62: *6* << check the url; return if bad >>
@ A valid url is (according to D.T.Hein):

3 or more lowercase alphas, followed by,
one ':', followed by,
one or more of: (excludes !"#;<>[\]^`|)
  $%&'()*+,-./0-9:=?@A-Z_a-z{}~
followed by one of: (same as above, except no minus sign or comma).
  $%&'()*+/0-9:=?@A-Z_a-z}~
@c

# urlPattern = "[a-z]{3,}:[\$-:=?-Z_a-z{}~]+[\$-+\/-:=?-Z_a-z}~]"

if not url or len(url) == 0:
    g.es("no url following @url")
    return

# Add http:// if required.
# if not re.match('^([a-z]{3,}:)',url):
#     url = 'http://' + url
# if not re.match(urlPattern,url):
#     g.es("invalid url:",url)
#     return
#@+node:tbrown.20090219095555.63: *6* << pass the url to the web browser >>
@ Most browsers should handle the following urls:
  ftp://ftp.uu.net/public/whatever.
  http://localhost/MySiteUnderDevelopment/index.html
  file://home/me/todolist.html
@c

try:
    
    parsed = urlparse(url)
    
    leo_path = parsed.path
    if parsed.netloc:
        leo_path = os.path.join(parsed.netloc, parsed.path)
        # "readme.txt" gets parsed into .netloc...
    
    if c and parsed.scheme in ('', 'file'):
        
        # local UNLs like "node-->subnode", "-->node", and "#node"
        if '-->' in parsed.path:
            g.recursiveUNLSearch(parsed.path.split("-->"), c)
            return
        if not parsed.path and parsed.fragment:
            g.recursiveUNLSearch(parsed.fragment.split("-->"), c)
            return

        # leo aware path
        leo_path = os.path.expanduser(leo_path)
        leo_path = g.os_path_expandExpression(leo_path, c=c)
        if p and not os.path.isabs(leo_path):
            leo_path = os.path.normpath(
                os.path.join(c.getNodePath(p), leo_path))

        # .leo file
        if leo_path.lower().endswith('.leo') and os.path.exists(leo_path):
            # 2011/07/28: Immediately end editing, so that
            # typing in the new window works properly.
            c.endEditing()
            c.redraw_now()
            ok,frame = g.openWithFileName(leo_path, c)
            
            # with UNL after path
            if ok and parsed.fragment:
                g.recursiveUNLSearch(parsed.fragment.split("-->"), frame.c)
                
            if ok:
                frame.c.bringToFront()
                return
                
    if parsed.scheme in ('', 'file'):
        if os.path.exists(leo_path):
            g.os_startfile(leo_path)
            return
        if parsed.scheme == 'file':
            g.es("File '%s' does not exist"%leo_path)
            return
        
    import webbrowser
    # Mozilla throws a weird exception, then opens the file!
    try: webbrowser.open(url)
    except: pass
    
except:
    g.es("exception opening",url)
    g.es_exception()
#@+node:ekr.20110728093358.6702: *4* Fixed p1 > p2
#@+node:ekr.20040228094013: *5*  p.ctor & other special methods...
#@+node:ekr.20080416161551.190: *6*  p.__init__
def __init__ (self,v,childIndex=0,stack=None,trace=False):

    '''Create a new position with the given childIndex and parent stack.'''

    # To support ZODB the code must set v._p_changed = 1
    # whenever any mutable vnode object changes.

    self._childIndex = childIndex
    self.v = v

    # New in Leo 4.5: stack entries are tuples (v,childIndex).
    if stack:
        self.stack = stack[:] # Creating a copy here is safest and best.
    else:
        self.stack = []

    g.app.positions += 1

    # if g.app.tracePositions and trace: g.trace(g.callers())

    self.txtOffset = None # see self.textOffset()
#@+node:ekr.20080920052058.3: *6* p.__eq__ & __ne__
def __eq__(self,p2):

    """Return True if two postions are equivalent."""

    p1 = self

    # Don't use g.trace: it might call p.__eq__ or p.__ne__.
    # print ('p.__eq__: %s %s' % (
        # p1 and p1.v and p1.h,p2 and p2.v and p2.h))

    if p2 is None or p2.v is None:
        return p1.v is None
    else:
        return ( p1.v == p2.v and
            p1._childIndex == p2._childIndex and
            p1.stack == p2.stack )

def __ne__(self,p2):

    """Return True if two postions are not equivalent."""

    return not self.__eq__(p2) # For possible use in Python 2.x.
#@+node:ekr.20091210082012.6230: *6* p.__ge__ & __le__& __lt__
def __ge__ (self,other):

    return self.__eq__(other) or self.__gt__(other)

def __le__ (self,other):

    return self.__eq__(other) or self.__lt__(other)

def __lt__ (self,other):

    return not self.__eq__(other) and not self.__gt__(other)
#@+node:ekr.20091210082012.6233: *6* p.__gt__
def __gt__ (self,other):

    '''Return True if self appears after other in outline order.'''

    stack1,stack2 = self.stack,other.stack
    n1,n2 = len(stack1),len(stack2) ; n = min(n1,n2)
    # Compare the common part of the stacks.
    for item1,item2 in zip(stack1,stack2):
        v1,x1 = item1 ; v2,x2 = item2
        if x1 > x2: return True
        elif x1 < x2: return False
    # Finish the comparison.
    if n1 == n2:
        x1,x2 = self._childIndex,other._childIndex
        return x1 > x2
    elif n1 < n2:
        x1 = self._childIndex; v2,x2 = other.stack[n]
        return x1 > x2
    else: # n1 > n2
        # 2011/07/28: Bug fix suggested by SegundoBob.
        x1 = other._childIndex; v2,x2 = self.stack[n]
        return x2 >= x1
#@+node:ekr.20040117170612: *6* p.__getattr__ (no longer used)
# No longer used.  All code must now be aware of the one-node world.

# def __getattr__ (self,attr):

    # """Convert references to p.t into references to p.v."""

    # if attr=="t":
        # return self.v
    # else:
        # # New in 4.3: _silently_ raise the attribute error.
        # # This allows plugin code to use hasattr(p,attr) !
        # if 0:
            # print("unknown position attribute: %s" % attr)
            # import traceback ; traceback.print_stack()
        # raise AttributeError(attr)
#@+node:ekr.20040117173448: *6* p.__nonzero__ & __bool__
@
Tests such as 'if p' or 'if not p' are the _only_ correct ways to test
whether a position p is valid. In particular, tests like 'if p is
None' or 'if p is not None' will not work properly.
@c

if g.isPython3:

    def __bool__ ( self):

        """Return True if a position is valid."""

        # Tracing this appears to cause unbounded prints.
        # print("__bool__",self.v and self.v.cleanHeadString())

        return self.v is not None

else:

    def __nonzero__ ( self):

        """Return True if a position is valid."""

        # if g.app.trace: "__nonzero__",self.v

        # g.trace(repr(self))

        return self.v is not None
#@+node:ekr.20040301205720: *6* p.__str__ and p.__repr__
def __str__ (self):

    p = self

    if p.v:
        # return "<pos %d childIndex: %d lvl: %d [%d] %s>" % (
            # id(p),p._childIndex,p.level(),len(p.stack),p.cleanHeadString())
        return "<pos %d childIndex: %d lvl: %d key: %s %s>" % (
            id(p),p._childIndex,p.level(),p.key(),p.cleanHeadString())
    else:
        return "<pos %d [%d] None>" % (id(p),len(p.stack))

__repr__ = __str__
#@+node:ekr.20061006092649: *6* p.archivedPosition
def archivedPosition (self,root_p=None):

    '''Return a representation of a position suitable for use in .leo files.'''

    p = self

    if root_p is None:
        aList = [z._childIndex for z in p.self_and_parents()]
    else:
        aList = []
        for z in p.self_and_parents():
            if z == root_p:
                aList.append(0)
                break
            else:
                aList.append(z._childIndex)
        # g.trace(aList)

    aList.reverse()
    return aList
#@+node:ekr.20040117171654: *6* p.copy
# Using this routine can generate huge numbers of temporary positions during a tree traversal.

def copy (self):

    """"Return an independent copy of a position."""

    # if g.app.tracePositions: g.trace(g.callers())

    return position(self.v,self._childIndex,self.stack,trace=False)
#@+node:ekr.20040310153624: *6* p.dump
def dumpLink (self,link):

    return g.choose(link,link,"<none>")

def dump (self,label=""):

    p = self
    if p.v:
        p.v.dump() # Don't print a label
#@+node:ekr.20080416161551.191: *6* p.key
def key (self):

    p = self

    # For unified nodes we must include a complete key,
    # so we can distinguish between clones.
    result = []
    for z in p.stack:
        v,childIndex = z
        result.append('%s:%s' % (id(v),childIndex))

    result.append('%s:%s' % (id(p.v),p._childIndex))

    return '.'.join(result)
#@+node:ekr.20110730091449.15132: *4* Fixed cacher problem
@nocolor-node

- leoCommands.__init__ now sets self.db = {}
- initGlobalDB now returns {} instead of None if there is no cacher.
#@+node:ekr.20100208062523.5886: *5*  ctor (cacher)
def __init__ (self,c=None):

    trace = False and not g.unitTesting
    if trace: g.trace('cacher','c',c)
    
    self.c = c

    # set by initFileDB and initGlobalDB...
    self.db = {}
        # 2011/07/30
        # When caching is enabled will be a PickleShareDB instance.
    self.dbdirname = None # A string.
    self.inited = False

#@+node:ekr.20100209160132.5759: *5* clear/AllCache(s) (cacher)
def clearCache (self):
    if self.db:
        # 2011/07/30: Be careful about calling db.clear.
        try:
            self.db.clear(verbose=True)
        except TypeError:
            self.db.clear() # self.db is a Python dict.
        except Exception:
            g.trace('unexpected exception')
            g.es_exception()
            self.db = {}

def clearAllCaches (self):

    # Clear the cachers *only* for all open windows.
    # This is much safer than tryting to Kill all db's.
    for frame in g.windows():
        c = frame.c
        if c.cacher:
            c.cacher.clearCache()
#@+node:ekr.20110908155830.6875: *4* Fixed encoding problem with @shadow
@nocolor-node

Important notes:
    
readOpenFile reads the private shadow file, detecting the encoding.
#@+node:ekr.20110908155830.6878: *5* Encoding...
#@+node:ekr.20041005105605.27: *6* at.readOpenFile & helpers
def readOpenFile(self,root,theFile,fileName,deleteNodes=False):

    '''Read an open derived file.

    Leo 4.5 and later can only read 4.x derived files.'''

    trace = False and not g.unitTesting
    at = self

    firstLines,read_new,thinFile = at.scanHeader(theFile,fileName)
        # Important: this sets at.encoding, used by at.readLine.
    at.thinFile = thinFile
        # 2010/01/22: use *only* the header to set self.thinFile.

    if deleteNodes and at.shouldDeleteChildren(root,thinFile):
        root.v.at_read = True # Create the attribute for all clones.
        while root.hasChildren():
            root.firstChild().doDelete()

    if read_new:
        lastLines = at.scanText4(theFile,fileName,root)
    else:
        firstLines = [] ; lastLines = []
        if at.atShadow:
            g.trace(g.callers())
            g.trace('invalid @shadow private file',fileName)
            at.error('invalid @shadow private file',fileName)
        else:
            at.error('can not read 3.x derived file',fileName)
            g.es('you may upgrade these file using Leo 4.0 through 4.4.x')
            g.trace('root',root and root.h,fileName)

    if root:
        root.v.setVisited() # Disable warning about set nodes.

    << handle first and last lines >>
    
    if trace: g.trace(at.encoding,fileName) # root.v.tempBodyString)

    return thinFile
#@+node:ekr.20041005105605.28: *7* << handle first and last lines >> (at.readOpenFile)
# The code below only deals with the root node!
# We terminate the root's body text if it exists.
# This is a hack to allow us to handle @first and @last.
v = root.v
tempString = hasattr(v,'tempBodyString') and v.tempBodyString or ''
tempList = hasattr(v,'tempBodyList') and ''.join(v.tempBodyList) or ''

if at.readVersion5:
    if hasattr(v,'tempBodyList'):
        body = tempList
        delattr(v,'tempBodyList') # So the change below "takes".
    elif hasattr(v,'tempBodyString'):
        body = tempString
        delattr(v,'tempBodyString')
    else:
        body = ''
else:
    body = tempString

lines = body.split('\n')

at.completeFirstDirectives(lines,firstLines)
at.completeLastDirectives(lines,lastLines)

s = '\n'.join(lines).replace('\r', '')

# *Always* put the temp body text into at.v.tempBodyString.
v.tempBodyString = s
#@+node:ekr.20100122130101.6175: *7* at.shouldDeleteChildren
def shouldDeleteChildren (self,root,thinFile):

    '''Return True if we should delete all children before a read.'''

    # Delete all children except for old-style @file nodes

    if root.isAtNoSentFileNode():
        return False
    elif root.isAtFileNode() and not thinFile:
        return False
    else:
        return True
#@+node:ekr.20041005105605.117: *7* at.completeFirstDirective
# 14-SEP-2002 DTHEIN: added for use by atFile.read()

# this function scans the lines in the list 'out' for @first directives
# and appends the corresponding line from 'firstLines' to each @first 
# directive found.  NOTE: the @first directives must be the very first
# lines in 'out'.
def completeFirstDirectives(self,out,firstLines):

    tag = "@first"
    foundAtFirstYet = 0
    outRange = range(len(out))
    j = 0
    for k in outRange:
        # skip leading whitespace lines
        if (not foundAtFirstYet) and (len(out[k].strip()) == 0): continue
        # quit if something other than @first directive
        i = 0
        if not g.match(out[k],i,tag): break
        foundAtFirstYet = 1
        # quit if no leading lines to apply
        if j >= len(firstLines): break
        # make the new @first directive
        #18-SEP-2002 DTHEIN: remove trailing newlines because they are inserted later
        # 21-SEP-2002 DTHEIN: no trailing whitespace on empty @first directive
        leadingLine = " " + firstLines[j]
        out[k] = tag + leadingLine.rstrip() ; j += 1
#@+node:ekr.20041005105605.118: *7* at.completeLastDirectives
# 14-SEP-2002 DTHEIN: added for use by atFile.read()

# this function scans the lines in the list 'out' for @last directives
# and appends the corresponding line from 'lastLines' to each @last 
# directive found.  NOTE: the @last directives must be the very last
# lines in 'out'.
def completeLastDirectives(self,out,lastLines):

    tag = "@last"
    foundAtLastYet = 0
    outRange = range(-1,-len(out),-1)
    j = -1
    for k in outRange:
        # skip trailing whitespace lines
        if (not foundAtLastYet) and (len(out[k].strip()) == 0): continue
        # quit if something other than @last directive
        i = 0
        if not g.match(out[k],i,tag): break
        foundAtLastYet = 1
        # quit if no trailing lines to apply
        if j < -len(lastLines): break
        # make the new @last directive
        #18-SEP-2002 DTHEIN: remove trailing newlines because they are inserted later
        # 21-SEP-2002 DTHEIN: no trailing whitespace on empty @last directive
        trailingLine = " " + lastLines[j]
        out[k] = tag + trailingLine.rstrip() ; j -= 1
#@+node:ekr.20041005105605.129: *6* at.scanHeader
def scanHeader(self,theFile,fileName):

    """Scan the @+leo sentinel.

    Sets self.encoding, and self.start/endSentinelComment.

    Returns (firstLines,new_df,isThinDerivedFile) where:
    firstLines        contains all @first lines,
    new_df            is True if we are reading a new-format derived file.
    isThinDerivedFile is True if the file is an @thin file."""

    trace = False and not g.unitTesting
    at = self
    firstLines = [] # The lines before @+leo.
    tag = "@+leo"
    valid = True ; new_df = False ; isThinDerivedFile = False
    << skip any non @+leo lines >>
    if valid:
        valid,new_df,start,end,isThinDerivedFile = at.parseLeoSentinel(s)
    if valid:
        at.startSentinelComment = start
        at.endSentinelComment = end
        # g.trace('start',repr(start),'end',repr(end))
    else:
        at.error("No @+leo sentinel in: %s" % fileName)
    # g.trace("start,end",repr(at.startSentinelComment),repr(at.endSentinelComment))
    # g.trace(fileName,firstLines)
    return firstLines,new_df,isThinDerivedFile
#@+node:ekr.20041005105605.130: *7* << skip any non @+leo lines >>
@ Queue up the lines before the @+leo.

These will be used to add as parameters to the @first directives, if any.
Empty lines are ignored (because empty @first directives are ignored).
NOTE: the function now returns a list of the lines before @+leo.

We can not call sentinelKind here because that depends on
the comment delimiters we set here.

at-first lines are written "verbatim", so nothing more needs to be done!
@c

s = at.readLine(theFile)
if trace: g.trace('first line',repr(s))
while len(s) > 0:
    j = s.find(tag)
    if j != -1: break
    firstLines.append(s) # Queue the line
    s = at.readLine(theFile)

n = len(s)
valid = n > 0
#@+node:ekr.20041005105605.120: *6* at.parseLeoSentinel
def parseLeoSentinel (self,s):

    trace = False and not g.unitTesting
    at = self ; c = at.c
    new_df = False ; valid = True ; n = len(s)
    start = '' ; end = '' ; isThinDerivedFile = False
    encoding_tag = "-encoding="
    version_tag = "-ver="
    tag = "@+leo"
    thin_tag = "-thin"
    << set the opening comment delim >>
    << make sure we have @+leo >>
    << read optional version param >>
    << read optional thin param >>
    << read optional encoding param >>
    << set the closing comment delim >>
    if trace:
        g.trace('valid',valid,'isThin',isThinDerivedFile)
    return valid,new_df,start,end,isThinDerivedFile
#@+node:ekr.20041005105605.121: *7* << set the opening comment delim >>
# s contains the tag
i = j = g.skip_ws(s,0)

# The opening comment delim is the initial non-tag
while i < n and not g.match(s,i,tag) and not g.is_nl(s,i):
    i += 1

if j < i:
    start = s[j:i]
else:
    if trace: g.trace('no opening delim')
    valid = False

#@+node:ekr.20041005105605.122: *7* << make sure we have @+leo >>
@
REM hack: leading whitespace is significant before the
@+leo. We do this so that sentinelKind need not skip
whitespace following self.startSentinelComment. This is
correct: we want to be as restrictive as possible about what
is recognized as a sentinel. This minimizes false matches.
@c

if 0: # Make leading whitespace significant.
    i = g.skip_ws(s,i)

if g.match(s,i,tag):
    i += len(tag)
else:
    if trace: g.trace('no @+leo')
    valid = False
#@+node:ekr.20041005105605.123: *7* << read optional version param >>
new_df = g.match(s,i,version_tag)

if trace and not new_df:
    g.trace('not new_df',repr(s[0:100]))

if new_df:
    # Pre Leo 4.4.1: Skip to the next minus sign or end-of-line.
    # Leo 4.4.1 +:   Skip to next minus sign, end-of-line,
    #                or non numeric character.
    # This is required to handle trailing comment delims properly.
    i += len(version_tag)
    j = i
    while i < len(s) and (s[i] == '.' or s[i].isdigit()):
        i += 1
    at.readVersion = s[j:i] # 2010/05/18.
    at.readVersion5 = at.readVersion >= '5'

    if j < i:
        pass
    else:
        if trace: g.trace('no version')
        valid = False
#@+node:ekr.20041005105605.124: *7* << read optional thin param >>
if g.match(s,i,thin_tag):
    i += len(tag)
    isThinDerivedFile = True
#@+node:ekr.20041005105605.125: *7* << read optional encoding param >>
# Set the default encoding
at.encoding = c.config.default_derived_file_encoding

if g.match(s,i,encoding_tag):
    # Read optional encoding param, e.g., -encoding=utf-8,
    i += len(encoding_tag)
    # Skip to the next end of the field.
    j = s.find(",.",i)
    if j > -1:
        # The encoding field was written by 4.2 or after:
        encoding = s[i:j]
        i = j + 2 # 6/8/04, 1/11/05 (was i = j + 1)
    else:
        # The encoding field was written before 4.2.
        j = s.find('.',i)
        if j > -1:
            encoding = s[i:j]
            i = j + 1 # 6/8/04
        else:
            encoding = None
    # g.trace("encoding:",encoding)
    if encoding:
        if g.isValidEncoding(encoding):
            at.encoding = encoding
        else:
            g.es_print("bad encoding in derived file:",encoding)
    else:
        if trace: g.trace('no encoding')
        valid = False
#@+node:ekr.20041005105605.126: *7* << set the closing comment delim >>
# The closing comment delim is the trailing non-whitespace.
i = j = g.skip_ws(s,i)
while i < n and not g.is_ws(s[i]) and not g.is_nl(s,i):
    i += 1
end = s[j:i]
#@+node:ekr.20110908155830.6876: *5* at.read path...
#@+node:ekr.20041005105605.129: *6* at.scanHeader
def scanHeader(self,theFile,fileName):

    """Scan the @+leo sentinel.

    Sets self.encoding, and self.start/endSentinelComment.

    Returns (firstLines,new_df,isThinDerivedFile) where:
    firstLines        contains all @first lines,
    new_df            is True if we are reading a new-format derived file.
    isThinDerivedFile is True if the file is an @thin file."""

    trace = False and not g.unitTesting
    at = self
    firstLines = [] # The lines before @+leo.
    tag = "@+leo"
    valid = True ; new_df = False ; isThinDerivedFile = False
    << skip any non @+leo lines >>
    if valid:
        valid,new_df,start,end,isThinDerivedFile = at.parseLeoSentinel(s)
    if valid:
        at.startSentinelComment = start
        at.endSentinelComment = end
        # g.trace('start',repr(start),'end',repr(end))
    else:
        at.error("No @+leo sentinel in: %s" % fileName)
    # g.trace("start,end",repr(at.startSentinelComment),repr(at.endSentinelComment))
    # g.trace(fileName,firstLines)
    return firstLines,new_df,isThinDerivedFile
#@+node:ekr.20041005105605.130: *7* << skip any non @+leo lines >>
@ Queue up the lines before the @+leo.

These will be used to add as parameters to the @first directives, if any.
Empty lines are ignored (because empty @first directives are ignored).
NOTE: the function now returns a list of the lines before @+leo.

We can not call sentinelKind here because that depends on
the comment delimiters we set here.

at-first lines are written "verbatim", so nothing more needs to be done!
@c

s = at.readLine(theFile)
if trace: g.trace('first line',repr(s))
while len(s) > 0:
    j = s.find(tag)
    if j != -1: break
    firstLines.append(s) # Queue the line
    s = at.readLine(theFile)

n = len(s)
valid = n > 0
#@+node:ekr.20041005105605.21: *6* at.read & helpers
def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    trace = False and not g.unitTesting
    if trace: g.trace(root.h)
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    # Fix bug 760531: always mark the root as read, even if there was an error.
    root.v.at_read = True
    # Bug fix 2011/05/23: Restore orphan trees from the outline.
    if root.isOrphan():
        g.es("reading:",root.h)
        # g.warning('The outline contains an orphan node!\nRetaining the outline')
        g.es_print('orphan node in',root.h,color='red')
        g.es_print('retaining the data from the .leo file',color='blue')
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    at.fromString = fromString
    if at.errors:
        if trace: g.trace('Init error')
        return False

    fileName = at.openFileForReading(fromString=fromString)
    if fileName and at.inputFile:
        c.setFileTimeStamp(fileName)
    elif fromString: # 2010/09/02.
        pass
    else:
        if trace: g.trace('No inputFile')
        return False

    # Get the file from the cache if possible.
    if fromString:
        s,loaded,fileKey = fromString,False,None
    else:
        s,loaded,fileKey = c.cacher.readFile(fileName,root)
    # Never read an external file with file-like sentinels from the cache.
    isFileLike = loaded and at.isFileLike(s)
    if not loaded or isFileLike:
        # if trace: g.trace('file-like file',fileName)
        force = True # Disable caching.
    if loaded and not force:
        if trace: g.trace('in cache',fileName)
        at.inputFile.close()
        root.clearDirty()
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    if isFileLike:
        if g.unitTesting:
            if 0: print("converting @file format in",root.h)
            g.app.unitTestDict['read-convert']=True
        else:
            g.es("converting @file format in",root.h,color='red')
    root.clearVisitedInTree()

    at.scanAllDirectives(root,importing=at.importing,reading=True)
        # Sets the following ivars:
            # at.default_directory
            # at.encoding: **Important**: changed later
            #     by readOpenFile/at.scanHeader.
            # at.explicitLineEnding
            # at.language
            # at.output_newline
            # at.page_width
            # at.tab_width

    if trace: g.trace(repr(at.encoding),fileName)
    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
        # Calls at.scanHeader, which sets at.encoding.
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.deleteUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        at.copyAllTempBodyStringsToVnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if isFileLike and at.errors == 0: # Old-style sentinels.
        # 2010/02/24: Make the root @file node dirty so it will
        # be written automatically when saving the file.
        # Do *not* set the orphan bit here!
        root.clearOrphan()
        root.setDirty()
        c.setChanged(True) # Essential, to keep dirty bit set.
    elif at.errors > 0:
        # 2010/10/22: Dirty bits are *always* cleared.
        # Only the orphan bit is preserved.
        ### root.setDirty() # 2011/06/17: Won't be preserved anyway
        root.setOrphan()
        ### c.setChanged(True) # 2011/06/17.
    else:
        root.clearOrphan()
    if at.errors == 0 and not isFileLike and not fromString:
        c.cacher.writeFile(root,fileKey)

    if trace: g.trace('at.errors',at.errors)
    return at.errors == 0
#@+node:ekr.20041005105605.25: *7* at.deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
        if hasattr(v,"tempBodyList"):
            delattr(v,"tempBodyList")
#@+node:ekr.20100122130101.6174: *7* at.deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@+node:ekr.20071105164407: *7* at.deleteUnvisitedNodes & helpers
def deleteUnvisitedNodes (self,root):

    '''Delete unvisited nodes in root's subtree, not including root.

    Actually, instead of deleting the nodes, we move them to be children of the
    'Resurrected Nodes' r.
    '''

    at = self

    if not root.hasChildren():
        return

    # Carefully set up the arguments.
    aList = [z.copy() for z in root.subtree() if not z.isVisited()]
    if not aList: return

    r = at.createResurrectedNodesNode()
    assert r not in aList
    callback=at.defineResurrectedNodeCallback(r,root)

    # Now move the nodes.
    root.firstChild().deletePositionsInList(aList,callback)
#@+node:ekr.20100803073751.5817: *8* createResurrectedNodesNode
def createResurrectedNodesNode(self):

    '''Create a 'Resurrected Nodes' node as the last top-level node.'''

    at = self ; c = at.c ; tag = 'Resurrected Nodes'

    # Find the last top-level node.
    last = c.rootPosition()
    while last.hasNext():
        last.moveToNext()

    if last.h == tag:
        # The 'Resurrected Nodes' node already exists.
        p = last
    else:
        # Create the 'Resurrected Nodes' node after 'last'.
        p = last.insertAfter()
        p.setHeadString(tag)

    p.expand()
    return p
#@+node:ekr.20100803073751.5818: *8* defineResurrectedNodeCallback
def defineResurrectedNodeCallback (self,r,root):

    '''Define a callback that moves node p as r's last child.'''

    def callback(p,r=r.copy(),root=root):

        '''The resurrected nodes callback.'''

        child = r.insertAsLastChild()
        child.h = 'From %s' % root.h
        p.moveToLastChildOf(child)

        if g.unitTesting:
            # g.trace(p.h,r.h)
            pass 
        else:
            g.es('resurrected node:',p.h,color='red')
            g.es('in file:',root.h,color='blue')

    return callback


#@+node:ekr.20041005105605.22: *7* at.initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName
#@+node:ekr.20100224050618.11547: *7* at.isFileLike
def isFileLike (self,s):

    '''Return True if s has file-like sentinels.'''

    trace = False and not g.unitTesting
    at = self ; tag = "@+leo"
    s = g.toUnicode(s)
    i = s.find(tag)
    if i == -1:
        if trace: g.trace('found: False',repr(s))
        return True # Don't use the cashe.
    else:
        j,k = g.getLine(s,i)
        line = s[j:k]
        valid,new_df,start,end,isThin = \
            at.parseLeoSentinel(line)
        if trace: g.trace('found: True isThin:',
            isThin,repr(line))
        return not isThin
#@+node:ekr.20041005105605.19: *6* at.openFileForReading
def openFileForReading(self,fromString=False):

    '''Open the file given by at.root.
    This will be the private file for @shadow nodes.'''

    trace = False and not g.app.unitTesting
    at = self ; c = at.c

    if fromString:
        if at.atShadow:
            return at.error(
                'can not call at.read from string for @shadow files')
        at.inputFile = g.fileLikeObject(fromString=fromString)
        fn = None
    else:
        fn = at.fullPath(self.root)
            # Returns full path, including file name.
        at.setPathUa(self.root,fn) # Remember the full path to this node.

        if at.atShadow:
            x = at.c.shadowController
            # readOneAtShadowNode should already have checked these.
            shadow_fn     = x.shadowPathName(fn)
            shadow_exists = g.os_path_exists(shadow_fn) and \
                g.os_path_isfile(shadow_fn)
            if not shadow_exists:
                g.trace('can not happen: no private file',
                    shadow_fn,g.callers())
                return at.error(
                    'can not happen: private file does not exist: %s' % (
                        shadow_fn))
            # This method is the gateway to the shadow algorithm.
            if trace:
                g.trace('         fn:       ',fn)
                g.trace('reading: shadow_fn:',shadow_fn)
            x.updatePublicAndPrivateFiles(self.root,fn,shadow_fn)
            fn = shadow_fn

        try:
            # Open the file in binary mode to allow 0x1a in bodies & headlines.
            at.inputFile = open(fn,'rb')
            at.warnOnReadOnlyFile(fn)
        except IOError:
            at.error("can not open: '@file %s'" % (fn))
            at.inputFile = None
            fn = None

    return fn
#@+node:ekr.20041005105605.27: *6* at.readOpenFile & helpers
def readOpenFile(self,root,theFile,fileName,deleteNodes=False):

    '''Read an open derived file.

    Leo 4.5 and later can only read 4.x derived files.'''

    trace = False and not g.unitTesting
    at = self

    firstLines,read_new,thinFile = at.scanHeader(theFile,fileName)
        # Important: this sets at.encoding, used by at.readLine.
    at.thinFile = thinFile
        # 2010/01/22: use *only* the header to set self.thinFile.

    if deleteNodes and at.shouldDeleteChildren(root,thinFile):
        root.v.at_read = True # Create the attribute for all clones.
        while root.hasChildren():
            root.firstChild().doDelete()

    if read_new:
        lastLines = at.scanText4(theFile,fileName,root)
    else:
        firstLines = [] ; lastLines = []
        if at.atShadow:
            g.trace(g.callers())
            g.trace('invalid @shadow private file',fileName)
            at.error('invalid @shadow private file',fileName)
        else:
            at.error('can not read 3.x derived file',fileName)
            g.es('you may upgrade these file using Leo 4.0 through 4.4.x')
            g.trace('root',root and root.h,fileName)

    if root:
        root.v.setVisited() # Disable warning about set nodes.

    << handle first and last lines >>
    
    if trace: g.trace(at.encoding,fileName) # root.v.tempBodyString)

    return thinFile
#@+node:ekr.20041005105605.28: *7* << handle first and last lines >> (at.readOpenFile)
# The code below only deals with the root node!
# We terminate the root's body text if it exists.
# This is a hack to allow us to handle @first and @last.
v = root.v
tempString = hasattr(v,'tempBodyString') and v.tempBodyString or ''
tempList = hasattr(v,'tempBodyList') and ''.join(v.tempBodyList) or ''

if at.readVersion5:
    if hasattr(v,'tempBodyList'):
        body = tempList
        delattr(v,'tempBodyList') # So the change below "takes".
    elif hasattr(v,'tempBodyString'):
        body = tempString
        delattr(v,'tempBodyString')
    else:
        body = ''
else:
    body = tempString

lines = body.split('\n')

at.completeFirstDirectives(lines,firstLines)
at.completeLastDirectives(lines,lastLines)

s = '\n'.join(lines).replace('\r', '')

# *Always* put the temp body text into at.v.tempBodyString.
v.tempBodyString = s
#@+node:ekr.20100122130101.6175: *7* at.shouldDeleteChildren
def shouldDeleteChildren (self,root,thinFile):

    '''Return True if we should delete all children before a read.'''

    # Delete all children except for old-style @file nodes

    if root.isAtNoSentFileNode():
        return False
    elif root.isAtFileNode() and not thinFile:
        return False
    else:
        return True
#@+node:ekr.20041005105605.117: *7* at.completeFirstDirective
# 14-SEP-2002 DTHEIN: added for use by atFile.read()

# this function scans the lines in the list 'out' for @first directives
# and appends the corresponding line from 'firstLines' to each @first 
# directive found.  NOTE: the @first directives must be the very first
# lines in 'out'.
def completeFirstDirectives(self,out,firstLines):

    tag = "@first"
    foundAtFirstYet = 0
    outRange = range(len(out))
    j = 0
    for k in outRange:
        # skip leading whitespace lines
        if (not foundAtFirstYet) and (len(out[k].strip()) == 0): continue
        # quit if something other than @first directive
        i = 0
        if not g.match(out[k],i,tag): break
        foundAtFirstYet = 1
        # quit if no leading lines to apply
        if j >= len(firstLines): break
        # make the new @first directive
        #18-SEP-2002 DTHEIN: remove trailing newlines because they are inserted later
        # 21-SEP-2002 DTHEIN: no trailing whitespace on empty @first directive
        leadingLine = " " + firstLines[j]
        out[k] = tag + leadingLine.rstrip() ; j += 1
#@+node:ekr.20041005105605.118: *7* at.completeLastDirectives
# 14-SEP-2002 DTHEIN: added for use by atFile.read()

# this function scans the lines in the list 'out' for @last directives
# and appends the corresponding line from 'lastLines' to each @last 
# directive found.  NOTE: the @last directives must be the very last
# lines in 'out'.
def completeLastDirectives(self,out,lastLines):

    tag = "@last"
    foundAtLastYet = 0
    outRange = range(-1,-len(out),-1)
    j = -1
    for k in outRange:
        # skip trailing whitespace lines
        if (not foundAtLastYet) and (len(out[k].strip()) == 0): continue
        # quit if something other than @last directive
        i = 0
        if not g.match(out[k],i,tag): break
        foundAtLastYet = 1
        # quit if no trailing lines to apply
        if j < -len(lastLines): break
        # make the new @last directive
        #18-SEP-2002 DTHEIN: remove trailing newlines because they are inserted later
        # 21-SEP-2002 DTHEIN: no trailing whitespace on empty @last directive
        trailingLine = " " + lastLines[j]
        out[k] = tag + trailingLine.rstrip() ; j -= 1
#@+node:ekr.20041005105605.74: *6* at.scanText4 & allies
def scanText4 (self,theFile,fileName,p,verbose=False):

    """Scan a 4.x derived file non-recursively."""

    at = self
    trace = False and at.readVersion5 and not g.unitTesting
    verbose = False
    << init ivars for scanText4 >>
    if trace: g.trace('filename:',fileName)
    try:
        while at.errors == 0 and not at.done:
            s = at.readLine(theFile)
            if trace and verbose: g.trace(repr(s))
            at.lineNumber += 1
            if len(s) == 0:
                # An error.  We expect readEndLeo to set at.done.
                break
            kind = at.sentinelKind4(s)
            if kind == at.noSentinel:
                i = 0
            else:
                i = at.skipSentinelStart4(s,0)
            func = at.dispatch_dict[kind]
            if trace: g.trace('%15s %16s %s' % (
                at.sentinelName(kind),func.__name__,repr(s)))
            func(s,i)
    except AssertionError:
        junk, message, junk = sys.exc_info()
        at.error('scanText4: unexpected assertion failure in',
            g.choose(at.fromString,'fromString',fileName),
            '\n',message)
        g.trace(g.callers(5))
        if g.unitTesting:
            raise

    if at.errors == 0 and not at.done:
        << report unexpected end of text >>

    return at.lastLines
#@+node:ekr.20041005105605.75: *7* << init ivars for scanText4 >>
# Unstacked ivars...
at.cloneSibCount = 0
at.done = False
at.inCode = True
at.indent = 0 # Changed only for sentinels.
at.lastLines = [] # The lines after @-leo
at.leadingWs = ""
at.lineNumber = 0
at.root = p.copy() # Bug fix: 12/10/05
at.rootSeen = False
at.updateWarningGiven = False

# Stacked ivars...
at.endSentinelStack = [at.endLeo] # We have already handled the @+leo sentinel.
at.endSentinelNodeStack = [None]
at.out = [] ; at.outStack = []
at.v = p.v
at.vStack = []
# New code: always identify root @thin node with self.root:
at.lastThinNode = None
at.thinNodeStack = []
#@+node:ekr.20041005105605.76: *7* << report unexpected end of text >>
assert at.endSentinelStack,'empty sentinel stack'

at.readError(
    "Unexpected end of file. Expecting %s sentinel" %
    at.sentinelName(at.endSentinelStack[-1]))
#@+node:ekr.20041005105605.77: *7* at.readNormalLine & appendToDocPart
def readNormalLine (self,s,i=0): # i not used.

    at = self

    if at.inCode:
        if not at.raw:
            s = g.removeLeadingWhitespace(s,at.indent,at.tab_width)
        at.appendToOut(s)
    else:
        at.appendToDocPart(s)
#@+node:ekr.20100624082003.5942: *8* at.appendToDocPart
def appendToDocPart (self,s):

    at = self
    trace = False and at.readVersion5 and not g.unitTesting

    # Skip the leading stuff
    if len(at.endSentinelComment) == 0:
        # Skip the single comment delim and a blank.
        i = g.skip_ws(s,0)
        if g.match(s,i,at.startSentinelComment):
            i += len(at.startSentinelComment)
            if g.match(s,i," "): i += 1
    else:
        i = at.skipIndent(s,0,at.indent)

    if at.readVersion5:
        # Append the line to docOut.
        line = s[i:]
        at.docOut.append(line)
    else:
        # Append line to docOut, possibly stripping the newline.
        line = s[i:-1] # remove newline for rstrip.

        if line == line.rstrip():
            # no trailing whitespace: the newline is real.
            at.docOut.append(line + '\n')
        else:
            # trailing whitespace: the newline is fake.
            at.docOut.append(line)

    if trace: g.trace(repr(line))
#@+node:ekr.20041005105605.80: *7* start sentinels
#@+node:ekr.20041005105605.81: *8* at.readStartAll
def readStartAll (self,s,i):

    """Read an @+all sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]

    if leadingWs:
        assert g.match(s,j,"@+all"),'missing @+all'
    else:
        assert g.match(s,j,"+all"),'missing +all'

    # Make sure that the generated at-all is properly indented.
    # New code (for both old and new sentinels).
    # Regularize the whitespace preceding the @all directive.
    junk_i,w = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    lws2 = g.computeLeadingWhitespace(max(0,w-at.indent),at.tab_width)
    at.appendToOut(lws2 + "@all\n")

    at.endSentinelStack.append(at.endAll)
    if at.readVersion5:
        at.endSentinelNodeStack.append(at.v)
        at.endSentinelLevelStack.append(len(at.thinNodeStack))
#@+node:ekr.20041005105605.85: *8* at.readStartNode & helpers
def readStartNode (self,s,i,middle=False):

    """Read an @+node or @+middle sentinel."""

    at = self
    gnx,headline,i,level,ok = at.parseNodeSentinel(s,i,middle)
    if not ok: return
    at.root_seen = True

    # Switch context.
    if at.readVersion5:
        # Terminate the *previous* doc part if it exists.
        if at.docOut:
            at.appendToOut(''.join(at.docOut))
            at.docOut = []
        # Important: with new sentinels we *never*
        # terminate nodes until the post-pass.
    else:
        assert not at.docOut,'not at.docOut' # Cleared by @-node sentinel.
        at.outStack.append(at.out)
        at.out = []

    at.inCode = True
    at.raw = False # End raw mode.

    at.vStack.append(at.v)

    at.indentStack.append(at.indent)
    i,at.indent = g.skip_leading_ws_with_indent(s,0,at.tab_width)

    if at.importing:
        p = at.createImportedNode(at.root,headline)
        at.v = p.v
    elif at.thinFile:
        at.v = at.createNewThinNode(gnx,headline,level)
    else:
        at.v = at.findChild4(headline)

    if not at.v:
        return # 2010/08/02: This can happen when reading strange files.

    at.v.setVisited()
        # Indicate that the vnode has been set in the external file.

    if not at.readVersion5:
        at.endSentinelStack.append(at.endNode)
#@+node:ekr.20100630144047.5783: *9* at.changeLevel
def changeLevel (self,oldLevel,newLevel):

    '''Update data structures when changing node level.'''

    at = self ; c = at.c

    # Crucial: we must be using new-style sentinels.
    assert at.readVersion5,'at.readVersion5'
    assert at.thinFile,'at.thinFile'
    assert not at.importing,'not at.importing'

    if newLevel > oldLevel:
        assert newLevel == oldLevel + 1,'newLevel == oldLevel + 1'
    else:
        while oldLevel > newLevel:
            oldLevel -= 1
            at.indentStack.pop()
            at.thinNodeStack.pop()
            at.vStack.pop()
        assert oldLevel == newLevel,'oldLevel == newLevel'
        assert len(at.thinNodeStack) == newLevel,'len(at.thinNodeStack) == newLevel'

    # The last node is the node at the top of the stack.
    at.lastThinNode = at.thinNodeStack[-1]
#@+node:ekr.20100625085138.5957: *9* at.createNewThinNode
def createNewThinNode (self,gnx,headline,level):

    at = self
    trace = False and at.readVersion5 and not g.unitTesting

    if at.thinNodeStack:
        if at.readVersion5:
            oldLevel = len(at.thinNodeStack)
            newLevel = level - 1
            assert newLevel >= 0,'newLevel >= 0'
            if trace: g.trace('old',oldLevel,'new',newLevel,headline)
            at.changeLevel(oldLevel,newLevel)
            v = at.createThinChild4(gnx,headline)
            at.thinNodeStack.append(v)
            # Terminate a previous clone if it exists.
            # Do not use the full terminateNode logic!
            if hasattr(v,'tempBodyList'):
                # v.tempBodyString = ''.join(v.tempBodyList)
                # To keep pylint happy.
                v.tempBodyString = ''.join(getattr(v,'tempBodyList'))
                delattr(v,'tempBodyList')
            else:
                # Major bug fix: 2010/07/6:
                # Do *not* create v.tempBodyString here!
                # That would tell at.copyAllTempBodyStringsToVnodes
                # that an older (empty) version exists!
                pass
        else:
            at.thinNodeStack.append(at.lastThinNode)
            v = at.createThinChild4(gnx,headline)
    else:
        v = at.root.v
        at.thinNodeStack.append(v)

    at.lastThinNode = v
    return v
#@+node:ekr.20100625184546.5979: *9* at.parseNodeSentinel & helpers
def parseNodeSentinel (self,s,i,middle):

    at = self

    if middle:
        assert g.match(s,i,"+middle:"),'missing +middle'
        i += 8
    else:
        if not g.match(s,i,'+node:'): g.trace(repr(s[i:i+40]),g.callers(5))
        assert g.match(s,i,"+node:"),'missing +node:'
        i += 6

    # Get the gnx and the headline.
    if at.thinFile:
        gnx,i,level,ok = at.parseThinNodeSentinel(s,i)
        if not ok: return None,None,None,False
    else:
        gnx,level = None,None

    headline = at.getNodeHeadline(s,i)
    return gnx,headline,i,level,True
#@+node:ekr.20100625085138.5955: *10* at.getNodeHeadline
def getNodeHeadline (self,s,i):

    '''Set headline to the rest of the line.
    Don't strip leading whitespace.'''

    at = self

    if len(at.endSentinelComment) == 0:
        h = s[i:-1].rstrip()
    else:
        k = s.rfind(at.endSentinelComment,i)
        h = s[i:k].rstrip() # works if k == -1

    # Undo the CWEB hack: undouble @ signs if\
    # the opening comment delim ends in '@'.
    if at.startSentinelComment[-1:] == '@':
        h = h.replace('@@','@')

    return h
#@+node:ekr.20100625085138.5953: *10* at.parseThinNodeSentinel
def parseThinNodeSentinel (self,s,i):

    at = self

    def oops(message):
        if g.unitTesting: g.trace(message,repr(s))
        else: at.readError(message)
        return None,None,None,False

    j = s.find(':',i)
    if j == -1:
        return oops('Expecting gnx in @+node sentinel')
    else:
        gnx = s[i:j]

    if at.readVersion5:
        if not g.match(s,j,': '):
            return oops('Expecting space after gnx')
        i = j + 2
        if not g.match(s,i,'*'):
            return oops('No level stars')
        i += 1
        if g.match(s,i,' '):
            level = 1 ; i += 1
        elif g.match(s,i,'* '):
            level = 2 ; i += 2
        else:
            # The level stars have the form *N*.
            level = 0  ; j = i
            while i < len(s) and s[i].isdigit():
                i += 1
            if i > j:
                level = int(s[j:i])
            else:
                return oops('No level number')
            if g.match(s,i,'* '):
                i += 2
            else:
                return oops('No space after level stars')
    else: # not readVersion5.
        i = j + 1 # Skip the gnx.
        level = 0

    return gnx,i,level,True
#@+node:ekr.20041005105605.111: *8* at.readRef (paired using new sentinels)
@ The sentinel contains an @ followed by a section name in angle brackets.
This code is different from the code for the @@ sentinel: the expansion
of the reference does not include a trailing newline.
@c

def readRef (self,s,i):

    """Handle an @<< sentinel."""

    at = self

    if at.readVersion5:
        assert g.match(s,i,"+"),'g.match(s,i,"+")'
        i += 1 # Skip the new plus sign.

        # New in Leo 4.8: Ignore the spellling in leadingWs.
        # Instead, compute lws2, the regularized leading whitespace.
        junk_i,w = g.skip_leading_ws_with_indent(s,0,at.tab_width)
        lws2 = g.computeLeadingWhitespace(max(0,w-at.indent),at.tab_width)
    else:
        lws2 = ''

    j = g.skip_ws(s,i)
    assert g.match(s,j,"<<"),'missing @<< sentinel'

    # g.trace(repr(at.endSentinelComment))
    if len(at.endSentinelComment) == 0:
        if at.readVersion5:
            line = lws2 + s[i:]
        else:
            line = s[i:-1] # No trailing newline
    else:
        k = s.find(at.endSentinelComment,i)
        if at.readVersion5:
            line = lws2 + s[i:k] + '\n' # Restore the newline.
        else:
            line = s[i:k] # No trailing newline, whatever k is.
        # g.trace(repr(line))

    # Undo the cweb hack.
    start = at.startSentinelComment
    if start and len(start) > 0 and start[-1] == '@':
        line = line.replace('@@','@')

    at.appendToOut(line)

    if at.readVersion5:
        # g.trace(at.indent,repr(line))
        at.endSentinelLevelStack.append(len(at.thinNodeStack))
        at.endSentinelIndentStack.append(at.indent)
        at.endSentinelStack.append(at.endRef)
        at.endSentinelNodeStack.append(at.v)
    else:
        pass # There is no paired @-ref sentinel.
#@+node:ekr.20041005105605.82: *8* at.readStartAt/Doc & helpers
#@+node:ekr.20100624082003.5938: *9* readStartAt
def readStartAt (self,s,i):

    """Read an @+at sentinel."""

    at = self
    assert g.match(s,i,"+at"),'missing +at'
    i += 3

    if at.readVersion5: # Append whatever follows the sentinel.
        j = at.skipToEndSentinel(s,i)
        follow = s[i:j]
        at.appendToOut('@' + follow + '\n')
        at.docOut = []
        at.inCode = False
    else:
        j = g.skip_ws(s,i)
        ws = s[i:j]
        at.docOut = ['@' + ws + '\n']
            # This newline may be removed by a following @nonl
        at.inCode = False
        at.endSentinelStack.append(at.endAt)
#@+node:ekr.20100624082003.5939: *9* readStartDoc
def readStartDoc (self,s,i):

    """Read an @+doc sentinel."""

    at = self
    assert g.match(s,i,"+doc"),'missing +doc'
    i += 4

    if at.readVersion5: # Append whatever follows the sentinel.
        j = at.skipToEndSentinel(s,i)
        follow = s[i:j]+'\n'
        at.appendToOut('@' + follow + '\n')
        at.docOut = []
        at.inCode = False
    else:
        j = g.skip_ws(s,i)
        ws = s[i:j]
        at.docOut = ["@doc" + ws + '\n']
            # This newline may be removed by a following @nonl
        at.inCode = False
        at.endSentinelStack.append(at.endDoc)
#@+node:ekr.20100624082003.5940: *9* skipToEndSentinel
def skipToEndSentinel(self,s,i):

    '''Skip to the end of the sentinel line.'''

    at = self
    end = at.endSentinelComment

    if end:
        j = s.find(end,i)
        if j == -1:
            return g.skip_to_end_of_line(s,i)
        else:
            return j
    else:
        return g.skip_to_end_of_line(s,i)
#@+node:ekr.20041005105605.83: *8* at.readStartLeo
def readStartLeo (self,s,i):

    """Read an unexpected @+leo sentinel."""

    at = self
    assert g.match(s,i,"+leo"),'missing +leo sentinel'
    at.readError("Ignoring unexpected @+leo sentinel")
#@+node:ekr.20041005105605.84: *8* at.readStartMiddle
def readStartMiddle (self,s,i):

    """Read an @+middle sentinel."""

    at = self

    at.readStartNode(s,i,middle=True)
#@+node:ekr.20041005105605.89: *8* at.readStartOthers
def readStartOthers (self,s,i):

    """Read an @+others sentinel."""

    at = self

    j = g.skip_ws(s,i)
    leadingWs = s[i:j]

    if leadingWs:
        assert g.match(s,j,"@+others"),'missing @+others'
    else:
        assert g.match(s,j,"+others"),'missing +others'

    # Make sure that the generated at-others is properly indented.
    # New code (for both old and new sentinels).
    # Regularize the whitespace preceding the @others directive.
    junk_i,w = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    lws2 = g.computeLeadingWhitespace(max(0,w-at.indent),at.tab_width)
    at.appendToOut(lws2 + "@others\n")

    if at.readVersion5:
        at.endSentinelIndentStack.append(at.indent)
        at.endSentinelStack.append(at.endOthers)
        at.endSentinelNodeStack.append(at.v)
        at.endSentinelLevelStack.append(len(at.thinNodeStack))
    else:
        at.endSentinelStack.append(at.endOthers)
#@+node:ekr.20041005105605.90: *7* end sentinels
#@+node:ekr.20041005105605.91: *8* at.readEndAll
def readEndAll (self,unused_s,unused_i):

    """Read an @-all sentinel."""

    at = self
    at.popSentinelStack(at.endAll)

    if at.readVersion5:

        # Restore the node containing the @all directive.
        # *Never* terminate new-sentinel nodes until the post-pass.
        at.raw = False # End raw mode: 2011/06/13.
        oldLevel = len(at.thinNodeStack)
        newLevel = at.endSentinelLevelStack.pop()
        at.v = at.endSentinelNodeStack.pop() # Bug fix: 2011/06/13.
        at.changeLevel(oldLevel,newLevel)

        # g.trace('oldLevel',oldLevel,'newLevel',newLevel,'at.v',at.v)
#@+node:ekr.20041005105605.92: *8* at.readEndAt & readEndDoc
def readEndAt (self,unused_s,unused_i):

    """Read an @-at sentinel."""

    at = self
    at.readLastDocLine("@")
    at.popSentinelStack(at.endAt)
    at.inCode = True

def readEndDoc (self,unused_s,unused_i):

    """Read an @-doc sentinel."""

    at = self
    at.readLastDocLine("@doc")
    at.popSentinelStack(at.endDoc)
    at.inCode = True
#@+node:ekr.20041005105605.93: *8* at.readEndLeo
def readEndLeo (self,unused_s,unused_i):

    """Read an @-leo sentinel."""

    at = self

    # Ignore everything after @-leo.
    # Such lines were presumably written by @last.
    while 1:
        s = at.readLine(at.inputFile)
        if len(s) == 0: break
        at.lastLines.append(s) # Capture all trailing lines, even if empty.

    at.done = True
#@+node:ekr.20041005105605.94: *8* at.readEndMiddle
def readEndMiddle (self,s,i):

    """Read an @-middle sentinel."""

    at = self

    at.readEndNode(s,i,middle=True)
#@+node:ekr.20041005105605.95: *8* at.readEndNode
def readEndNode (self,unused_s,unused_i,middle=False):

    """Handle @-node sentinels."""

    at = self ; c = at.c

    assert not at.readVersion5,'not at.readVersion5'
        # Must not be called for new sentinels.

    at.raw = False # End raw mode.

    at.terminateNode(middle)
        # Set the body text and warn about changed text.
        # This must not be called when handling new sentinels!

    # End the previous node sentinel.
    at.indent = at.indentStack.pop()
    at.out = at.outStack.pop()
    at.docOut = []
    at.v = at.vStack.pop()

    if at.thinFile and not at.importing:
        at.lastThinNode = at.thinNodeStack.pop()

    at.popSentinelStack(at.endNode)
#@+node:ekr.20041005105605.98: *8* at.readEndOthers
def readEndOthers (self,unused_s,unused_i):

    """Read an @-others sentinel."""

    at = self

    at.popSentinelStack(at.endOthers)

    if at.readVersion5:
        # g.trace(at.readVersion5,repr(at.docOut))
        # Terminate the *previous* doc part if it exists.
        if at.docOut:
            s = ''.join(at.docOut)
            s = at.massageAtDocPart(s) # 2011/05/24
            at.appendToOut(s)
            at.docOut = []
            at.inCode = True

        # Restore the node continain the @others directive.
        # *Never* terminate new-sentinel nodes until the post-pass.
        at.raw = False # End raw mode.
        at.v = at.endSentinelNodeStack.pop()
        at.indent = at.endSentinelIndentStack.pop()
        oldLevel = len(at.thinNodeStack)
        newLevel = at.endSentinelLevelStack.pop()
        at.changeLevel(oldLevel,newLevel)
#@+node:ekr.20100625140824.5968: *8* at.readEndRef
def readEndRef (self,unused_s,unused_i):

    """Read an @-<< sentinel."""

    at = self

    at.popSentinelStack(at.endRef)

    if at.readVersion5:
        # Terminate the *previous* doc part if it exists.
        if at.docOut:
            at.appendToOut(''.join(at.docOut))
            at.docOut = []
            at.inCode = True

        # Restore the node containing the section reference.
        # *Never* terminate new-sentinel nodes until the post-pass.
        at.raw = False # End raw mode.
        at.lastRefNode = at.v # A kludge for at.readAfterRef
        at.v = at.endSentinelNodeStack.pop()
        at.indent = at.endSentinelIndentStack.pop()
        oldLevel = len(at.thinNodeStack)
        newLevel = at.endSentinelLevelStack.pop()
        at.changeLevel(oldLevel,newLevel)
#@+node:ekr.20041005105605.99: *8* at.readLastDocLine (old sentinels only)
def readLastDocLine (self,tag):

    """Read the @c line that terminates the doc part.
    tag is @doc or @.

    Not used when reading new sentinels.
    """

    at = self
    end = at.endSentinelComment
    start = at.startSentinelComment
    s = ''.join(at.docOut)

    # Remove the @doc or @space.  We'll add it back at the end.
    if g.match(s,0,tag):
        s = s[len(tag):]
    else:
        at.readError("Missing start of doc part")
        return

    # Bug fix: Append any whitespace following the tag to tag.
    while s and s[0] in (' ','\t'):
        tag = tag + s[0] ; s = s[1:]

    if end:
        # Remove leading newline.
        if s[0] == '\n': s = s[1:]
        # Remove opening block delim.
        if g.match(s,0,start):
            s = s[len(start):]
        else:
            at.readError("Missing open block comment")
            g.trace('tag',repr(tag),'start',repr(start),'s',repr(s))
            return
        # Remove trailing newline.
        if s[-1] == '\n': s = s[:-1]
        # Remove closing block delim.
        if s[-len(end):] == end:
            s = s[:-len(end)]
        else:
            at.readError("Missing close block comment")
            g.trace(s)
            g.trace(end)
            g.trace(start)
            return

    at.appendToOut(tag + s)
    at.docOut = []
#@+node:ekr.20041005105605.100: *7* Unpaired sentinels
# Ooops: shadow files are cleared if there is a read error!!
#@+node:ekr.20041005105605.101: *8* at.ignoreOldSentinel
def  ignoreOldSentinel (self,s,unused_i):

    """Ignore an 3.x sentinel."""

    g.es("ignoring 3.x sentinel:",s.strip(),color="blue")
#@+node:ekr.20041005105605.102: *8* at.readAfterRef
def  readAfterRef (self,s,i):

    """Read an @afterref sentinel."""

    at = self
    trace = False and not g.unitTesting
    assert g.match(s,i,"afterref"),'missing afterref'

    # Append the next line to the text.
    s = at.readLine(at.inputFile)

    v = at.lastRefNode
    hasList = hasattr(v,'tempBodyList')
    hasString = hasattr(v,'tempBodyString')
    # g.trace('hasList',hasList,'hasString',hasString,'v',v and v.h)

    if at.readVersion5:
        if hasList and at.v.tempBodyList:
            # Remove the trailing newline.
            s2 = at.v.tempBodyList[-1]
            if s2.endswith('\n'): s2 = s2[:-1]
            at.v.tempBodyList[-1] = s2
            if trace: g.trace('v: %30s %s' % (at.v.h,repr(s2+s)))

    at.appendToOut(s)
#@+node:ekr.20041005105605.103: *8* at.readClone
def readClone (self,s,i):

    at = self ; tag = "clone"

    assert g.match(s,i,tag),'missing clone sentinel'

    # Skip the tag and whitespace.
    i = g.skip_ws(s,i+len(tag))

    # Get the clone count.
    junk,val = g.skip_long(s,i)

    if val == None:
        at.readError("Invalid count in @clone sentinel")
    else:
        at.cloneSibCount = val
#@+node:ekr.20041005105605.104: *8* at.readComment
def readComment (self,s,i):

    """Read an @comment sentinel."""

    assert g.match(s,i,"comment"),'missing comment sentinel'

    # Just ignore the comment line!
#@+node:ekr.20041005105605.105: *8* at.readDelims
def readDelims (self,s,i):

    """Read an @delims sentinel."""

    at = self
    assert g.match(s,i-1,"@delims"),'missing @delims'

    # Skip the keyword and whitespace.
    i0 = i-1
    i = g.skip_ws(s,i-1+7)

    # Get the first delim.
    j = i
    while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
        i += 1

    if j < i:
        at.startSentinelComment = s[j:i]

        # Get the optional second delim.
        j = i = g.skip_ws(s,i)
        while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
            i += 1
        end = g.choose(j<i,s[j:i],"")
        i2 = g.skip_ws(s,i)
        if end == at.endSentinelComment and (i2 >= len(s) or g.is_nl(s,i2)):
            at.endSentinelComment = "" # Not really two params.
            line = s[i0:j]
            line = line.rstrip()
            at.appendToOut(line+'\n')
        else:
            at.endSentinelComment = end
            line = s[i0:i]
            line = line.rstrip()
            at.appendToOut(line+'\n')
    else:
        at.readError("Bad @delims")
        at.appendToOut("@delims")
#@+node:ekr.20041005105605.106: *8* at.readDirective (@@)
def readDirective (self,s,i):

    """Read an @@sentinel."""

    trace = False and not g.unitTesting
    at = self
    assert g.match(s,i,"@"),'missing @@ sentinel'
        # The first '@' has already been eaten.

    if trace: g.trace(repr(s[i:]))
        # g.trace(g.get_line(s,i))

    if g.match_word(s,i,"@raw"):
        at.raw = True
    elif g.match_word(s,i,"@end_raw"):
        at.raw = False

    e = at.endSentinelComment
    s2 = s[i:]
    if len(e) > 0:
        k = s.rfind(e,i)
        if k != -1:
            s2 = s[i:k] + '\n'

    start = at.startSentinelComment
    if start and len(start) > 0 and start[-1] == '@':
        s2 = s2.replace('@@','@')

    if 0: # New in 4.2.1: never change comment delims here...
        if g.match_word(s,i,"@language"):
            << handle @language >>
        elif g.match_word(s,i,"@comment"):
            << handle @comment >>

    # An @c ends the doc part when using new sentinels.
    if at.readVersion5 and s2 in ('@c','@c\n','@code','@code\n'):
        if at.docOut:
            s = ''.join(at.docOut)
            s = at.massageAtDocPart(s) # 2011/05/24
            at.appendToOut(s)
            at.docOut = []
        at.inCode = True # End the doc part.

    at.appendToOut(s2)
#@+node:ekr.20041005105605.107: *9* << handle @language >>
# Skip the keyword and whitespace.
i += len("@language")
i = g.skip_ws(s,i)
j = g.skip_c_id(s,i)
language = s[i:j]

delim1,delim2,delim3 = g.set_delims_from_language(language)

if trace:
    g.trace(g.get_line(s,i))
    g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("ignoring bad @language sentinel:",line,color="red")
#@+node:ekr.20041005105605.108: *9* << handle @comment >>
j = g.skip_line(s,i)
line = s[i:j]
delim1,delim2,delim3 = g.set_delims_from_string(line)

#g.trace(g.get_line(s,i))
#g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    self.startSentinelComment = delim1
    self.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    self.startSentinelComment = delim2
    self.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("ignoring bad @comment sentinel:",line,color="red")
#@+node:ekr.20041005105605.109: *8* at.readNl
def readNl (self,s,i):

    """Handle an @nonl sentinel."""

    at = self
    assert g.match(s,i,"nl"),'missing nl sentinel'

    if at.inCode:
        at.appendToOut('\n')
    else:
        at.docOut.append('\n')
#@+node:ekr.20041005105605.110: *8* at.readNonl
def readNonl (self,s,i):

    """Handle an @nonl sentinel."""

    at = self
    assert g.match(s,i,"nonl"),'missing nonl sentinel'

    if at.inCode:
        s = ''.join(at.out)
        # 2010/01/07: protect against a mostly-harmless read error.
        if s:
            if s[-1] == '\n':
                at.out = [s[:-1]] # Do not use at.appendToOut here!
            else:
                g.trace("out:",s)
                at.readError("unexpected @nonl directive in code part")
    else:
        s = ''.join(at.pending)
        if s:
            if s[-1] == '\n':
                at.pending = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in pending doc part")
        else:
            s = ''.join(at.docOut)
            if s and s[-1] == '\n':
                at.docOut = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in doc part")
#@+node:ekr.20041005105605.112: *8* at.readVerbatim
def readVerbatim (self,s,i):

    """Read an @verbatim sentinel."""

    at = self
    assert g.match(s,i,"verbatim"),'missing verbatim sentinel'

    # Append the next line to the text.
    s = at.readLine(at.inputFile) 
    i = at.skipIndent(s,0,at.indent)
    # Do **not** insert the verbatim line itself!
        # at.appendToOut("@verbatim\n")
    at.appendToOut(s[i:])
#@+node:ekr.20041005105605.113: *7* at.badEndSentinel, popSentinelStack
def badEndSentinel (self,expectedKind):

    """Handle a mismatched ending sentinel."""

    at = self
    assert at.endSentinelStack,'empty sentinel stack'
    s = "(badEndSentinel) Ignoring %s sentinel.  Expecting %s" % (
        at.sentinelName(at.endSentinelStack[-1]),
        at.sentinelName(expectedKind))
    at.readError(s)

def popSentinelStack (self,expectedKind):

    """Pop an entry from endSentinelStack and check it."""

    at = self
    if at.endSentinelStack and at.endSentinelStack[-1] == expectedKind:
        at.endSentinelStack.pop()
    else:
        if 1: g.trace('%s\n%s' % (
            [at.sentinelName(z) for z in at.endSentinelStack],
            g.callers(4)))
        at.badEndSentinel(expectedKind)
#@+node:ekr.20110523201030.18288: *7* at.massageAtDocPart (new)
def massageAtDocPart (self,s):
    
    '''Compute the final @doc part when block comments are used.'''
    
    at = self
    
    if at.endSentinelComment:
        ok1 = s.startswith(at.startSentinelComment+'\n')
        ok2 = s.endswith(at.endSentinelComment+'\n')
        if ok1 and ok2:
            n1 = len(at.startSentinelComment)
            n2 = len(at.endSentinelComment)
            s = s[n1+1:-(n2+1)]
        else:
            at.error('invalid @doc part...\n%s' % repr(s))
            
    # g.trace(repr(s))
    return s
#@+node:ekr.20041005105605.128: *6* at.readLine
def readLine (self,theFile):

    """Reads one line from file using the present encoding"""

    s = g.readlineForceUnixNewline(theFile) # calls theFile.readline
    # g.trace(repr(s),g.callers(4))
    u = g.toUnicode(s,self.encoding)
    return u
#@+node:ekr.20110909091748.6947: *5* at.write path...
#@+node:ekr.20080712150045.2: *6* at.openStringFile
def openStringFile (self,fn,encoding='utf-8'):

    at = self

    at.shortFileName = g.shortFileName(fn)
    at.outputFileName = "<string: %s>" % at.shortFileName
    at.outputFile = g.fileLikeObject(encoding=encoding)
    at.targetFileName = "<string-file>"

    return at.outputFile
#@+node:ekr.20080711093251.5: *6* at.writeOneAtShadowNode & helpers
def writeOneAtShadowNode(self,p,toString,force):

    '''Write p, an @shadow node.

    File indices *must* have already been assigned.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; x = c.shadowController
    root = p.copy() 

    fn = p.atShadowFileNodeName()
    if trace: g.trace(p.h,fn)
    if not fn:
        g.es_print('can not happen: not an @shadow node',p.h,color='red')
        return False

    # A hack to support unknown extensions.
    self.adjustTargetLanguage(fn) # May set c.target_language.

    fn = at.fullPath(p)
    at.default_directory = g.os_path_dirname(fn)
    exists = g.os_path_exists(fn)
    if trace: g.trace('exists %s fn %s' % (exists,fn))

    # Bug fix 2010/01/18: Make sure we can compute the shadow directory.
    private_fn = x.shadowPathName(fn)
    if not private_fn:
        return False

    if not toString and not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @shadow node would overwrite the existing public file.
        ok = self.promptForDangerousWrite(fn,kind='@shadow')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fn)
            return

    c.endEditing() # Capture the current headline.

    at.initWriteIvars(root,targetFileName=None, # Not used.
        atShadow=True,
        nosentinels=None, # set below.  Affects only error messages (sometimes).
        thinFile=True, # New in Leo 4.5 b2: private files are thin files.
        scriptWrite=False,
        toString=False, # True: create a fileLikeObject.  This is done below.
        forcePythonSentinels=True) # A hack to suppress an error message.
            # The actual sentinels will be set below.
            
    # g.trace('encoding',repr(at.encoding))

    # Bug fix: Leo 4.5.1: use x.markerFromFileName to force the delim to match
    #                     what is used in x.propegate changes.
    marker = x.markerFromFileName(fn)
    at.startSentinelComment,at.endSentinelComment=marker.getDelims()

    if g.app.unitTesting: ivars_dict = g.getIvarsDict(at)

    # Write the public and private files to public_s and private_s strings.
    data = []
    for sentinels in (False,True):
        # 2011/09/09: specify encoding explicitly.
        theFile = at.openStringFile(fn,encoding=at.encoding)
        at.sentinels = sentinels
        at.writeOpenFile(root,
            nosentinels=not sentinels,toString=False)
            # nosentinels only affects error messages, and then only if atAuto is True.
        s = at.closeStringFile(theFile)
        data.append(s)

    # Set these new ivars for unit tests.
    at.public_s, at.private_s = data

    if g.app.unitTesting:
        exceptions = ('public_s','private_s','sentinels','stringOutput')
        assert g.checkUnchangedIvars(at,ivars_dict,exceptions),'writeOneAtShadowNode'

    if at.errors == 0 and not toString:
        # Write the public and private files.
        if trace: g.trace('writing',fn)
        x.makeShadowDirectory(fn) # makeShadowDirectory takes a *public* file name.
        at.replaceFileWithString(private_fn,at.private_s)
        at.replaceFileWithString(fn,at.public_s)

    self.checkPythonCode(root,s=at.private_s,targetFn=fn)

    if at.errors == 0:
        root.clearOrphan()
        root.clearDirty()
    else:
        g.es("not written:",at.outputFileName,color='red')
        root.setDirty() # New in Leo 4.4.8.
        root.setOrphan() # 2010/10/22.

    return at.errors == 0
#@+node:ekr.20080819075811.13: *7* adjustTargetLanguage
def adjustTargetLanguage (self,fn):

    """Use the language implied by fn's extension if
    there is a conflict between it and c.target_language."""

    at = self ; c = at.c

    if c.target_language:
        junk,target_ext = g.os_path_splitext(fn)  
    else:
        target_ext = ''

    junk,ext = g.os_path_splitext(fn)

    if ext:
        if ext.startswith('.'): ext = ext[1:]

        language = g.app.extension_dict.get(ext)
        if language:
            c.target_language = language
        else:
            # An unknown language.
            pass # Use the default language, **not** 'unknown_language'
#@+node:ekr.20040331083824.1: *6* g.fileLikeObject
# Note: we could use StringIo for this.

class fileLikeObject:

    """Define a file-like object for redirecting writes to a string.

    The caller is responsible for handling newlines correctly."""

    @others
#@+node:ekr.20050404151753: *7*  ctor
def __init__(self,encoding='utf-8',fromString=None):

    # g.trace('g.fileLikeObject:__init__','fromString',fromString)

    # New in 4.2.1: allow the file to be inited from string s.

    self.encoding = encoding or 'utf-8'

    if fromString:
        self.list = g.splitLines(fromString) # Must preserve newlines!
    else:
        self.list = []

    self.ptr = 0

# In CStringIO the buffer is read-only if the initial value (fromString) is non-empty.
#@+node:ekr.20050404151753.1: *7* clear
def clear (self):

    self.list = []
#@+node:ekr.20050404151753.2: *7* close
def close (self):

    pass

    # The StringIo version free's the memory buffer.
#@+node:ekr.20050404151753.3: *7* flush
def flush (self):

    pass
#@+node:ekr.20050404151753.4: *7* get & getvalue & read
def get (self):

    return ''.join(self.list)

getvalue = get # for compatibility with StringIo
read = get # for use by sax.
#@+node:ekr.20050404151753.5: *7* readline
def readline(self): # New for read-from-string (readOpenFile).

    if self.ptr < len(self.list):
        line = self.list[self.ptr]
        # g.trace(repr(line))
        self.ptr += 1
        return line
    else:
        return ''
#@+node:ekr.20050404151753.6: *7* write
def write (self,s):

    if s:
        if g.isBytes(s):
            s = g.toUnicode(s,self.encoding)

        self.list.append(s)
#@+node:ekr.20041005105605.204: *6* os
def os (self,s):

    """Write a string to the output stream.

    All output produced by leoAtFile module goes here."""

    trace = False and not g.unitTesting
    at = self ; tag = self.underindentEscapeString
    f = at.outputFile

    if s and f:
        try:
            if s.startswith(tag):
                junk,s = self.parseUnderindentTag(s)
            # at.outputFile is a fileLikeObject.
            # Bug fix: this must be done last.
            s = g.toEncodedString(s,at.encoding,reportErrors=True)
            if trace: g.trace(at.encoding,f,repr(s)) # ,g.callers(5))
            f.write(s)
        except Exception:
            at.exception("exception writing:" + s)
#@+node:ekr.20110908155830.6877: *5* x.update path...
#@+node:bwmulder.20041231170726: *6* x.updatePublicAndPrivateFiles
def updatePublicAndPrivateFiles (self,root,fn,shadow_fn):

    '''handle crucial @shadow read logic.

    This will be called only if the public and private files both exist.'''

    trace = False and not g.unitTesting
    x = self

    if x.isSignificantPublicFile(fn):
        # Update the private shadow file from the public file.
        written = x.propagate_changes(fn,shadow_fn)
        if written: x.message("updated private %s from public %s" % (shadow_fn, fn))
    else:
        if trace: g.trace('not significant',fn)
        # Don't write *anything*.
        # if 0: # This causes considerable problems.
            # # Create the public file from the private shadow file.
            # x.copy_file_removing_sentinels(shadow_fn,fn)
            # x.message("created public %s from private %s " % (fn, shadow_fn))
#@+node:ekr.20080708094444.36: *6* x.propagate_changes
def propagate_changes(self, old_public_file, old_private_file):

    '''Propagate the changes from the public file (without_sentinels)
    to the private file (with_sentinels)'''

    trace = False and not g.unitTesting ; verbose = False
    x = self ; at = self.c.atFileCommands
    at.errors = 0
    
    # A massive klude: read the file private file just to read the encoding.
    f = open(old_private_file)
    at.scanHeader(f,old_private_file)
    f.close()
    self.encoding = at.encoding
    if trace: g.trace(self.encoding)
    
    if g.isPython3:
        old_public_lines  = open(old_public_file,encoding=self.encoding).readlines()
        old_private_lines = open(old_private_file,encoding=self.encoding).readlines()
    else:
        old_public_lines  = open(old_public_file).readlines()
        old_private_lines = open(old_private_file).readlines()
    
        # 2011/09/09: convert each line to unicode.
        def cvt(s):
            return g.choose(g.isUnicode(s),s,g.toUnicode(s,self.encoding))

        old_public_lines  = [cvt(s) for s in old_public_lines]
        old_private_lines = [cvt(s) for s in old_private_lines]
    
    if 0:
        g.trace('\nprivate lines...%s' % old_private_file)
        for s in old_private_lines:
            g.trace(type(s),g.isUnicode(s),repr(s))
        g.trace('\npublic lines...%s' % old_public_file)
        for s in old_public_lines:
            g.trace(type(s),g.isUnicode(s),repr(s))

    marker = x.markerFromFileLines(old_private_lines,old_private_file)

    if trace and verbose:
        g.trace(
            'marker',marker,
            '\npublic_file',old_public_file,
            '\npublic lines...\n%s' %(
                g.listToString(old_public_lines,toRepr=True)),
            '\nprivate_file',old_private_file,
            '\nprivate lines...\n%s\n' %(
                g.listToString(old_private_lines,toRepr=True)))

    new_private_lines = x.propagate_changed_lines(
        old_public_lines,old_private_lines,marker)

    # Important bug fix: Never create the private file here!
    fn = old_private_file
    copy = os.path.exists(fn) and new_private_lines != old_private_lines

    # 2010/01/07: check at.errors also.
    if copy and x.errors == 0 and at.errors == 0:
        s = ''.join(new_private_lines)
        ok = x.replaceFileWithString(fn,s)
        # g.trace('ok',ok,'writing private file',fn)

    return copy
#@+node:ekr.20080713091247.1: *6* x.replaceFileWithString (@shadow)
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    trace = False and not g.unitTesting ; verbose = False
    x = self
    exists = g.os_path_exists(fn)

    if exists:
        # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s2 is None:
            return False
        if s == s2:
            if not g.unitTesting: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            x.error('not written: %s directory not found' % fn)
        return False

    # Replace the file.
    try:
        f = open(fn,'wb')
        # 2011/09/09: Use self.encoding.
        f.write(g.toEncodedString(s,encoding=self.encoding))
        if trace:
            g.trace('encoding',self.encoding)
            if verbose: g.trace('fn',fn,
                '\nlines...\n%s' %(g.listToString(g.splitLines(s))),
                '\ncallers',g.callers(4))
        f.close()
        if not g.unitTesting:
            # g.trace('created:',fn,g.callers())
            if exists:  g.es('wrote:',fn)
            else:       g.es('created:',fn)
        return True
    except IOError:
        x.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20110917130105.6873: *4* Fix a w.see botch.
@nocolor-node

The call to w.see(ins+5) in rp_reformat created a big problem.

Replacing this with w.see(ins) is much better.
#@+node:ekr.20110930174206.15471: *4* Attempted another fix of the scrolling bug
@nocolor-node

The last time it happened:
    
- Search for something.
- Manually scroll the pane.
- Click scrolls the pane again.
#@+node:ekr.20110930174206.15474: *5* Changed
#@+node:ekr.20110605121601.18209: *6* deactivateEditors (qtBody)
def deactivateEditors(self,wrapper):

    '''Deactivate all editors except wrapper's editor.'''

    trace = False and not g.unitTesting
    d = self.editorWidgets

    # Don't capture ivars here! assignPositionToEditor keeps them up-to-date. (??)
    for key in d:
        wrapper2 = d.get(key)
        w2 = wrapper2.widget
        if hasattr(w2,'leo_active'):
            active = w2.leo_active
        else:
            active = True
        if wrapper2 != wrapper and active:
            w2.leo_active = False
            self.unselectLabel(wrapper2)
            ### 2011/09/30
            ### w2.leo_scrollBarSpot = wrapper2.getYScrollPosition()
            w2.leo_insertSpot = wrapper2.getInsertPoint()
            w2.leo_selection = wrapper2.getSelectionRange()
            if trace: g.trace('**deactivate wrapper %s w %s' % (
                id(wrapper2),id(w2)))
            self.onFocusOut(w2)
#@+node:ekr.20070424080640: *6* inactivateActiveEditor
def inactivateActiveEditor(self,w):

    '''Inactivate the previously active editor.'''

    d = self.editorWidgets

    # Don't capture ivars here! assignPositionToEditor keeps them up-to-date. (??)
    for key in d:
        w2 = d.get(key)
        if w2 != w and w2.leo_active:
            w2.leo_active = False
            self.unselectLabel(w2)
            ### 2011/09/30
            ### w2.leo_scrollBarSpot = w2.yview()
            w2.leo_insertSpot = w2.getInsertPoint()
            w2.leo_selection = w2.getSelectionRange()
            # g.trace('inactive:',id(w2),'scroll',w2.leo_scrollBarSpot,'ins',w2.leo_insertSpot)
            # g.trace('inactivate',id(w2))
            return
#@+node:ekr.20110605121601.18027: *6* injectIvars (leoQtBaseTextWidget)
def injectIvars (self,name='1',parentFrame=None):

    w = self ; p = self.c.currentPosition()

    if name == '1':
        w.leo_p = None # Will be set when the second editor is created.
    else:
        w.leo_p = p.copy()

    w.leo_active = True

    # New in Leo 4.4.4 final: inject the scrollbar items into the text widget.
    w.leo_bodyBar = None
    w.leo_bodyXBar = None
    w.leo_chapter = None
    w.leo_frame = None
    w.leo_name = name
    w.leo_label = None
    ### 2011/09/30
    ### w.leo_scrollBarSpot = None
    w.leo_insertSpot = None
    w.leo_selection = None

    return w
#@+node:ekr.20110605121601.18211: *6* injectIvars (qtBody)
def injectIvars (self,parentFrame,name,p,wrapper):

    trace = False and not g.unitTesting

    w = wrapper.widget
    assert isinstance(wrapper,leoQTextEditWidget),wrapper
    assert isinstance(w,QtGui.QTextEdit),w

    if trace: g.trace(w)

    # Inject ivars
    if name == '1':
        w.leo_p = None # Will be set when the second editor is created.
    else:
        w.leo_p = p.copy()

    w.leo_active = True
    w.leo_bodyBar = None
    w.leo_bodyXBar = None
    w.leo_chapter = None
    # w.leo_colorizer = None # Set in leoQtColorizer ctor.
    w.leo_frame = parentFrame
    w.leo_insertSpot = None
    # w.leo_label = None # Injected by packLabel.
    w.leo_name = name
    # w.leo_on_focus_in = onFocusInCallback
    ### 2011/09/30
    ### w.leo_scrollBarSpot = None
    w.leo_selection = None
    w.leo_wrapper = wrapper
#@+node:ekr.20070423102603: *6* selectEditorHelper
def selectEditorHelper (self,w):

    c = self.c ; cc = c.chapterController ; d = self.editorWidgets

    trace = False

    if not w.leo_p:
        g.trace('no w.leo_p') 
        return # (for Tk) 'break'

    if trace:
        g.trace('==1',id(w),
            hasattr(w,'leo_chapter') and w.leo_chapter and w.leo_chapter.name,
            hasattr(w,'leo_p') and w.leo_p and w.leo_p.h)

    self.inactivateActiveEditor(w)

    # The actual switch.
    c.frame.body.bodyCtrl = w
    w.leo_active = True

    self.switchToChapter(w)
    self.selectLabel(w)

    if not self.ensurePositionExists(w):
        g.trace('***** no position editor!')
        return # (for Tk) 'break'

    if trace:
        g.trace('==2',id(w),
            hasattr(w,'leo_chapter') and w.leo_chapter and w.leo_chapter.name,
            hasattr(w,'leo_p') and w.leo_p and w.leo_p.h)

    # g.trace('expanding ancestors of ',w.leo_p.h,g.callers())
    c.redraw(w.leo_p)
    c.recolor()
    << restore the selection, insertion point and the scrollbar >>
    c.bodyWantsFocus()
    return # (for Tk) 'break'
#@+node:ekr.20061017083312.1: *7* << restore the selection, insertion point and the scrollbar >>
# g.trace('active:',id(w),'scroll',w.leo_scrollBarSpot,'ins',w.leo_insertSpot)

if w.leo_insertSpot:
    w.setInsertPoint(w.leo_insertSpot)
else:
    w.setInsertPoint(0)
    
w.seeInsertPoint() ### 2011/09/30

### 2011/09/30
# if w.leo_scrollBarSpot is not None:
    # first,last = w.leo_scrollBarSpot
    # w.yview('moveto',first)
# else:
    # w.seeInsertPoint()

if w.leo_selection:
    try:
        start,end = w.leo_selection
        w.setSelectionRange(start,end)
        w.see(start) ### 2011/09/30
    except Exception:
        pass
#@+node:ekr.20110605121601.18203: *6* selectEditorHelper (leoBody)
def selectEditorHelper (self,wrapper):

    trace = False and not g.unitTesting
    c = self.c ; cc = c.chapterController
    d = self.editorWidgets
    assert isinstance(wrapper,leoQTextEditWidget),wrapper
    w = wrapper.widget
    assert isinstance(w,QtGui.QTextEdit),w

    if not w.leo_p:
        g.trace('no w.leo_p') 
        return 'break'

    # The actual switch.
    self.deactivateEditors(wrapper)
    self.recolorWidget (w.leo_p,wrapper) # switches colorizers.
    # g.trace('c.frame.body',c.frame.body)
    # g.trace('c.frame.body.bodyCtrl',c.frame.body.bodyCtrl)
    # g.trace('wrapper',wrapper)
    c.frame.body.bodyCtrl = wrapper
    c.frame.body.widget = wrapper # Major bug fix: 2011/04/06
    w.leo_active = True

    self.switchToChapter(wrapper)
    self.selectLabel(wrapper)

    if not self.ensurePositionExists(w):
        return g.trace('***** no position editor!')
    if not (hasattr(w,'leo_p') and w.leo_p):
        return g.trace('***** no w.leo_p',w)
        
    # if not (hasattr(w,'leo_chapter') and w.leo_chapter):
        # return g.trace('***** no w.leo_chapter',w)

    p = w.leo_p
    assert p,p

    if trace: g.trace('wrapper %s chapter %s old %s p %s' % (
        id(wrapper),w.leo_chapter,c.p.h,p.h))

    c.expandAllAncestors(p)
    c.selectPosition(p) # Calls assignPositionToEditor.
    c.redraw()
    c.recolor_now()
    << restore the selection, insertion point and the scrollbar >>
    c.bodyWantsFocus()
#@+node:ekr.20110605121601.18204: *7* << restore the selection, insertion point and the scrollbar >>
# g.trace('active:',id(w),'scroll',w.leo_scrollBarSpot,'ins',w.leo_insertSpot)

if hasattr(w,'leo_insertSpot') and w.leo_insertSpot:
    wrapper.setInsertPoint(w.leo_insertSpot)
else:
    wrapper.setInsertPoint(0)
    
wrapper.seeInsertPoint() ###

###
# if hasattr(w,'leo_scrollBarSpot') and w.leo_scrollBarSpot is not None:
    # first,last = w.leo_scrollBarSpot
    # wrapper.see(first)
# else:
    # wrapper.seeInsertPoint()

if hasattr(w,'leo_selection') and w.leo_selection:
    try:
        start,end = w.leo_selection
        wrapper.setSelectionRange(start,end)
    except Exception:
        pass
#@+node:ekr.20070423101911: *6* selectHelper (leoTree)
#  Do **not** try to "optimize" this by returning if p==tree.currentPosition.

def selectHelper (self,p,scroll):

    trace = False and not g.unitTesting
    verbose = True
    c = self.c ; frame = c.frame
    body = w = frame.body.bodyCtrl
    if not w: return # Defensive.

    old_p = c.p

    if p:
        # 2009/10/10: selecting a foreign position
        # will not be pretty.
        assert p.v.context == c
    else:
        # Do *not* test c.positionExists(p) here.
        # We may be in the process of changing roots.
        return None # Not an error.

    if trace:
        if old_p:
            g.trace('old: %s %s new: %s %s' % (
                len(old_p.b),old_p.h,len(p.b),p.h))
        else:
            g.trace('old: <none> new: %s %s' % (len(p.b),p.h))

    if not g.doHook("unselect1",c=c,new_p=p,old_p=old_p,new_v=p,old_v=old_p):
        if old_p:
            << unselect the old node >>

    g.doHook("unselect2",c=c,new_p=p,old_p=old_p,new_v=p,old_v=old_p)

    if not g.doHook("select1",c=c,new_p=p,old_p=old_p,new_v=p,old_v=old_p):
        << select the new node >>
        c.nodeHistory.update(p) # Remember this position.
    c.setCurrentPosition(p)
    << set the current node >>
    c.frame.body.assignPositionToEditor(p) # New in Leo 4.4.1.
    c.frame.updateStatusLine() # New in Leo 4.4.1.

    if trace: g.trace('**** after old: %s new %s' % (
        old_p and len(old_p.b),len(p.b)))

    # what UNL.py used to do
    c.frame.clearStatusLine()
    c.frame.putStatusLine("-->".join(reversed(
        [i.h for i in p.self_and_parents()])))

    g.doHook("select2",c=c,new_p=p,old_p=old_p,new_v=p,old_v=old_p)
    g.doHook("select3",c=c,new_p=p,old_p=old_p,new_v=p,old_v=old_p)

    return # (for Tk) 'break' # Supresses unwanted selection.
#@+node:ekr.20040803072955.129: *7* << unselect the old node >>
# Remember the position of the scrollbar before making any changes.
if body:
    yview = body.getYScrollPosition()
    insertSpot = c.frame.body.getInsertPoint()
    # g.trace('set insert spot',insertSpot)
else:
    g.trace('no body!','c.frame',c.frame,'old_p',old_p)
    yview,insertSpot = None,0

if old_p != p:
    self.endEditLabel() # sets editPosition = None
    self.setUnselectedLabelState(old_p)

if old_p and old_p != p: # 2010/02/11: Don't change the *new* node's insert point!
    ### old_p.v.scrollBarSpot = yview
    old_p.v.insertSpot = insertSpot
#@+node:ekr.20040803072955.130: *7* << select the new node >>
# Bug fix: we must always set this, even if we never edit the node.
self.revertHeadline = p.h
frame.setWrap(p)
self.setBodyTextAfterSelect(p,old_p)
#@+node:ekr.20040803072955.133: *7* << set the current node >>
self.setSelectedLabelState(p)

frame.scanForTabWidth(p) #GS I believe this should also get into the select1 hook

if self.use_chapters:
    cc = c.chapterController
    theChapter = cc and cc.getSelectedChapter()
    if theChapter:
        theChapter.p = p.copy()
        # g.trace('tkTree',theChapter.name,'v',id(p.v),p.h)

c.treeFocusHelper() # 2010/12/14
c.undoer.onSelect(old_p,p)
#@+node:ekr.20031218072017.3344: *6* v.__init
# To support ZODB, the code must set v._p_changed = 1 whenever
# v.unknownAttributes or any mutable vnode object changes.

def __init__ (self,context):

    # The primary data: headline and body text.
    self._headString = g.u('newHeadline')
    self._bodyString = g.u('')

    # Structure data...
    self.children = [] # Ordered list of all children of this node.
    self.parents = [] # Unordered list of all parents of this node.

    # Other essential data...
    self.fileIndex = g.app.nodeIndices.getNewIndex()
        # The immutable file index for this vnode.
        # New in Leo 4.6 b2: allocate gnx (fileIndex) immediately.
    self.iconVal = 0 # The present value of the node's icon.
    self.statusBits = 0 # status bits

    # v.t no longer exists.  All code must now be aware of the one-node world.
    # self.t = self # For compatibility with scripts and plugins.

    # Information that is never written to any file...
    self.context = context # The context containing context.hiddenRootNode.
        # Required so we can compute top-level siblings.
        # It is named .context rather than .c to emphasize its limited usage.
    self.insertSpot = None # Location of previous insert point.
    ### self.scrollBarSpot = None # Previous value of scrollbar position.
    self.selectionLength = 0 # The length of the selected body text.
    self.selectionStart = 0 # The start of the selected body text.
#@+node:ekr.20100303074003.5636: *6* v.restoreCursorAndScroll
def restoreCursorAndScroll (self,w):

    v = self

    if v and v.insertSpot != None:
        spot = v.insertSpot
        w.setInsertPoint(spot)
        w.see(spot)
    else:
        w.setInsertPoint(0)
        
    w.seeInsertPoint() ### 2011/09/30

    ### 2011/09/30 
    # # Restore the scroll spot after the call to w.see.
    # if v and v.scrollBarSpot != None:
        # first,last = v.scrollBarSpot
        # w.setYScrollPosition(first)
#@+node:ekr.20100303074003.5638: *6* v.saveCursorAndScroll(w)
def saveCursorAndScroll(self,w):

    v = self
    if not w: return
    
    try:
        ### 2011/09/30
        ### v.scrollBarSpot = w.getYScrollPosition()
        v.insertSpot = w.getInsertPoint()
    except AttributeError:
        # 2011/03/21: w may not support the high-level interface.
        pass
#@+node:ekr.20110930075237.15471: *4* Investigated autocomplete popup bug
@nocolor-node

On Ubuntu only, the auto complete popup is system-wide modal, it should only be modal over Leo windows.

However, there does not seem to be any fix:
http://groups.google.com/group/leo-editor/browse_thread/thread/171aaf79e0bea256

All works well on Windows 7.  I do see the "system-wide" model
behavior on Ubuntu.

This appears to be a Ubuntu-specific bug.  Indeed, the popup is a
QListWidget.  Such widgets have a setWindowModality method::

    setWindowModality ( Qt::WindowModality windowModality )

The valid modalities are at: http://doc.qt.nokia.com/4.7-snapshot/qt.html#WindowModality-enum

NonModal: The window is not modal and does not block input to other
windows.

WindowModal: The window is modal to a single window hierarchy and
blocks input to its parent window, all grandparent windows, and all
siblings of its parent and grandparent windows.

ApplicationModal: The window is modal to the application and blocks
input to all windows.

None of these would appear to be a system-wide modality, and
furthermore, the default is supposed to be NonModal.

Anyway, calling setWindowModality(QtCore.Qt.NonModal) does not seem to
have much effect on Ubuntu, so I think I can safely say there is
nothing more I can do. 
#@+node:ekr.20111001155050.15480: *4* Fixed scrolling bugs
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/de76f22b16ebc8f

As explained in detail in the thread, "dangerous" code is no longer executed immediately,
but instead executed at idle time using g.app.gui.runAtIdle.
#@+node:ekr.20111001155050.15482: *5* Reference
#@+node:ekr.20080514131122.20: *6* c.outerUpdate
def outerUpdate (self):

    trace = False and not g.unitTesting
    verbose = False ; traceFocus = True
    c = self ; aList = []
    if not c.exists or not c.k:
        return

    # Suppress any requested redraw until we have iconified or diconified.
    redrawFlag = c.requestRedrawFlag
    c.requestRedrawFlag = False
    
    if trace and (verbose or aList):
        g.trace('**start',g.callers(5))
    
    if c.requestBringToFront:
        if hasattr(c.frame,'bringToFront'):
            c.frame.bringToFront()
        c.requestBringToFront = False

    # The iconify requests are made only by c.bringToFront.
    if c.requestedIconify == 'iconify':
        if verbose: aList.append('iconify')
        c.frame.iconify()

    if c.requestedIconify == 'deiconify':
        if verbose: aList.append('deiconify')
        c.frame.deiconify()

    if redrawFlag:
        if trace: g.trace('****','tree.drag_p',c.frame.tree.drag_p)
        # A hack: force the redraw, even if we are dragging.
        aList.append('*** redraw')
        c.frame.tree.redraw_now(forceDraw=True)

    if c.requestRecolorFlag:
        if verbose: aList.append('%srecolor' % (
            g.choose(c.incrementalRecolorFlag,'','full ')))
        # This should be the only call to c.recolor_now.
        c.recolor_now(incremental=c.incrementalRecolorFlag)

    if c.requestedFocusWidget:
        w = c.requestedFocusWidget
        if traceFocus: aList.append('focus: %s' % (
            g.app.gui.widget_name(w)))
        c.set_focus(w)
    else:
        # We must not set the focus to the body pane here!
        # That would make nested calls to c.outerUpdate significant.
        pass

    if trace and (verbose or aList):
        g.trace('** end',aList)

    c.incrementalRecolorFlag = False
    c.requestRecolorFlag = None
    c.requestRedrawFlag = False
    c.requestedFocusWidget = None
    c.requestedIconify = ''

    # g.trace('after')
#@+node:ekr.20110605121601.18186: *6* Colors (qtBody)
#@+node:ekr.20110605121601.18187: *7* setEditorColors (qtBody)
def setEditorColors (self,bg,fg):
    
    obj = self.bodyCtrl.widget # A QTextEditor or QTextBrowser.
    
    # g.trace('(leoQtBody)',bg,fg,g.callers())
    
    self.setForegroundColorHelper(fg,obj)
    self.setBackgroundColorHelper(bg,obj)
#@+node:ekr.20110605121601.18188: *7* setBackgroundColorHelper (qtBody)
def setBackgroundColorHelper (self,colorName,obj):
    
    # obj is a QTextEdit or QTextBrowser.
    
    trace = False and not g.unitTesting
    
    if not colorName: return

    styleSheet = 'QTextEdit#richTextEdit { background-color: %s; }' % (
        colorName)
        
    if trace: g.trace(colorName,str(obj.objectName()),obj.__class__)
    
    if QtGui.QColor(colorName).isValid():
        obj.setStyleSheet(styleSheet)
    elif colorName not in self.badFocusColors:
        self.badFocusColors.append(colorName)
        g.es_print('invalid body background color: %s' % (colorName),color='blue')
#@+node:ekr.20110605121601.18189: *7* setForegroundColorHelper (qtBody)
def setForegroundColorHelper (self,colorName,obj):
    # obj is a QTextEdit or QTextBrowser.

    trace = False and not g.unitTesting
    if not colorName: return

    styleSheet = 'QTextEdit#richTextEdit { color: %s; }' % (
        colorName)
        
    if trace: g.trace(colorName,str(obj.objectName()),obj.__class__)
    
    if QtGui.QColor(colorName).isValid():
        obj.setStyleSheet(styleSheet)
    elif colorName not in self.badFocusColors:
        self.badFocusColors.append(colorName)
        g.es_print('invalid body foreground color: %s' % (colorName),color='blue')
#@+node:ekr.20061031170011.9: *6* extendLabel
def extendLabel(self,s,select=False,protect=False):
    
    trace = False and not g.unitTesting

    k = self ; c = k.c ; w = self.w
    if not (w and s): return
    
    if trace: g.trace(s)

    c.widgetWantsFocusNow(w)

    w.insert('end',s)

    if select:
        i,j = k.getEditableTextRange()
        w.setSelectionRange(i,j,insert=j)

    if protect:
        k.protectLabel()
#@+node:ekr.20031218072017.4038: *6* get/setYScrollPosition (leoBody)
def getYScrollPosition (self):

    return self.bodyCtrl.getYScrollPosition()

def setYScrollPosition (self,scrollPosition):
    
    if len(scrollPosition) == 2:
        first,last = scrollPosition
    else:
        first = scrollPosition
        
    self.bodyCtrl.setYScrollPosition(first)
#@+node:ekr.20050920084036.138: *6* insertNewLine
def insertNewLine (self,event):

    '''Insert a newline at the cursor.'''

    c = self.c ; k = c.k ; w = self.editWidget(event)
    if not w: return

    assert g.app.gui.isTextWidget(w)
    name = c.widget_name(w)
    if name.startswith('head'): return

    oldSel = w.getSelectionRange()
    # g.trace('oldSel',oldSel)

    self.beginCommand(undoType='newline')

    # New in Leo 4.5: use the same logic as in selfInsertCommand.
    self.insertNewlineHelper(w=w,oldSel=oldSel,undoType=None)
    k.setInputState('insert')
    k.showStateAndMode()

    self.endCommand()

insertNewline = insertNewLine
#@+node:ekr.20110605121601.18048: *6* onTextChanged (leoQtBaseTextWidget)
def onTextChanged (self):

    '''Update Leo after the body has been changed.

    self.selecting is guaranteed to be True during
    the entire selection process.'''

    # Important: usually w.changingText is True.
    # This method very seldom does anything.
    trace = False and not g.unitTesting
    verbose = True
    c = self.c ; p = c.p
    tree = c.frame.tree ; w = self

    if w.changingText: 
        if trace and verbose: g.trace('already changing')
        return
    if tree.tree_select_lockout:
        if trace and verbose: g.trace('selecting lockout')
        return
    if tree.selecting:
        if trace and verbose: g.trace('selecting')
        return
    if tree.redrawing:
        if trace and verbose: g.trace('redrawing')
        return
    if not p:
        if trace: g.trace('*** no p')
        return

    newInsert = w.getInsertPoint()
    newSel = w.getSelectionRange()
    newText = w.getAllText() # Converts to unicode.

    # Get the previous values from the vnode.
    oldText = p.b
    if oldText == newText:
        # This can happen as the result of undo.
        # g.trace('*** unexpected non-change',color="red")
        return

    # g.trace('**',len(newText),p.h,'\n',g.callers(8))

    oldIns  = p.v.insertSpot
    i,j = p.v.selectionStart,p.v.selectionLength
    oldSel  = (i,i+j)
    if trace: g.trace('oldSel',oldSel,'newSel',newSel)
    oldYview = None
    undoType = 'Typing'
    c.undoer.setUndoTypingParams(p,undoType,
        oldText=oldText,newText=newText,
        oldSel=oldSel,newSel=newSel,oldYview=oldYview)

    # Update the vnode.
    p.v.setBodyString(newText)
    if True:
        p.v.insertSpot = newInsert
        i,j = newSel
        i,j = self.toGuiIndex(i),self.toGuiIndex(j)
        if i > j: i,j = j,i
        p.v.selectionStart,p.v.selectionLength = (i,j-i)

    # No need to redraw the screen.
    if not self.useScintilla:
        c.recolor()

    if g.app.qt_use_tabs:
        if trace: g.trace(c.frame.top)

    if not c.changed and c.frame.initComplete:
        c.setChanged(True)

    c.frame.body.updateEditors()
    c.frame.tree.updateIcon(p)

    if 1: # This works, and is probably better.
        # Set a hook for the old jEdit colorer.
        colorer = c.frame.body.colorizer.highlighter.colorer
        colorer.initFlag = True
    else:
        # Allow incremental recoloring.
        c.incrementalRecolorFlag = True
        c.outerUpdate()
#@+node:ekr.20110605121601.18521: *6* qtGui.runAtIdle
def runAtIdle (self,aFunc):
    
    '''This can not be called in some contexts.'''
    
    timer = QtCore.QTimer()
    timer.setSingleShot(True)
    
    # print('runAtIdle',aFunc)

    def atIdleCallback(aFunc=aFunc):
        print('atIdleCallBack',aFunc)
        aFunc()

    timer.connect(timer,QtCore.SIGNAL("timeout()"),atIdleCallback)

    # To make your application perform idle processing, use a QTimer with 0 timeout.
    timer.start(0)
#@+node:ekr.20080512115455.1: *6* showStateColors
def showStateColors (self,inOutline,w):

    trace = True and not g.unitTesting
    k = self ; c = k.c ; state = k.unboundKeyAction

    # body = c.frame.body ; bodyCtrl = body.bodyCtrl
    w_name = g.app.gui.widget_name(w)

    if state not in ('insert','command','overwrite'):
        g.trace('bad input state',state)

    # if trace: g.trace('%9s' % (state),w_name)
    
    if w_name.startswith('body'):
        w = c.frame.body
    elif w_name.startswith('head'):
        pass
    else:
        # Don't recolor the minibuffer, log panes, etc.
        if trace: g.trace('not body or head')
        return

    if state == 'insert':
        bg = k.insert_mode_bg_color
        fg = k.insert_mode_fg_color
    elif state == 'command':
        bg = k.command_mode_bg_color
        fg = k.command_mode_fg_color
    elif state == 'overwrite':
        bg = k.overwrite_mode_bg_color
        fg = k.overwrite_mode_fg_color
    else:
        bg = fg = 'red'

    if hasattr(w,'setEditorColors'):
        # Note: fg color has no effect on Qt at present.
        w.setEditorColors(bg=bg,fg=fg)
    else:
        try:
            w.configure(bg=bg,fg=fg)
        except Exception:
            pass # g.es_exception()
#@+node:ekr.20110605121601.18261: *6* update (qtStatusLineClass)
def update (self):

    if g.app.killed: return

    c = self.c ; body = c.frame.body

    # te is a QTextEdit.
    # 2010/02/19: Fix bug 525090
    # An added editor window doesn't display line/col
    if not hasattr(body.bodyCtrl,'widget'): return
    te = body.bodyCtrl.widget # was body.widget.widget
    cr = te.textCursor()
    bl = cr.block()

    col = cr.columnNumber()
    row = bl.blockNumber() + 1
    line = bl.text()

    if col > 0:
        s2 = line[0:col]        
        col = g.computeWidth (s2,c.tab_width)
    fcol = col + c.currentPosition().textOffset()

    # g.trace('fcol',fcol,'te',id(te),g.callers(2))
    # g.trace('c.frame.body.bodyCtrl',body.bodyCtrl)
    # g.trace(row,col,fcol)

    self.put1(
        "line: %d, col: %d, fcol: %d" % (row,col,fcol))
    self.lastRow = row
    self.lastCol = col
    self.lastFcol = fcol
#@+node:ekr.20111002125540.7024: *5* Changed
#@+node:ekr.20110605121601.18539: *6*  ctor (leoQtEventFilter)
def __init__(self,c,w,tag=''):

    # g.trace('leoQtEventFilter',tag,w)

    # Init the base class.
    QtCore.QObject.__init__(self)

    self.c = c
    self.w = w      # A leoQtX object, *not* a Qt object.
    self.tag = tag

    # Debugging.
    self.keyIsActive = False
    self.trace_masterKeyHandler = c.config.getBool('trace_masterKeyHandler')

    # Pretend there is a binding for these characters.
    close_flashers = c.config.getString('close_flash_brackets') or ''
    open_flashers  = c.config.getString('open_flash_brackets') or ''
    self.flashers = open_flashers + close_flashers
    
    # Support for ctagscompleter.py plugin.
    self.ctagscompleter_active = False
    self.ctagscompleter_onKey = None
#@+node:ekr.20110605121601.18026: *6* << define mouseReleaseEvent >> (leoQtBaseTextWidget)
def mouseReleaseEvent (*args,**keys):
    
    '''Override QLineEdit.mouseReleaseEvent.
    
    Simulate alt-x if we are not in an input state.'''
    
    trace = False and not g.unitTesting
    
    # Call the base class method.
    if len(args) == 1:
        event = args[0]
        QtGui.QTextBrowser.mouseReleaseEvent(widget,event) # widget is unbound.
    elif len(args) == 2:
        event = args[1]
        QtGui.QTextBrowser.mouseReleaseEvent(*args)
    else:
        g.trace('can not happen')
        return

    # Open the url on a control-click.
    if QtCore.Qt.ControlModifier & event.modifiers():
        event = {'c':c}
        openURL(event) # A module-level function.
        
    if trace: g.trace()
        
    # 2011/05/28: Do *not* change the focus!
    # This would rip focus away from tab panes.
    
    # 2011/10/02: Calling k.keyboardQuit here causes some
    # unwanted scrolling in rare cases, but seemingly that
    # can't be helped: removing this call would be confusing.
    
    c.k.keyboardQuit(setFocus=False)
    
    # Does not work: the layout-request event happens later.
    # w = self.widget
    # g.trace('blocking',w)
    # w.blockSignals(True)
    # try:
        # c.k.keyboardQuit(setFocus=False)
        # c.frame.top.update()
    # finally:
        # w.blockSignals(False)
        # g.trace('unblocking',w)
#@+node:ekr.20111002071727.15509: *6* Event handlers...
#@+node:ekr.20110930174206.15473: *7* onFocusOut (qtBody)
def onFocusOut (self,obj):

    '''Handle a focus-out event in the body pane.'''
    
    trace = False and not g.unitTesting

    if trace: g.trace(str(obj.objectName()))
    
    # Apparently benign.
    if obj.objectName() == 'richTextEdit':
        self.onFocusColorHelper('focus-out',obj)
        obj.setReadOnly(True)
    
#@+node:ekr.20110930174206.15472: *7* onFocusIn (qtBody)
def onFocusIn (self,obj):

    '''Handle a focus-in event in the body pane.'''

    trace = False and not g.unitTesting

    c = self.c
    
    if trace: g.trace(str(obj.objectName()))

    # 2010/08/01: Update the history only on focus in events.
    # 2011/04/02: Update history only in leoframe.tree.select.
    # c.nodeHistory.update(c.p)
    
    if obj.objectName() == 'richTextEdit':
        wrapper = hasattr(obj,'leo_wrapper') and obj.leo_wrapper
        if wrapper and wrapper != self.bodyCtrl:
            self.selectEditor(wrapper)
        self.onFocusColorHelper('focus-in',obj)
        obj.setReadOnly(False)
        obj.setFocus() # Weird, but apparently necessary.
#@+node:ekr.20110605121601.18224: *7* onFocusColorHelper (qtBody)
badFocusColors = []

def onFocusColorHelper(self,kind,obj):

    trace = False and not g.unitTesting
    
    c = self.c ; w = c.frame.body.bodyCtrl
    
    if trace: g.trace(kind)
    
    if kind == 'focus-in':
        # if trace: g.trace('%9s' % (kind),'calling c.k.showStateColors()')
        c.k.showStateColors(inOutline=False,w=self.widget)
    else:
        # 2011/03/14: Also set the foreground color.
        colorName = self.unselectedForegroundColor
        # if trace: g.trace('%9s' % (kind),colorName)
        self.setForegroundColorHelper(colorName,obj)
        
        colorName = self.unselectedBackgroundColor
        # if trace: g.trace('%9s' % (kind),colorName)
        self.setBackgroundColorHelper(colorName,obj)

    w.widget.ensureCursorVisible()
        # 2011/10/02: Fix cursor-movement bug.
#@+node:ekr.20110605121601.18540: *6* eventFilter
def eventFilter(self, obj, event):

    trace = (False or self.trace_masterKeyHandler) and not g.unitTesting
    verbose = True
    traceEvent = True
    traceKey = (True or self.trace_masterKeyHandler)
    traceFocus = True
    c = self.c ; k = c.k
    eventType = event.type()
    ev = QtCore.QEvent
    gui = g.app.gui
    aList = []

    # if trace and verbose: g.trace('*****',eventType)

    kinds = [ev.ShortcutOverride,ev.KeyPress,ev.KeyRelease]

    if trace and traceFocus: self.traceFocus(eventType,obj)
    
    # Hack: QLineEdit generates ev.KeyRelease only on Windows,Ubuntu
    lineEditKeyKinds = [ev.KeyPress,ev.KeyRelease]
        
    if eventType in lineEditKeyKinds:
        p = c.currentPosition()
        isEditWidget = obj == c.frame.tree.edit_widget(p)
        self.keyIsActive = g.choose(
            isEditWidget,
            eventType == ev.KeyRelease,
            eventType == ev.KeyPress)
        # g.trace(isEditWidget,eventType,obj)
    else:
        self.keyIsActive = False

    if eventType == ev.WindowActivate:
        gui.onActivateEvent(event,c,obj,self.tag)
        override = False ; tkKey = None
    elif eventType == ev.WindowDeactivate:
        gui.onDeactivateEvent(event,c,obj,self.tag)
        override = False ; tkKey = None
    # elif eventType == ev.LayoutRequest:
        # g.trace(event,event.spontaneous())
        # event.accept()
        # override = True
        # tkKey = None
    elif eventType in kinds:
        tkKey,ch,ignore = self.toTkKey(event)
        aList = c.k.masterGuiBindingsDict.get('<%s>' %tkKey,[])
        if ignore:
            override = False
        # This is extremely bad.  At present, it is needed to handle tab properly.
        elif self.isSpecialOverride(tkKey,ch):
            override = True
        elif k.inState():
            override = not ignore # allow all keystrokes.
        else:
            override = len(aList) > 0
        # if trace and verbose: g.trace(
            # tkKey,len(aList),'ignore',ignore,'override',override)
    else:
        override = False ; tkKey = '<no key>'
        if self.tag == 'body':
            if eventType == ev.FocusIn:
                c.frame.body.onFocusIn(obj)
            elif eventType == ev.FocusOut:
                c.frame.body.onFocusOut(obj)

    if self.keyIsActive:
        stroke = self.toStroke(tkKey,ch)

        if override:
            if trace and traceKey and not ignore:
                g.trace('bound',repr(stroke)) # repr(aList))
            w = self.w # Pass the wrapper class, not the wrapped widget.
            event = self.create_key_event(event,c,w,ch,tkKey,stroke)
            ret = k.masterKeyHandler(event)
            c.outerUpdate()
        else:
            if trace and traceKey and verbose:
                g.trace(self.tag,'unbound',tkKey,stroke)
        
        if trace and traceKey:
            # Trace key events.
            self.traceEvent(obj,event,tkKey,override)

    elif trace and traceEvent:
        # Trace non-key events.
        self.traceEvent(obj,event,tkKey,override)

    return override
#@+node:ekr.20111002125540.7021: *6* get/setYScrollPosition (LeoQTextBrowser) (New)
def getYScrollPosition(self):

    w = self
    sb = w.verticalScrollBar()
    i = sb.sliderPosition()
    # g.trace('(LeoQTextBrowser)',i)
    return i

def setYScrollPosition(self,pos):

    w = self
    sb = w.verticalScrollBar()
    i = pos or 0 # pos may be None.
    # g.trace('(LeoQTextBrowser)',i)
    sb.setSliderPosition(i)
#@+node:ekr.20110605121601.18089: *6* insert (avoid call to setAllText) (leoQTextWidget)
def insert(self,i,s):

    c,w = self.c,self.widget
    colorer = c.frame.body.colorizer.highlighter.colorer
    n = colorer.recolorCount

    # Set a hook for the colorer.
    colorer.initFlag = True

    i = self.toGuiIndex(i)
    ##### It's not a good idea to force the scrollbar like this.
    ##### sb = w.verticalScrollBar()
    ##### pos = sb.sliderPosition()
    cursor = w.textCursor()
    try:
        self.changingText = True # Disable onTextChanged.
        cursor.setPosition(i)
        cursor.insertText(s) # This cause an incremental call to recolor.
        w.setTextCursor(cursor) # Bug fix: 2010/01/27
    finally:
        self.changingText = False

    ##### sb.setSliderPosition(pos)
    ##### w.ensureCursorVisible() # This has no effect.
#@+node:ekr.20061031131434.130: *6* keyboardQuit
def keyboardQuit (self,event=None,setFocus=True,mouseClick=False):

    '''This method clears the state and the minibuffer label.

    k.endCommand handles all other end-of-command chores.'''

    trace = False and not g.unitTesting
    k = self ; c = k.c
    
    if trace: g.trace(g.callers())

    if g.app.quitting:
        return
        
    # 2011/05/30: We may be called from Qt event handlers.
    # Make sure to end editing!
    c.endEditing() 
    
    # Completely clear the mode.
    if setFocus:
        c.frame.log.deleteTab('Mode')
        c.frame.log.hideTab('Completion')

    if k.inputModeName:
        k.endMode()

    # Complete clear the state.
    k.state.kind = None
    k.state.n = None

    k.clearState()
    k.resetLabel()

    if setFocus:
        c.bodyWantsFocus()

    # At present, only the auto-completer suppresses this.
    k.setDefaultInputState()
    k.showStateAndMode(setFocus=setFocus)
#@+node:ekr.20110605121601.18224: *6* onFocusColorHelper (qtBody)
badFocusColors = []

def onFocusColorHelper(self,kind,obj):

    trace = False and not g.unitTesting
    
    c = self.c ; w = c.frame.body.bodyCtrl
    
    if trace: g.trace(kind)
    
    if kind == 'focus-in':
        # if trace: g.trace('%9s' % (kind),'calling c.k.showStateColors()')
        c.k.showStateColors(inOutline=False,w=self.widget)
    else:
        # 2011/03/14: Also set the foreground color.
        colorName = self.unselectedForegroundColor
        # if trace: g.trace('%9s' % (kind),colorName)
        self.setForegroundColorHelper(colorName,obj)
        
        colorName = self.unselectedBackgroundColor
        # if trace: g.trace('%9s' % (kind),colorName)
        self.setBackgroundColorHelper(colorName,obj)

    w.widget.ensureCursorVisible()
        # 2011/10/02: Fix cursor-movement bug.
#@+node:ekr.20061031170011.8: *6* setLabel
def setLabel (self,s,protect=False):

    trace = (False or self.trace_minibuffer) and not g.app.unitTesting
    k = self ; c = k.c ; w = self.w
    if not w: return

    if trace: g.trace(repr(s),w)

    w.setAllText(s)
    n = len(s)
    w.setSelectionRange(n,n,insert=n)
    
    w2 = c.frame.body.bodyCtrl.widget
    if w2: w2.ensureCursorVisible()
        # 2011/10/02: Fix cursor-movement bug.

    if protect:
        k.mb_prefix = s
#@+node:ekr.20061031131434.192: *6* showStateAndMode
def showStateAndMode(self,w=None,prompt=None,setFocus=True):

    trace = False and not g.unitTesting
    k = self ; c = k.c
    state = k.unboundKeyAction
    mode = k.getStateKind()
    inOutline = False
    if not g.app.gui: return
    if not w:
        w = g.app.gui.get_focus(c)
        if not w: return
        
    isText = g.app.gui.isTextWidget(w)

    # This fixes a problem with the tk gui plugin.
    if mode and mode.lower().startswith('isearch'):
        return

    wname = g.app.gui.widget_name(w).lower()
    
    # 2011/02/12: get the wrapper for the headline widget.
    if wname.startswith('head'):
        if hasattr(c.frame.tree,'getWrapper'):
            if hasattr(w,'widget'): w2 = w.widget
            else: w2 = w
            w = c.frame.tree.getWrapper(w2,item=None)
            isText = bool(w) # A benign hack.

    if trace: g.trace('state: %s, text?: %s, w: %s' % (
        state,isText,w))

    if mode:
        if mode in ('getArg','getFileName','full-command'):
            s = None
        elif prompt:
            s = prompt
        else:
            mode = mode.strip()
            if mode.endswith('-mode'):
                mode = mode[:-5]
            s = '%s Mode' % mode.capitalize()
    else:
        s = '%s State' % state.capitalize()
        if c.editCommands.extendMode:
            s = s + ' (Extend Mode)'
            
    if s:
        k.setLabelBlue(label=s,protect=True)
    if w and isText:
        k.showStateColors(inOutline,w)
        k.showStateCursor(state,w)
        w.seeInsertPoint()
        # 2011/10/02: Fix cursor-movement bug.

    # Doesn't work.
    # self.w.widget.blockSignals(True)
    # try:
        # if s:
            # k.setLabelBlue(label=s,protect=True)
        # if w and isText:
            # k.showStateColors(inOutline,w)
            # k.showStateCursor(state,w)
            # w.seeInsertPoint()
            # # 2011/10/02: Fix cursor-movement bug.
    # finally:
        # self.w.widget.blockSignals(False)
#@+node:ekr.20051026171121.1: *6* updateAutoIndent (leoEditCommands)
def updateAutoIndent (self,p,w):

    c = self.c ; d = c.scanAllDirectives(p)
    tab_width = d.get("tabwidth",c.tab_width)
    # Get the previous line.
    s = w.getAllText()
    ins = w.getInsertPoint()
    i = g.skip_to_start_of_line(s,ins)
    i,j = g.getLine(s,i-1)
    s = s[i:j-1]
    # g.trace(i,j,repr(s))

    # Add the leading whitespace to the present line.
    junk, width = g.skip_leading_ws_with_indent(s,0,tab_width)
    # g.trace('width',width,'tab_width',tab_width)

    if s and s [-1] == ':':
        # For Python: increase auto-indent after colons.
        if g.findLanguageDirectives(c,p) == 'python':
            width += abs(tab_width)
    if self.smartAutoIndent:
        # Determine if prev line has unclosed parens/brackets/braces
        bracketWidths = [width] ; tabex = 0
        for i in range(0,len(s)):
            if s [i] == '\t':
                tabex += tab_width-1
            if s [i] in '([{':
                bracketWidths.append(i+tabex+1)
            elif s [i] in '}])' and len(bracketWidths) > 1:
                bracketWidths.pop()
        width = bracketWidths.pop()
    ws = g.computeLeadingWhitespace(width,tab_width)
    if ws:
        i = w.getInsertPoint()
        w.insert(i,ws)
        w.setInsertPoint(i+len(ws))
        w.seeInsertPoint()
            # 2011/10/02: Fix cursor-movement bug.
#@+node:ekr.20110918184425.6915: *3* Features
#@+node:ekr.20110929165422.15464: *4* Supported auto-hide in viewrendered plugin
#@+node:ekr.20110918180029.15527: *4* set g.app.execute_script during script execution
@nocolor-node

This allows the following pattern to appear in Leo source files::

    class myClass:
        @others
        
    if g.app.testing:
        myClass(c).test()
        
This is better than enabling the test with "if 1:" because
c is not defined while importing the module, so the import
will fail if I forget to change "if 1:" to "if 0" when saving
the .leo file.
#@+node:ekr.20110916215321.6710: *4* Added select-to-matching-bracket command
#@+node:ekr.20110916215321.6708: *5* selectToMatchingBracket
def selectToMatchingBracket (self,event):
    
    c = self.c ; k = c.k ; w = self.editWidget(event)
    if not w: return
    
    i = w.getInsertPoint()
    s = w.getAllText()
    
    allBrackets = self.openBracketsList + self.closeBracketsList
    
    if i < len(s) and s[i] in allBrackets:
        ch = s[i]
    elif i > 0 and s[i-1] in allBrackets:
        i -= 1
        ch = s[i]
    else:
        g.es('no bracket selected')
        return

    d = {}
    if ch in self.openBracketsList:
        for z in range(len(self.openBracketsList)):
            d [self.openBracketsList[z]] = self.closeBracketsList[z]
        reverse = False # Search forward
    else:
        for z in range(len(self.openBracketsList)):
            d [self.closeBracketsList[z]] = self.openBracketsList[z]
        reverse = True # Search backward

    delim2 = d.get(ch)
    
    # This should be generalized...
    language = g.findLanguageDirectives(c,c.p)
    if language in ('c','cpp','csharp'):
        j = g.skip_matching_c_delims(s,i,ch,delim2,reverse=reverse)
    else:
        j = g.skip_matching_python_delims(s,i,ch,delim2,reverse=reverse)
    # g.trace(i,j,ch,delim2,reverse,language)
    if j not in (-1,i):
        if reverse:
            i += 1; j += 1
        w.setSelectionRange(i,j,ins=j)
        w.see(j)
#@+node:ekr.20110916215321.6712: *5* g.skip_matching_c_delims
def skip_matching_c_delims(s,i,delim1,delim2,reverse=False):

    '''Skip from the opening delim to the matching delim2.

    Return the index of the matching ')', or -1'''

    level = 0
    assert(g.match(s,i,delim1))
    if reverse:
        # Reverse scanning is tricky.
        # This doesn't handle single-line comments properly.
        while i >= 0:
            progress = i
            ch = s[i]
            if ch == delim1:
                level += 1 ; i -= 1
            elif ch == delim2:
                level -= 1
                if level <= 0:  return i-1
                i -= 1
            elif ch in ('\'','"'):
                i -= 1
                while i >= 0:
                    if s[i] == ch and not s[i-1] == '\\':
                        i -= 1 ; break
                    else:
                        i -= 1
            elif g.match(s,i,'*/'):
                i += 2
                while i >= 0:
                    if g.match(s,i,'/*'):
                        i -= 2
                        break
                    else:
                        i -= 1
            else: i -= 1
            if i == progress:
                g.trace('oops: reverse')
                return -1
    else:
        while i < len(s):
            progress = i
            ch = s[i]
            # g.trace(i,repr(ch))
            if ch == delim1:
                level += 1 ; i += 1
            elif ch == delim2:
                level -= 1 ; i += 1
                if level <= 0:  return i
            elif ch in ('\'','"'):
                i += 1
                while i < len(s):
                    if s[i] == ch and not s[i-1] == '\\':
                        i += 1 ; break
                    else:
                        i += 1
            elif g.match(s,i,'//'):
                i = g.skip_to_end_of_line(s,i+2)
            elif g.match(s,i,'/*'):
                i += 2
                while i < len(s):
                    if g.match(s,i,'*/'):
                        i += 2
                        break
                    else:
                        i += 1
            else: i += 1
            if i == progress:
                g.trace('oops')
                return -1
    g.trace('not found')
    return -1
#@+node:ekr.20090724081340.5987: *4* Improved recursive import script
@nocolor-node

- Generates only @auto, does not do an actual import.
- Creates @path nodes so actual @auto nodes are short.
#@+node:ekr.20110917174948.6875: *4* Added beautify-c command
#@+node:ekr.20110917174948.6903: *5* class CPrettyPrinter
class CPrettyPrinter:
    
    @others
    
if g.app.inScript:
    
    cpp = CPrettyPrinter(c)
    p2 = g.findNodeAnywhere(c,'c tokenize test')
    
    if 1: # test of indent.
        # import os ; os.system('cls')
        cpp.indent(p2)
        print('done')
    
    if 0: # test of tokenize.
        aList = cpp.tokenize(p2.b)
        assert(p2.b == ''.join(aList))
        if 0:
            import os ; os.system('cls')
            print('*' * 40)
            # print(''.join(aList))
            for z in aList:
                print(repr(z))
        print('done')
#@+node:ekr.20110917174948.6904: *6* __init__
def __init__ (self,c):
    
    self.c = c
    self.p = None # Set in indent.
    
    self.brackets = 0
        # The brackets indentation level.
    self.parens = 0
        # The parenthesis nesting level.
    self.result = []
        # The list of tokens that form the final result.
    self.tab_width = 4
        # The number of spaces in each unit of leading indentation.
        
    # No longer used.
    
    # self.ignored_brackets = 0
        # # The number of '}' to ignore before reducing self.brackets.
    # self.ignore_ws = False
        # # True: ignore the next whitespace token if any.
#@+node:ekr.20110917174948.6911: *6* indent & helpers
def indent (self,p,toList=False):

    c = self.c
    if not p.b: return
    self.p = p.copy()
    
    aList = self.tokenize(p.b)
    assert ''.join(aList) == p.b
    
    aList = self.add_statement_braces(aList)

    self.bracketLevel = 0
    self.parens = 0
    self.result = []
    for s in aList:
        # g.trace(repr(s))
        self.put_token(s)
        
    if 0:
        for z in self.result:
            print(repr(z))

    if toList:
        return self.result
    else:
        return ''.join(self.result)
#@+node:ekr.20110918225821.6815: *7* add_statement_braces
def add_statement_braces (self,s):
    
    p = self.p
    trace = False
    
    def oops(message,i,j):
        g.es('** changed ',p.h,color='red')
        g.es('%s after\n%s' % (
            message,repr(''.join(s[i:j]))))
    
    i,n,result = 0,len(s),[]
    while i < n:
        token = s[i]
        progress = i
        if token in ('if','for','while',):
            j = self.skip_ws_and_comments(s,i+1)
            if self.match(s,j,'('):
                j = self.skip_parens(s,j)
                if self.match(s,j,')'):
                    old_j = j+1
                    j = self.skip_ws_and_comments(s,j+1)
                    if self.match(s,j,';'):
                        # Example: while (*++prefix);
                        result.extend(s[i:j])
                    elif self.match(s,j,'{'):
                        result.extend(s[i:j])
                    else:
                        oops("insert '{'",i,j)
                        # Back up, and don't go past a newline or comment.
                        j = self.skip_ws(s,old_j)
                        result.extend(s[i:j])
                        result.append(' ')
                        result.append('{')
                        result.append('\n')
                        i = j
                        j = self.skip_statement(s,i)
                        result.extend(s[i:j])
                        result.append('\n')
                        result.append('}')
                        oops("insert '}'",i,j)
                else:
                    oops("missing ')'",i,j)
                    result.extend(s[i:j])
            else:
                oops("missing '('",i,j)
                result.extend(s[i:j])
            i = j
        else:
            result.append(token)
            i += 1
        assert progress < i
            
    if trace: g.trace(''.join(result))
    return result
            
#@+node:ekr.20110919184022.6903: *8* skip_ws
def skip_ws (self,s,i):
    
    while i < len(s):
        token = s[i]
        if token.startswith(' ') or token.startswith('\t'):
            i += 1
        else:
            break
        
    return i
#@+node:ekr.20110918225821.6820: *8* skip_ws_and_comments
def skip_ws_and_comments (self,s,i):
    
    while i < len(s):
        token = s[i]
        if token.isspace():
            i += 1
        elif token.startswith('//') or token.startswith('/*'):
            i += 1
        else:
            break
        
    return i
#@+node:ekr.20110918225821.6817: *8* skip_parens
def skip_parens(self,s,i):

    '''Skips from the opening ( to the matching ).

    If no matching is found i is set to len(s)'''

    assert(self.match(s,i,'('))
    
    level = 0
    while i < len(s):
        ch = s[i]
        if ch == '(':
            level += 1 ; i += 1
        elif ch == ')':
            level -= 1
            if level <= 0:  return i
            i += 1
        else: i += 1
    return i
#@+node:ekr.20110918225821.6818: *8* skip_statement
def skip_statement (self,s,i):
    
    '''Skip to the next ';' or '}' token.'''
    
    while i < len(s):
        if s[i] in ';}':
            i += 1
            break
        else:
            i += 1
    return i
#@+node:ekr.20110917204542.6967: *7* put_token & helpers
def put_token (self,s):
    
    '''Append token s to self.result as is,
    *except* for adjusting leading whitespace and comments.
    
    '{' tokens bump self.brackets or self.ignored_brackets.
    self.brackets determines leading whitespace.
    '''

    if s == '{':
        self.brackets += 1
    elif s == '}':
        self.brackets -= 1
        self.remove_indent()
    elif s == '(':
        self.parens += 1
    elif s == ')':
        self.parens -= 1
    elif s.startswith('\n'):
        if self.parens <= 0:
            s = '\n%s' % (' ' * self.brackets * self.tab_width)
        else: pass # Use the existing indentation.
    elif s.isspace():
        if self.parens <= 0 and self.result and self.result[-1].startswith('\n'):
            # Kill the whitespace.
            s = ''
        else: pass # Keep the whitespace.
    elif s.startswith('/*'):
        s = self.reformat_block_comment(s)
    else:
        pass # put s as it is.
    
    if s:
        self.result.append(s)
        
@
    # It doesn't hurt to increase indentation after *all* '{'.
    if s == '{':
        # Increase brackets unless '=' precedes it.
        if self.prev_token('='):
            self.ignored_brackets += 1
        else:
            self.brackets += 1
    elif s == '}':
        if self.ignored_brackets:
            self.ignored_brackets -= 1
        else:
            self.brackets -= 1
            self.remove_indent()
#@+node:ekr.20110917204542.6968: *8* prev_token
def prev_token (self,s):
    
    '''Return the previous token, ignoring whitespace and comments.'''
    
    i = len(self.result)-1
    while i >= 0:
        s2 = self.result[i]
        if s == s2:
            return True
        elif s.isspace() or s.startswith('//') or s.startswith ('/*'):
            i -= 1
        else:
            return False
#@+node:ekr.20110918184425.6916: *8* reformat_block_comment
def reformat_block_comment (self,s):
    
    return s
#@+node:ekr.20110917204542.6969: *8* remove_indent
def remove_indent (self):
    
    '''Remove one tab-width of blanks from the previous token.'''
    
    w = abs(self.tab_width)
    
    if self.result:
        s = self.result[-1]
        if s.isspace():
            self.result.pop()
            s = s.replace('\t',' ' * w)
            if s.startswith('\n'):
                s2 = s[1:]
                self.result.append('\n'+s2[:-w])
            else:
                self.result.append(s[:-w])
#@+node:ekr.20110918225821.6819: *6* match
def match(self,s,i,pat):
    
    return i < len(s) and s[i] == pat
#@+node:ekr.20110917174948.6930: *6* tokenize & helper
def tokenize (self,s):
    
    '''Tokenize comments, strings, identifiers, whitespace and operators.'''

    i,result = 0,[]
    while i < len(s):
        # Loop invariant: at end: j > i and s[i:j] is the new token.
        j = i
        ch = s[i]
        if ch in '@\n': # Make *sure* these are separate tokens.
            j += 1
        elif ch == '#': # Preprocessor directive.
            j = g.skip_to_end_of_line(s,i)
        elif ch in ' \t':
            j = g.skip_ws(s,i)
        elif ch.isalpha() or ch == '_':
            j = g.skip_c_id(s,i)
        elif g.match(s,i,'//'):
            j = g.skip_line(s,i)
        elif g.match(s,i,'/*'):
            j = self.skip_block_comment(s,i)
        elif ch in "'\"":
            j = g.skip_string(s,i)
        else:
            j += 1
            
        assert j > i
        result.append(''.join(s[i:j]))
        i = j # Advance.
        
    return result
    
@ The following could be added to the 'else' clause::
    # Accumulate everything else.
    while (
        j < n and
        not s[j].isspace() and
        not s[j].isalpha() and
        not s[j] in '"\'_@' and
            # start of strings, identifiers, and single-character tokens.
        not g.match(s,j,'//') and
        not g.match(s,j,'/*') and
        not g.match(s,j,'-->')
    ):
        j += 1
#@+node:ekr.20110917193725.6974: *7* skip_block_comment
def skip_block_comment (self,s,i):

    assert(g.match(s,i,"/*"))

    j = s.find("*/",i)
    if j == -1:
        return n
    else:
        return j + 2
#@+node:ekr.20110917174948.6877: *5* beautifyCCode
def beautifyCCode (self,event=None):

    '''Reformat all C code in the selected tree.'''

    c = self
    pp = c.CPrettyPrinter(c)
    u = c.undoer ; undoType = 'beautify-c'
    
    u.beforeChangeGroup(c.p,undoType)
    dirtyVnodeList = []
    changed = False

    for p in c.p.self_and_subtree():
        if g.scanForAtLanguage(c,p) == "c":
            bunch = u.beforeChangeNodeContents(p,oldBody=p.b)
            s = pp.indent(p)
            if p.b != s:
                # g.es('changed: %s' % (p.h))
                p.b = s
                p.v.setDirty()
                dirtyVnodeList.append(p.v)
                u.afterChangeNodeContents(p,undoType,bunch)
                changed = True

    if changed:
        u.afterChangeGroup(c.p,undoType,
            reportFlag=False,dirtyVnodeList=dirtyVnodeList)
            
    c.bodyWantsFocus()
#@+node:ekr.20110917193725.6973: *5* c tokenize test
@language c

static exit_values_ty indent_main_loop(void)
{
    codes_ty         hd_type         = code_eof;
    char           * t_ptr           = NULL;
    codes_ty         type_code       = start_token;
    exit_values_ty   file_exit_value = total_success;
    int              dec_ind         = 0; /* current indentation for declarations */

    BOOLEAN          scase           = false; /* true when we've just see a "case";
                                               * determines what to do with the
                                               * following colon */
    BOOLEAN          flushed_nl;              /* Used when buffering up comments to remember that
                                               * a newline was passed over */
    BOOLEAN          sp_sw           = false; /* true when in the expression part of if(...),
                                               * while(...), etc. */
    BOOLEAN          force_nl        = false;

    /* last_token_ends_sp: True if we have just encountered the end of an if (...),
     * etc. (i.e. the ')' of the if (...) was the last token).  The variable is
     * set to 2 in the middle of the main token reading loop and is decremented
     * at the beginning of the loop, so it will reach zero when the second token
     * after the ')' is read.
     */

    BOOLEAN          last_token_ends_sp = false;

    BOOLEAN          last_else = false; /* true if last keyword was an else */

    for (;;)
    {
        /* this is the main loop.  it will go until
         * we reach eof */

        BOOLEAN is_procname_definition;
        bb_code_ty can_break;

        if (type_code != newline)
        {
            can_break = parser_state_tos->can_break;
        }

        parser_state_tos->last_saw_nl = false;
        parser_state_tos->can_break = bb_none;

        type_code = lexi ();    /* lexi reads one token.  "token" points to
                                 * the actual characters. lexi returns a code
                                 * indicating the type of token */

        /* If the last time around we output an identifier or
         * a paren, then consider breaking the line here if it's
         * too long.
         *
         * A similar check is performed at the end of the loop, after
         * we've put the token on the line. */

        if ((settings.max_col > 0) &&
            (buf_break != NULL) &&
            ( ( (parser_state_tos->last_token == ident) &&
                (type_code != comma) &&
                (type_code != semicolon) &&
                (type_code != newline) &&
                (type_code != form_feed) &&
                (type_code != rparen) &&
                (type_code != struct_delim)) ||
              ( (parser_state_tos->last_token == rparen) &&
                (type_code != comma) &&
                (type_code != rparen) ) ) &&
            (output_line_length () > settings.max_col))
        {
            break_line = 1;
        }

        if (last_token_ends_sp > 0)
        {
            last_token_ends_sp--;
        }

        is_procname_definition =
                (((parser_state_tos->procname[0] != '\0') &&
                  parser_state_tos->in_parameter_declaration) ||
                 (parser_state_tos->classname[0] != '\0'));

        /* The following code moves everything following an if (), while (),
         * else, etc. up to the start of the following stmt to a buffer. This
         * allows proper handling of both kinds of brace placement.
         */

        flushed_nl = false;

        if (!search_brace(&type_code, &force_nl, &flushed_nl, &last_else, &is_procname_definition))
        {
            /* Hit EOF unexpectedly in comment. */
            return indent_punt;
        }
        
        if (type_code == code_eof)
        {
            /* we got eof */
            if (s_lab != e_lab || s_code != e_code || s_com != e_com)   /* must dump end of line */
            {
                dump_line(true, &paren_target);
            }

            if (parser_state_tos->tos > 1)      /* check for balanced braces */
            {
                ERROR (_("Unexpected end of file"), 0, 0);
                file_exit_value = indent_error;
            }

            if (settings.verbose)
            {
                printf (_("There were %d non-blank output lines and %d comments\n"),
                        (int) out_lines, (int) com_lines);
                if (com_lines > 0 && code_lines > 0)
                {
                    printf (_("(Lines with comments)/(Lines with code): %6.3f\n"),
                            (1.0 * com_lines) / code_lines);
                }
            }
            flush_output ();

            return file_exit_value;                                              /* RETURN */
        }

        if ((type_code != comment) &&
            (type_code != cplus_comment) &&
            (type_code != newline) &&
            (type_code != preesc) &&
            (type_code != form_feed))
        {
            if (force_nl &&
                (type_code != semicolon) &&
                ( (type_code != lbrace) ||
                  (!parser_state_tos->in_decl && !settings.btype_2) ||
                  (parser_state_tos->in_decl && !settings.braces_on_struct_decl_line) ||
                  (parser_state_tos->last_token == rbrace)))
            {
                if (settings.verbose && !flushed_nl)
                {
                    WARNING (_("Line broken 2"), 0, 0);
                }

                flushed_nl = false;
                dump_line(true, &paren_target);
                parser_state_tos->want_blank = false;
                force_nl = false;
            }

            parser_state_tos->in_stmt = true;   /* turn on flag which causes
                                                 * an extra level of
                                                 * indentation. this is
                                                 * turned off by a ; or } */
            if (s_com != e_com)
            {
                /* the code has an embedded comment in the
                 * line. Move it from the com buffer to the
                 * code buffer.
                 *
                 * Do not add a space before the comment if it is the first
                 * thing on the line.
                 */

                if (e_code != s_code)
                {
                    set_buf_break (bb_embedded_comment_start, paren_target);
                    *e_code++ = ' ';
                    embedded_comment_on_line = 2;
                }
                else
                {
                    embedded_comment_on_line = 1;
                }

                for (t_ptr = s_com; *t_ptr; ++t_ptr)
                {
                    check_code_size();
                    *e_code++ = *t_ptr;
                }

                set_buf_break (bb_embedded_comment_end, paren_target);
                *e_code++ = ' ';
                *e_code = '\0'; /* null terminate code sect */
                parser_state_tos->want_blank = false;
                e_com = s_com;
            }
        }
        else if ((type_code != comment) &&
                 (type_code != cplus_comment) &&
                 !(settings.break_function_decl_args &&
                   (parser_state_tos->last_token == comma)) &&
                 !( (parser_state_tos->last_token == comma) &&
                    !settings.leave_comma))
        {
            /* preserve force_nl thru a comment but
             * cancel forced newline after newline, form feed, etc.
             * however, don't cancel if last thing seen was comma-newline
             * and -bc flag is on. */

            force_nl = false;
        }

        /* Main switch on type of token scanned */

        check_code_size();
        
        /* now, decide what to do with the token */

        handle_the_token(type_code, &scase, &force_nl, &sp_sw, &flushed_nl,
                         &hd_type, &dec_ind, &last_token_ends_sp, &file_exit_value,
                         can_break, &last_else, is_procname_definition);
        
        *e_code = '\0';         /* make sure code section is null terminated */

        if ((type_code != comment) &&
            (type_code != cplus_comment) &&
            (type_code != newline) &&
            (type_code != preesc) &&
            (type_code != form_feed))
        {
            parser_state_tos->last_token = type_code;
        }

        /* Now that we've put the token on the line (in most cases),
         * consider breaking the line because it's too long.
         *
         * Don't consider the cases of `unary_op', newlines,
         * declaration types (int, etc.), if, while, for,
         * identifiers (handled at the beginning of the loop),
         * periods, or preprocessor commands. */

        if ((settings.max_col > 0) && (buf_break != NULL))
        {
            if ( ( (type_code == binary_op) ||
                   (type_code == postop) ||
                   (type_code == question) ||
                   ((type_code == colon) && (scase || (squest <= 0))) ||
                   (type_code == semicolon) ||
                   (type_code == sp_nparen) ||
                   (type_code == sp_else) ||
                   ((type_code == ident) && (*token == '\"')) ||
                   (type_code == struct_delim) ||
                   (type_code == comma)) &&
                 (output_line_length () > settings.max_col))
            {
                break_line = 1;
            }
        }
    }                           /* end of main infinite loop */
}
#@+node:ekr.20110916215321.7767: *4* Added c-to-python command
#@+node:ekr.20110919184022.6900: *5* To do
@nocolor-node

* Simplify declaration code by using lookahead.

- change skip_to_matching bracket to skip_past_matching_braket.

- (Maybe) Put type decls as comments at end of line.
    Only decls in function bodies need to be munged, but that's not easy.

- (Maybe) Use @ and @c to delimit block comments.
#@+node:ekr.20110919184022.6901: *5* What I did
@nocolor-node

What I did:

- Wrapped the code in a class.

- Replaced all globals with ivars.

- Replaced listToString with ''.join(aList)
    
- Eliminated stringToList.
    The code never passes None where a sequence is expected.
    
- Get tab_width from @tabwidth directives.

- Get user data from::
    
    @data c-to-python-class-list
    @data c-to-python-type-list
    @data c-to-python-ivars-dict
        keys end in a colon
        all other lines contain comma-delimited values for the current key.
        
- Add extra parens for 'if' that span several lines.
- Fixed extra indentation.
- Changed ! to not except before =.
- Dedented C blocks, such as::
    
    {
        statement;
        statement;
    }
    
- Improved formatting of block comments.
#@+node:ekr.20110917174948.6903: *5* class CPrettyPrinter
class CPrettyPrinter:
    
    @others
    
if g.app.inScript:
    
    cpp = CPrettyPrinter(c)
    p2 = g.findNodeAnywhere(c,'c tokenize test')
    
    if 1: # test of indent.
        # import os ; os.system('cls')
        cpp.indent(p2)
        print('done')
    
    if 0: # test of tokenize.
        aList = cpp.tokenize(p2.b)
        assert(p2.b == ''.join(aList))
        if 0:
            import os ; os.system('cls')
            print('*' * 40)
            # print(''.join(aList))
            for z in aList:
                print(repr(z))
        print('done')
#@+node:ekr.20110917174948.6904: *6* __init__
def __init__ (self,c):
    
    self.c = c
    self.p = None # Set in indent.
    
    self.brackets = 0
        # The brackets indentation level.
    self.parens = 0
        # The parenthesis nesting level.
    self.result = []
        # The list of tokens that form the final result.
    self.tab_width = 4
        # The number of spaces in each unit of leading indentation.
        
    # No longer used.
    
    # self.ignored_brackets = 0
        # # The number of '}' to ignore before reducing self.brackets.
    # self.ignore_ws = False
        # # True: ignore the next whitespace token if any.
#@+node:ekr.20110917174948.6911: *6* indent & helpers
def indent (self,p,toList=False):

    c = self.c
    if not p.b: return
    self.p = p.copy()
    
    aList = self.tokenize(p.b)
    assert ''.join(aList) == p.b
    
    aList = self.add_statement_braces(aList)

    self.bracketLevel = 0
    self.parens = 0
    self.result = []
    for s in aList:
        # g.trace(repr(s))
        self.put_token(s)
        
    if 0:
        for z in self.result:
            print(repr(z))

    if toList:
        return self.result
    else:
        return ''.join(self.result)
#@+node:ekr.20110918225821.6815: *7* add_statement_braces
def add_statement_braces (self,s):
    
    p = self.p
    trace = False
    
    def oops(message,i,j):
        g.es('** changed ',p.h,color='red')
        g.es('%s after\n%s' % (
            message,repr(''.join(s[i:j]))))
    
    i,n,result = 0,len(s),[]
    while i < n:
        token = s[i]
        progress = i
        if token in ('if','for','while',):
            j = self.skip_ws_and_comments(s,i+1)
            if self.match(s,j,'('):
                j = self.skip_parens(s,j)
                if self.match(s,j,')'):
                    old_j = j+1
                    j = self.skip_ws_and_comments(s,j+1)
                    if self.match(s,j,';'):
                        # Example: while (*++prefix);
                        result.extend(s[i:j])
                    elif self.match(s,j,'{'):
                        result.extend(s[i:j])
                    else:
                        oops("insert '{'",i,j)
                        # Back up, and don't go past a newline or comment.
                        j = self.skip_ws(s,old_j)
                        result.extend(s[i:j])
                        result.append(' ')
                        result.append('{')
                        result.append('\n')
                        i = j
                        j = self.skip_statement(s,i)
                        result.extend(s[i:j])
                        result.append('\n')
                        result.append('}')
                        oops("insert '}'",i,j)
                else:
                    oops("missing ')'",i,j)
                    result.extend(s[i:j])
            else:
                oops("missing '('",i,j)
                result.extend(s[i:j])
            i = j
        else:
            result.append(token)
            i += 1
        assert progress < i
            
    if trace: g.trace(''.join(result))
    return result
            
#@+node:ekr.20110919184022.6903: *8* skip_ws
def skip_ws (self,s,i):
    
    while i < len(s):
        token = s[i]
        if token.startswith(' ') or token.startswith('\t'):
            i += 1
        else:
            break
        
    return i
#@+node:ekr.20110918225821.6820: *8* skip_ws_and_comments
def skip_ws_and_comments (self,s,i):
    
    while i < len(s):
        token = s[i]
        if token.isspace():
            i += 1
        elif token.startswith('//') or token.startswith('/*'):
            i += 1
        else:
            break
        
    return i
#@+node:ekr.20110918225821.6817: *8* skip_parens
def skip_parens(self,s,i):

    '''Skips from the opening ( to the matching ).

    If no matching is found i is set to len(s)'''

    assert(self.match(s,i,'('))
    
    level = 0
    while i < len(s):
        ch = s[i]
        if ch == '(':
            level += 1 ; i += 1
        elif ch == ')':
            level -= 1
            if level <= 0:  return i
            i += 1
        else: i += 1
    return i
#@+node:ekr.20110918225821.6818: *8* skip_statement
def skip_statement (self,s,i):
    
    '''Skip to the next ';' or '}' token.'''
    
    while i < len(s):
        if s[i] in ';}':
            i += 1
            break
        else:
            i += 1
    return i
#@+node:ekr.20110917204542.6967: *7* put_token & helpers
def put_token (self,s):
    
    '''Append token s to self.result as is,
    *except* for adjusting leading whitespace and comments.
    
    '{' tokens bump self.brackets or self.ignored_brackets.
    self.brackets determines leading whitespace.
    '''

    if s == '{':
        self.brackets += 1
    elif s == '}':
        self.brackets -= 1
        self.remove_indent()
    elif s == '(':
        self.parens += 1
    elif s == ')':
        self.parens -= 1
    elif s.startswith('\n'):
        if self.parens <= 0:
            s = '\n%s' % (' ' * self.brackets * self.tab_width)
        else: pass # Use the existing indentation.
    elif s.isspace():
        if self.parens <= 0 and self.result and self.result[-1].startswith('\n'):
            # Kill the whitespace.
            s = ''
        else: pass # Keep the whitespace.
    elif s.startswith('/*'):
        s = self.reformat_block_comment(s)
    else:
        pass # put s as it is.
    
    if s:
        self.result.append(s)
        
@
    # It doesn't hurt to increase indentation after *all* '{'.
    if s == '{':
        # Increase brackets unless '=' precedes it.
        if self.prev_token('='):
            self.ignored_brackets += 1
        else:
            self.brackets += 1
    elif s == '}':
        if self.ignored_brackets:
            self.ignored_brackets -= 1
        else:
            self.brackets -= 1
            self.remove_indent()
#@+node:ekr.20110917204542.6968: *8* prev_token
def prev_token (self,s):
    
    '''Return the previous token, ignoring whitespace and comments.'''
    
    i = len(self.result)-1
    while i >= 0:
        s2 = self.result[i]
        if s == s2:
            return True
        elif s.isspace() or s.startswith('//') or s.startswith ('/*'):
            i -= 1
        else:
            return False
#@+node:ekr.20110918184425.6916: *8* reformat_block_comment
def reformat_block_comment (self,s):
    
    return s
#@+node:ekr.20110917204542.6969: *8* remove_indent
def remove_indent (self):
    
    '''Remove one tab-width of blanks from the previous token.'''
    
    w = abs(self.tab_width)
    
    if self.result:
        s = self.result[-1]
        if s.isspace():
            self.result.pop()
            s = s.replace('\t',' ' * w)
            if s.startswith('\n'):
                s2 = s[1:]
                self.result.append('\n'+s2[:-w])
            else:
                self.result.append(s[:-w])
#@+node:ekr.20110918225821.6819: *6* match
def match(self,s,i,pat):
    
    return i < len(s) and s[i] == pat
#@+node:ekr.20110917174948.6930: *6* tokenize & helper
def tokenize (self,s):
    
    '''Tokenize comments, strings, identifiers, whitespace and operators.'''

    i,result = 0,[]
    while i < len(s):
        # Loop invariant: at end: j > i and s[i:j] is the new token.
        j = i
        ch = s[i]
        if ch in '@\n': # Make *sure* these are separate tokens.
            j += 1
        elif ch == '#': # Preprocessor directive.
            j = g.skip_to_end_of_line(s,i)
        elif ch in ' \t':
            j = g.skip_ws(s,i)
        elif ch.isalpha() or ch == '_':
            j = g.skip_c_id(s,i)
        elif g.match(s,i,'//'):
            j = g.skip_line(s,i)
        elif g.match(s,i,'/*'):
            j = self.skip_block_comment(s,i)
        elif ch in "'\"":
            j = g.skip_string(s,i)
        else:
            j += 1
            
        assert j > i
        result.append(''.join(s[i:j]))
        i = j # Advance.
        
    return result
    
@ The following could be added to the 'else' clause::
    # Accumulate everything else.
    while (
        j < n and
        not s[j].isspace() and
        not s[j].isalpha() and
        not s[j] in '"\'_@' and
            # start of strings, identifiers, and single-character tokens.
        not g.match(s,j,'//') and
        not g.match(s,j,'/*') and
        not g.match(s,j,'-->')
    ):
        j += 1
#@+node:ekr.20110917193725.6974: *7* skip_block_comment
def skip_block_comment (self,s,i):

    assert(g.match(s,i,"/*"))

    j = s.find("*/",i)
    if j == -1:
        return n
    else:
        return j + 2
#@+node:ekr.20110916215321.8054: *5* cToPy (leoEditCommands)
class C_to_python:
    << docstring: theory of operation >>
    @others

def cToPy (self,event):
    << docstring: c-to-python >>
    self.C_to_python(self.c).go()
    self.c.bodyWantsFocus()

if g.app.inScript:
    cpp = c.CPrettyPrinter(c)
    c2p = C_to_python(c)
    p2 = g.findNodeAnywhere(c,'c tokenize test')
    
    # import os ; os.system('cls')
    aList = cpp.tokenize(p2.b)
    c2p.convertCodeList(aList)
    s = ''.join(aList)
    if s != p.b:
        g.es('changed')
    # print(''.join(aList))
    print('done')
#@+node:ekr.20110916215321.7982: *6* << docstring: c-to-python >>
''' The c-to-python command converts C or C++ text to python text. The
conversion is not complete. Nevertheless, c2py eliminates much of the tedious
text manipulation that would otherwise be required.

The following is a list of the translations performed by convertCodeList:

Prepass
=======

These translations happen before removing all curly braces.

Suppose we are translating::

    aTypeSpec aClass::aMethod(t1 v1,...,tn vn)
    {
        body
    }

Prepass part 1
--------------

Translates the function prototype, i.e., translates::

    aTypeSpec aClass::aMethod(t1 v1,...,tn vn)
    
to::
    
    def aMethod(v1,...vn):

As a special case, c2py translates::

    aTypeSpec aClass::aClass(t1 v1,...,tn vn)
    
to::
    
    aClass.__init__(t1 v1,...,tn vn)

True, aClass.__init__ isn't proper Python, but retaining the class name is useful.

Prepass part 2
--------------

Let t denote any member of typeList or classList.  The code::

    a) Removes all casts of the form (t) or (t*) or (t**), etc.
    b) Converts t x, t *x, t **x, etc. to x.
    c) Converts x = new t(...) to x = t(...)
    d) For all i in ivarsDict[aClass] converts this -> i to self.i
    e) For all i in ivarsDict[aClass] converts i to self.i

Prepass part 3
--------------

[No longer used.] Converts < < x > > = to @c. A Leo-specific translation.

Main Pass
=========

This pass does the following simple translations everywhere except in comments
and strings::

    Changes all -> to .
    Changes all this.self to self (This corrects problems during the prepass.)
    Removes all curly braces
    Changes all #if to if
    Changes all else if to elif
    Changes all #else to else:
    Changes all else to else:
    Removes all #endif
    Changes all && to and
    Changes all || to or
    Changes all TRUE to True
    Changes all FALSE to False
    Changes all NULL to None
    Changes all this to self
    Changes all @code to @c.  [No longer used: aLeo-specific translation.]

Complex Pass
============

This pass attempts more complex translations::

    Converts if ( x ) to if x:
    Converts elif ( x ) to elif x:
    Converts while ( x ) to while x:
    Converts for ( x ; y ; z ) to for x SEMI y SEMI z:

Final Pass
==========

This pass completes the translation::

    Removes all semicolons.
    Removes @c if it starts the text.  [No longer used: a Leo-specific translation.]
    Removes all blank lines.
    Removes excess whitespace from all lines, leaving leading whitespace unchanged.
    Replaces C/C++ comments by Python comments.
    Removes trailing whitespace from all lines.

'''
#@+node:ekr.20110918184425.6914: *6* class C_to_python
#@+node:ekr.20110916215321.7983: *7* << docstring: theory of operation >>
@nocolor-node

'''
We use a single list for all changes to the text. This eliminates stress on the
gc. Using multiple passes greatly simplifies the code and does not it down
significantly. Anyway, speed is both good and unimportant.

A convention: within this class only, s denotes a *sequence*, not just a string.
We use this convention in methods that do not, in fact, change the sequence.

No replacements are done within strings or comments. The idiom is::

    def someScan(self,aList):
        i = 0
        while i < len(aList):
            if self.is_string_or_comment(aList,i):
                i = skip_string_or_comment(aList,i)
            elif < found what we are looking for ?>:
                <convert what we are looking for, setting i>
            else: i += 1

That's all.
'''
#@+node:ekr.20110916215321.8056: *7* Unused
if 0:
    @others
#@+node:ekr.20110917104720.6871: *8* Drivers & helpers
#@+node:ekr.20110916215321.7989: *9* convertLeo1to2 & helper
def convertLeo1to2 (self):

    for p in self.p.self_and_subtree():
        g.es("converting:",p.h)
        s=convertStringLeo1to2(p.b)
        p.b = s

    g.es("done")
#@+node:ekr.20110916215321.7990: *10* convertStringLeo1to2
def convertStringLeo1to2 (self,s):
    
    aList = [z for z in s]
    outputList = []
    i = 0
    while i < len(aList):
        j = skipCodePart(aList,i)
        if j > i:
            code = aList[i:j]
            convertCodeList1to2(code)
            i = j
            #print "-----code:", listToString(code)
            for item in code:
                outputList.append(item)
        j = skipDocPart(aList,i)
        if j > i:
            doc = aList[i:j]
            convertDocList(doc) # same as in c2py
            #print "-----doc:", listToString(doc)
            i = j
            for item in doc:
                outputList.append(item)

    result = listToString(outputList)
    global printFlag
    if printFlag: print("-----:\n", result)
    return result
#@+node:ekr.20110916215321.7994: *9* convertLeoTree
def convertLeoTree (self):

    for p2 in self.p.self_and_subtree():
        print("converting:",v.h)
        s = convertCStringToPython(p2.b,leoFlag=True)
        p2.b = s

    g.es('done')
#@+node:ekr.20110916215321.7995: *9* convertCFileToPython
def convertCFileToPython(fn):

    f=open(fn, 'r')
    if not f: return
    s = f.read()
    f.close()

    f=open(fn + ".py", 'w')
    if not f: return
    s = convertCStringToPython(s,leoFlag=False)
    f.write(s)
    f.close()
#@+node:ekr.20110916215321.7991: *9* convertCodeList1to2
@ We do _not_ replace @root by @file or insert @others as needed.
Inserting @others can be done easily enough by hand,
and may take more global knowledge than we can reasonably expect to have.
@c

def convertCodeList1to2 (self,aList):

    if 0: # There isn't much reason to do this.
        removeAtRoot(aList)

    self.safeReplace(aList,"@code","@c")
    self.replaceSectionDefs(aList)
    self.removeLeadingAtCode(aList)
#@+node:ekr.20110916215321.7996: *9* convertCStringToPython
def convertCStringToPython (self,s,leoFlag):

    # print "convertCStringToPython:start\n", s
    firstPart = True
    aList = [z for z in s]

    if not leoFlag:
        self.convertCodeList(aList,firstPart,dontDoLeoTranslations)
        return ''.join(aList)

    outputList = []
    i = 0
    while i < len(aList):
        j = skipCodePart(aList,i)
        if j > i:
            code = aList [i: j]
            convertCodeList(code,firstPart,doLeoTranslations)
            i = j
            #print "-----code:", ''.join(code)
            for item in code:
                outputList.append(item)
        firstPart = False # don't remove @c from here on.
        j = skipDocPart(aList,i)
        if j > i:
            doc = aList [i: j]
            convertDocList(doc)
            #print "-----doc:", ''.join(doc)
            i = j
            for item in doc:
                outputList.append(item)

    result = ''.join(outputList)
    global printFlag
    if printFlag: print("-----:\n",result)
    return result
#@+node:ekr.20110917104720.6876: *9* get_default_user_types
def get_default_user_types (self):
    
    '''Return default user types.'''
    
    self.class_list = [
        # "vnode", "tnode", "Commands",
        # "wxString", "wxTreeCtrl", "wxTextCtrl", "wxSplitterWindow",
    ]

    self.ivars_dict = {
        # "atFile": [
            # "mCommands", "mErrors", "mStructureErrors",
            # "mTargetFileName", "mOutputFileName", "mOutputStream",
            # "mStartSentinelComment", "mEndSentinelComment", "mRoot",
        # ],
        # "vnode": [
            # "mCommands", "mJoinList", "mIconVal", "mTreeID", "mT", "mStatusBits",
        # ],
        # "tnode": [
            # "mBodyString", "mBodyRTF", "mJoinHead", "mStatusBits", "mFileIndex",
            # "mSelectionStart", "mSelectionLength", "mCloneIndex",
        # ],
        # "LeoFrame": [
            # "mNextFrame", "mPrevFrame", "mCommands",
        # ],
        # "Commands": [
            # # public
            # "mCurrentVnode", "mLeoFrame", "mInhibitOnTreeChanged", "mMaxTnodeIndex",
            # "mTreeCtrl", "mBodyCtrl", "mFirstWindowAndNeverSaved",
            # #private
            # "mTabWidth", "mChanged", "mOutlineExpansionLevel", "mUsingClipboard",
            # "mFileName", "mMemoryInputStream", "mMemoryOutputStream", "mFileInputStream",
            # "mInputFile", "mFileOutputStream", "mFileSize", "mTopVnode", "mTagList",
            # "mMaxVnodeTag",
            # "mUndoType", "mUndoVnode", "mUndoParent", "mUndoBack", "mUndoN",
            # "mUndoDVnodes", "mUndoLastChild", "mUndoablyDeletedVnode",
        # ],
    }
#@+node:ekr.20110919211949.6921: *8* Multi-character code
# This is all fairly horrible code...

# None of it has been tested...
#@+node:ekr.20110919211949.6922: *9* match
def match (self,s,i,pat):
    
    '''Return True if s[i:] matches the pat string.
    
    We can't use g.match because s is usually a list.
    '''
    
    assert pat
    
    aList,i,n = [],0,0
    while n < len(pat) and i < len(s):
        token = s[i]
        n += len(token)
        aList.append(token)
    
    return pat.startswith(''.join(aList))
#@+node:ekr.20110919211949.6923: *9* match_word
def match_word (self,s,i,pat):
    
    '''Return True if s[i:] word matches the pat string.'''
    
    aList,i,n = [],0,0
    while i < len(s) and n < len(pat):
        token = s[i]
        i += 1
        n += len(token)
        aList.append(token)
    if n == len(pat):
        return pat == ''.join(aList)
    elif n > len(pat):
        s2 = ''.join(aList)
        if pat.startswith(s2):
            ch = s2[len(pat)]
            return not ch.isalnum() and not ch == '_'
        else:
            return False
    else: # n < len(pat)
        assert i == len(s)
        return False
#@+node:ekr.20110917104720.6873: *8* Scanning
#@+node:ekr.20110916215321.8002: *9* convertLeadingBlanks
def convertLeadingBlanks(self,aList):

    w = self.tab_width
    if w < 2: return

    i = 0
    while i < len(aList):
        n = 0
        while i < len(aList) and aList[i] == ' ':
            n += 1 ; i += 1
            if n == w:
                aList[i-w:i] = ['\t']
                i = i - w + 1
                n = 0
        i = self.skip_past_line(aList, i)
#@+node:ekr.20110916215321.7998: *9* convertDocList
def convertDocList (self,docList):

    # print "convertDocList:", docList
    if self.match_word(docList,0,"@doc"):
        i = self.skip_ws(docList,4)
        if self.match(docList,i,"\n"):
            i += 1
        docList [0: i] = [z for z in ("@ ")]
#@+node:ekr.20110916215321.8000: *9* skipCodePart
def skipCodePart (self,aList,i):

    # print "skipCodePart", i
    if self.match_word(aList,i,"@doc") or self.match_word(aList,i,"@"):
        return i
    while i < len(aList):
        if self.match(aList,i,"//"):
            i = skipPastLine(aList,i)
        elif self.match(aList,i,"/*"):
            i = skipCBlockComment(aList,i)
        elif self.match(aList,i,'"') or self.match(aList,i,"'"):
            i = skipString(aList,i)
        elif self.match(aList,i,"\n"):
            i += 1
            if self.match_word(aList,i,"@doc") or self.match_word(aList,i,"@"):
                break
        else: i += 1
    return i
#@+node:ekr.20110916215321.7999: *9* skipDocPart
def skipDocPart (self,aList,i):

    # print "skipDocPart", i
    while i < len(aList):
        if self.match_word(aList,i,"@code") or self.match_word(aList,i,"@c"):
            break
        elif isSectionDef(aList,i):
            break
        else: i = skipPastLine(aList,i)
    return i
#@+node:ekr.20110917104720.6872: *8* Utils
#@+node:ekr.20110916215321.8018: *9* findInCode
def findInCode (self,aList,i,findString):

    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif self.match(aList,i,findString):
            return i
        else:
            i += 1

    return -1
#@+node:ekr.20110916215321.8019: *9* findInList
def findInList (self,aList,i,findString):

    while i < len(aList):
        if self.match(aList,i,findString):
            return i
        else:
            i += 1

    return-1
#@+node:ekr.20110916215321.7986: *8* speedTest
def speedTest (self,passes):

    import time
    fn = r"c:\prog\LeoPy\LeoPy.leo"
    f=open(fn)
    if not f:
        print("not found: ",fn)
        return
    s=f.read()
    f.close()
    print("file:", fn, " size:", len(s), " passes:", passes)
    print("speedTest start")
    time1 = time.clock()
    p = passes
    while p > 0:
        n = len(s) ; i = 0 ; lines = 0
        while -1 < i < n:
            if s[i] == '\n':
                lines += 1 ; i += 1
            else:
                i = s.find('\n',i) # _much_ faster than list-based-find.
            continue
            # match is about 9 times slower than simple test.
            if s[i]=='\n': # match(s,i,'\n'): # 
                i += 1
            else:
                i += 1
        p -= 1
    time2 = time.clock()
    print("lines:", lines)
    print("speedTest done:")
    print("elapsed time:", time2-time1)
    print("time/pass:", (time2-time1)/passes)
#@+node:ekr.20110916215321.7981: *8* test
def test(self):
    
    << define test data >>
    
    self.print_flag = True
    for s in testData:
        self.convertCStringToPython(s,leoFlag=True)
#@+node:ekr.20110917104720.6875: *9* << define test data >>
testData = [
"\n@doc\n\
This is a doc part: format, whilest, {};->.\n\
<<\
section def>>=\n\
LeoFrame::LeoFrame(vnode *v, char *s, int i)\n\
{\n\
    // test ; {} /* */.\n\
    #if 0 //comment\n\
        if(gLeoFrameList)gLeoFrameList -> mPrevFrame = this ;\n\
        else\n\
            this -> mNextFrame = gLeoFrameList ;\n\
    #else\n\
        \n\
        vnode *v = new vnode(a,b);\n\
        Commands *commander = (Commands) NULL ; // after cast\n\
        this -> mPrevFrame = NULL ;\n\
    #endif\n\
    if (a==b)\n\
        a = 2;\n\
    else if (a ==c)\n\
        a = 3;\n\
    else return; \n\
    /* Block comment test:\n\
        if(2):while(1): end.*/\n\
    for(int i = 1; i < limit; ++i){\n\
        mVisible = FALSE ;\n\
        mOnTop = TRUE ;\n\
    }\n\
    // trailing ws.	 \n\
    mCommands = new Commands(this, mTreeCtrl, mTextCtrl) ;\n\
    gActiveFrame = this ;\n\
}\n\
    ", "<<" +
"vnode methods >>=\n\
\n\
void vnode::OnCopyNode(wxCommandEvent& WXUNUSED(event))\n\
{\n\
    mCommands -> copyOutline();\n\
}\n\
\n@doc\n\
another doc part if, then, else, -> \n<<" +
"vnode methods >>=\n\
void vnode::OnPasteNode(wxCommandEvent& WXUNUSED(event))\n\
{\n\
    mCommands -> pasteOutline();\n\
}\n" ]
#@+node:ekr.20110916215321.8057: *7* ctor & helpers
def __init__ (self,c):
    
    self.c = c
    self.p = self.c.p.copy()
    
    aList = g.get_directives_dict_list(self.p)
    self.tab_width = g.scanAtTabwidthDirectives(aList) or 4

    # Internal state...
    self.class_name = ''
        # The class name for the present function.  Used to modify ivars.
    self.ivars = []
        # List of ivars to be converted to self.ivar
    self.print_flag = False
        
    # Get user types.
    self.get_user_types()
#@+node:ekr.20110916215321.7984: *8* get_user_types
@nocolor
@

Change the following lists so they contain the types and classes used by your
program. c-to-python converts::
    
    new aType(...)

to::
    
    aType(...)
    
Change ivarsDict so it represents the instance variables (ivars) used by your
program's classes. ivarsDict is a dictionary used to translate ivar i of class c
to self.i. It also translates this->i to self.i.

@c
@color
        
def get_user_types (self):
    
    c = self.c

    self.class_list = c.config.getData('c-to-python-class-list') or []
    
    self.type_list  = (
        c.config.getData('c-to-python-type-list') or
        ["char", "void", "short", "long", "int", "double", "float"]
    )
    aList = c.config.getData('c-to-python-ivars-dict')
    if aList:
        self.ivars_dict = self.parse_ivars_data(aList)
    else:
        self.ivars_dict = {}
    
    if 0:
        #g.trace('class_list',self.class_list)
        #g.trace('type_list',self.type_list)
        g.trace('ivars_dict...')
        d = self.ivars_dict
        keys = list(d.keys())
        for key in sorted(keys):
            print('%s:' % (key))
            for val in d.get(key):
                print('  %s' % (val))
    
#@+node:ekr.20110917104720.6877: *8* parse_ivars_data
def parse_ivars_data (self,aList):
    
    d,key = {},None
    aList = [z.strip() for z in aList if z.strip()]
    for s in aList:
        if s.endswith(':'):
            key = s[:-1].strip()
        elif key:
            ivars = [z.strip() for z in s.split(',') if z.strip()]
            aList = d.get(key,[])
            aList.extend(ivars)
            d [key] = aList
        else:
            g.es('invalid @data c-to-python-ivars-dict',repr(s),color='red')
            return {}

    return d
#@+node:ekr.20110916215321.8058: *7* go
def go (self):
    
    c = self.c
    u = c.undoer ; undoType = 'c-to-python'
    pp = c.CPrettyPrinter(c)
    
    u.beforeChangeGroup(c.p,undoType)
    dirtyVnodeList = []
    changed = False
    
    for p in self.p.self_and_subtree():
        if p.b:
            # g.es("converting:",p.h)
            bunch = u.beforeChangeNodeContents(p,oldBody=p.b)
            
            s = pp.indent(p)
            aList = list(s)
            self.convertCodeList(aList)
        
            s = ''.join(aList)
            if s != p.b:
                p.b = s
                p.v.setDirty()
                dirtyVnodeList.append(p.v)
                c.undoer.afterChangeNodeContents(p,undoType,bunch)
                changed = True
                    
        if changed:
            u.afterChangeGroup(c.p,undoType,
                reportFlag=False,dirtyVnodeList=dirtyVnodeList)
    g.es("done")
#@+node:ekr.20110916215321.7997: *7* convertCodeList (main pattern function)
def convertCodeList(self,aList):
    
    r,sr = self.replace,self.safe_replace

    # First...
    r(aList, "\r", '')
    # self.convertLeadingBlanks(aList) # Now done by indent.
    # if leoFlag: replaceSectionDefs(aList)
    self.mungeAllFunctions(aList)
    
    # Next...
    if 1:
        # CC2 stuff:
        sr(aList, "TRACEPB",   "if trace: g.trace")
        sr(aList, "TRACEPN",   "if trace: g.trace")
        sr(aList, "TRACEPX",   "if trace: g.trace")
        sr(aList, "TICKB",     "if trace: g.trace")
        sr(aList, "TICKN",     "if trace: g.trace")
        sr(aList, "TICKX",     "if trace: g.trace")
        sr(aList, "g.trace(ftag,", "g.trace(")
        sr(aList, "ASSERT_TRACE", "assert")

    sr(aList, "ASSERT","assert")
    sr(aList, " -> ", '.')
    sr(aList, "->", '.')
    sr(aList, " . ", '.')
    sr(aList, "this.self", "self")
    sr(aList, "{", '')
    sr(aList, "}", '')
    sr(aList, "#if", "if")
    sr(aList, "#else", "else")
    sr(aList, "#endif", '')
    sr(aList, "else if", "elif")
    sr(aList, "else", "else:")
    sr(aList, "&&", " and ")
    sr(aList, "||", " or ")
    sr(aList, "TRUE", "True")
    sr(aList, "FALSE", "False")
    sr(aList, "NULL", "None")
    sr(aList, "this", "self")
    sr(aList, "try", "try:")
    sr(aList, "catch", "except:")
    # if leoFlag: sr(aList, "@code", "@c")

    # Next...
    self.handle_all_keywords(aList)
    self.insert_not(aList)
    self.removeSemicolonsAtEndOfLines(aList)
        # after processing for keywords

    # Last...
    # if firstPart and leoFlag: removeLeadingAtCode(aList)
    self.removeBlankLines(aList)
    self.removeExcessWs(aList)
    # your taste may vary: in Python I don't like extra whitespace
    sr(aList, " :", ":") 
    sr(aList, ", ", ",")
    sr(aList, " ,", ",")
    sr(aList, " (", "(")
    sr(aList, "( ", "(")
    sr(aList, " )", ")")
    sr(aList, ") ", ")")
    sr(aList, "@language c","@language python")
    self.replaceComments(aList) # should follow all calls to safe_replace
    self.removeTrailingWs(aList)
    r(aList, "\t ", "\t") # happens when deleting declarations.
#@+node:ekr.20110916215321.8001: *7* Scanning
#@+node:ekr.20110919211949.6920: *8* insert_not
def insert_not (self,aList):
    
    '''Change "!" to "not" except before "="'''
    
    i = 0
    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif aList[i] == '!' and not self.match(aList,i+1,'='):
            aList[i:i+1] = list('not ')
            i += 4
        else:
            i += 1
#@+node:ekr.20110916215321.8003: *8* mungeAllFunctions
def mungeAllFunctions(self,aList):
    
    '''Scan for a '{' at the top level that is preceeded by ')' '''

    prevSemi = 0 # Previous semicolon: header contains all previous text
    i = 0
    firstOpen = None
    while i < len(aList):
        progress = i
        if self.is_string_or_comment(aList,i):
            j = self.skip_string_or_comment(aList,i)
            prevSemi = j
        elif self.match(aList,i,'('):
            if not firstOpen:
                firstOpen = i
            j = i + 1
        elif self.match(aList,i,'#'):
            # At this point, it is a preprocessor directive.
            j = self.skip_past_line(aList, i)
            prevSemi = j
        elif self.match(aList,i,';'):
            j = i + 1
            prevSemi = j
        elif self.match(aList,i,"{"):
            j = self.handlePossibleFunctionHeader(aList,i,prevSemi,firstOpen)
            prevSemi = j
            firstOpen = None # restart the scan
            # g.trace(repr(''.join(aList[prevSemi:prevSemi+20])))
        else:
            j = i + 1
        
        assert j > progress
        i = j
        
# elif self.match_word(aList, i, "@code"):
    # j = i + 5
    # prevSemi = j # restart the scan
# elif self.match_word(aList, i, "@c"):
    # j = i + 2 ; prevSemi = j # restart the scan
#@+node:ekr.20110916215321.8004: *9* handlePossibleFunctionHeader
# converts function header lines from c++ format to python format.
# That is, converts
# x1..nn w::y ( t1 z1,..tn zn) {
# to
# def y (z1,..zn): {

def handlePossibleFunctionHeader (self,aList,i,prevSemi,firstOpen):

    trace = False
    assert(self.match(aList,i,"{"))

    prevSemi = self.skip_ws_and_nl(aList, prevSemi)
    close = self.prevNonWsOrNlChar(aList,i)

    if close < 0 or aList[close] != ')':
        # Should not increase *Python* indent.
        return 1 + self.skip_to_matching_bracket(aList,i)
        
    if not firstOpen:
        return 1 + self.skip_to_matching_bracket(aList,i)

    close2 = self.skip_to_matching_bracket(aList, firstOpen)
    if close2 != close:
        return 1 + self.skip_to_matching_bracket(aList,i)

    open_paren = firstOpen
    assert(aList[open_paren]=='(')
    head = aList[prevSemi:open_paren]

    # do nothing if the head starts with "if", "for" or "while"
    k = self.skip_ws(head,0)
    if k >= len(head) or not head[k].isalpha():
        return 1 + self.skip_to_matching_bracket(aList,i)

    kk = self.skip_past_word(head,k)
    if kk > k:
        headString = ''.join(head[k:kk])
        # C keywords that might be followed by '{'
        # print "headString:", headString
        if headString in [ "class", "do", "for", "if", "struct", "switch", "while"]:
            return 1 + self.skip_to_matching_bracket(aList, i)

    args = aList[open_paren:close+1]
    k = 1 + self.skip_to_matching_bracket(aList,i)
    body = aList[close+1:k]
    
    if True and trace:
        g.trace('\nhead: %s\nargs: %s\nbody: %s' % (
            ''.join(head),''.join(args),''.join(body)))
    
    head = self.massageFunctionHead(head)
    args = self.massageFunctionArgs(args)
    body = self.massageFunctionBody(body)

    if False and trace:
        g.trace('\nhead2: %s\nargs2: %s\nbody2: %s' % (
            ''.join(head),''.join(args),''.join(body)))

    result = []
    if head: result.extend(head)
    if args: result.extend(args)
    if body: result.extend(body)

    aList[prevSemi:k] = result
    return prevSemi + len(result)
#@+node:ekr.20110916215321.8005: *9* massageFunctionArgs
def massageFunctionArgs (self,args):

    assert(args[0]=='(')
    assert(args[-1]==')')

    result = ['('] ; lastWord = []
    if self.class_name:
        for item in list("self,"): result.append(item) #can put extra comma

    i = 1
    while i < len(args):
        i = self.skip_ws_and_nl(args, i)
        c = args[i]
        if c.isalpha():
            j = self.skip_past_word(args,i)
            lastWord = args[i:j]
            i = j
        elif c == ',' or c == ')':
            for item in lastWord:
                result.append(item)
            if lastWord != [] and c == ',':
                result.append(',')
            lastWord = []
            i += 1
        else: i += 1
    if result[-1] == ',':
        del result[-1]
    result.append(')')
    result.append(':')
    # print "new args:", ''.join(result)
    return result
#@+node:ekr.20110916215321.8006: *9* massageFunctionHead (sets .class_name)
def massageFunctionHead (self,head):
    
    result = []
    prevWord = []
    self.class_name = ''
    i = 0
    # g.trace(repr(''.join(head)))
    while i < len(head):
        i = self.skip_ws_and_nl(head,i)
        if i < len(head) and head[i].isalpha():
            result = []
            j = self.skip_past_word(head,i)
            prevWord = head[i:j]
            i = j
            # look for ::word2
            i = self.skip_ws(head,i)
            if self.match(head,i,"::"):
                # Set the global to the class name.
                self.class_name = ''.join(prevWord)
                # print(class name:", self.class_name)
                i = self.skip_ws(head,i+2)
                if i < len(head) and (head[i]=='~' or head[i].isalpha()):
                    j = self.skip_past_word(head,i)
                    if head[i:j] == prevWord:
                        result.extend('__init__')
                    elif head[i]=='~' and head[i+1:j] == prevWord:
                        result.extend('__del__')
                    else:
                        # result.extend(list('::'))
                        result.extend(head[i:j])
                    i = j
            else:
                result.extend(prevWord)
        else: i += 1

    finalResult = list("def ")
    finalResult.extend(result)
    return finalResult
#@+node:ekr.20110916215321.8007: *9* massageFunctionBody & helpers
def massageFunctionBody (self,body):

    body = self.massageIvars(body)
    body = self.removeCasts(body)
    body = self.removeTypeNames(body)
    body = self.dedentBlocks(body)
    return body
#@+node:ekr.20110919224143.6928: *10* dedentBlocks
def dedentBlocks (self,body):
    
    '''Look for '{' preceded by '{' or '}' or ';'
    (with intervening whitespace and comments).
    '''
    
    i = 0
    while i < len(body):
        j = i
        ch = body[i]
        if self.is_string_or_comment(body,i):
            j = self.skip_string_or_comment(body,i)
        elif ch in '{};':
            # Look ahead ofr '{'
            j += 1
            while True:
                k = j
                j = self.skip_ws_and_nl(body,j)
                if self.is_string_or_comment(body,j):
                    j = self.skip_string_or_comment(body,j)
                if k == j: break
                assert k < j
            if self.match(body,j,'{'):
                k = j
                j = self.skip_to_matching_bracket(body,j)
                # g.trace('found block\n',''.join(body[k:j+1]))
                m = '# <Start dedented block>...'
                body[k:k+1] = list(m)
                j += len(m)
                while k < j:
                    progress = k
                    if body[k] == '\n':
                        k += 1
                        spaces = 0
                        while spaces < 4 and k < j:
                            if body[k] == ' ':
                                spaces += 1
                                k += 1
                            else:
                                break
                        if spaces > 0:
                            del body[k-spaces:k]
                            k -= spaces
                            j -= spaces
                    else:
                        k += 1
                    assert progress < k
                m = '    # <End dedented block>'
                body[j:j+1] = list(m)
                j += len(m)
        else:
            j = i + 1
        assert i < j
        i = j
                
    return body
#@+node:ekr.20110916215321.8008: *10* massageIvars
def massageIvars (self,body):

    if self.class_name and self.ivars_dict.has_key(self.class_name):
        ivars = self.ivars_dict.get(self.class_name)
    else:
        ivars = []

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif body[i].isalpha():
            j = self.skip_past_word(body,i)
            word = ''.join(body[i:j])
            # print "looking up:", word
            if word in ivars:
                # replace word by self.word
                # print "replacing", word, " by self.", word
                word = "self." + word
                word = list(word)
                body[i:j] = word
                delta = len(word)-(j-i)
                i = j + delta
            else: i = j
        else: i += 1
    return body
#@+node:ekr.20110916215321.8009: *10* removeCasts
def removeCasts (self,body):

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif self.match(body, i, '('):
            start = i
            i = self.skip_ws(body, i+1)
            if body[i].isalpha():
                j = self.skip_past_word(body,i)
                word = ''.join(body[i:j])
                i = j
                if word in self.class_list or word in self.type_list:
                    i = self.skip_ws(body, i)
                    while self.match(body,i,'*'):
                        i += 1
                    i = self.skip_ws(body, i)
                    if self.match(body,i,')'):
                        i += 1
                        # print "removing cast:", ''.join(body[start:i])
                        del body[start:i]
                        i = start
        else: i += 1
    return body
#@+node:ekr.20110916215321.8010: *10* removeTypeNames
# Do _not_ remove type names when preceeded by new.

def removeTypeNames (self,body):

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif self.match_word(body, i, "new"):
            i = self.skip_past_word(body,i)
            i = self.skip_ws(body,i)
            # don't remove what follows new.
            if body[i].isalpha():
                i = self.skip_past_word(body,i)
        elif body[i].isalpha():
            j = self.skip_past_word(body,i)
            word = ''.join(body[i:j])
            if word in self.class_list or word in self.type_list:
                j = self.skip_ws(body,j)
                while self.match(body,j,'*'):
                    j += 1
                # print "Deleting type name:", ''.join(body[i:j])
                j = self.skip_ws(body,j)
                del body[i:j]
            else:
                i = j
        else: i += 1
    return body
#@+node:ekr.20110916215321.8011: *8* handle_all_keywords
def handle_all_keywords (self,aList):
    
    '''
    converts if ( x ) to if x:
    converts while ( x ) to while x:
    '''

    i = 0
    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif (
            self.match_word(aList,i,"if") or
            self.match_word(aList,i,"while") or
            self.match_word(aList,i,"for") or
            self.match_word(aList,i,"elif")
        ):
            i = self.handle_keyword(aList,i)
        else:
            i += 1
    # print "handAllKeywords2:", ''.join(aList)
#@+node:ekr.20110916215321.8012: *9* handle_keyword
def handle_keyword (self,aList,i):

    isFor = False
    if self.match_word(aList,i,"if"):
        i += 2
    elif self.match_word(aList,i,"elif"):
        i += 4
    elif self.match_word(aList,i,"while"):
        i += 5
    elif self.match_word(aList,i,"for"):
        i += 3
        isFor = True
    else: assert(0)

    # Make sure one space follows the keyword.
    k = i
    i = self.skip_ws(aList,i)
    if k == i:
        c = aList[i]
        aList[i:i+1] = [ ' ', c ]
        i += 1

    # Remove '(' and matching ')' and add a ':'
    if aList[i] == "(":
        # Look ahead.  Don't remove if we span a line.
        j = self.skip_to_matching_bracket(aList, i)
        k = i
        found = False
        while k < j and not found:
            found = aList[k] == '\n'
            k += 1
        if not found:
            j = self.removeMatchingBrackets(aList,i)
        if j > i and j < len(aList):
            ch = aList[j]
            aList[j:j+1] = [ch,":", " "]
            j = j + 2
        return j
    return i
#@+node:ekr.20110916215321.8063: *7* Utils
#@+node:ekr.20110916215321.8017: *8* match...
#@+node:ekr.20110916215321.8020: *9* match
def match (self,s,i,pat):
    
    '''Return True if s[i:] matches the pat string.
    
    We can't use g.match because s is usually a list.
    '''
    
    assert pat

    j = 0
    while i+j < len(s) and j < len(pat):
        if s[i+j] == pat[j]:
            j += 1
            if j == len(pat):
                return True
        else:
            return False

    return False
#@+node:ekr.20110916215321.8021: *9* match_word
def match_word (self,s,i,pat):
    
    '''Return True if s[i:] word matches the pat string.'''

    if self.match(s,i,pat):
        j = i + len(pat)
        if j >= len(s):
            # g.trace(i,pat)
            return True
        else:
            ch = s[j]
            return not ch.isalnum() and ch != '_'
    else:
        return False
#@+node:ekr.20110916215321.8066: *8* is...
#@+node:ekr.20110916215321.8015: *9* isSectionDef
# returns the ending index if i points to < < x > > =
def isSectionDef (self,aList,i):

    i = self.skip_ws(aList,i)
    if not self.match(aList,i,"<<"):
        return False
    while i < len(aList) and aList[i] != '\n':
        if self.match(aList,i,">>="):
            return i+3
        else:
            i += 1
    return False
#@+node:ekr.20110916215321.8016: *9* is_string_or_comment
def is_string_or_comment (self,s,i):

    # Does range checking.
    m = self.match
    return m(s,i,"'") or m(s,i,'"') or m(s,i,"//") or m(s,i,"/*")
#@+node:ekr.20110916215321.8014: *9* is_ws and is_ws_or_nl
def is_ws (self,ch):
    return ch in ' \t'

def is_ws_or_nl (self,ch):
    return ch in ' \t\n'
#@+node:ekr.20110916215321.8041: *8* prevNonWsChar and prevNonWsOrNlChar
def prevNonWsChar (self,s,i):

    i -= 1
    while i >= 0 and self.is_ws(s[i]):
        i -= 1
    return i

def prevNonWsOrNlChar (self,s,i):

    i -= 1
    while i >= 0 and self.is_ws_or_nl(s[i]):
        i -= 1
    return i
#@+node:ekr.20110916215321.8022: *8* remove...
#@+node:ekr.20110919113533.6821: *9* Not used
if 0:
    @others
#@+node:ekr.20110916215321.8023: *10* removeAllCComments (Not used)
def removeAllCComments (self,aList,delim):

    i = 0
    while i < len(aList):
        progress = i
        if self.match(aList,i,"'") or self.match(aList,i,'"'):
            i = self.skip_string(aList,i)
        elif self.match(aList,i,"//"):
            j = self.skip_to_end_of_line(aList,i)
            print("deleting single line comment:", ''.join(aList[i:j]))
            del aList[i:j]
        elif self.match(aList,i,"/*"):
            j = self.skip_c_block_comment(aList,i)
            print("deleting block comment:", ''.join(aList[i:j]))
            del aList[i:j]
        else:
            i += 1
        assert i > progress
#@+node:ekr.20110916215321.8024: *10* removeAllCSentinels
def removeAllCSentinels (self,aList,delim):

    i = 0
    while i < len(aList):
        if self.match(aList,i,"'") or self.match(aList,i,'"'):
            # string starts a line.
            i = self.skip_string(aList,i)
            i = self.skip_past_line(aList,i)
        elif self.match(aList,i,"/*"):
            # block comment starts a line
            i = self.skip_c_block_comment(aList,i)
            i = self.skip_past_line(line,i)
        elif self.match(aList,i,"//@"):
            j = self.skip_past_line(aList,i)
            print("deleting sentinel:", ''.join(aList[i:j]))
            del aList[i:j]
        else:
            i = self.skip_past_line(aList,i)
#@+node:ekr.20110916215321.8025: *10* removeAllPythonComments
def removeAllPythonComments (self,aList,delim):

    i = 0
    while i < len(aList):
        if self.match(aList,i,"'") or self.match(aList,i,'"'):
            i = self.skip_string(aList,i)
        elif self.match(aList,i,"#"):
            j = self.skip_past_line(aList,i)
            print("deleting comment:", ''.join(aList[i:j]))
            del aList[i:j]
        else:
            i += 1
#@+node:ekr.20110916215321.8026: *10* removeAllPythonSentinels
def removeAllPythonSentinels (self,aList,delim):

    i = 0
    while i < len(aList):
        if self.match(aList,i,"'") or self.match(aList,i,'"'):
            # string starts a line.
            i = self.skip_string(aList,i)
            i = self.skip_past_line(aList,i)
        elif self.match(aList,i,"#@"):
            j = self.skip_past_line(aList,i)
            print("deleting sentinel:", ''.join(aList[i:j]))
            del aList[i:j]
        else:
            i = self.skip_past_line(aList,i)
#@+node:ekr.20110916215321.8027: *10* removeAtRoot
def removeAtRoot (self,aList):

    i = self.skip_ws(aList, 0)
    if self.match_word(aList,i,"@root"):
        j = self.skip_past_line(aList,i)
        del aList[i:j]

    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif self.match(aList,i,"\n"):
            i = self.skip_ws(aList, i+1)
            if self.match_word (aList,i,"@root"):
                j = self.skip_past_line(aList,i)
                del aList[i:j]
        else: i += 1
#@+node:ekr.20110916215321.8031: *10* removeLeadingAtCode
def removeLeadingAtCode (self,aList):

    i = self.skip_ws_and_nl(aList,0)
    if self.match_word(aList,i,"@code"):
        i = self.skip_ws_and_nl(aList,5)
        del aList[0:i]
    elif self.match_word(aList,i,"@c"):
        i = self.skip_ws_and_nl(aList,2)
        del aList[0:i]
#@+node:ekr.20110916215321.8028: *9* removeBlankLines
def removeBlankLines (self,aList):

    i = 0
    while i < len(aList):
        j = i
        while j < len(aList) and aList[j] in " \t":
            j += 1
        if j == len(aList) or aList[j] == '\n':
            del aList[i:j+1]
        else:
            i = self.skip_past_line(aList,i)
#@+node:ekr.20110916215321.8029: *9* removeExcessWs
def removeExcessWs (self,aList):

    i = 0
    i = self.removeExcessWsFromLine(aList,i)
    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif self.match(aList,i,'\n'):
            i += 1
            i = self.removeExcessWsFromLine(aList,i)
        else: i += 1
#@+node:ekr.20110916215321.8030: *9* removeExessWsFromLine
def removeExcessWsFromLine (self,aList,i):

    assert(i==0 or aList[i-1] == '\n')
    i = self.skip_ws(aList,i)
        # Retain the leading whitespace.

    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            break # safe
        elif self.match(aList,i,'\n'):
            break
        elif self.match(aList,i,' ') or self.match(aList,i,'\t'):
            # Replace all whitespace by one blank.
            j = self.skip_ws(aList,i)
            assert(j > i)
            aList[i:j] = [' ']
            i += 1 # make sure we don't go past a newline!
        else: i += 1
    return i
#@+node:ekr.20110916215321.8032: *9* removeMatchingBrackets
def removeMatchingBrackets (self,aList, i):

    j = self.skip_to_matching_bracket(aList, i)
    if j > i and j < len(aList):
        # print "del brackets:", ''.join(aList[i:j+1])
        c = aList[j]
        if c == ')' or c == ']' or c == '}':
            del aList[j:j+1]
            del aList[i:i+1]
            # print "returning:", ''.join(aList[i:j])
            return j - 1
        else: return j + 1
    else: return j
#@+node:ekr.20110916215321.8033: *9* removeSemicolonsAtEndOfLines
def removeSemicolonsAtEndOfLines (self,aList):

    i = 0
    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif aList[i] == ';':
            j = self.skip_ws(aList,i+1)
            if (
                j >= len(aList) or
                self.match(aList,j,'\n') or
                self.match(aList,j,'#') or
                self.match(aList,j,"//")
            ):
                del aList[i]
            else: i += 1
        else: i += 1
#@+node:ekr.20110916215321.8034: *9* removeTrailingWs
def removeTrailingWs (self,aList):

    i = 0
    while i < len(aList):
        if self.is_ws(aList[i]):
            j = i
            i = self.skip_ws(aList,i)
            assert(j < i)
            if i >= len(aList) or aList[i] == '\n':
                # print "removing trailing ws:", `i-j`
                del aList[j:i]
                i = j
        else: i += 1
#@+node:ekr.20110916215321.8035: *8* replace... & safe_replace
#@+node:ekr.20110916215321.8036: *9* replace
def replace (self,aList,findString,changeString):
    
    '''# Replaces all occurances of findString by changeString.
    changeString may be the empty string, but not None.
    '''

    if not findString: return
    
    changeList = list(changeString)
    i = 0
    while i < len(aList):
        if self.match(aList,i,findString):
            aList[i:i+len(findString)] = changeList
            i += len(changeList)
        else:
            i += 1
#@+node:ekr.20110916215321.8037: *9* replaceComments
def replaceComments (self,aList):

    i = 0
    while i < len(aList):
        # Loop invariant: j > progress at end.
        progress = i
        if self.match(aList,i,"//"):
            aList[i:i+2] = ['#']
            j = self.skip_past_line(aList,i)
        elif self.match(aList,i,"/*"):
            j = self.skip_c_block_comment(aList,i)
            k = i
            while k-1 >= 0 and aList[k-1] in ' \t':
                k -= 1
            assert k == 0 or aList[k-1] not in ' \t'
            lws = ''.join(aList[k:i])
            comment_body = ''.join(aList[i+2:j-2])
            comment_lines = g.splitLines(lws + comment_body)
            comment_lines = self.munge_block_comment(comment_lines)
            comment = '\n'.join(comment_lines) # A list of lines.
            comment_list = list(comment) # A list of characters.
            aList[k:j] = comment_list
            j = k + len(comment_list)
            progress = j - 1 # Disable the check below.
        elif self.match(aList,i,'"') or self.match(aList,i,"'"):
            j = self.skip_string(aList,i)
        else:
            j = i+1

        assert j > progress
        i = j
#@+node:ekr.20110920063732.6935: *10* munge_block_comment
def munge_block_comment (self,comment_lines):
    
    trace = False
    n = len(comment_lines)
    assert n > 0
    
    s = comment_lines[0]
    junk,w = g.skip_leading_ws_with_indent(s,0,tab_width=4)

    if n == 1:
        return ['%s# %s' % ((' ' * (w-1)),s.strip())]
    
    junk,w = g.skip_leading_ws_with_indent(s,0,tab_width=4)
    i,result = 0,[]
    for i in range(len(comment_lines)):
        s = comment_lines[i]
        if s.strip():
            result.append('%s# %s' % ((' ' * w),s.strip()))
        elif i == n-1:
            pass # Omit the line entirely.
        else:
            result.append('') # Add a blank line
    
    if trace:
        g.trace()
        for z in result: print(repr(z))

    return result
#@+node:ekr.20110916215321.8038: *9* replaceSectionDefs
def replaceSectionDefs (self,aList):
    
    '''Replaces < < x > > = by @c (at the start of lines).'''

    i = 0
    j = self.isSectionDef(aList,i)
    if j > 0: aList[i:j] = list("@c ")

    while i < len(aList):
        if self.is_string_or_comment(aList,i):
            i = self.skip_string_or_comment(aList,i)
        elif self.match(aList,i,"\n"):
            i += 1
            j = self.isSectionDef(aList,i)
            if j > i: aList[i:j] = list("@c ")
        else: i += 1
#@+node:ekr.20110916215321.8039: *9* safe_replace
def safe_replace (self,aList,findString,changeString):
    
    '''Replaces occurances of findString by changeString,
    but only outside of C comments and strings.
    changeString may be the empty string, but not None.
    '''

    if not findString: return

    changeList = list(changeString)
    i = 0
    if findString[0].isalpha(): # use self.match_word
        while i < len(aList):
            if self.is_string_or_comment(aList,i):
                i = self.skip_string_or_comment(aList,i)
            elif self.match_word(aList,i,findString):
                aList[i:i+len(findString)] = changeList
                i += len(changeList)
            else:
                i += 1
    else: #use self.match
        while i < len(aList):
            if self.match(aList,i,findString):
                aList[i:i+len(findString)] = changeList
                i += len(changeList)
            else:
                i += 1
#@+node:ekr.20110916215321.8040: *8* skip
#@+node:ekr.20110916215321.8042: *9* skip_c_block_comment
def skip_c_block_comment (self,s,i):
    
    # if 'replaceComments' in g.callers():
        # g.trace(repr(''.join(s[i:i+20])))

    assert(self.match(s,i,"/*"))
    i += 2

    while i < len(s):
        if self.match(s,i,"*/"):
            return i + 2
        else:
            i += 1

    return i
#@+node:ekr.20110916215321.8043: *9* skip_past_line
def skip_past_line (self,s,i):

    while i < len(s) and s[i] != '\n':
        i += 1
    if i < len(s) and s[i] == '\n':
        i += 1
    return i
#@+node:ekr.20110916215321.8044: *9* skip_past_word
def skip_past_word (self,s,i):

    assert(s[i].isalpha() or s[i]=='~')

    # Kludge: this helps recognize dtors.
    if s[i]=='~':
        i += 1

    while i < len(s):
        ch = s[i]
        if ch.isalnum() or ch =='_':
            i += 1
        else:
            break
    return i
#@+node:ekr.20110916215321.8045: *9* skip_string
def skip_string (self,s,i):

    delim = s[i] # handle either single or double-quoted strings
    assert(delim == '"' or delim == "'")
    i += 1

    while i < len(s):
        if s[i] == delim:
            return i + 1
        elif s[i] == '\\':
            i += 2
        else:
            i += 1
    return i
#@+node:ekr.20110916215321.8046: *9* skip_string_or_comment
def skip_string_or_comment (self,s,i):

    if self.match(s,i,"'") or self.match(s,i,'"'):
        j = self.skip_string(s,i)
    elif self.match(s,i,"//"):
        j = self.skip_past_line(s,i)
    elif self.match(s,i,"/*"):
        j = self.skip_c_block_comment(s,i)
    else: assert(0)
    
    # g.trace(repr(''.join(s[i:j])))
    return j
#@+node:ekr.20110916215321.8047: *9* skip_to_matching_bracket
def skip_to_matching_bracket (self,s,i):

    ch = s[i]
    if   ch == '(': delim = ')'
    elif ch == '{': delim = '}'
    elif ch == '[': delim = ']'
    else: assert(0)

    i += 1
    while i < len(s):
        ch = s[i]
        if self.is_string_or_comment(s,i):
            i = self.skip_string_or_comment(s,i)
        elif ch == delim:
            return i
        elif ch == '(' or ch == '[' or ch == '{':
            i = self.skip_to_matching_bracket(s,i)
            i += 1 # skip the closing bracket.
        else: i += 1
    return i
#@+node:ekr.20110916215321.8048: *9* skip_ws and skip_ws_and_nl
def skip_ws (self,aList,i):

    while i < len(aList):
        c = aList[i]
        if c == ' ' or c == '\t':
            i += 1
        else: break
    return i

def skip_ws_and_nl (self,aList,i):

    while i < len(aList):
        c = aList[i]
        if c == ' ' or c == '\t' or c == '\n':
            i += 1
        else: break
    return i
#@+node:ekr.20110916215321.8003: *5* mungeAllFunctions
def mungeAllFunctions(self,aList):
    
    '''Scan for a '{' at the top level that is preceeded by ')' '''

    prevSemi = 0 # Previous semicolon: header contains all previous text
    i = 0
    firstOpen = None
    while i < len(aList):
        progress = i
        if self.is_string_or_comment(aList,i):
            j = self.skip_string_or_comment(aList,i)
            prevSemi = j
        elif self.match(aList,i,'('):
            if not firstOpen:
                firstOpen = i
            j = i + 1
        elif self.match(aList,i,'#'):
            # At this point, it is a preprocessor directive.
            j = self.skip_past_line(aList, i)
            prevSemi = j
        elif self.match(aList,i,';'):
            j = i + 1
            prevSemi = j
        elif self.match(aList,i,"{"):
            j = self.handlePossibleFunctionHeader(aList,i,prevSemi,firstOpen)
            prevSemi = j
            firstOpen = None # restart the scan
            # g.trace(repr(''.join(aList[prevSemi:prevSemi+20])))
        else:
            j = i + 1
        
        assert j > progress
        i = j
        
# elif self.match_word(aList, i, "@code"):
    # j = i + 5
    # prevSemi = j # restart the scan
# elif self.match_word(aList, i, "@c"):
    # j = i + 2 ; prevSemi = j # restart the scan
#@+node:ekr.20110916215321.8004: *6* handlePossibleFunctionHeader
# converts function header lines from c++ format to python format.
# That is, converts
# x1..nn w::y ( t1 z1,..tn zn) {
# to
# def y (z1,..zn): {

def handlePossibleFunctionHeader (self,aList,i,prevSemi,firstOpen):

    trace = False
    assert(self.match(aList,i,"{"))

    prevSemi = self.skip_ws_and_nl(aList, prevSemi)
    close = self.prevNonWsOrNlChar(aList,i)

    if close < 0 or aList[close] != ')':
        # Should not increase *Python* indent.
        return 1 + self.skip_to_matching_bracket(aList,i)
        
    if not firstOpen:
        return 1 + self.skip_to_matching_bracket(aList,i)

    close2 = self.skip_to_matching_bracket(aList, firstOpen)
    if close2 != close:
        return 1 + self.skip_to_matching_bracket(aList,i)

    open_paren = firstOpen
    assert(aList[open_paren]=='(')
    head = aList[prevSemi:open_paren]

    # do nothing if the head starts with "if", "for" or "while"
    k = self.skip_ws(head,0)
    if k >= len(head) or not head[k].isalpha():
        return 1 + self.skip_to_matching_bracket(aList,i)

    kk = self.skip_past_word(head,k)
    if kk > k:
        headString = ''.join(head[k:kk])
        # C keywords that might be followed by '{'
        # print "headString:", headString
        if headString in [ "class", "do", "for", "if", "struct", "switch", "while"]:
            return 1 + self.skip_to_matching_bracket(aList, i)

    args = aList[open_paren:close+1]
    k = 1 + self.skip_to_matching_bracket(aList,i)
    body = aList[close+1:k]
    
    if True and trace:
        g.trace('\nhead: %s\nargs: %s\nbody: %s' % (
            ''.join(head),''.join(args),''.join(body)))
    
    head = self.massageFunctionHead(head)
    args = self.massageFunctionArgs(args)
    body = self.massageFunctionBody(body)

    if False and trace:
        g.trace('\nhead2: %s\nargs2: %s\nbody2: %s' % (
            ''.join(head),''.join(args),''.join(body)))

    result = []
    if head: result.extend(head)
    if args: result.extend(args)
    if body: result.extend(body)

    aList[prevSemi:k] = result
    return prevSemi + len(result)
#@+node:ekr.20110916215321.8005: *6* massageFunctionArgs
def massageFunctionArgs (self,args):

    assert(args[0]=='(')
    assert(args[-1]==')')

    result = ['('] ; lastWord = []
    if self.class_name:
        for item in list("self,"): result.append(item) #can put extra comma

    i = 1
    while i < len(args):
        i = self.skip_ws_and_nl(args, i)
        c = args[i]
        if c.isalpha():
            j = self.skip_past_word(args,i)
            lastWord = args[i:j]
            i = j
        elif c == ',' or c == ')':
            for item in lastWord:
                result.append(item)
            if lastWord != [] and c == ',':
                result.append(',')
            lastWord = []
            i += 1
        else: i += 1
    if result[-1] == ',':
        del result[-1]
    result.append(')')
    result.append(':')
    # print "new args:", ''.join(result)
    return result
#@+node:ekr.20110916215321.8006: *6* massageFunctionHead (sets .class_name)
def massageFunctionHead (self,head):
    
    result = []
    prevWord = []
    self.class_name = ''
    i = 0
    # g.trace(repr(''.join(head)))
    while i < len(head):
        i = self.skip_ws_and_nl(head,i)
        if i < len(head) and head[i].isalpha():
            result = []
            j = self.skip_past_word(head,i)
            prevWord = head[i:j]
            i = j
            # look for ::word2
            i = self.skip_ws(head,i)
            if self.match(head,i,"::"):
                # Set the global to the class name.
                self.class_name = ''.join(prevWord)
                # print(class name:", self.class_name)
                i = self.skip_ws(head,i+2)
                if i < len(head) and (head[i]=='~' or head[i].isalpha()):
                    j = self.skip_past_word(head,i)
                    if head[i:j] == prevWord:
                        result.extend('__init__')
                    elif head[i]=='~' and head[i+1:j] == prevWord:
                        result.extend('__del__')
                    else:
                        # result.extend(list('::'))
                        result.extend(head[i:j])
                    i = j
            else:
                result.extend(prevWord)
        else: i += 1

    finalResult = list("def ")
    finalResult.extend(result)
    return finalResult
#@+node:ekr.20110916215321.8007: *6* massageFunctionBody & helpers
def massageFunctionBody (self,body):

    body = self.massageIvars(body)
    body = self.removeCasts(body)
    body = self.removeTypeNames(body)
    body = self.dedentBlocks(body)
    return body
#@+node:ekr.20110919224143.6928: *7* dedentBlocks
def dedentBlocks (self,body):
    
    '''Look for '{' preceded by '{' or '}' or ';'
    (with intervening whitespace and comments).
    '''
    
    i = 0
    while i < len(body):
        j = i
        ch = body[i]
        if self.is_string_or_comment(body,i):
            j = self.skip_string_or_comment(body,i)
        elif ch in '{};':
            # Look ahead ofr '{'
            j += 1
            while True:
                k = j
                j = self.skip_ws_and_nl(body,j)
                if self.is_string_or_comment(body,j):
                    j = self.skip_string_or_comment(body,j)
                if k == j: break
                assert k < j
            if self.match(body,j,'{'):
                k = j
                j = self.skip_to_matching_bracket(body,j)
                # g.trace('found block\n',''.join(body[k:j+1]))
                m = '# <Start dedented block>...'
                body[k:k+1] = list(m)
                j += len(m)
                while k < j:
                    progress = k
                    if body[k] == '\n':
                        k += 1
                        spaces = 0
                        while spaces < 4 and k < j:
                            if body[k] == ' ':
                                spaces += 1
                                k += 1
                            else:
                                break
                        if spaces > 0:
                            del body[k-spaces:k]
                            k -= spaces
                            j -= spaces
                    else:
                        k += 1
                    assert progress < k
                m = '    # <End dedented block>'
                body[j:j+1] = list(m)
                j += len(m)
        else:
            j = i + 1
        assert i < j
        i = j
                
    return body
#@+node:ekr.20110916215321.8008: *7* massageIvars
def massageIvars (self,body):

    if self.class_name and self.ivars_dict.has_key(self.class_name):
        ivars = self.ivars_dict.get(self.class_name)
    else:
        ivars = []

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif body[i].isalpha():
            j = self.skip_past_word(body,i)
            word = ''.join(body[i:j])
            # print "looking up:", word
            if word in ivars:
                # replace word by self.word
                # print "replacing", word, " by self.", word
                word = "self." + word
                word = list(word)
                body[i:j] = word
                delta = len(word)-(j-i)
                i = j + delta
            else: i = j
        else: i += 1
    return body
#@+node:ekr.20110916215321.8009: *7* removeCasts
def removeCasts (self,body):

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif self.match(body, i, '('):
            start = i
            i = self.skip_ws(body, i+1)
            if body[i].isalpha():
                j = self.skip_past_word(body,i)
                word = ''.join(body[i:j])
                i = j
                if word in self.class_list or word in self.type_list:
                    i = self.skip_ws(body, i)
                    while self.match(body,i,'*'):
                        i += 1
                    i = self.skip_ws(body, i)
                    if self.match(body,i,')'):
                        i += 1
                        # print "removing cast:", ''.join(body[start:i])
                        del body[start:i]
                        i = start
        else: i += 1
    return body
#@+node:ekr.20110916215321.8010: *7* removeTypeNames
# Do _not_ remove type names when preceeded by new.

def removeTypeNames (self,body):

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif self.match_word(body, i, "new"):
            i = self.skip_past_word(body,i)
            i = self.skip_ws(body,i)
            # don't remove what follows new.
            if body[i].isalpha():
                i = self.skip_past_word(body,i)
        elif body[i].isalpha():
            j = self.skip_past_word(body,i)
            word = ''.join(body[i:j])
            if word in self.class_list or word in self.type_list:
                j = self.skip_ws(body,j)
                while self.match(body,j,'*'):
                    j += 1
                # print "Deleting type name:", ''.join(body[i:j])
                j = self.skip_ws(body,j)
                del body[i:j]
            else:
                i = j
        else: i += 1
    return body
#@+node:ekr.20110920174648.6945: *5* mungeAllFunctions NEW
def mungeAllFunctions(self,aList):
    
    '''Scan for a '{' at the top level that is preceeded by ')' '''
    
    i,start_of_decl,paren_parts = 0,0,[]
    while i < len(aList):
        j = i
        ch = aList[i]
        if ch in '*[], \t\n':
            j += 1
        elif ch == '(':
            j = self.skip_parens(aList,i)
            paren_parts.append((i,j),)
        elif ch == ';':
            # A function declaration.
            j = self.munge_declaration(aList,start_of_decl,i,paren_parts)
            start_of_decl,paren_parts = j,[]
        elif ch == "{":
            # A function definition or enum/struct/union
            # depending on the word at aList[start_of_decl]...
            j1 = self.skip_parens(aList,i)
            j2 = self.munge_declaration(aList,start_of_decl,j1,paren_parts)
            j = self.munge_function_body(aList,i,j2)
            start_of_decl,paren_parts = j,[]
        elif ch == '=':
            # An initializer.
            j = self.skip_statement(aList,i)
            j = self.munge_declaration(aList,start_of_decl,j,paren_parts)
            start_of_decl,paren_parts = j,[]
        elif self.match(aList,i,'#'):
            # A preprocessor directive.
            j = self.skip_past_line(aList,i)
        elif ch in ('"',"'"):
            j = self.skip_string(aList,i)
        elif self.match(aList,i,'//'):
            j = self.skip_to_end_of_line(aList,i)
        elif self.match(aList,i,'/*'):
            j = self.skip_omment(aList,i)
        elif ch == '_' or ch.isalpha():
            j = g.skip_c_id(aList,i)
        elif ch.isdigit():
            j = g.skip_number(aList,i)
        else:
            g.trace('unexpected character in declaration:',repr(ch))
            j = i + 1
        
        assert j > i
        i = j
#@+node:ekr.20110920174648.6946: *6* handlePossibleFunctionHeader
# converts function header lines from c++ format to python format.
# That is, converts
# x1..nn w::y ( t1 z1,..tn zn) {
# to
# def y (z1,..zn): {

def handlePossibleFunctionHeader (self,aList,i,prevSemi,firstOpen):

    trace = False
    assert(self.match(aList,i,"{"))

    prevSemi = self.skip_ws_and_nl(aList, prevSemi)
    close = self.prevNonWsOrNlChar(aList,i)

    if close < 0 or aList[close] != ')':
        # Should not increase *Python* indent.
        return 1 + self.skip_to_matching_bracket(aList,i)
        
    if not firstOpen:
        return 1 + self.skip_to_matching_bracket(aList,i)

    close2 = self.skip_to_matching_bracket(aList, firstOpen)
    if close2 != close:
        return 1 + self.skip_to_matching_bracket(aList,i)

    open_paren = firstOpen
    assert(aList[open_paren]=='(')
    head = aList[prevSemi:open_paren]

    # do nothing if the head starts with "if", "for" or "while"
    k = self.skip_ws(head,0)
    if k >= len(head) or not head[k].isalpha():
        return 1 + self.skip_to_matching_bracket(aList,i)

    kk = self.skip_past_word(head,k)
    if kk > k:
        headString = ''.join(head[k:kk])
        # C keywords that might be followed by '{'
        # print "headString:", headString
        if headString in [ "class", "do", "for", "if", "struct", "switch", "while"]:
            return 1 + self.skip_to_matching_bracket(aList, i)

    args = aList[open_paren:close+1]
    k = 1 + self.skip_to_matching_bracket(aList,i)
    body = aList[close+1:k]
    
    if True and trace:
        g.trace('\nhead: %s\nargs: %s\nbody: %s' % (
            ''.join(head),''.join(args),''.join(body)))
    
    head = self.massageFunctionHead(head)
    args = self.massageFunctionArgs(args)
    body = self.massageFunctionBody(body)

    if False and trace:
        g.trace('\nhead2: %s\nargs2: %s\nbody2: %s' % (
            ''.join(head),''.join(args),''.join(body)))

    result = []
    if head: result.extend(head)
    if args: result.extend(args)
    if body: result.extend(body)

    aList[prevSemi:k] = result
    return prevSemi + len(result)
#@+node:ekr.20110920174648.6947: *6* massageFunctionArgs
def massageFunctionArgs (self,args):

    assert(args[0]=='(')
    assert(args[-1]==')')

    result = ['('] ; lastWord = []
    if self.class_name:
        for item in list("self,"): result.append(item) #can put extra comma

    i = 1
    while i < len(args):
        i = self.skip_ws_and_nl(args, i)
        c = args[i]
        if c.isalpha():
            j = self.skip_past_word(args,i)
            lastWord = args[i:j]
            i = j
        elif c == ',' or c == ')':
            for item in lastWord:
                result.append(item)
            if lastWord != [] and c == ',':
                result.append(',')
            lastWord = []
            i += 1
        else: i += 1
    if result[-1] == ',':
        del result[-1]
    result.append(')')
    result.append(':')
    # print "new args:", ''.join(result)
    return result
#@+node:ekr.20110920174648.6948: *6* massageFunctionHead (sets .class_name)
def massageFunctionHead (self,head):
    
    result = []
    prevWord = []
    self.class_name = ''
    i = 0
    # g.trace(repr(''.join(head)))
    while i < len(head):
        i = self.skip_ws_and_nl(head,i)
        if i < len(head) and head[i].isalpha():
            result = []
            j = self.skip_past_word(head,i)
            prevWord = head[i:j]
            i = j
            # look for ::word2
            i = self.skip_ws(head,i)
            if self.match(head,i,"::"):
                # Set the global to the class name.
                self.class_name = ''.join(prevWord)
                # print(class name:", self.class_name)
                i = self.skip_ws(head,i+2)
                if i < len(head) and (head[i]=='~' or head[i].isalpha()):
                    j = self.skip_past_word(head,i)
                    if head[i:j] == prevWord:
                        result.extend('__init__')
                    elif head[i]=='~' and head[i+1:j] == prevWord:
                        result.extend('__del__')
                    else:
                        # result.extend(list('::'))
                        result.extend(head[i:j])
                    i = j
            else:
                result.extend(prevWord)
        else: i += 1

    finalResult = list("def ")
    finalResult.extend(result)
    return finalResult
#@+node:ekr.20110920174648.6949: *6* massageFunctionBody & helpers
def massageFunctionBody (self,body):

    body = self.massageIvars(body)
    body = self.removeCasts(body)
    body = self.removeTypeNames(body)
    body = self.dedentBlocks(body)
    return body
#@+node:ekr.20110920174648.6950: *7* dedentBlocks
def dedentBlocks (self,body):
    
    '''Look for '{' preceded by '{' or '}' or ';'
    (with intervening whitespace and comments).
    '''
    
    i = 0
    while i < len(body):
        j = i
        ch = body[i]
        if self.is_string_or_comment(body,i):
            j = self.skip_string_or_comment(body,i)
        elif ch in '{};':
            # Look ahead ofr '{'
            j += 1
            while True:
                k = j
                j = self.skip_ws_and_nl(body,j)
                if self.is_string_or_comment(body,j):
                    j = self.skip_string_or_comment(body,j)
                if k == j: break
                assert k < j
            if self.match(body,j,'{'):
                k = j
                j = self.skip_to_matching_bracket(body,j)
                # g.trace('found block\n',''.join(body[k:j+1]))
                m = '# <Start dedented block>...'
                body[k:k+1] = list(m)
                j += len(m)
                while k < j:
                    progress = k
                    if body[k] == '\n':
                        k += 1
                        spaces = 0
                        while spaces < 4 and k < j:
                            if body[k] == ' ':
                                spaces += 1
                                k += 1
                            else:
                                break
                        if spaces > 0:
                            del body[k-spaces:k]
                            k -= spaces
                            j -= spaces
                    else:
                        k += 1
                    assert progress < k
                m = '    # <End dedented block>'
                body[j:j+1] = list(m)
                j += len(m)
        else:
            j = i + 1
        assert i < j
        i = j
                
    return body
#@+node:ekr.20110920174648.6951: *7* massageIvars
def massageIvars (self,body):

    if self.class_name and self.ivars_dict.has_key(self.class_name):
        ivars = self.ivars_dict.get(self.class_name)
    else:
        ivars = []

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif body[i].isalpha():
            j = self.skip_past_word(body,i)
            word = ''.join(body[i:j])
            # print "looking up:", word
            if word in ivars:
                # replace word by self.word
                # print "replacing", word, " by self.", word
                word = "self." + word
                word = list(word)
                body[i:j] = word
                delta = len(word)-(j-i)
                i = j + delta
            else: i = j
        else: i += 1
    return body
#@+node:ekr.20110920174648.6952: *7* removeCasts
def removeCasts (self,body):

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif self.match(body, i, '('):
            start = i
            i = self.skip_ws(body, i+1)
            if body[i].isalpha():
                j = self.skip_past_word(body,i)
                word = ''.join(body[i:j])
                i = j
                if word in self.class_list or word in self.type_list:
                    i = self.skip_ws(body, i)
                    while self.match(body,i,'*'):
                        i += 1
                    i = self.skip_ws(body, i)
                    if self.match(body,i,')'):
                        i += 1
                        # print "removing cast:", ''.join(body[start:i])
                        del body[start:i]
                        i = start
        else: i += 1
    return body
#@+node:ekr.20110920174648.6953: *7* removeTypeNames
# Do _not_ remove type names when preceeded by new.

def removeTypeNames (self,body):

    i = 0
    while i < len(body):
        if self.is_string_or_comment(body,i):
            i = self.skip_string_or_comment(body,i)
        elif self.match_word(body, i, "new"):
            i = self.skip_past_word(body,i)
            i = self.skip_ws(body,i)
            # don't remove what follows new.
            if body[i].isalpha():
                i = self.skip_past_word(body,i)
        elif body[i].isalpha():
            j = self.skip_past_word(body,i)
            word = ''.join(body[i:j])
            if word in self.class_list or word in self.type_list:
                j = self.skip_ws(body,j)
                while self.match(body,j,'*'):
                    j += 1
                # print "Deleting type name:", ''.join(body[i:j])
                j = self.skip_ws(body,j)
                del body[i:j]
            else:
                i = j
        else: i += 1
    return body
#@+node:ekr.20110929074744.15447: *4* removed scrolledmessage plugin
The viewrendered plugin does more.
#@+node:ekr.20110930075237.15469: *4* Added import-org-mode script
#@+node:ekr.20110929165422.15432: *5* import-org-mode (command, not used)
class ImportOrgMode:
    @others

def importOrgMode (self,event):
    c = self.c
    self.ImportOrgMode(c).go(c.p)
    c.bodyWantsFocus()

if g.app.inScript:
    print('='*40)
    ImportOrgMode(c).test()
    print('done')
#@+node:ekr.20110929185034.15461: *6* ctor
def __init__ (self,c):
    
    self.c = c
#@+node:ekr.20110929185034.15457: *6* go
def go (self,p):
    
    '''Prompt for a file and pass the contents to scan().'''
#@+node:ekr.20110929185034.15460: *6* scan
def scan (self,fn,p,s):

    self.c = c
    root = p.insertAsLastChild()
    root.h = fn
    level,stack = 0,[root]
    body = ['@others\n']
    
    for s in g.splitLines(s):
        g.trace(repr(s))
        if s.startswith('*'):
            i,level = 0,0
            while s[i] == '*':
                i += 1
                level += 1
            if level > len(stack):
                g.trace('bad level',repr(s))
                last = None
            elif level == len(stack):
                last = stack[-1]
                last.b = ''.join(body)
            else:
                last = stack[-1]
                last.b = ''.join(body)
                stack = stack[:level]
            parent = stack[-1]
            p = parent.insertAsLastChild()
            p.h = s.strip()
            stack.append(p)
            body = []
        else:
            body.append(s)
            
    # Finish any trailing lines.
    if body:
        parent = stack[-1]
        parent.b = ''.join(body)
        
    root.contract()
    c.redraw(root)
#@+node:ekr.20110929185034.15459: *6* test
def test (self):
    
    s = '''
* A1
    a1.1
    a1.2
** B11
** B12
b12.1
*** C121
c121.1
    c121.2
c121.3
* A2
a2.1
** B21
*** C211
c211.1
*** C212
** B22
    b22.1
b22.1
* A3
* A4
a4.1
* A5
** B51
*** C511
**** D5111
***** E51111
** B52
*** C521
c521.1
'''

    tag = 'test-import-org-mode'
    p = g.findNodeAnywhere(c,tag)
    s = g.adjustTripleString(s,-4)
    if p:
        try:
            self.scan('test-file',p,s)
        except Exception:
            c.redraw(p)
    else:
        print('not found: %s' % tag)
#@+node:ekr.20110929185034.15578: *5* @@button import-org-mode
'''Import each file in the files list after the presently selected node.'''


files = (
    r'c:\Users\edreamleo\test\import-org-mode.txt',
    r'c:\Users\edreamleo\test\import-org-mode.txt',
)

@others

for fn in files:
    try:
        root = c.p.copy()
        f = open(fn)
        s = f.read()
        scan(c,fn,s)
        c.selectPosition(root)
    except IOError:
        print('can not open %s' % fn)
#@+node:ekr.20110929185034.15580: *6* scan
def scan (c,fn,s):

    last = root = c.p.insertAsLastChild()
    last.h = g.shortFileName(fn)
    level,stack = 0,[root]
    body = ['@others\n']
    
    for s in g.splitLines(s):
        if s.startswith('*'):
            i,level = 0,0
            while s[i] == '*':
                i += 1 ; level += 1
            if level > len(stack):
                g.trace('bad level',repr(s))
            elif level == len(stack):
                last.b = ''.join(body)
            else:
                last.b = ''.join(body)
                stack = stack[:level]
            parent = stack[-1]
            last = parent.insertAsLastChild()
            last.h = s.strip()
            stack.append(last)
            body = []
        else:
            body.append(s)
            
    # Finish any trailing lines.
    if body:
        last.b = ''.join(body)
        
    root.contract()
    c.redraw(root)
#@+node:ekr.20110929185034.15463: *5* test-import-org-mode
#@+node:ekr.20110930213637.15474: *4* The Find tab now scrolls
@nocolor-node

The change was to DynamicWindow.createLogPane.
#@+node:ekr.20111003130143.15562: *4* Removed Leo's old syntax coloring code
@nocolor-node

This was Tk code, and so can not possibly be useful now.

Also removed the settings specific to the Tk colorizer.
#@+node:ekr.20110730093802.15135: *3* Investigations
#@+node:ekr.20110728093358.6703: *4* Over-riding bindings
#@+node:ekr.20061031131434.3: *5* << about key dicts >>
@nocolor
@
ivars:

c.commandsDict:
    Keys are emacs command names; values are functions f.

k.inverseCommandsDict:
    Keys are f.__name__; values are emacs command names.

k.bindingsDict:
    Keys are shortcuts; values are *lists* of g.bunch(func,name,warningGiven)

k.masterBindingsDict:
    Keys are scope names: 'all','text',etc. or mode names.
    Values are dicts:  keys are strokes, values are g.Bunch(commandName,func,pane,stroke)

k.masterGuiBindingsDict:
    Keys are strokes; value is a list of widgets for which stroke is bound.

k.settingsNameDict:
    Keys are lowercase settings; values are 'real' Tk key specifiers.
    Important: this table has no inverse.

inverseBindingDict: not an ivar (computed by k.computeInverseBindingDict):
    Keys are emacs command names; values are *lists* of shortcuts.
#@+node:ekr.20061031131434.146: *5* masterKeyHandler & helpers
master_key_count = 0

def masterKeyHandler (self,event):

    '''This is the handler for almost all key bindings.'''
    
    trace = (False or self.trace_masterKeyHandler) and not g.app.unitTesting
    traceGC = self.trace_masterKeyHandlerGC and not g.app.unitTesting
    verbose = True
    
    k,c = self,self.c ; gui = g.app.gui
    c.check_event(event)
    << define vars >>

    if char in special_keys:
        if trace and verbose: g.trace('char',char)
        return None
    
    if traceGC: g.printNewObjects('masterKey 1')
    if trace and verbose: g.trace('stroke:',repr(stroke),'char:',
        repr(event and event.char),
        'ch:',repr(event and event.char),
        'state',state,'state2',k.unboundKeyAction)

    # Handle keyboard-quit first.
    if k.abortAllModesKey and stroke == k.abortAllModesKey:
        if c.macroCommands.recordingMacro:
            c.macroCommands.endMacro()
            return # (for Tk) 'break'
        else:
            return k.masterCommand(event,k.keyboardQuit,stroke,'keyboard-quit')

    if k.inState():
        if trace: g.trace('   state %-10s %s' % (stroke,state))
        done,val = k.doMode(event,state,stroke)
        if done: return val

    if traceGC: g.printNewObjects('masterKey 2')
            
    # 2011/02/08: An important simplification.
    if isPlain and k.unboundKeyAction != 'command':
        if self.isAutoCompleteChar(stroke):
            if trace: g.trace('autocomplete key',stroke)
        else:
            if trace: g.trace('inserted %-10s (insert/overwrite mode)' % (stroke))
            return k.handleUnboundKeys(event,char,stroke)

    # 2011/02/08: Use getPandBindings for *all* keys.
    b = k.getPaneBinding(stroke,w)
    if b:
        if traceGC: g.printNewObjects('masterKey 3')
        if trace: g.trace('   bound',stroke,b.func.__name__)
        return k.masterCommand(event,b.func,b.stroke,b.commandName)
    else:
        if traceGC: g.printNewObjects('masterKey 4')
        if trace: g.trace(' unbound',stroke)
        return k.handleUnboundKeys(event,char,stroke)
#@+node:ekr.20061031131434.147: *6* << define vars >>
w = event and event.widget
char = event and event.char or ''
stroke = event and event.stroke or ''
w_name = c.widget_name(w)
state = k.state.kind

special_keys = (
    'Alt_L','Alt_R',
    'Caps_Lock','Control_L','Control_R',
    'Meta_L','Meta_R', # Meta support.
    'Num_Lock',
    'Shift_L','Shift_R',
    'Win_L','Win_R',
)

self.master_key_count += 1

isPlain =  k.isPlainKey(stroke)
#@+node:ekr.20061031131434.108: *6* callStateFunction
def callStateFunction (self,event):

    trace = False and not g.unitTesting
    k = self ; val = None 
    ch = event and event.char or ''
    stroke = event and event.stroke or ''

    if trace: g.trace(k.state.kind,'ch',ch,'stroke',stroke,
        'ignore_unbound_non_ascii_keys',k.ignore_unbound_non_ascii_keys)
        
    if k.state.kind == 'auto-complete':
        # 2011/06/17.
        # k.auto_completer_state_handler returns 'do-standard-keys' for control keys.
        val = k.state.handler(event)
        if trace: g.trace('auto-complete returns',repr(val))
        return val
    elif k.state.kind:
        if (
            k.ignore_unbound_non_ascii_keys and
            len(ch) == 1 and # 2011/04/01
            ch and ch not in ('\b','\n','\r','\t') and
            (ord(ch) < 32 or ord(ch) > 128)
        ):
            # g.trace('non-ascii',ord(ch))
            pass
        elif k.state.handler:
            val = k.state.handler(event)
            if val != 'continue':
                k.endCommand(k.commandName)
        else:
            g.es_print('no state function for',k.state.kind,color='red')

    return val
#@+node:ekr.20091230094319.6244: *6* doMode
def doMode (self,event,state,stroke):

    trace = False and not g.unitTesting
    k = self

    # First, honor minibuffer bindings for all except user modes.
    if state in ('getArg','getFileName','full-command','auto-complete'):
        if k.handleMiniBindings(event,state,stroke):
            return True,'break'

    # Second, honor general modes.
    if state == 'getArg':
        return True,k.getArg(event,stroke=stroke)
    elif state == 'getFileName':
        return True,k.getFileName(event)
    elif state in ('full-command','auto-complete'):
        # Do the default state action.
        if trace: g.trace('calling state function',k.state.kind)
        val = k.callStateFunction(event) # Calls end-command.
        if trace: g.trace('state function returns',repr(val))
        if val == 'do-standard-keys':
            return False,None # 2011/06/17.
        else:
            return True,'break'

    # Third, pass keys to user modes.
    d =  k.masterBindingsDict.get(state)
    if d:
        b = d.get(stroke)
        if b:
            if trace: g.trace('calling generalModeHandler',stroke)
            k.generalModeHandler (event,
                commandName=b.commandName,func=b.func,
                modeName=state,nextMode=b.nextMode)
            return True,'break'
        else:
            # New in Leo 4.5: unbound keys end mode.
            # if trace: g.trace('unbound key ends mode',stroke,state)
            g.warning('unbound key ends mode',stroke) # 2011/02/02
            k.endMode()
            return False,None
    else:
        # New in 4.4b4.
        handler = k.getStateHandler()
        if handler:
            if trace: g.trace('handler',handler)
            handler(event)
        else:
            if trace: g.trace('No state handler for %s' % state)
        return True,'break'
#@+node:ekr.20091230094319.6240: *6* getPaneBinding
def getPaneBinding (self,stroke,w):

    trace = False and not g.unitTesting
    verbose = True
    k = self ; w_name = k.c.widget_name(w)
    # keyStatesTuple = ('command','insert','overwrite')
    state = k.unboundKeyAction

    if trace: g.trace('w_name',repr(w_name),'stroke',stroke,'w',w,
        'isTextWidget(w)',g.app.gui.isTextWidget(w))

    for key,name in (
        # Order here is similar to bindtags order.
        ('command',None),
        ('insert',None),
        ('overwrite',None),
        ('button',None),
        ('body','body'),
        ('text','head'), # Important: text bindings in head before tree bindings.
        ('tree','head'),
        ('tree','canvas'),
        ('log', 'log'),
        ('text','log'),
        ('text',None),
        ('all',None),
    ):
        if (
            # key in keyStatesTuple and isPlain and k.unboundKeyAction == key or
            name and w_name.startswith(name) or
            key in ('command','insert','overwrite') and state == key or # 2010/02/09
            key in ('text','all') and g.app.gui.isTextWidget(w) or
            key in ('button','all')
        ):
            d = k.masterBindingsDict.get(key,{})
            if trace and verbose:
                # g.trace('key',key,'name',name,'stroke',stroke,'stroke in d.keys',stroke in d)
                g.trace('key: %7s name: %6s stroke: %10s in keys: %s' %
                    (key,name,stroke,stroke in d))
                # g.trace(key,'keys',g.listToString(list(d.keys()),sort=True)) # [:5])
            if d:
                b = d.get(stroke)
                if b:
                    table = ('previous-line','next-line',)
                    if key == 'text' and name == 'head' and b.commandName in table:
                        if trace: g.trace('***** special case',b.commandName)
                        pass
                    else:
                        if trace: g.trace('key: %7s name: %6s  found %s = %s' % (
                            key,name,repr(b.stroke),b.commandName))
                        return b
#@+node:ekr.20061031131434.152: *6* handleMiniBindings
def handleMiniBindings (self,event,state,stroke):

    k = self ; c = k.c
    trace = (False or self.trace_masterKeyHandler) and not g.app.unitTesting

    # Special case for bindings handled in k.getArg:
    if state in ('getArg','full-command'):
        if stroke in ('\b','BackSpace','\r','Linefeed','\n','Return','\t','Tab','Escape',):
            return False
        if k.isFKey(stroke):
            return False

    if not state.startswith('auto-'):
        # New in Leo 4.5: ignore plain key binding in the minibuffer.
        if not stroke or k.isPlainKey(stroke):
            if trace: g.trace('plain key',stroke)
            return False
        # New in Leo 4.5: The minibuffer inherits 'text' and 'all' bindings
        # for all single-line editing commands.
        for pane in ('mini','all','text'):
            d = k.masterBindingsDict.get(pane)
            if d:
                b = d.get(stroke)
                if b:
                    if b.commandName == 'replace-string' and state == 'getArg':
                        if trace: g.trace('%s binding for replace-string' % (pane),stroke)
                        return False # Let getArg handle it.
                    elif b.commandName not in k.singleLineCommandList:
                        if trace: g.trace('%s binding terminates minibuffer' % (pane),b.commandName,stroke)
                        k.keyboardQuit()
                    else:
                        if trace: g.trace(repr(stroke),'mini binding',b.commandName)
                        c.minibufferWantsFocus() # New in Leo 4.5.
                    # Pass this on for macro recording.
                    k.masterCommand(event,b.func,stroke,b.commandName)
                    # Careful: the command could exit.
                    if c.exists and not k.silentMode:
                        c.minibufferWantsFocus()
                    return True

    return False
#@+node:ekr.20110209083917.16004: *6* isAutoCompleteChar
def isAutoCompleteChar (self,stroke):
    
    '''Return True if stroke is bound to the auto-complete in
    the insert or overwrite state.'''

    k = self ; state = k.unboundKeyAction
    
    if stroke and state in ('insert','overwrite'):
        for key in (state,'body','log','text','all'):
            d = k.masterBindingsDict.get(key,{})
            if d:
                b = d.get(stroke)
                if b and b.commandName == 'auto-complete':
                    return True
    return False
#@+node:ekr.20080510095819.1: *6* k.handleUnboundKeys
def handleUnboundKeys (self,event,char,stroke):

    trace = False and not g.unitTesting
    verbose = False
    k = self ; c = k.c
    modesTuple = ('insert','overwrite')
    
    # g.trace('self.enable_alt_ctrl_bindings',self.enable_alt_ctrl_bindings)

    if trace and verbose: g.trace('ch: %s, stroke %s' % (
        repr(event and event.char),repr(stroke)))

    # g.trace('stroke',repr(stroke),'isFKey',k.isFKey(stroke))

    if k.unboundKeyAction == 'command':
        # Ignore all unbound characters in command mode.
        w = g.app.gui.get_focus(c)
        if w and g.app.gui.widget_name(w).lower().startswith('canvas'):
            c.onCanvasKey(event)
        if trace: g.trace('ignoring unbound character in command mode',stroke)
        return # (for Tk) 'break'

    elif k.isFKey(stroke):
        if trace: g.trace('ignoring F-key',stroke)
        return # (for Tk) 'break'

    elif stroke and k.isPlainKey(stroke) and k.unboundKeyAction in modesTuple:
        # insert/overwrite normal character.  <Return> is *not* a normal character.
        if trace: g.trace('plain key in insert mode',repr(stroke))
        return k.masterCommand(event,func=None,stroke=stroke,commandName=None)

    elif (not self.enable_alt_ctrl_bindings and
        (stroke.find('Alt+') > -1 or stroke.find('Ctrl+') > -1)
    ):
        # 2011/02/11: Always ignore unbound Alt/Ctrl keys.
        if trace: g.trace('ignoring unbound Alt/Ctrl key',
            repr(char),repr(stroke))
        return # (for Tk) 'break'

    elif k.ignore_unbound_non_ascii_keys and (
        len(char) > 1 or
        char not in string.printable # 2011/06/10: risky test?
    ):
        if trace: g.trace('ignoring unbound non-ascii key',
            repr(char),repr(stroke))
        return # (for Tk) 'break'

    elif (
        stroke and stroke.find('Escape') != -1 or
        stroke and stroke.find('Insert') != -1
    ):
        # Never insert escape or insert characters.
        if trace: g.trace('ignore Escape/Ignore',stroke)
        return # (for Tk) 'break'

    else:
        if trace: g.trace('no func',repr(char),repr(stroke))
        return k.masterCommand(event,func=None,stroke=stroke,commandName=None)
#@+node:ekr.20061031131434.119: *5* k.printBindings & helper
def printBindings (self,event=None):

    '''Print all the bindings presently in effect.'''

    k = self ; c = k.c
    d = k.bindingsDict ; tabName = 'Bindings'
    c.frame.log.clearTab(tabName)
    legend = '''\
legend:
[S] leoSettings.leo
[ ] default binding
[F] loaded .leo File
[M] myLeoSettings.leo
[@] mode
'''
    legend = g.adjustTripleString(legend,c.tab_width)

    data = [] ; n1 = 4 ; n2 = 20
    if not d: return g.es('no bindings')
    for key in sorted(d):
        bunchList = d.get(key,[])
        for b in bunchList:
            pane = g.choose(b.pane=='all','',' %s:' % (b.pane))
            s1 = pane
            s2 = k.prettyPrintKey(key,brief=True)
            s3 = b.commandName
            s4 = b.get('_hash','<no hash>')
            n1 = max(n1,len(s1))
            n2 = max(n2,len(s2))
            data.append((s1,s2,s3,s4),)

    # Print keys by type:
    result = []
    result.append('\n'+legend)
    sep = '-' * n1
    for prefix in (
        'Alt+Ctrl+Shift', 'Alt+Shift', 'Alt+Ctrl', 'Alt+Key','Alt',
        'Ctrl+Shift', 'Ctrl', 'Shift',
        'Meta+Ctrl+Shift', 'Meta+Shift', 'Meta+Ctrl', 'Meta+Key','Meta',
        # Meta support
    ):
        data2 = []
        for item in data:
            s1,s2,s3,s4 = item
            if s2.startswith(prefix):
                data2.append(item)
        # g.es('','%s %s' % (sep, prefix),tabName=tabName)
        result.append('%s %s\n' % (sep, prefix))
        self.printBindingsHelper(result,data2,n1,n2,prefix=prefix)
        # Remove all the items in data2 from data.
        # This must be done outside the iterator on data.
        for item in data2:
            data.remove(item)
    # Print all plain bindings.
    result.append('%s %s\n' % (sep, 'Plain Keys'))
    self.printBindingsHelper(result,data,n1,n2,prefix=None)
    if not g.unitTesting:
        g.es('',''.join(result),tabName=tabName)
    state = k.unboundKeyAction 
    k.showStateAndMode()
    return result # for unit test.
#@+node:ekr.20061031131434.120: *6* printBindingsHelper
def printBindingsHelper (self,result,data,n1,n2,prefix):

    n = prefix and len(prefix)+1 or 0 # Add 1 for the '+' after the prefix.

    data1 = [z for z in data if z and z[1] and len(z[1][n:]) == 1]
        # The list of all items with only one character following the prefix.

    data2 = [z for z in data if z and z[1] and len(z[1][n:]) >  1]
        # The list of all other items.

    # This isn't perfect in variable-width fonts.
    for data in (data1,data2):
        data.sort(key=lambda x: x[1])
            # key is a function that extracts args.
        for s1,s2,s3,s4 in data:
            
            # 2011/02/10: Print the source of the binding: s4 is the _hash.
            s4 = s4.lower()
            if s4.endswith('myleosettings.leo'):
                letter = 'M'
            elif s4.endswith('leosettings.leo'):
                letter = 'S'
            elif s4.endswith('.leo'):
                letter = 'F'
            elif s4.find('mode') != -1:
                letter = '@' # the full mode.
            else:
                letter = ' '
            
            # g.es('','%*s %*s %s' % (-n1,s1,-(min(12,n2)),s2,s3),tabName='Bindings')
            result.append('%s %*s %*s %s\n' % (letter,-n1,s1,-(min(12,n2)),s2,s3))
#@+node:ekr.20041117062717.14: *5* getShortcut (g.app.config)
def getShortcut (self,c,shortcutName):

    '''Return rawKey,accel for shortcutName'''

    key = c.frame.menu.canonicalizeMenuName(shortcutName)
    key = key.replace('&','') # Allow '&' in names.
    
    if c.k.new_bindings:
        bunchList = self.getShortcutHelper(c,key) # 2011/02/11
    else:
        bunchList = self.get(c,key,'shortcut')
    # g.trace(c.k.new_bindings) # 'bunchList',bunchList)
    if bunchList:
        bunchList = [bunch for bunch in bunchList
            if bunch.val and bunch.val.lower() != 'none']
        return key,bunchList
    else:
        return key,[]
#@+node:ekr.20110211041914.15415: *6* getShortcutHelper(g.app.config)
def getShortcutHelper (self,c,key):
    
    '''Like get, but return *all* the found bunchLists's.
    
    'key' is actually a commandname.'''

    trace = False and not g.unitTesting
    kind = 'shortcut'
    isLeoSettings = c and c.shortFileName().endswith('leoSettings.leo')
    result = []

    if c and not isLeoSettings:
        d = self.localOptionsDict.get(c.hash())
        if d:
            bunchList,junk = self.getValFromDict(d,key,kind)
            if bunchList: self.mergeShortcuts(result,bunchList,key)

    for d in self.localOptionsList:
        bunchList,junk = self.getValFromDict(d,key,kind)
        if bunchList: self.mergeShortcuts(result,bunchList,key)

    for d in self.dictList:
        bunchList,junk = self.getValFromDict(d,key,kind)
        if bunchList: self.mergeShortcuts(result,bunchList,key)

    # Use settings in leoSettings.leo *last*.
    if c and isLeoSettings:
        d = self.localOptionsDict.get(c.hash())
        if d:
            bunchList,junk = self.getValFromDict(d,key,kind)
            if bunchList: self.mergeShortcuts(result,bunchList,key)

    return result
#@+node:ekr.20110211041914.15418: *6* mergeShortcuts
def mergeShortcuts (self,result,aList,key):
        # key is for debugging.
        # key is a conical command name, *not* a keystroke.
    
    '''Append all non-conflicting entries of aList to result.'''
    
    trace = False and not g.unitTesting
    # If there is a real override, **earlier** entries take precedence.
    # Don't add a bunch if it conflicts with a previous val, **regardless** of pane.
    
    vals = [z.val for z in result]
    aList = [z for z in aList if z.val not in vals]
    result.extend(aList)

    if trace and len(result) > 1:
        g.trace(key,['%s %s' % (z.val,z.pane) for z in result])
#@+node:ekr.20041117083141: *5* get & allies (g.app.config)
def get (self,c,setting,kind):

    """Get the setting and make sure its type matches the expected type."""

    trace = False and not g.unitTesting

    isLeoSettings = c and c.shortFileName().endswith('leoSettings.leo')

    # New in Leo 4.6. Use settings in leoSettings.leo *last*.
    if c and not isLeoSettings:
        d = self.localOptionsDict.get(c.hash())
        if d:
            val,junk = self.getValFromDict(d,setting,kind)
            if val is not None:
                # if setting == 'targetlanguage':
                    # g.trace(c.shortFileName(),setting,val,g.callers())
                return val

    for d in self.localOptionsList:
        val,junk = self.getValFromDict(d,setting,kind)
        if val is not None:
            # kind2 = d.get('_hash','<no hash>')
            # if setting == 'targetlanguage':
                # g.trace(kind2,setting,val,g.callers())
            return val

    for d in self.dictList:
        val,junk = self.getValFromDict(d,setting,kind)
        if val is not None:
            kind = d.get('_hash','<no hash>')
            # if setting == 'targetlanguage':
                # g.trace(kind,setting,val,g.callers())
            return val

    # New in Leo 4.6. Use settings in leoSettings.leo *last*.
    if c and isLeoSettings:
        d = self.localOptionsDict.get(c.hash())
        if d:
            val,junk = self.getValFromDict(d,setting,kind)
            if val is not None:
                # if setting == 'targetlanguage':
                    # g.trace(c.shortFileName(),setting,val,g.callers())
                return val

    return None
#@+node:ekr.20041121143823: *6* getValFromDict
def getValFromDict (self,d,setting,requestedType,warn=True):

    '''Look up the setting in d. If warn is True, warn if the requested type
    does not (loosely) match the actual type.
    returns (val,exists)'''

    bunch = d.get(self.munge(setting))
    if not bunch: return None,False

    # g.trace(setting,requestedType,bunch.toString())
    val = bunch.val

    if g.isPython3:
        isNone = val in ('None','none','',None)
    else:
        isNone = val in (
            unicode('None'),unicode('none'),unicode(''),
            'None','none','',None)

    if not self.typesMatch(bunch.kind,requestedType):
        # New in 4.4: make sure the types match.
        # A serious warning: one setting may have destroyed another!
        # Important: this is not a complete test of conflicting settings:
        # The warning is given only if the code tries to access the setting.
        if warn:
            g.es_print('warning: ignoring',bunch.kind,'',setting,'is not',requestedType,color='red')
            g.es_print('there may be conflicting settings!',color='red')
        return None, False
    # elif val in (u'None',u'none','None','none','',None):
    elif isNone:
        return None, True # Exists, but is None
    else:
        # g.trace(setting,val)
        return val, True
#@+node:ekr.20051015093141: *6* typesMatch
def typesMatch (self,type1,type2):

    '''
    Return True if type1, the actual type, matches type2, the requeseted type.

    The following equivalences are allowed:

    - None matches anything.
    - An actual type of string or strings matches anything *except* shortcuts.
    - Shortcut matches shortcuts.
    '''

    shortcuts = ('shortcut','shortcuts',)

    return (
        type1 == None or type2 == None or
        type1.startswith('string') and type2 not in shortcuts or
        type1 == 'int' and type2 == 'size' or
        (type1 in shortcuts and type2 in shortcuts) or
        type1 == type2
    )
#@+node:ekr.20110904102049.15417: *4* Relative path problems
#@+node:ekr.20101022172109.6108: *5* g.scanAtPathDirectives scanAllAtPathDirectives
def scanAtPathDirectives(c,aList):

    path = c.scanAtPathDirectives(aList)
    return path

def scanAllAtPathDirectives(c,p):

    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    return path
#@+node:ekr.20080828103146.15: *5* c.scanAtPathDirectives
def scanAtPathDirectives(self,aList):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and not g.unitTesting
    verbose = True

    c = self
    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        warning = d.get('@path_in_body')
        if trace and path:
            g.trace('**** d',d)
            g.trace('**** @path path',path)
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and not warning:
                paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose:
        g.printList(paths,tag='c.scanAtPathDirectives: raw paths')

    path = c.os_path_finalize_join(*paths)

    if trace and verbose: g.trace('joined path:',path)
    if trace: g.trace('returns',path)

    return path or g.getBaseDirectory(c)
        # 2010/10/22: A useful default.
#@+node:ekr.20080922124033.6: *5* os_path_expandExpression
def os_path_expandExpression (s,**keys):

    '''Expand {{anExpression}} in c's context.'''

    trace = False
    
    s1 = s
    c = keys.get('c')
    if not c:
        g.trace('can not happen: no c',g.callers())
        return s

    if not s:
        if trace: g.trace('no s')
        return ''

    i = s.find('{{')
    j = s.find('}}')
    if -1 < i < j:
        exp = s[i+2:j].strip()
        if exp:
            try:
                import os
                import sys
                p = c.p
                d = {'c':c,'g':g,'p':p,'os':os,'sys':sys,}
                val = eval(exp,d)
                s = s[:i] + str(val) + s[j+2:]
                if trace: g.trace(s1,s)
            except Exception:
                g.trace(g.callers())
                g.es_exception(full=True, c=c, color='red')

    return s
#@+node:ekr.20080921060401.14: *5* g.os_path_finalize & os_path_finalize_join
def os_path_finalize (path,**keys):

    '''
    Expand '~', then return os.path.normpath, os.path.abspath of the path.

    There is no corresponding os.path method'''

    c = keys.get('c')

    if c: path = g.os_path_expandExpression(path,**keys)

    path = g.os_path_expanduser(path)

    return os.path.normpath(os.path.abspath(path))

def os_path_finalize_join (*args,**keys):

    '''Do os.path.join(*args), then finalize the result.'''

    c = keys.get('c')

    if c:
        args = [g.os_path_expandExpression(z,**keys)
            for z in args if z]

    return os.path.normpath(os.path.abspath(
        g.os_path_join(*args,**keys))) # Handles expanduser
#@-all

# Put this @language after the @all as a kind of permanent unit test.

#@@language python # Override the default .txt coloring.
#@-leo
