#@+leo-ver=4-thin
#@+node:EKR.20040429143933:@thin leoProjects.txt
#@+at 
#@nonl
# This part of the tree shows views of the outline related to specific 
# projects or tasks.  I put such headlines in parentheses, and that is just my 
# convention.
# 
# I create a new view by cloning headlines that relate to its task, and moving 
# the cloned headlines under the task headline.  This greatly increases my 
# focus.  Any changes made in a task view to clone headlines affect the other 
# clones scattered throughout the outline.  In particular, all @file nodes 
# containing changed clones become marked as dirty, so they will be written 
# when the entire outline is saved.
#@-at
#@@c

#@@language python 
#@@tabwidth -4

#@+all
#@+node:ekr.20080917153158.11:4.6 b2
#@+node:ekr.20090410090554.1:Proof of @shadow theorems
#@+node:ekr.20080711093251.7:readOneAtShadowNode (atFile) & helper
def readOneAtShadowNode (self,fn,p):

    at = self ; c = at.c ; x = c.shadowController

    if not fn == p.atShadowFileNodeName():
        return at.error('can not happen: fn: %s != atShadowNodeName: %s' % (
            fn, p.atShadowFileNodeName()))

    at.scanDefaultDirectory(p,importing=True) # Sets at.default_directory

    fn = c.os_path_finalize_join(at.default_directory,fn)
    shadow_fn     = x.shadowPathName(fn)
    shadow_exists = g.os_path_exists(shadow_fn) and g.os_path_isfile(shadow_fn)

    if shadow_exists:
        # at.read (via at.openFileForReading) calls x.updatePublicAndPrivateFiles.
        at.read(p,thinFile=True,atShadow=True)
    else:
        if not g.unitTesting: g.es("reading:",p.h)
        ok = at.importAtShadowNode(fn,p)
        if ok:
            # Create the private file automatically.
            at.writeOneAtShadowNode(p,toString=False,force=True)
#@+node:ekr.20080712080505.1:importAtShadowNode
def importAtShadowNode (self,fn,p):

    at = self ; c = at.c  ; ic = c.importCommands
    oldChanged = c.isChanged()

    # Delete all the child nodes.
    while p.hasChildren():
        p.firstChild().doDelete()

    # Import the outline, exactly as @auto does.
    ic.createOutline(fn,parent=p.copy(),atAuto=True,atShadow=True)

    if ic.errors:
        g.es_print('errors inhibited read @shadow',fn,color='red')

    if ic.errors or not g.os_path_exists(fn):
        p.clearDirty()
        c.setChanged(oldChanged)

    # else: g.doHook('after-shadow', p = p)

    return ic.errors == 0
#@-node:ekr.20080712080505.1:importAtShadowNode
#@-node:ekr.20080711093251.7:readOneAtShadowNode (atFile) & helper
#@+node:ekr.20080708094444.38:x.propagate_changed_lines (calls diff)
def propagate_changed_lines(self,new_public_lines,old_private_lines,marker,p=None):

    '''Propagate changes from 'new_public_lines' to 'old_private_lines.

    We compare the old and new public lines, create diffs and
    propagate the diffs to the new private lines, copying sentinels as well.

    We have two invariants:
    1. We *never* delete any sentinels.
    2. Insertions that happen at the boundary between nodes will be put at
       the end of a node.  However, insertions must always be done within sentinels.
    '''

    x = self ; trace = False ; verbose = True
    # mapping tells which line of old_private_lines each line of old_public_lines comes from.
    old_public_lines, mapping = self.strip_sentinels_with_map(old_private_lines,marker)

    << init vars >>
    << define print_tags >>

    sm = difflib.SequenceMatcher(None,old_public_lines,new_public_lines)
    prev_old_j = 0 ; prev_new_j = 0

    for tag,old_i,old_j,new_i,new_j in sm.get_opcodes():

        << About this loop >>

        # Verify that SequenceMatcher never leaves gaps.
        if old_i != prev_old_j: # assert old_i == prev_old_j
            x.error('can not happen: gap in old:',old_i,prev_old_j)
        if new_i != prev_new_j: # assert new_i == prev_new_j
            x.error('can not happen: gap in new:',new_i,prev_new_j)

        << Handle the opcode >>

        # Remember the ends of the previous tag ranges.
        prev_old_j = old_j
        prev_new_j = new_j

    # Copy all unwritten sentinels.
    self.copy_sentinels(
        old_private_lines_rdr,new_private_lines_wtr,
        marker, limit = old_private_lines_rdr.size())

    # Get the result.
    result = new_private_lines_wtr.getlines()
    if 1:
        << do final correctness check>>
    return result
#@+node:ekr.20080708094444.40:<< init vars >>
new_private_lines_wtr = sourcewriter(self)
# collects the contents of the new file.

new_public_lines_rdr = sourcereader(self,new_public_lines)
    # Contains the changed source code.

old_public_lines_rdr = sourcereader(self,old_public_lines)
    # this is compared to new_public_lines_rdr to find out the changes.

old_private_lines_rdr = sourcereader(self,old_private_lines) # lines_with_sentinels)
    # This is the file which is currently produced by Leo, with sentinels.

# Check that all ranges returned by get_opcodes() are contiguous
old_old_j, old_i2_modified_lines = -1,-1

tag = old_i = old_j = new_i = new_j = None
#@nonl
#@-node:ekr.20080708094444.40:<< init vars >>
#@+node:ekr.20080708094444.39:<< define print_tags >>
def print_tags(tag, old_i, old_j, new_i, new_j, message):

    sep1 = '=' * 10 ; sep2 = '-' * 20

    g.pr('\n',sep1,message,sep1,p and p.h)

    g.pr('\n%s: old[%s:%s] new[%s:%s]' % (tag,old_i,old_j,new_i,new_j))

    g.pr('\n',sep2)

    table = (
        (old_private_lines_rdr,'old private lines'),
        (old_public_lines_rdr,'old public lines'),
        (new_public_lines_rdr,'new public lines'),
        (new_private_lines_wtr,'new private lines'),
    )

    for f,tag in table:
        f.dump(tag)
        g.pr(sep2)


#@-node:ekr.20080708094444.39:<< define print_tags >>
#@+node:ekr.20080708192807.2:<< about this loop >>
@

This loop writes all output lines using a single writer: new_private_lines_wtr.

The output lines come from two, and *only* two readers:

1. old_private_lines_rdr delivers the complete original sources. All
   sentinels and unchanged regular lines come from this reader.

2. new_public_lines_rdr delivers the new, changed sources. All inserted or
   replacement text comes from this reader.

Each time through the loop, the following are true:

- old_i is the index into old_public_lines of the start of the present SequenceMatcher opcode.

- mapping[old_i] is the index into old_private_lines of the start of the same opcode.

At the start of the loop, the call to copy_sentinels effectively skips (deletes)
all previously unwritten non-sentinel lines in old_private_lines_rdr whose index
is less than mapping[old_i].

As a result, the opcode handlers do not need to delete elements from the
old_private_lines_rdr explicitly. This explains why opcode handlers for the
'insert' and 'delete' opcodes are identical.
#@-node:ekr.20080708192807.2:<< about this loop >>
#@+node:ekr.20080708192807.5:<< Handle the opcode >>
# Do not copy sentinels if a) we are inserting and b) limit is at the end of the old_private_lines.
# In this special case, we must do the insert before the sentinels.
limit=mapping[old_i]

if trace: g.trace(tag,'old_i',old_i,'limit',limit)

if tag == 'insert' and limit >= old_private_lines_rdr.size():
    pass
else:
    # Ignore (delete) all unwritten lines of old_private_lines_rdr up to limit.
    # Because of this, nothing has to be explicitly deleted below.
    self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)

if tag == 'equal':
    # Copy all lines (including sentinels) from the old private file to the new private file.
    start = old_private_lines_rdr.index()
    while old_private_lines_rdr.index() <= mapping[old_j-1]:
        line = old_private_lines_rdr.get()
        new_private_lines_wtr.put(line,tag='%s %s:%s' % (tag,start,mapping[old_j-1]))

    # Ignore all new lines up to new_j: the same lines (with sentinels) have just been written.
    new_public_lines_rdr.sync(new_j)

elif tag in ('insert','replace'):
    # All unwritten lines from old_private_lines_rdr up to mapping[old_i] have already been ignored.
    # Copy lines from new_public_lines_rdr up to new_j.
    start = new_public_lines_rdr.index()
    while new_public_lines_rdr.index() < new_j:
        line = new_public_lines_rdr.get()
        if x.is_sentinel(line,marker):
            new_private_lines_wtr.put('%sverbatim\n' % (marker),tag='%s %s:%s' % ('new sent',start,new_j))
        new_private_lines_wtr.put(line,tag='%s %s:%s' % (tag,start,new_j))

elif tag=='delete':
    # All unwritten lines from old_private_lines_rdr up to mapping[old_i] have already been ignored.
    # Leave new_public_lines_rdr unchanged.
    pass

else: g.trace('can not happen: unknown difflib.SequenceMather tag: %s' % repr(tag))

if trace and verbose:
    print_tags(tag, old_i, old_j, new_i, new_j, "After tag")
#@nonl
#@-node:ekr.20080708192807.5:<< Handle the opcode >>
#@+node:ekr.20080708094444.45:<< do final correctness check >>
t_sourcelines, t_sentinel_lines = self.separate_sentinels(
    new_private_lines_wtr.lines, marker)

self.check_the_final_output(
    new_private_lines   = result,
    new_public_lines    = new_public_lines,
    sentinel_lines      = t_sentinel_lines,
    marker              = marker)
#@-node:ekr.20080708094444.45:<< do final correctness check >>
#@-node:ekr.20080708094444.38:x.propagate_changed_lines (calls diff)
#@-node:ekr.20090410090554.1:Proof of @shadow theorems
#@+node:ekr.20090401105902.2:Bugs
#@+node:ekr.20090401093731.1:Fixed elisp importer problem
#@+node:ekr.20070707073859:skipBlock
def skipBlock(self,s,i,delim1=None,delim2=None):

    '''Skip from the opening delim to *past* the matching closing delim.

    If no matching is found i is set to len(s)'''

    trace = False and not g.unitTesting
    start = i
    if delim1 is None: delim1 = self.blockDelim1
    if delim2 is None: delim2 = self.blockDelim2
    match1 = g.choose(len(delim1)==1,g.match,g.match_word)
    match2 = g.choose(len(delim2)==1,g.match,g.match_word)
    assert match1(s,i,delim1)
    level = 0 ; start = i
    startIndent = self.startSigIndent
    if trace: g.trace('***','startIndent',startIndent,g.callers())
    while i < len(s):
        progress = i
        if g.is_nl(s,i):
            backslashNewline = i > 0 and g.match(s,i-1,'\\\n')
            i = g.skip_nl(s,i)
            if not backslashNewline and not g.is_nl(s,i):
                j, indent = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                line = g.get_line(s,j)
                if trace: g.trace('indent',indent,line)
                if indent < startIndent and line.strip():
                    # An non-empty underindented line.
                    # Issue an error unless it contains just the closing bracket.
                    if level == 1 and match2(s,j,delim2):
                        pass
                    else:
                        if j not in self.errorLines: # No error yet given.
                            self.errorLines.append(j)
                            self.underindentedLine(line)
        elif s[i] in (' ','\t',):
            i += 1 # speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif match1(s,i,delim1):
            level += 1 ; i += len(delim1)
        elif match2(s,i,delim2):
            level -= 1 ; i += len(delim2)
            # Skip junk following Pascal 'end'
            for z in self.blockDelim2Cruft:
                i2 = g.skip_ws(s,i)
                if g.match(s,i2,z):
                    i = i2 + len(z)
                    break
            if level <= 0:
                if trace: g.trace('returns:',repr(s[start:i]))
                return i

        else: i += 1
        assert progress < i

    self.error('no block')
    if 1:
        g.pr('** no block **')
        i,j = g.getLine(s,start)
        g.trace(i,s[i:j])
    else:
        if trace: g.trace('** no block')
    return start
#@-node:ekr.20070707073859:skipBlock
#@+node:ekr.20070711060113:class elispScanner
class elispScanner (baseScannerClass):

    @others
#@+node:ekr.20070711060113.1: __init__
def __init__ (self,importCommands,atAuto):

    # Init the base class.
    baseScannerClass.__init__(self,importCommands,atAuto=atAuto,language='elisp')

    # Set the parser delims.
    self.blockCommentDelim1 = None
    self.blockCommentDelim2 = None
    self.lineCommentDelim = ';'
    self.lineCommentDelim2 = None
    self.blockDelim1 = '('
    self.blockDelim2 = ')'
    self.extraIdChars = '-'

#@-node:ekr.20070711060113.1: __init__
#@+node:ekr.20070711060113.2:Overrides
# skipClass/Function/Signature are defined in the base class.
#@nonl
#@+node:ekr.20070711060113.3:startsClass/Function & skipSignature
def startsClass (self,unused_s,unused_i):
    '''Return True if s[i:] starts a class definition.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    return False

def startsFunction(self,s,i):
    '''Return True if s[i:] starts a function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''

    self.sigStart = i
    self.codeEnd = self.sigEnd = self.sigId = None
    if not g.match(s,i,'('): return False

    end = self.skipBlock(s,i)
    # g.trace('%3s %15s block: %s' % (i,repr(s[i:i+10]),repr(s[i:end])))
    if not g.match(s,end-1,')'): return False

    i = g.skip_ws(s,i+1)
    if not g.match_word(s,i,'defun'): return False

    i += len('defun')
    sigEnd = i = g.skip_ws_and_nl(s,i)
    j = g.skip_id(s,i)
    word = s[i:j]
    if not word: return False

    self.codeEnd = end + 1
    self.sigEnd = sigEnd
    self.sigId = word
    return True
#@-node:ekr.20070711060113.3:startsClass/Function & skipSignature
#@+node:ekr.20070711063339:startsString
def startsString(self,s,i):

    # Single quotes are not strings.
    return g.match(s,i,'"')
#@-node:ekr.20070711063339:startsString
#@-node:ekr.20070711060113.2:Overrides
#@-node:ekr.20070711060113:class elispScanner
#@-node:ekr.20090401093731.1:Fixed elisp importer problem
#@+node:ekr.20090427103358.1:Fixed back-to-home so it works as expected
@nocolor-node

https://bugs.launchpad.net/leo-editor/+bug/367462

The expected/customary behaviour (one you get used to in almost every editor) is:

End: always move to end of line
Home: Move to first visible chararacter on the line. When pressing home again, move to column zero. If Home is pressed one more time, move to first visible character again.

This is also the way emacs behaves, though ctrl+a always moves to column zero.
#@nonl
#@+node:ekr.20081123102100.1:backToHome
def backToHome (self,event):

    '''Smart home:
    Position the point at the first non-blank character on the line,
    or the start of the line if already there.''',

    w = self.editWidget(event)
    if not w: return

    s = w.getAllText()
    ins = w.getInsertPoint()
    if ins == 0 or not(s): return

    # Toggle back and forth between start of line and first-non-blank character.
    i,j = g.getLine(s,ins)
    i1 = i
    while i < j and s[i] in (' \t'):
        i += 1
    if i == ins:
        i = i1

    self.moveToHelper(event,i,extend=False)
#@-node:ekr.20081123102100.1:backToHome
#@-node:ekr.20090427103358.1:Fixed back-to-home so it works as expected
#@+node:ekr.20090428075532.1:Added patch for startup logic
@nocolor-node

Insert at beginning of the loadOnePlugin::

   if g.app.config is None:
       print "No g.app.config, making stub..."
       class StubConfig:
           def getBool(self, c, setting):
               return False
       g.app.config = StubConfig()

This hack prevents leo from crashing and allows the gui prompt for a
leoID to come up.  I think this is a better solution than asking users
to manually create the .leoID.txt file and figure out where it goes.
#@+node:ekr.20041113113140:loadOnePlugin
def loadOnePlugin (moduleOrFileName, verbose=False):

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
       print ('No g.app.config, making stub...')
       class StubConfig:
           def getBool(self, c, setting):
               return False
       g.app.config = StubConfig()

    global loadedModules,loadingModuleNameStack

    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.endswith('.py'):
        moduleName = moduleOrFileName [:-3]
    else:
        moduleName = moduleOrFileName
    moduleName = g.shortFileName(moduleName)

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if verbose:
            g.es_print('plugin',moduleName,'already loaded',color="blue")
        return module

    plugins_path = g.os_path_join(g.app.loadDir,"..","plugins")
    moduleName = g.toUnicode(moduleName,g.app.tkEncoding)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)
    result = g.importFromPath(moduleName,plugins_path,pluginName=moduleName,verbose=True)
    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)
        if hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.
            g.trace('no init()',moduleName)
            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.unitTesting or g.app.batchMode or g.app.inBridge:
        pass
    elif result is None:
        if warn_on_failure or (verbose and not g.app.initing): # or not g.app.unitTesting:
            g.es_print('can not load enabled plugin:',moduleName,color="red")
    elif verbose:
        g.es_print('loaded plugin:',moduleName,color="blue")

    return result
#@-node:ekr.20041113113140:loadOnePlugin
#@-node:ekr.20090428075532.1:Added patch for startup logic
#@+node:ekr.20090428075532.2:Fixed rst3 problem
@nocolor-node

http://mail.google.com/mail/#inbox/11ef0076a3f4d866

today I've updated my leo installation and downloaded leo from trunk.
When trying to generate a pdf document with the rst3 plugin the
following error appears in the log pane:

Traceback (most recent call last):

 File "/usr/local/src/leo-editor/leo/plugins/rst3.py", line 1244, in
writeSpecialTree
   output = self.writeToDocutils(self.source)

 File "/usr/local/src/leo-editor/leo/plugins/rst3.py", line 1344, in
writeToDocutils
   overrides.update(args)     # MWC add args to settings

ValueError: dictionary update sequence element #0 has length 13; 2 is
required

It seems that the problem comes from the node containing my
@rst_options:

@nocolor

@ @rst-options
default_path=./latex
code_mode=False
generate_rst=True
http_server_support = False
show_organizer_nodes=True
show_headlines=True
show_leo_directives=True
write_intermediate_file = False
verbose=True
publish_argv_for_missing_stylesheets=--language=ca,--use-latex-toc,--
output-encoding=utf-8,--stylesheet=/home/vmas/.leo/custom_style.sty
@c

In rst3.py, inserting a g.es_print line just before the
overrides.update(args) one can see that the arguments passed to option
publish_argv_for_missing_stylesheets are passed to the overrides
dictionary as a list:

[u'--language=ca', u'--use-latex-toc', u'--output-encoding=utf-8', u'--
stylesheet=/home/vmas/.leo/custom_style.sty']

which is neither a dictionary nor an iterable of key/value pairs so
the error is raised. Hope it helps to fix the problem.

Vicent
#@nonl
#@-node:ekr.20090428075532.2:Fixed rst3 problem
#@+node:ekr.20090507065104.1:Allocate gnx's when nodes are created
# This is reasonable now that old-style file indices are extremely rare.
#@nonl
#@+node:ekr.20031218072017.3344:v.__init__
def __init__ (self,context,t=None):

    if g.unified_nodes:
        assert t is None
    elif t is None:
        t = tnode()

    # To support ZODB the code must set v._p_changed = 1 whenever
    # v.unknownAttributes or any mutable vnode object changes.

    self.context = context # The context containing context.hiddenRootNode.
        # Required for trees, so we can compute top-level siblings.
        # It is named .context rather than .c to emphasize its limited usage.

    self.iconVal = 0
    self.parents = [] # List of all parents of this node.
        # This list will have 1 member unless the parent node is a clone.
        # In particular, cloned nodes do *not* share parents.
    self.statusBits = 0 # status bits

    if g.unified_nodes: # vnodes contain all tnode info.
        self.t = self 
        self.cloneIndex = 0 # For Pre-3.12 files.  Zero for @file nodes
        self.fileIndex = None # The immutable file index for this tnode.
        self.insertSpot = None # Location of previous insert point.
        self.scrollBarSpot = None # Previous value of scrollbar position.
        self.selectionLength = 0 # The length of the selected body text.
        self.selectionStart = 0 # The start of the selected body text.

        # Convert everything to unicode...
        if g.isPython3:
            self._headString = ''
            self._bodyString = ''
        else:
            self._headString = unicode('')
            self._bodyString = unicode('')

        self.children = [] # List of all children of this node.
        self.vnodeList = []
            # List of all vnodes pointing to this tnode.
            # v is a clone iff len(v.vnodeList) > 1.

        # New in Leo 4.6 b2: allocate gnx (fileIndex) immediately.
        self.fileIndex = g.app.nodeIndices.getNewIndex()
    else:
        self.t = t # The tnode.
#@nonl
#@-node:ekr.20031218072017.3344:v.__init__
#@+node:ekr.20031218072017.2006:t.__init__
def __init__ (self,bodyString=None,headString='NewHeadline'):

    # To support ZODB the code must set t._p_changed = 1 whenever
    # t.vnodeList, t.unknownAttributes or any mutable tnode attribute changes.

    self.cloneIndex = 0 # For Pre-3.12 files.  Zero for @file nodes
    self.fileIndex = None # The immutable file index for this tnode.
    self.insertSpot = None # Location of previous insert point.
    self.scrollBarSpot = None # Previous value of scrollbar position.
    self.selectionLength = 0 # The length of the selected body text.
    self.selectionStart = 0 # The start of the selected body text.
    self.statusBits = 0 # status bits

    # Convert everything to unicode...
    self._headString = g.toUnicode(headString,g.app.tkEncoding)
    self._bodyString = g.toUnicode(bodyString,g.app.tkEncoding)

    self.children = [] # List of all children of this node.
    self.vnodeList = []
        # List of all vnodes pointing to this tnode.
        # v is a clone iff len(v.t.vnodeList) > 1.

    # New in Leo 4.6 b2: allocate gnx (fileIndex) immediately.
    self.fileIndex = g.app.nodeIndices.getNewIndex()
#@nonl
#@-node:ekr.20031218072017.2006:t.__init__
#@+node:ekr.20070325101652:cc.createChaptersNode
def createChaptersNode (self):

    cc = self ; c = cc.c ; root = c.rootPosition()

    # Create the node with a postion method
    # so we don't involve the undo logic.
    # g.trace('root',root)
    p = root.insertAsLastChild()
    p.initHeadString('@chapters')
    p.moveToRoot(oldRoot=root)
    c.setRootPosition(p)
    cc.chaptersNode = p.copy()
    t = p.v.t

    ### t.fileIndex is now allocated immedately.
    if t.fileIndex:
        pass
        ### self.error('***** t.fileIndex already exists')
    else:
        t.setFileIndex(g.app.nodeIndices.getNewIndex())

    c.setChanged(True)
#@-node:ekr.20070325101652:cc.createChaptersNode
#@-node:ekr.20090507065104.1:Allocate gnx's when nodes are created
#@-node:ekr.20090401105902.2:Bugs
#@+node:ekr.20090401105902.3:Features
#@+node:ekr.20090307063422.2:find-clone-all as synonym for clone-find-all
#@+node:ekr.20050920084036.259:getPublicCommands (searchCommandsClass)
def getPublicCommands (self):

    return {
        'clone-find-all':                       self.cloneFindAll,
        'find-clone-all':                       self.cloneFindAll, # Synonym.

        'find-all':                             self.findAll,
        'change-all':                           self.changeAll,

        # Thin wrappers on Find tab
        'change':                               self.findTabChange,
        'change-then-find':                     self.findTabChangeThenFind,
        'find-next':                            self.findTabFindNext,
        'find-prev':                            self.findTabFindPrev,

        'hide-find-tab':                        self.hideFindTab,

        'isearch-forward':                      self.isearchForward,
        'isearch-backward':                     self.isearchBackward,
        'isearch-forward-regexp':               self.isearchForwardRegexp,
        'isearch-backward-regexp':              self.isearchBackwardRegexp,
        'isearch-with-present-options':         self.isearchWithPresentOptions,

        'open-find-tab':                        self.openFindTab,

        'replace-string':                       self.replaceString,

        're-search-forward':                    self.reSearchForward,
        're-search-backward':                   self.reSearchBackward,

        'search-again':                         self.findAgain,
        # Uses existing search pattern.

        'search-forward':                       self.searchForward,
        'search-backward':                      self.searchBackward,
        'search-with-present-options':          self.searchWithPresentOptions,
        # Prompts for search pattern.

        'set-find-everywhere':                  self.setFindScopeEveryWhere,
        'set-find-node-only':                   self.setFindScopeNodeOnly,
        'set-find-suboutline-only':             self.setFindScopeSuboutlineOnly,

        'show-find-options':                    self.showFindOptions,

        'toggle-find-collapses_nodes':          self.toggleFindCollapesNodes,

        'toggle-find-ignore-case-option':       self.toggleIgnoreCaseOption,
        'toggle-find-in-body-option':           self.toggleSearchBodyOption,
        'toggle-find-in-headline-option':       self.toggleSearchHeadlineOption,
        'toggle-find-mark-changes-option':      self.toggleMarkChangesOption,
        'toggle-find-mark-finds-option':        self.toggleMarkFindsOption,
        'toggle-find-regex-option':             self.toggleRegexOption,
        'toggle-find-reverse-option':           self.toggleReverseOption,
        'toggle-find-word-option':              self.toggleWholeWordOption,
        'toggle-find-wrap-around-option':       self.toggleWrapSearchOption,

        'word-search-forward':                  self.wordSearchForward,
        'word-search-backward':                 self.wordSearchBackward,
    }
#@-node:ekr.20050920084036.259:getPublicCommands (searchCommandsClass)
#@-node:ekr.20090307063422.2:find-clone-all as synonym for clone-find-all
#@-node:ekr.20090401105902.3:Features
#@+node:ekr.20090511055302.5784:Integrate leoRst.py into Leo
#@+node:ekr.20090512080015.5801:import-files-recursively command?
How would the command specify settings?

A line added to test bzr push.
#@-node:ekr.20090512080015.5801:import-files-recursively command?
#@+node:ekr.20090511055302.10653:Re rst3 plugin
#@+node:ekr.20050920093543:c.finishCreate & helper
def finishCreate (self,initEditCommanders=True):  # New in 4.4.

    '''Finish creating the commander after frame.finishCreate.

    Important: this is the last step in the startup process.'''

    c = self ; p = c.p
    c.miniBufferWidget = c.frame.miniBufferWidget
    # print('Commands.finishCreate',c.fileName())

    # Create a keyHandler even if there is no miniBuffer.
    c.keyHandler = c.k = k = g.app.gui.createKeyHandlerClass(c,
        useGlobalKillbuffer=True,
        useGlobalRegisters=True)

    if initEditCommanders:
        # A 'real' .leo file.
        import leo.core.leoEditCommands as leoEditCommands
        c.commandsDict = leoEditCommands.finishCreateEditCommanders(c)
        self.rstCommands.finishCreate()
        k.finishCreate()
    else:
        # A leoSettings.leo file.
        c.commandsDict = {}

    c.frame.log.finishCreate()
    c.bodyWantsFocusNow()
#@+node:ekr.20051007143620:printCommandsDict
def printCommandsDict (self):

    c = self

    print('Commands...')
    for key in sorted(c.commandsDict):
        command = c.commandsDict.get(key)
        print('%30s = %s' % (
            key,g.choose(command,command.__name__,'<None>')))
    print('')
#@-node:ekr.20051007143620:printCommandsDict
#@-node:ekr.20050920093543:c.finishCreate & helper
#@+node:ekr.20090502071837.33:class rstCommands
@
This plugin optionally stores information for the http plugin. Each node can
have one additional attribute, with the name rst_http_attributename, which is a
list. The first three elements are stack of tags, the rest is html code::

    [<tag n start>, <tag n end>, <other stack elements>, <html line 1>, <html line 2>, ...]

<other stack elements has the same structure::

    [<tag n-1 start>, <tag n-1 end>, <other stack elements>]
@c

class rstCommands:

    '''A class to write rst markup in Leo outlines.'''

    @others
#@+node:ekr.20090502071837.34: Birth & init
#@+node:ekr.20090502071837.35: ctor (rstClass)
def __init__ (self,c):

    global SilverCity

    # g.trace('rst3.py:rstClass',g.callers())

    self.c = c
    << init ivars >>

    self.createDefaultOptionsDict()
    self.initOptionsFromSettings() # Still needed.
    self.initHeadlineCommands() # Only needs to be done once.
    self.initSingleNodeOptions()
    ### self.addMenu()
#@+node:ekr.20090502071837.36:<< init ivars >>
self.silverCityWarningGiven = False

# The options dictionary.
self.optionsDict = {}
self.option_prefix = '@rst-option'

# Formatting...
self.code_block_string = ''
self.node_counter = 0
self.toplevel = 0
self.topNode = None
self.use_alternate_code_block = SilverCity is None

# Http support...
self.nodeNumber = 0
# All nodes are numbered so that unique anchors can be generated.

self.http_map = {} 
# Keys are named hyperlink targets.  Value are positions.
# The targets mark the beginning of the html code specific
# for this position.

self.anchor_map = {}
# Maps anchors (generated by this module) to positions

self.rst3_all = False
# Set to True by the button which processes all @rst trees.

# For writing.
self.defaultEncoding = 'utf-8'
self.leoDirectivesList = g.globalDirectiveList
self.encoding = self.defaultEncoding
self.ext = None # The file extension.
self.outputFileName = None # The name of the file being written.
self.outputFile = None # The open file being written.
self.path = '' # The path from any @path directive.
self.source = None # The written source as a string.
#@nonl
#@-node:ekr.20090502071837.36:<< init ivars >>
#@-node:ekr.20090502071837.35: ctor (rstClass)
#@+node:ekr.20090502071837.102: getPublicCommands
def getPublicCommands (self):        

    c = self.c

    return {
        'rst3':                 self.rst3, # Formerly write-restructured-text.
        'import-rst':           self.importRst,
        'write-at-auto-rst':    self.writeAtAutoRst
    }
#@-node:ekr.20090502071837.102: getPublicCommands
#@+node:ekr.20090502071837.37:addMenu
def addMenu (self):

    c = self.c ; editMenu = c.frame.menu.getMenu('Edit')

    def rst3PluginCallback (event=None):
        self.processTopTree(c.p)

    c.k.registerCommand('write-restructured-text',shortcut=None,
        func=rst3PluginCallback,pane='all',verbose=False)

    table = (
        ("-",None,None),
        ### ("Write Restructed Text","",rst3PluginCallback),
        '&write-restructured-text',
    )

    c.frame.menu.createMenuEntries(editMenu,table,dynamicMenu=True)
#@nonl
#@-node:ekr.20090502071837.37:addMenu
#@+node:ekr.20090511055302.5792:finishCreate
def finishCreate(self):

    c = self.c
    d = self.getPublicCommands()
    c.commandsDict.update(d)
#@-node:ekr.20090511055302.5792:finishCreate
#@+node:ekr.20090502071837.38:initHeadlineCommands
def initHeadlineCommands (self):

    '''Init the list of headline commands used by writeHeadline.'''

    self.headlineCommands = [
        self.getOption('code_prefix'),
        self.getOption('doc_only_prefix'),
        self.getOption('default_path_prefix'),
        self.getOption('rst_prefix'),
        self.getOption('ignore_headline_prefix'),
        self.getOption('ignore_headlines_prefix'),
        self.getOption('ignore_node_prefix'),
        self.getOption('ignore_tree_prefix'),
        self.getOption('option_prefix'),
        self.getOption('options_prefix'),
        self.getOption('show_headline_prefix'),
        # # Suggested by Hemanth P.S.: prevent @file nodes from creating headings.
        # self.getOption('keep_at_file_prefix'),
        # self.getOption('strip_at_file_prefix'),
    ]
#@nonl
#@-node:ekr.20090502071837.38:initHeadlineCommands
#@+node:ekr.20090502071837.39:initSingleNodeOptions
def initSingleNodeOptions (self):

    self.singleNodeOptions = [
        'ignore_this_headline',
        'ignore_this_node',
        'ignore_this_tree',
        'preformat_this_node',
        'show_this_headline',
    ]
#@nonl
#@-node:ekr.20090502071837.39:initSingleNodeOptions
#@+node:ekr.20090502071837.40:munge
def munge (self,name):

    '''Convert an option name to the equivalent ivar name.'''

    i = g.choose(name.startswith('rst'),3,0)

    while i < len(name) and name[i].isdigit():
        i += 1

    if i < len(name) and name[i] == '_':
        i += 1

    s = name[i:].lower()
    s = s.replace('-','_')

    return s
#@nonl
#@-node:ekr.20090502071837.40:munge
#@-node:ekr.20090502071837.34: Birth & init
#@+node:ekr.20090511055302.5789:commands
#@+node:ekr.20090511055302.5793:rst3
def rst3 (self,event=None):

    '''Write all @rst nodes.'''

    # This used to be the called the write-restructured-text command.

    self.processTopTree(self.c.p)
#@-node:ekr.20090511055302.5793:rst3
#@+node:ekr.20090511055302.5790:importRst
def importRst(self,event=None):

    g.trace('not ready yet')
#@-node:ekr.20090511055302.5790:importRst
#@+node:ekr.20090511055302.5791:writeAtAutoRst
def writeAtAutoRst(self,event=None):

    '''Write an @auto node assumed to contain restructured text.'''

    g.trace('not ready yet')
#@-node:ekr.20090511055302.5791:writeAtAutoRst
#@-node:ekr.20090511055302.5789:commands
#@+node:ekr.20090502071837.41:options...
#@+node:ekr.20090502071837.42:createDefaultOptionsDict
def createDefaultOptionsDict(self):

    # Warning: changing the names of options changes the names of the corresponding ivars.

    self.defaultOptionsDict = {
        # Http options...
        'rst3_clear_http_attributes':   False,
        'rst3_http_server_support':     False,
        'rst3_http_attributename':      'rst_http_attribute',
        'rst3_node_begin_marker':       'http-node-marker-',
        # Path options...
        'rst3_default_path': None, # New in Leo 4.4a4 # Bug fix: must be None, not ''.
        'rst3_stylesheet_name': 'default.css',
        'rst3_stylesheet_path': None, # Bug fix: must be None, not ''.
        'rst3_publish_argv_for_missing_stylesheets': None,
        # Global options...
        'rst3_code_block_string': '',
        'rst3_number_code_lines': True,
        'rst3_underline_characters': '''#=+*^~"'`-:><_''',
        'rst3_verbose':True,
        'rst3_write_intermediate_file': False, # Used only if generate_rst is True.
        # Mode options...
        'rst3_code_mode': False, # True: generate rst markup from @code and @doc parts.
        'rst3_doc_only_mode': False, # True: generate only from @doc parts.
        'rst3_generate_rst': True, # True: generate rst markup.  False: generate plain text.
        'rst3_generate_rst_header_comment': True,
            # True generate header comment (requires generate_rst option)
        # Formatting options that apply to both code and rst modes....
        'rst3_show_headlines': True,  # Can be set by @rst-no-head headlines.
        'rst3_show_organizer_nodes': True,
        'rst3_show_options_nodes': False,
        'rst3_show_sections': True,
        'rst3_strip_at_file_prefixes': True,
        'rst3_show_doc_parts_in_rst_mode': True,
        # Formatting options that apply only to code mode.
        'rst3_show_doc_parts_as_paragraphs': False,
        'rst3_show_leo_directives': True,
        'rst3_show_markup_doc_parts': False,
        'rst3_show_options_doc_parts': False,
        # *Names* of headline commands...
        'rst3_code_prefix':             '@rst-code',     # Enter code mode.
        'rst3_doc_only_prefix':         '@rst-doc-only', # Enter doc-only mode.
        'rst3_rst_prefix':              '@rst',          # Enter rst mode.
        'rst3_ignore_headline_prefix':  '@rst-no-head',
        'rst3_ignore_headlines_prefix': '@rst-no-headlines',
        'rst3_ignore_node_prefix':      '@rst-ignore-node',
        'rst3_ignore_prefix':           '@rst-ignore',
        'rst3_ignore_tree_prefix':      '@rst-ignore-tree',
        'rst3_option_prefix':           '@rst-option',
        'rst3_options_prefix':          '@rst-options',
        'rst3_preformat_prefix':        '@rst-preformat',
        'rst3_show_headline_prefix':    '@rst-head',
    }
#@nonl
#@-node:ekr.20090502071837.42:createDefaultOptionsDict
#@+node:ekr.20090502071837.43:dumpSettings (debugging)
def dumpSettings (self):

    d = self.optionsDict
    keys = d.keys() ; keys.sort()

    g.pr('present settings...')
    for key in keys:
        g.pr('%20s %s' % (key,d.get(key)))
#@nonl
#@-node:ekr.20090502071837.43:dumpSettings (debugging)
#@+node:ekr.20090502071837.44:getOption
def getOption (self,name):

    bwm = False
    if bwm:
        g.trace("bwm: getOption self:%s, name:%s, value:%s" % (
            self, name, self.optionsDict.get(name)))

    return self.optionsDict.get(name)
#@nonl
#@-node:ekr.20090502071837.44:getOption
#@+node:ekr.20090502071837.45:initCodeBlockString
def initCodeBlockString(self,p):

    # New in Leo 4.4.4: do this here, not in initWrite:
    c = self.c
    d = c.scanAllDirectives(p)
    language = d.get('language')
    if language is None: language = 'python'
    else: language = language.lower()
    syntax = SilverCity is not None

    # g.trace('language',language,'language.title()',language.title(),p.h)

    s = self.getOption('code_block_string')
    if s:
        self.code_block_string = s.replace('\\n','\n')
    elif syntax and language in ('python','ruby','perl','c'):
        self.code_block_string = '**code**:\n\n.. code-block:: %s\n' % language.title()
    else:
        self.code_block_string = '**code**:\n\n.. class:: code\n..\n\n::\n'
#@-node:ekr.20090502071837.45:initCodeBlockString
#@+node:ekr.20090502071837.46:preprocessTree & helpers
def preprocessTree (self,root):

    self.tnodeOptionDict = {}

    # Bug fix 12/4/05: must preprocess parents too.
    for p in root.parents_iter():
        self.preprocessNode(p)

    for p in root.self_and_subtree_iter():
        self.preprocessNode(p)

    if 0:
        g.trace(root.h)
        for key in self.tnodeOptionDict.keys():
            g.trace(key)
            g.printDict(self.tnodeOptionDict.get(key))
#@nonl
#@+node:ekr.20090502071837.47:preprocessNode
def preprocessNode (self,p):

    d = self.tnodeOptionDict.get(p.v.t)
    if d is None:
        d = self.scanNodeForOptions(p)
        self.tnodeOptionDict [p.v.t] = d
#@nonl
#@-node:ekr.20090502071837.47:preprocessNode
#@+node:ekr.20090502071837.48:parseOptionLine
def parseOptionLine (self,s):

    '''Parse a line containing name=val and return (name,value) or None.

    If no value is found, default to True.'''

    s = s.strip()
    if s.endswith(','): s = s[:-1]
    # Get name.  Names may contain '-' and '_'.
    i = g.skip_id(s,0,chars='-_')
    name = s [:i]
    if not name: return None
    j = g.skip_ws(s,i)
    if g.match(s,j,'='):
        val = s [j+1:].strip()
        # g.trace(val)
        return name,val
    else:
        # g.trace('*True')
        return name,'True'
#@nonl
#@-node:ekr.20090502071837.48:parseOptionLine
#@+node:ekr.20090502071837.49:scanForOptionDocParts
def scanForOptionDocParts (self,p,s):

    '''Return a dictionary containing all options from @rst-options doc parts in p.
    Multiple @rst-options doc parts are allowed: this code aggregates all options.
    '''

    d = {} ; n = 0 ; lines = g.splitLines(s)
    while n < len(lines):
        line = lines[n] ; n += 1
        if line.startswith('@'):
            i = g.skip_ws(line,1)
            for kind in ('@rst-options','@rst-option'):
                if g.match_word(line,i,kind):
                    # Allow options on the same line.
                    line = line[i+len(kind):]
                    d.update(self.scanOption(p,line))
                    # Add options until the end of the doc part.
                    while n < len(lines):
                        line = lines[n] ; n += 1 ; found = False
                        for stop in ('@c','@code', '@'):
                            if g.match_word(line,0,stop):
                                found = True ; break
                        if found:
                            break
                        else:
                            d.update(self.scanOption(p,line))
                    break
    return d
#@nonl
#@-node:ekr.20090502071837.49:scanForOptionDocParts
#@+node:ekr.20090502071837.50:scanHeadlineForOptions
def scanHeadlineForOptions (self,p):

    '''Return a dictionary containing the options implied by p's headline.'''

    h = p.h.strip()

    if p == self.topNode:
        return {} # Don't mess with the root node.
    elif g.match_word(h,0,self.getOption('option_prefix')): # '@rst-option'
        s = h [len(self.option_prefix):]
        return self.scanOption(p,s)
    elif g.match_word(h,0,self.getOption('options_prefix')): # '@rst-options'
        return self.scanOptions(p,p.b)
    else:
        # Careful: can't use g.match_word because options may have '-' chars.
        i = g.skip_id(h,0,chars='@-')
        word = h[0:i]

        for prefix,ivar,val in (
            ('code_prefix','code_mode',True), # '@rst-code'
            ('doc_mode_prefix','doc_only_mode',True), # @rst-doc-only.
            ('default_path_prefix','default_prefix',''), # '@rst-default-path'
            ('rst_prefix','code_mode',False), # '@rst'
            ('ignore_headline_prefix','ignore_this_headline',True), # '@rst-no-head'
            ('show_headline_prefix','show_this_headline',True), # '@rst-head'  
            ('ignore_headlines_prefix','show_headlines',False), # '@rst-no-headlines'
            ('ignore_prefix','ignore_this_tree',True),      # '@rst-ignore'
            ('ignore_node_prefix','ignore_this_node',True), # '@rst-ignore-node'
            ('ignore_tree_prefix','ignore_this_tree',True), # '@rst-ignore-tree'
            ('preformat_prefix','preformat_this_node',True), # '@rst-preformat
        ):
            prefix = self.getOption(prefix)
            if prefix and word == prefix: # Do _not_ munge this prefix!
                d = { ivar: val }
                if ivar != 'code_mode':
                    d ['code_mode'] = False # Enter rst mode.
                    d ['doc_only_mode'] = False
                # Special case: Treat a bare @rst like @rst-no-head
                if h == self.getOption('rst_prefix'):
                    d ['ignore_this_headline'] = True
                # g.trace(repr(h),repr(prefix),ivar,d)
                return d

        if h.startswith('@rst'):
            g.trace('word',word,'rst_prefix',self.getOption('rst_prefix'))
            g.trace('unknown kind of @rst headline',p.h)

        return {}
#@-node:ekr.20090502071837.50:scanHeadlineForOptions
#@+node:ekr.20090502071837.51:scanNodeForOptions
def scanNodeForOptions (self,p):

    '''Return a dictionary containing all the option-name:value entries in p.

    Such entries may arise from @rst-option or @rst-options in the headline,
    or from @ @rst-options doc parts.'''

    h = p.h

    d = self.scanHeadlineForOptions(p)

    d2 = self.scanForOptionDocParts(p,p.b)

    # A fine point: body options over-ride headline options.
    d.update(d2)

    return d
#@nonl
#@-node:ekr.20090502071837.51:scanNodeForOptions
#@+node:ekr.20090502071837.52:scanOption
def scanOption (self,p,s):

    '''Return { name:val } if s is a line of the form name=val.
    Otherwise return {}'''

    if not s.strip() or s.strip().startswith('..'): return {}

    data = self.parseOptionLine(s)

    if data:
        name,val = data
        fullName = 'rst3_' + self.munge(name)
        if fullName in self.defaultOptionsDict.keys():
            if   val.lower() == 'true': val = True
            elif val.lower() == 'false': val = False
            # g.trace('%24s %8s %s' % (self.munge(name),val,p.h))
            return { self.munge(name): val }
        else:
            g.es_print('ignoring unknown option: %s' % (name),color='red')
            return {}
    else:
        g.trace(repr(s))
        s2 = 'bad rst3 option in %s: %s' % (p.h,s)
        g.es_print(s2,color='red')
        return {}
#@nonl
#@-node:ekr.20090502071837.52:scanOption
#@+node:ekr.20090502071837.53:scanOptions
def scanOptions (self,p,s):

    '''Return a dictionary containing all the options in s.'''

    d = {}

    for line in g.splitLines(s):
        d2 = self.scanOption(p,line)
        if d2: d.update(d2)

    return d
#@nonl
#@-node:ekr.20090502071837.53:scanOptions
#@-node:ekr.20090502071837.46:preprocessTree & helpers
#@+node:ekr.20090502071837.54:scanAllOptions & helpers
# Once an option is seen, no other related options in ancestor nodes have any effect.

def scanAllOptions(self,p):

    '''Scan position p and p's ancestors looking for options,
    setting corresponding ivars.
    '''

    self.initOptionsFromSettings() # Must be done on every node.
    self.handleSingleNodeOptions(p)
    seen = self.singleNodeOptions[:] # Suppress inheritance of single-node options.

    # g.trace('-'*20)
    for p in p.self_and_parents_iter():
        d = self.tnodeOptionDict.get(p.v.t,{})
        # g.trace(p.h,d)
        for key in d.keys():
            ivar = self.munge(key)
            if not ivar in seen:
                seen.append(ivar)
                val = d.get(key)
                self.setOption(key,val,p.h)

    # self.dumpSettings()
    if self.rst3_all:
        self.setOption("generate_rst", True, "rst3_all")
        self.setOption("generate_rst_header_comment",True, "rst3_all")
        self.setOption("http_server_support", True, "rst3_all")
        self.setOption("write_intermediate_file", True, "rst3_all")
#@+node:ekr.20090502071837.55:initOptionsFromSettings
def initOptionsFromSettings (self):

    c = self.c ; d = self.defaultOptionsDict
    keys = d.keys() ; keys.sort()

    for key in keys:
        for getter,kind in (
            (c.config.getBool,'@bool'),
            (c.config.getString,'@string'),
            (d.get,'default'),
        ):
            val = getter(key)
            if kind == 'default' or val is not None:
                self.setOption(key,val,'initOptionsFromSettings')
                break
    # Special case.
    if self.getOption('http_server_support') and not mod_http:
        g.es('No http_server_support: can not import mod_http plugin',color='red')
        self.setOption('http_server_support',False)
#@-node:ekr.20090502071837.55:initOptionsFromSettings
#@+node:ekr.20090502071837.56:handleSingleNodeOptions
def handleSingleNodeOptions (self,p):

    '''Init the settings of single-node options from the tnodeOptionsDict.

    All such options default to False.'''

    d = self.tnodeOptionDict.get(p.v.t, {} )

    for ivar in self.singleNodeOptions:
        val = d.get(ivar,False)
        #g.trace('%24s %8s %s' % (ivar,val,p.h))
        self.setOption(ivar,val,p.h)

#@-node:ekr.20090502071837.56:handleSingleNodeOptions
#@-node:ekr.20090502071837.54:scanAllOptions & helpers
#@+node:ekr.20090502071837.57:setOption
def setOption (self,name,val,tag):

    ivar = self.munge(name)

    bwm = False
    if bwm:
        if not self.optionsDict.has_key(ivar):
            g.trace('init %24s %20s %s %s' % (ivar, val, tag, self))
        elif self.optionsDict.get(ivar) != val:
            g.trace('set  %24s %20s %s %s' % (ivar, val, tag, self))

    self.optionsDict [ivar] = val
#@nonl
#@-node:ekr.20090502071837.57:setOption
#@-node:ekr.20090502071837.41:options...
#@+node:ekr.20090502071837.58:write methods
#@+node:ekr.20090502071837.59: Top-level write code
#@+node:ekr.20090502071837.60:initWrite
def initWrite (self,p,encoding=None):

    self.initOptionsFromSettings() # Still needed.

    # Set the encoding from any parent @encoding directive.
    # This can be overridden by @rst-option encoding=whatever.
    c = self.c
    d = c.scanAllDirectives(p)
    self.encoding = encoding or d.get('encoding') or self.defaultEncoding
    self.path = d.get('path') or ''

    # g.trace('path:',self.path)
#@-node:ekr.20090502071837.60:initWrite
#@+node:ekr.20090502071837.61:writeNormalTree
def writeNormalTree (self,p,toString=False):

    self.initWrite(p)

    # Always write to a string first.
    self.outputFile = StringIO.StringIO()
    self.writeTree(p)
    self.source = self.stringOutput = self.outputFile.getvalue()

    # Copy to a file if requested.
    if not toString:
        # Comput the output file name *after* calling writeTree.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)
        self.outputFile = open(self.outputFileName,'w')
        self.outputFile.write(self.stringOutput)
        self.outputFile.close()

    return True
#@-node:ekr.20090502071837.61:writeNormalTree
#@+node:ekr.20090502071837.62:processTopTree
def processTopTree (self,p,justOneFile=False):

    c = self.c ; current = p.copy()

    for p in current.self_and_parents_iter():
        h = p.h
        if h.startswith('@rst') and not h.startswith('@rst-'):
            self.processTree(p,ext=None,toString=False,justOneFile=justOneFile)
            break
    else:
        self.processTree(current,ext=None,toString=False,justOneFile=justOneFile)

    g.es_print('done',color='blue')
#@nonl
#@-node:ekr.20090502071837.62:processTopTree
#@+node:ekr.20090502071837.63:processTree
def processTree(self,p,ext,toString,justOneFile):

    '''Process all @rst nodes in a tree.'''

    self.preprocessTree(p)
    found = False ; self.stringOutput = ''
    p = p.copy() ; after= p.nodeAfterTree()
    while p and p != after:
        h = p.h.strip()
        if g.match_word(h,0,"@rst"):
            self.outputFileName = h[4:].strip()
            if (
                (self.outputFileName and self.outputFileName[0] != '-') or
                (toString and not self.outputFileName)
            ):
                found = True
                self.toplevel = p.level() # Define toplevel separately for each rst file.
                if toString:
                    self.ext = ext
                else:
                    self.ext = g.os_path_splitext(self.outputFileName)[1].lower()
                # g.trace('ext',self.ext,self.outputFileName)
                if self.ext in ('.htm','.html','.tex','.pdf'):
                    ok = self.writeSpecialTree(p,toString=toString,justOneFile=justOneFile)
                else:
                    ok = self.writeNormalTree(p,toString=toString)
                self.scanAllOptions(p) # Restore the top-level verbose setting.
                if toString:
                    return p.copy(),self.stringOutput
                else:
                    if ok: self.report(self.outputFileName)
                p.moveToNodeAfterTree()
            else:
                p.moveToThreadNext()
        else: p.moveToThreadNext()
    if not found:
        g.es('No @rst nodes in selected tree',color='blue')
    return None,None
#@-node:ekr.20090502071837.63:processTree
#@+node:ekr.20090502071837.64:writeSpecialTree
def writeSpecialTree (self,p,toString,justOneFile):

    c = self.c
    isHtml = self.ext in ('.html','.htm')
    if isHtml and not SilverCity:
        if not self.silverCityWarningGiven:
            self.silverCityWarningGiven = True
            g.es('SilverCity not present so no syntax highlighting')

    self.initWrite(p,encoding=g.choose(isHtml,'utf-8','iso-8859-1'))
    self.outputFile = StringIO.StringIO()
    self.writeTree(p)
    self.source = self.outputFile.getvalue()
    self.outputFile = None

    if not toString:
        # Compute this here for use by intermediate file.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)

        # Create the directory if it doesn't exist.
        theDir, junk = g.os_path_split(self.outputFileName)
        theDir = c.os_path_finalize(theDir)
        if not g.os_path_exists(theDir):
            ok = g.makeAllNonExistentDirectories(theDir,c=c,force=False)
            if not ok:
                g.es_print('did not create:',theDir,color='red')
                return False

        # if not os.access(theDir,os.F_OK):
            # os.mkdir(theDir)

        if self.getOption('write_intermediate_file'):
            name = self.outputFileName + '.txt'
            f = open(name,'w')
            f.write(self.source)
            f.close()
            self.report(name)

    try:
        output = self.writeToDocutils(self.source)
        ok = True
    except Exception:
        g.pr('Exception in docutils')
        g.es_exception()
        ok = False

    if ok:
        if isHtml:
            import re
            idxTitle = output.find('<title></title>')
            if idxTitle > -1:
                m = re.search('<h1>([^<]*)</h1>', output)
                if not m:
                    m = re.search('<h1><[^>]+>([^<]*)</a></h1>', output)
                if m:
                    output = output.replace(
                        '<title></title>',
                        '<title>%s</title>' % m.group(1)
                    )


        if toString:
            self.stringOutput = output
        else:
            # Write the file to the directory containing the .leo file.
            f = open(self.outputFileName,'w')
            f.write(output)
            f.close()
            self.http_endTree(self.outputFileName, p, justOneFile=justOneFile)

    return ok
#@-node:ekr.20090502071837.64:writeSpecialTree
#@+node:ekr.20090502071837.65:writeToDocutils (sets argv) & helper
def writeToDocutils (self,s):

    '''Send s to docutils using the writer implied by self.ext and return the result.'''

    openDirectory = self.c.frame.openDirectory
    overrides = {'output_encoding': self.encoding }

    # Compute the args list if the stylesheet path does not exist.
    styleSheetArgsDict = self.handleMissingStyleSheetArgs()

    for ext,writer in (
        ('.html','html'),
        ('.htm','html'),
        ('.tex','latex'),
        ('.pdf','leo_pdf'),
    ):
        if self.ext == ext:
            break
    else:
        g.es_print('unknown docutils extension: %s' % (self.ext),color='red')
        return ''

    # Make the stylesheet path relative to the directory containing the output file.
    rel_stylesheet_path = self.getOption('stylesheet_path') or ''

    # New in Leo 4.5: The rel_stylesheet_path is relative to the open directory.
    stylesheet_path = g.os_path_finalize_join(
        self.c.frame.openDirectory,rel_stylesheet_path)

    path = g.os_path_finalize_join(
        stylesheet_path,self.getOption('stylesheet_name'))

    res = ""
    if g.os_path_exists(path):
        if self.ext != '.pdf':
            overrides['stylesheet'] = path
            overrides['stylesheet_path'] = None
    elif styleSheetArgsDict:
        g.es_print('using publish_argv_for_missing_stylesheets',
            styleSheetArgsDict)
        overrides.update(styleSheetArgsDict)
            # MWC add args to settings
    elif rel_stylesheet_path == stylesheet_path:
        g.es_print('stylesheet not found: %s' % (path),color='red')
    else:
        g.es_print('stylesheet not found\n',path,color='red')
        if self.path:g.es_print('@path:', self.path)
        g.es_print('open path:',self.c.frame.openDirectory)
        if rel_stylesheet_path:
            g.es_print('relative path:', rel_stylesheet_path)
    try:
        # All paths now come through here.
        res = docutils.core.publish_string(source=s,
                reader_name='standalone',
                parser_name='restructuredtext',
                writer_name=writer,
                settings_overrides=overrides)
    except docutils.ApplicationError, error:
        g.es_print('Error (%s): %s' % (error.__class__.__name__, error))
    return res
#@+node:ekr.20090502071837.66:handleMissingStyleSheetArgs
def handleMissingStyleSheetArgs (self,s=None):

    '''Parse the publish_argv_for_missing_stylesheets option,
    returning a dict containing the parsed args.'''

    d = {}
    if not s:
        s = self.getOption('publish_argv_for_missing_stylesheets')
    if not s: return d

    args = s.strip()
    if args.find(',') == -1:
        args = [args]
    else:
        args = args.split(',')

    for arg in args:
        data = arg.split('=')
        if len(data) == 1:
            key = data[0]
            d[str(key)] = ""
        elif len(data) == 2:
            key,value = data
            d[str(key)] = str(value)
        else:
            g.es_print('bad option: %s' % s,color='red')
            break

    return d
#@-node:ekr.20090502071837.66:handleMissingStyleSheetArgs
#@-node:ekr.20090502071837.65:writeToDocutils (sets argv) & helper
#@+node:ekr.20090502071837.67:writeNodeToString (New in 4.4.1)
def writeNodeToString (self,p=None,ext=None):

    '''Scan p's tree (defaults to presently selected tree) looking for @rst nodes.
    Convert the first node found to an ouput of the type specified by ext.

    The @rst may or may not be followed by a filename; the filename is *ignored*,
    and its type does not affect ext or the output generated in any way.

    ext should start with a period:  .html, .tex or None (specifies rst output).

    Returns p, s, where p is the position of the @rst node and s is the converted text.'''

    c = self.c ; current = p or c.p

    for p in current.self_and_parents_iter():
        if p.h.startswith('@rst'):
            return self.processTree(p,ext=ext,toString=True,justOneFile=True)
    else:
        return self.processTree(current,ext=ext,toString=True,justOneFile=True)
#@nonl
#@-node:ekr.20090502071837.67:writeNodeToString (New in 4.4.1)
#@-node:ekr.20090502071837.59: Top-level write code
#@+node:ekr.20090502071837.68:getDocPart
def getDocPart (self,lines,n):

    # g.trace('n',n,repr(''.join(lines)))

    result = []
    << Append whatever follows @doc or @space to result >>
    while n < len(lines):
        s = lines [n] ; n += 1
        if g.match_word(s,0,'@code') or g.match_word(s,0,'@c'):
            break
        result.append(s)
    return n, result
#@nonl
#@+node:ekr.20090502071837.69:<< Append whatever follows @doc or @space to result >>
if n > 0:
    line = lines[n-1]
    if line.startswith('@doc'):
        s = line[4:].lstrip()
    elif line.startswith('@'):
        s = line[1:].lstrip()
    else:
        s = ''

    # New in Leo 4.4.4: remove these special tags.
    for tag in ('@rst-options','@rst-option','@rst-markup'):
        if g.match_word(s,0,tag):
            s = s[len(tag):].strip()

    if s.strip():
        result.append(s)
#@-node:ekr.20090502071837.69:<< Append whatever follows @doc or @space to result >>
#@-node:ekr.20090502071837.68:getDocPart
#@+node:ekr.20090502071837.70:skip_literal_block
def skip_literal_block (self,lines,n):

    s = lines[n] ; result = [s] ; n += 1
    indent = g.skip_ws(s,0)

    # Skip lines until a non-blank line is found with same or less indent.
    while n < len(lines):
        s = lines[n]
        indent2 = g.skip_ws(s,0)
        if s and not s.isspace() and indent2 <= indent:
            break # We will rescan lines [n]
        n += 1
        result.append(s)

    # g.printList(result,tag='literal block')
    return n, result
#@nonl
#@-node:ekr.20090502071837.70:skip_literal_block
#@+node:ekr.20090502071837.71:writeBody & helpers
def writeBody (self,p):

    # remove trailing cruft and split into lines.
    lines = p.b.rstrip().split('\n') 

    if self.getOption('code_mode'):
        if not self.getOption('show_options_doc_parts'):
            lines = self.handleSpecialDocParts(lines,'@rst-options',
                retainContents=False)
        if not self.getOption('show_markup_doc_parts'):
            lines = self.handleSpecialDocParts(lines,'@rst-markup',
                retainContents=False)
        if not self.getOption('show_leo_directives'):
            lines = self.removeLeoDirectives(lines)
        lines = self.handleCodeMode(lines)
    elif self.getOption('doc_only_mode'):
        # New in version 1.15
        lines = self.handleDocOnlyMode(p,lines)
    else:
        lines = self.handleSpecialDocParts(lines,'@rst-options',
            retainContents=False)
        lines = self.handleSpecialDocParts(lines,'@rst-markup',
            retainContents=self.getOption('generate_rst'))
        if self.getOption('show_doc_parts_in_rst_mode') is True:
            pass  # original behaviour, treat as plain text
        elif self.getOption('show_doc_parts_in_rst_mode'):
            # use value as class for content
            lines = self.handleSpecialDocParts(lines,None,
                retainContents=True, asClass=self.getOption('show_doc_parts_in_rst_mode'))
        else:  # option evaluates to false, cut them out
            lines = self.handleSpecialDocParts(lines,None,
                retainContents=False)
        lines = self.removeLeoDirectives(lines)
        if self.getOption('generate_rst') and self.getOption('use_alternate_code_block'):
            lines = self.replaceCodeBlockDirectives(lines)

    s = '\n'.join(lines).strip()
    if s:
        self.write('%s\n\n' % s)
#@+node:ekr.20090502071837.72:handleCodeMode & helper
def handleCodeMode (self,lines):

    '''Handle the preprocessed body text in code mode as follows:

    - Blank lines are copied after being cleaned.
    - @ @rst-markup lines get copied as is.
    - Everything else gets put into a code-block directive.'''

    result = [] ; n = 0 ; code = []
    while n < len(lines):
        s = lines [n] ; n += 1
        if (
            self.isSpecialDocPart(s,'@rst-markup') or
            (self.getOption('show_doc_parts_as_paragraphs') and self.isSpecialDocPart(s,None))
        ):
            if code:
                self.finishCodePart(result,code)
                code = []
            result.append('')
            n, lines2 = self.getDocPart(lines,n)
            result.extend(lines2)
        elif not s.strip() and not code:
            pass # Ignore blank lines before the first code block.
        elif not code: # Start the code block.
            result.append('')
            result.append(self.code_block_string)
            code.append(s)
        else: # Continue the code block.
            code.append(s)

    if code:
        self.finishCodePart(result,code)
        code = []
    return self.rstripList(result)
#@nonl
#@+node:ekr.20090502071837.73:formatCodeModeLine
def formatCodeModeLine (self,s,n,numberOption):

    if not s.strip(): s = ''

    if numberOption:
        return '\t%d: %s' % (n,s)
    else:
        return '\t%s' % s
#@nonl
#@-node:ekr.20090502071837.73:formatCodeModeLine
#@+node:ekr.20090502071837.74:rstripList
def rstripList (self,theList):

    '''Removed trailing blank lines from theList.'''

    s = '\n'.join(theList).rstrip()
    return s.split('\n')
#@nonl
#@-node:ekr.20090502071837.74:rstripList
#@+node:ekr.20090502071837.75:finishCodePart
def finishCodePart (self,result,code):

    numberOption = self.getOption('number_code_lines')
    code = self.rstripList(code)
    i = 0
    for line in code:
        i += 1
        result.append(self.formatCodeModeLine(line,i,numberOption))
#@nonl
#@-node:ekr.20090502071837.75:finishCodePart
#@-node:ekr.20090502071837.72:handleCodeMode & helper
#@+node:ekr.20090502071837.76:handleDocOnlyMode
def handleDocOnlyMode (self,p,lines):

    '''Handle the preprocessed body text in doc_only mode as follows:

    - Blank lines are copied after being cleaned.
    - @ @rst-markup lines get copied as is.
    - All doc parts get copied.
    - All code parts are ignored.'''

    ignore              = self.getOption('ignore_this_headline')
    showHeadlines       = self.getOption('show_headlines')
    showThisHeadline    = self.getOption('show_this_headline')
    showOrganizers      = self.getOption('show_organizer_nodes')

    result = [] ; n = 0
    while n < len(lines):
        s = lines [n] ; n += 1
        if self.isSpecialDocPart(s,'@rst-options'):
            n, lines2 = self.getDocPart(lines,n) # ignore.
        elif self.isAnyDocPart(s):
            # Handle any other doc part, including @rst-markup.
            n, lines2 = self.getDocPart(lines,n)
            if lines2: result.extend(lines2)
    if not result: result = []
    if showHeadlines:
        if result or showThisHeadline or showOrganizers or p == self.topNode:
            # g.trace(len(result),p.h)
            self.writeHeadlineHelper(p)
    return result
#@nonl
#@-node:ekr.20090502071837.76:handleDocOnlyMode
#@+node:ekr.20090502071837.77:isAnyDocPart
def isAnyDocPart (self,s):

    if s.startswith('@doc'):
        return True
    elif not s.startswith('@'):
        return False
    else:
        return len(s) == 1 or s[1].isspace()
#@nonl
#@-node:ekr.20090502071837.77:isAnyDocPart
#@+node:ekr.20090502071837.78:isSpecialDocPart
def isSpecialDocPart (self,s,kind):

    '''Return True if s is a special doc part of the indicated kind.

    If kind is None, return True if s is any doc part.'''

    if s.startswith('@') and len(s) > 1 and s[1].isspace():
        if kind:
            i = g.skip_ws(s,1)
            result = g.match_word(s,i,kind)
        else:
            result = True
    elif not kind:
        result = g.match_word(s,0,'@doc') or g.match_word(s,0,'@')
    else:
        result = False

    return result
#@nonl
#@-node:ekr.20090502071837.78:isSpecialDocPart
#@+node:ekr.20090502071837.79:isAnySpecialDocPart
def isAnySpecialDocPart (self,s):

    for kind in (
        '@rst-markup',
        '@rst-option',
        '@rst-options',
    ):
        if self.isSpecialDocPart(s,kind):
            return True

    return False
#@-node:ekr.20090502071837.79:isAnySpecialDocPart
#@+node:ekr.20090502071837.80:removeLeoDirectives
def removeLeoDirectives (self,lines):

    '''Remove all Leo directives, except within literal blocks.'''

    n = 0 ; result = []
    while n < len(lines):
        s = lines [n] ; n += 1
        if s.strip().endswith('::'):
            n, lit = self.skip_literal_block(lines,n-1)
            result.extend(lit)
        elif s.startswith('@') and not self.isAnySpecialDocPart(s):
            for key in self.leoDirectivesList:
                if g.match_word(s,0,key):
                    # g.trace('removing %s' % s)
                    break
            else:
                result.append(s)
        else:
            result.append(s)

    return result
#@nonl
#@-node:ekr.20090502071837.80:removeLeoDirectives
#@+node:ekr.20090502071837.81:handleSpecialDocParts
def handleSpecialDocParts (self,lines,kind,retainContents,asClass=None):

    # g.trace(kind,g.listToString(lines))

    result = [] ; n = 0
    while n < len(lines):
        s = lines [n] ; n += 1
        if s.strip().endswith('::'):
            n, lit = self.skip_literal_block(lines,n-1)
            result.extend(lit)
        elif self.isSpecialDocPart(s,kind):
            n, lines2 = self.getDocPart(lines,n)
            if retainContents:
                result.extend([''])
                if asClass:
                    result.extend(['.. container:: '+asClass, ''])
                    if 'literal' in asClass.split():
                        result.extend(['  ::', ''])
                    for l2 in lines2: result.append('    '+l2)
                else:
                    result.extend(lines2)
                result.extend([''])
        else:
            result.append(s)

    return result
#@-node:ekr.20090502071837.81:handleSpecialDocParts
#@+node:ekr.20090502071837.82:replaceCodeBlockDirectives
def replaceCodeBlockDirectives (self,lines):

    '''Replace code-block directive, but not in literal blocks.'''

    n = 0 ; result = []
    while n < len(lines):
        s = lines [n] ; n += 1
        if s.strip().endswith('::'):
            n, lit = self.skip_literal_block(lines,n-1)
            result.extend(lit)
        else:
            i = g.skip_ws(s,0)
            if g.match(s,i,'..'):
                i = g.skip_ws(s,i+2)
                if g.match_word(s,i,'code-block'):
                    if 1: # Create a literal block to hold the code.
                        result.append('::\n')
                    else: # This 'annotated' literal block is confusing.
                        result.append('%s code::\n' % s[i+len('code-block'):])
                else:
                    result.append(s)
            else:
                result.append(s)

    return result
#@nonl
#@-node:ekr.20090502071837.82:replaceCodeBlockDirectives
#@-node:ekr.20090502071837.71:writeBody & helpers
#@+node:ekr.20090502071837.83:writeHeadline & helper
def writeHeadline (self,p):

    '''Generate an rST section if options permit it.
    Remove headline commands from the headline first,
    and never generate an rST section for @rst-option and @rst-options.'''

    docOnly             =  self.getOption('doc_only_mode')
    ignore              = self.getOption('ignore_this_headline')
    showHeadlines       = self.getOption('show_headlines')
    showThisHeadline    = self.getOption('show_this_headline')
    showOrganizers      = self.getOption('show_organizer_nodes')

    if (
        p == self.topNode or
        ignore or
        docOnly or # handleDocOnlyMode handles this.
        not showHeadlines and not showThisHeadline or
        # docOnly and not showOrganizers and not thisHeadline or
        not p.h.strip() and not showOrganizers or
        not p.b.strip() and not showOrganizers
    ):
        return

    self.writeHeadlineHelper(p)
#@nonl
#@+node:ekr.20090502071837.84:writeHeadlineHelper
def writeHeadlineHelper (self,p):

    h = p.h.strip()

    # Remove any headline command before writing the 
    i = g.skip_id(h,0,chars='@-')
    word = h [:i]
    if word:
        # Never generate a section for @rst-option or @rst-options.
        if word in (self.getOption('option_prefix'),self.getOption('options_prefix')):
            return
        # Remove all other headline commands from the headline.
        for prefix in self.headlineCommands:
            if word == prefix:
                h = h [len(word):].strip()
                break

        # New in Leo 4.4.4.
        if word.startswith('@'):
            if self.getOption('strip_at_file_prefixes'):
                for s in ('@auto','@file','@nosent','@thin',):
                    if g.match_word(word,0,s):
                        h = h [len(s):].strip()

    if not h.strip(): return

    if self.getOption('show_sections'):
        if self.getOption('generate_rst'):
            self.write('%s\n%s\n' % (h,self.underline(h,p)))
        else:
            self.write('\n%s\n' % h)
    else:
        self.write('\n**%s**\n\n' % h.replace('*',''))
#@-node:ekr.20090502071837.84:writeHeadlineHelper
#@-node:ekr.20090502071837.83:writeHeadline & helper
#@+node:ekr.20090502071837.85:writeNode
def writeNode (self,p):

    '''Format a node according to the options presently in effect.'''

    self.initCodeBlockString(p)
    self.scanAllOptions(p)

    if 0:
        g.trace('%24s code_mode %s' % (p.h,self.getOption('code_mode')))

    h = p.h.strip()

    if self.getOption('preformat_this_node'):
        self.http_addNodeMarker(p)
        self.writePreformat(p)
        p.moveToThreadNext()
    elif self.getOption('ignore_this_tree'):
        p.moveToNodeAfterTree()
    elif self.getOption('ignore_this_node'):
        p.moveToThreadNext()
    elif g.match_word(h,0,'@rst-options') and not self.getOption('show_options_nodes'):
        p.moveToThreadNext()
    else:
        self.http_addNodeMarker(p)
        self.writeHeadline(p)
        self.writeBody(p)
        p.moveToThreadNext()
#@-node:ekr.20090502071837.85:writeNode
#@+node:ekr.20090502071837.86:writePreformat
def writePreformat (self,p):

    '''Write p's body text lines as if preformatted.

     ::

        line 1
        line 2 etc.
    '''

    # g.trace(p.h,g.callers())

    lines = p.b.split('\n')
    lines = [' '*4 + z for z in lines]
    lines.insert(0,'::\n')

    s = '\n'.join(lines)
    if s.strip():
        self.write('%s\n\n' % s)
#@-node:ekr.20090502071837.86:writePreformat
#@+node:ekr.20090502071837.87:writeTree
def writeTree(self,p):

    '''Write p's tree to self.outputFile.'''

    self.scanAllOptions(p)

    # g.trace(self.getOption('generate_rst_header_comment'))

    if self.getOption('generate_rst'):
        if self.getOption('generate_rst_header_comment'):
            self.write(self.rstComment(
                'rst3: filename: %s\n\n' % self.outputFileName))

    # We can't use an iterator because we may skip parts of the tree.
    p = p.copy() # Only one copy is needed for traversal.
    self.topNode = p.copy() # Indicate the top of this tree.
    after = p.nodeAfterTree()

    while p and p != after:
        self.writeNode(p)
#@-node:ekr.20090502071837.87:writeTree
#@-node:ekr.20090502071837.58:write methods
#@+node:ekr.20090502071837.88:Utils
#@+node:ekr.20090502071837.89:computeOutputFileName
def computeOutputFileName (self,fileName):

    openDirectory = self.c.frame.openDirectory
    default_path = self.getOption('default_path')

    if default_path:
        path = g.os_path_finalize_join(self.path,default_path,fileName)
    elif self.path:
        path = g.os_path_finalize_join(self.path,fileName)
    elif openDirectory:
        path = g.os_path_finalize_join(self.path,openDirectory,fileName)
    else:
        path = g.os_path_finalize_join(fileName)

    return path
#@nonl
#@-node:ekr.20090502071837.89:computeOutputFileName
#@+node:ekr.20090502071837.90:encode
def encode (self,s):

    return g.toEncodedString(s,encoding=self.encoding,reportErrors=True)
#@nonl
#@-node:ekr.20090502071837.90:encode
#@+node:ekr.20090502071837.91:report
def report (self,name):

    if self.getOption('verbose'):

        name = g.os_path_finalize(name)

        g.es_print('wrote: %s' % (name),color="blue")
#@nonl
#@-node:ekr.20090502071837.91:report
#@+node:ekr.20090502071837.92:rstComment
def rstComment (self,s):

    return '.. %s' % s
#@nonl
#@-node:ekr.20090502071837.92:rstComment
#@+node:ekr.20090502071837.93:underline
def underline (self,s,p):

    '''Return the underlining string to be used at the given level for string s.'''

    u = self.getOption('underline_characters') #  '''#=+*^~"'`-:><_'''

    level = max(0,p.level()-self.toplevel)
    level = min(level+1,len(u)-1) # Reserve the first character for explicit titles.

    ch = u [level]

    # g.trace(self.toplevel,p.level(),level,repr(ch),p.h)

    n = max(4,len(s))

    return ch * n + '\n'
#@nonl
#@-node:ekr.20090502071837.93:underline
#@+node:ekr.20090502071837.94:write
def write (self,s):

    s = self.encode(s)

    self.outputFile.write(s)
#@nonl
#@-node:ekr.20090502071837.94:write
#@-node:ekr.20090502071837.88:Utils
#@+node:ekr.20090502071837.95:Support for http plugin
#@+node:ekr.20090502071837.96:http_addNodeMarker
def http_addNodeMarker (self,p):

    if (
        self.getOption('http_server_support') and
        self.getOption('generate_rst')
    ):
        self.nodeNumber += 1
        anchorname = "%s%s" % (self.getOption('node_begin_marker'),self.nodeNumber)
        s = "\n\n.. _%s:\n\n" % anchorname
        self.write(s)
        self.http_map [anchorname] = p.copy()
        # if bwm_file: print >> bwm_file, "addNodeMarker", anchorname, p
#@nonl
#@-node:ekr.20090502071837.96:http_addNodeMarker
#@+node:ekr.20090502071837.97:http_endTree & helpers
# Was http_support_main

def http_endTree (self,filename,p,justOneFile):

    '''Do end-of-tree processing to support the http plugin.'''

    if (
        self.getOption('http_server_support') and
        self.getOption('generate_rst')
    ):
        self.set_initial_http_attributes(filename)
        self.find_anchors(p)
        if justOneFile:
            self.relocate_references(p.self_and_subtree_iter)

        g.es_print('html updated for http plugin',color="blue")

        if self.getOption('clear_http_attributes'):
            g.es_print("http attributes cleared")
#@nonl
#@+node:ekr.20090502071837.98:set_initial_http_attributes
def set_initial_http_attributes (self,filename):

    f = open(filename)
    parser = htmlParserClass(self)

    for line in f.readlines():
        parser.feed(line)

    f.close()
#@nonl
#@-node:ekr.20090502071837.98:set_initial_http_attributes
#@+node:ekr.20090502071837.99:find_anchors
def find_anchors (self, p):

    '''Find the anchors in all the nodes.'''

    for p1, attrs in self.http_attribute_iter(p):
        html = mod_http.reconstruct_html_from_attrs(attrs)
        # g.trace(pprint.pprint(html))
        parser = anchor_htmlParserClass(self, p1)
        for line in html:
            try:
                parser.feed(line)
            # bwm: changed to unicode(line)
            except:
                line = ''.join([ch for ch in line if ord(ch) <= 127])
                # filter out non-ascii characters.
                # bwm: not quite sure what's going on here.
                parser.feed(line)        
    # g.trace(g.dictToString(self.anchor_map,tag='anchor_map'))
#@nonl
#@-node:ekr.20090502071837.99:find_anchors
#@+node:ekr.20090502071837.100:relocate_references
@ Relocate references here if we are only running for one file.

Otherwise we must postpone the relocation until we have processed all files.
@c

def relocate_references (self, iterator_generator):

    for p in iterator_generator():
        attr = mod_http.get_http_attribute(p)
        if not attr:
            continue
        # g.trace('before',p.h,attr)
        # if bwm_file:
            # print >> bwm_file
            # print >> bwm_file, "relocate_references(1): Position, attr:"
            # pprint.pprint((p, attr), bwm_file)
        http_lines = attr [3:]
        parser = link_htmlparserClass(self,p)
        for line in attr [3:]:
            try:
                parser.feed(line)
            except:
                line = ''.join([ch for ch in line if ord(ch) <= 127])
                parser.feed(line)
        replacements = parser.get_replacements()
        replacements.reverse()
        if not replacements:
            continue
        # if bwm_file:
            # print >> bwm_file, "relocate_references(2): Replacements:"
            # pprint.pprint(replacements, bwm_file)
        for line, column, href, href_file, http_node_ref in replacements:
            # if bwm_file: 
                # print >> bwm_file, "relocate_references(3): line:", line,
                # "Column:", column, "href:", href, "href_file:",
                # href_file, "http_node_ref:", http_node_ref
            marker_parts = href.split("#")
            if len(marker_parts) == 2:
                marker = marker_parts [1]
                replacement = u"%s#%s" % (http_node_ref,marker)
                try:
                    attr [line + 2] = attr [line + 2].replace(u'href="%s"' % href, u'href="%s"' % replacement)
                except:
                    g.es("Skipped ", attr[line + 2])
            else:
                filename = marker_parts [0]
                try:
                    attr [line + 2] = attr [line + 2].replace(u'href="%s"' % href,u'href="%s"' % http_node_ref)
                except:
                    g.es("Skipped", attr[line+2])
    # g.trace('after %s\n\n\n',attr)
#@nonl
#@-node:ekr.20090502071837.100:relocate_references
#@+node:ekr.20090502071837.101:http_attribute_iter
def http_attribute_iter (self, p):
    """
    Iterator for all the nodes which have html code.
    Look at the descendents of p.
    Used for relocation.
    """

    for p1 in p.self_and_subtree_iter():
        attr = mod_http.get_http_attribute(p1)
        if attr:
            yield (p1.copy(),attr)
#@nonl
#@-node:ekr.20090502071837.101:http_attribute_iter
#@-node:ekr.20090502071837.97:http_endTree & helpers
#@-node:ekr.20090502071837.95:Support for http plugin
#@-node:ekr.20090502071837.33:class rstCommands
#@-node:ekr.20090511055302.10653:Re rst3 plugin
#@+node:ekr.20090511055302.10652:Support @auto for general rST files
@nocolor-node

* How can we test @auto-rst with minimal changes?
    - *Temporily* add support for import-rst-file or @auto-rst.
      Should this command be in leoRst.py?  leoAtFile.py?, leoImport.py?

* Add language keyword arg to createOutline.

* Add support for @ua to read/writeOneAtAutoNode.
    - isSignificant should ignore @ua lines?

- @ua at-auto:language=rest
  This should override the parser given by the file extension.
#@nonl
#@+node:ekr.20070909100252:readOneAtAutoNode (atFile)
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    if not g.unitTesting:
        g.es("reading:",p.h)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        #c.setBodyString(p,'')
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@-node:ekr.20070909100252:readOneAtAutoNode (atFile)
#@+node:ekr.20031218072017.3210:createOutline (leoImport)
def createOutline (self,fileName,parent,
    atAuto=False,atShadow=False,s=None,ext=None):

    c = self.c ; u = c.undoer ; s1 = s

    # New in Leo 4.4.7: honor @path directives.
    self.scanDefaultDirectory(parent) # sets .defaultDirectory.
    fileName = c.os_path_finalize_join(self.default_directory,fileName)
    junk,self.fileName = g.os_path_split(fileName)
    self.methodName,self.fileType = g.os_path_splitext(self.fileName)
    self.setEncoding(p=parent,atAuto=atAuto)
    if not ext: ext = self.fileType
    ext = ext.lower()
    if not s:
        << Read file into s >>
    << convert s to the proper encoding >>

    # Create the top-level headline.
    if atAuto:
        p = parent.copy()
        p.setBodyString('')
    else:
        undoData = u.beforeInsertNode(parent)
        p = parent.insertAsLastChild()

        if self.treeType == "@file":
            p.initHeadString("@file " + fileName)
        else:
            # @root nodes don't have @root in the headline.
            p.initHeadString(fileName)
        u.afterInsertNode(p,'Import',undoData)

    self.rootLine = g.choose(self.treeType=="@file","","@root-code "+self.fileName+'\n')

    func = self.importDispatchDict.get(ext)
    if func and not c.config.getBool('suppress_import_parsing',default=False):
        func(s,p,atAuto=atAuto)
    else:
        # Just copy the file to the parent node.
        self.scanUnknownFileType(s,p,ext,atAuto=atAuto)

    p.contract()
    return p
#@+node:ekr.20031218072017.3211:<< Read file into s >>
try:
    fileName = c.os_path_finalize(fileName)
    theFile = open(fileName)
    s = theFile.read()
    theFile.close()
except IOError:
    if atShadow: kind = '@shadow '
    elif atAuto: kind = '@auto '
    else: kind = ''
    # g.trace('c.frame.openDirectory',c.frame.openDirectory)
    g.es("can not open", "%s%s" % (kind,fileName),color='red')
    # g.trace(g.callers())
    leoTest.fail()
    return None
#@-node:ekr.20031218072017.3211:<< Read file into s >>
#@+node:ekr.20080212092908:<< convert s to the proper encoding >>
if s and fileName.endswith('.py'):
    # Python's encoding comments override everything else.
    lines = g.splitLines(s)
    tag = '# -*- coding:' ; tag2 = '-*-'
    n1,n2 = len(tag),len(tag2)
    line1 = lines[0].strip()
    if line1.startswith(tag) and line1.endswith(tag2):
        e = line1[n1:-n2].strip()
        if e and g.isValidEncoding(e):
            # g.pr('found',e,'in',line1)
            self.encoding = e

s = g.toUnicode(s,self.encoding)
#@-node:ekr.20080212092908:<< convert s to the proper encoding >>
#@-node:ekr.20031218072017.3210:createOutline (leoImport)
#@-node:ekr.20090511055302.10652:Support @auto for general rST files
#@+node:ekr.20090512080015.5794:Indent rst3 nodes based on underlining level
#@+node:ekr.20070703122141.65:<< class baseScannerClass >>
class baseScannerClass (scanUtility):

    '''The base class for all import scanner classes.
    This class contains common utility methods.'''

    @others
#@+node:ekr.20070703122141.66:baseScannerClass.__init__
def __init__ (self,importCommands,atAuto,language):

    ic = importCommands

    self.atAuto = atAuto
    self.c = c = ic.c

    self.atAutoWarnsAboutLeadingWhitespace = c.config.getBool('at_auto_warns_about_leading_whitespace')
    self.classId = None # The identifier containing the class tag: 'class', 'interface', 'namespace', etc.
    self.codeEnd = None
        # The character after the last character of the class, method or function.
        # An error will be given if this is not a newline.
    self.encoding = ic.encoding # g.app.tkEncoding
    self.errors = 0
    ic.errors = 0
    self.errorLines = []
    self.extraIdChars = ''
    self.fileName = ic.fileName # The original filename.
    self.fileType = ic.fileType # The extension,  '.py', '.c', etc.
    self.file_s = '' # The complete text to be parsed.
    self.fullChecks = c.config.getBool('full_import_checks')
    self.functionSpelling = 'function' # for error message.
    self.importCommands = ic
    self.indentRefFlag = None # None, True or False.
    self.language = language
    self.lastParent = None # The last generated parent node (used only by rstScanner).
    self.methodName = ic.methodName # x, as in < < x methods > > =
    self.methodsSeen = False
    self.mismatchWarningGiven = False
    self.output_newline = ic.output_newline # = c.config.getBool('output_newline')
    self.output_indent = 0 # The minimum indentation presently in effect.
    self.root = None # The top-level node of the generated tree.
    self.rootLine = ic.rootLine # '' or @root + self.fileName
    self.sigEnd = None # The index of the end of the signature.
    self.sigId = None # The identifier contained in the signature, i.e., the function or method name.
    self.sigStart = None
        # The start of the line containing the signature.
        # An error will be given if something other than whitespace precedes the signature.
    self.startSigIndent = None
    self.tab_width = None # Set in run: the tab width in effect in the c.currentPosition.
    self.tab_ws = '' # Set in run: the whitespace equivalent to one tab.
    self.trace = False or ic.trace # = c.config.getBool('trace_import')
    self.treeType = ic.treeType # '@root' or '@file'
    self.webType = ic.webType # 'cweb' or 'noweb'  

    # Compute language ivars.
    delim1,junk,junk = g.set_delims_from_language(language)
    self.comment_delim = delim1

    # May be overridden in subclasses.
    self.anonymousClasses = [] # For Delphi Pascal interfaces.
    self.blockCommentDelim1 = None
    self.blockCommentDelim2 = None
    self.blockCommentDelim1_2 = None
    self.blockCommentDelim2_2 = None
    self.blockDelim1 = '{'
    self.blockDelim2 = '}'
    self.blockDelim2Cruft = [] # Stuff that can follow .blockDelim2.
    self.classTags = ['class',] # tags that start a tag.
    self.functionTags = []
    self.hasClasses = True
    self.hasFunctions = True
    self.lineCommentDelim = None
    self.lineCommentDelim2 = None
    self.outerBlockDelim1 = None
    self.outerBlockDelim2 = None
    self.outerBlockEndsDecls = True
    self.sigHeadExtraTokens = [] # Extra tokens valid in head of signature.
    self.sigFailTokens = []
        # A list of strings that abort a signature when seen in a tail.
        # For example, ';' and '=' in C.

    self.strict = False # True if leading whitespace is very significant.
#@-node:ekr.20070703122141.66:baseScannerClass.__init__
#@+node:ekr.20070808115837:Checking
#@+node:ekr.20070703122141.102:check
def check (self,unused_s,unused_parent):

    '''Make sure the generated nodes are equivalent to the original file.

    1. Regularize and check leading whitespace.
    2. Check that a trial write produces the original file.

    Return True if the nodes are equivalent to the original file.
    '''

    if self.fullChecks and self.treeType == '@file':
        return self.checkTrialWrite()
    else:
        return True
#@-node:ekr.20070703122141.102:check
#@+node:ekr.20070703122141.104:checkTrialWrite
def checkTrialWrite (self,s1=None,s2=None):

    '''Return True if a trial write produces the original file.'''

    # s1 and s2 are for unit testing.

    c = self.c ; at = c.atFileCommands

    if s1 is None and s2 is None:
        at.write(self.root,
            nosentinels=True,thinFile=False,
            scriptWrite=False,toString=True)
        s1,s2 = self.file_s, at.stringOutput

    s1 = g.toUnicode(s1,self.encoding)
    s2 = g.toUnicode(s2,self.encoding)

    # Make sure we have a trailing newline in both strings.
    s1 = s1.replace('\r','')
    s2 = s2.replace('\r','')
    if not s1.endswith('\n'): s1 = s1 + '\n'
    if not s2.endswith('\n'): s2 = s2 + '\n'

    if s1 == s2: return True

    lines1 = g.splitLines(s1) ; n1 = len(lines1)
    lines2 = g.splitLines(s2) ; n2 = len(lines2)

    # g.trace('lines1',lines1)
    # g.trace('lines2',lines2)

    ok = True ; bad_i = 0
    for i in range(max(n1,n2)):
        ok = self.compareHelper(lines1,lines2,i,self.strict)
        if not ok:
            bad_i = i + 1
            break

    if g.app.unitTesting:
        d = g.app.unitTestDict
        # g.trace('expected',d.get('expectedMismatchLine'),'actual',d.get('actualMismatchLine'))
        ok = d.get('expectedMismatchLine') == d.get('actualMismatchLine')
        # Unit tests do not generate errors unless the mismatch line does not match.
        if not ok: d['fail'] = g.callers() # 2008/10/3

    if not ok:
        self.reportMismatch(lines1,lines2,bad_i)

    return ok
#@-node:ekr.20070703122141.104:checkTrialWrite
#@+node:ekr.20070730093735:compareHelper
def compareHelper (self,lines1,lines2,i,strict):

    '''Compare lines1[i] and lines2[i].
    strict is True if leading whitespace is very significant.'''

    def pr(*args,**keys): #compareHelper
        g.es_print(color='blue',*args,**keys)

    def pr_mismatch(i,line1,line2):
        g.es_print('first mismatched line at line',str(i+1))
        g.es_print('original line: ',line1)
        g.es_print('generated line:',line2)

    d = g.app.unitTestDict
    expectedMismatch = g.app.unitTesting and d.get('expectedMismatchLine')
    enableWarning = not self.mismatchWarningGiven and self.atAutoWarnsAboutLeadingWhitespace
    messageKind = None

    if i >= len(lines1):
        if i != expectedMismatch or not g.unitTesting:
            pr('extra lines')
            for line in lines2[i:]:
                pr(repr(line))
        d ['actualMismatchLine'] = i
        return False

    if i >= len(lines2):
        if i != expectedMismatch or not g.unitTesting:
            g.es_print('missing lines')
            for line in lines2[i:]:
                g.es_print('',repr(line))
        d ['actualMismatchLine'] = i
        return False

    line1,line2 = lines1[i],lines2[i]

    if line1 == line2:
        return True # An exact match.
    elif not line1.strip() and not line2.strip():
        return True # Blank lines compare equal.
    elif strict:
        s1,s2 = line1.lstrip(),line2.lstrip()
        messageKind = g.choose(
            s1 == s2 and self.startsComment(s1,0) and self.startsComment(s2,0),
            'comment','error')
    else:
        s1,s2 = line1.lstrip(),line2.lstrip()
        messageKind = g.choose(s1==s2,'warning','error')

    if g.unitTesting:
        d ['actualMismatchLine'] = i+1
        ok = i+1 == expectedMismatch
        if not ok:  pr_mismatch(i,line1,line2)
        return ok
    elif strict:
        if enableWarning:
            self.mismatchWarningGiven = True
            if messageKind == 'comment':
                self.warning('mismatch in leading whitespace before comment')
            else:
                self.error('mismatch in leading whitespace')
            pr_mismatch(i,line1,line2)
        return messageKind == 'comment' # Only mismatched comment lines are valid.
    else:
        if enableWarning:
            self.mismatchWarningGiven = True
            self.checkLeadingWhitespace(line1)
            self.warning('mismatch in leading whitespace')
            pr_mismatch(i,line1,line2)
        return messageKind in ('comment','warning') # Only errors are invalid.
#@nonl
#@-node:ekr.20070730093735:compareHelper
#@+node:ekr.20071110144948:checkLeadingWhitespace
def checkLeadingWhitespace (self,line):

    tab_width = self.tab_width
    lws = line[0:g.skip_ws(line,0)]
    w = g.computeWidth(lws,tab_width)
    ok = (w % abs(tab_width)) == 0

    if not ok:
        self.report('leading whitespace not consistent with @tabwidth %d' % tab_width)
        g.es_print('line:',repr(line),color='red')

    return ok
#@-node:ekr.20071110144948:checkLeadingWhitespace
#@+node:ekr.20070911110507:reportMismatch
def reportMismatch (self,lines1,lines2,bad_i):

    def pr(*args,**keys): # reportMismatch
        g.es_print(color='blue',*args,**keys)

    kind = g.choose(self.atAuto,'@auto','import command')

    self.error(
        '%s did not import %s perfectly\nfirst mismatched line: %d\n%s' % (
            kind,self.root.h,bad_i,repr(lines2[bad_i-1])))

    if len(lines1) < 100:
        pr('input...')
        for i in range(len(lines1)):
            pr('%3d %s' % (i,lines1[i]),newline=False)
        pr('output...')
        for i in range(len(lines2)):
            pr('%3d %s' % (i,lines2[i]),newline=False)

    return False
#@-node:ekr.20070911110507:reportMismatch
#@-node:ekr.20070808115837:Checking
#@+node:ekr.20070706084535:Code generation
@ None of these methods should ever need to be overridden in subclasses.

#@+node:ekr.20090512080015.5800:adjustParent
def adjustParent (self,parent,headline):

    '''Return the effective parent.

    This is overridden by the rstScanner class.'''

    return parent
#@-node:ekr.20090512080015.5800:adjustParent
#@+node:ekr.20070707073044.1:addRef
def addRef (self,parent):

    '''Create an unindented @others or section reference in the parent node.'''

    c = self.c

    # g.trace(parent.h)

    if self.treeType == '@file':
        self.appendStringToBody(parent,'@others\n')

    if self.treeType == '@root' and self.methodsSeen:
        self.appendStringToBody(parent,
            g.angleBrackets(' ' + self.methodName + ' methods ') + '\n\n')
#@-node:ekr.20070707073044.1:addRef
#@+node:ekr.20090122201952.6:appendStringToBody & setBodyString (baseScannerClass)
def appendStringToBody (self,p,s,encoding="utf-8"):

    '''Similar to c.appendStringToBody,
    but does not recolor the text or redraw the screen.'''

    return self.importCommands.appendStringToBody(p,s,encoding)

def setBodyString (self,p,s,encoding="utf-8"):

    '''Similar to c.setBodyString,
    but does not recolor the text or redraw the screen.'''

    return self.importCommands.setBodyString(p,s,encoding)
#@-node:ekr.20090122201952.6:appendStringToBody & setBodyString (baseScannerClass)
#@+node:ekr.20070705144309:createDeclsNode
def createDeclsNode (self,parent,s):

    '''Create a child node of parent containing s.'''

    # Create the node for the decls.
    headline = self.methodName + ' declarations'
    body = self.undentBody(s)
    self.createHeadline(parent,body,headline)
#@-node:ekr.20070705144309:createDeclsNode
#@+node:ekr.20070707085612:createFunctionNode
def createFunctionNode (self,headline,body,parent):

    # Create the prefix line for @root trees.
    if self.treeType == '@file':
        prefix = ''
    else:
        prefix = g.angleBrackets(' ' + headline + ' methods ') + '=\n\n'
        self.methodsSeen = True

    # Create the node.
    return self.createHeadline(parent,prefix + body,headline)

#@-node:ekr.20070707085612:createFunctionNode
#@+node:ekr.20070703122141.77:createHeadline
def createHeadline (self,parent,body,headline):

    # g.trace('parent,headline:',parent.h,headline)

    # Create the node.
    p = parent.insertAsLastChild()
    p.initHeadString(headline,self.encoding)

    # Set the body.
    if body:
        self.setBodyString(p,body,self.encoding)
    return p
#@-node:ekr.20070703122141.77:createHeadline
#@+node:ekr.20090502071837.1:endGen
def endGen (self,s):

    '''Do any language-specific post-processing.'''
    pass
#@-node:ekr.20090502071837.1:endGen
#@+node:ekr.20070703122141.79:getLeadingIndent
def getLeadingIndent (self,s,i,ignoreComments=True):

    '''Return the leading whitespace of a line.
    Ignore blank and comment lines if ignoreComments is True'''

    width = 0
    i = g.find_line_start(s,i)
    if ignoreComments:
        while i < len(s):
            # g.trace(g.get_line(s,i))
            j = g.skip_ws(s,i)
            if g.is_nl(s,j) or g.match(s,j,self.comment_delim):
                i = g.skip_line(s,i) # ignore blank lines and comment lines.
            else:
                i, width = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                break      
    else:
        i, width = g.skip_leading_ws_with_indent(s,i,self.tab_width)

    # g.trace('returns:',width)
    return width
#@-node:ekr.20070703122141.79:getLeadingIndent
#@+node:ekr.20070709094002:indentBody
def indentBody (self,s,lws=None):

    '''Add whitespace equivalent to one tab for all non-blank lines of s.'''

    result = []
    if not lws: lws = self.tab_ws

    for line in g.splitLines(s):
        if line.strip():
            result.append(lws + line)
        elif line.endswith('\n'):
            result.append('\n')

    result = ''.join(result)
    return result
#@-node:ekr.20070709094002:indentBody
#@+node:ekr.20070705085335:insertIgnoreDirective
def insertIgnoreDirective (self,parent):

    self.appendStringToBody(parent,'@ignore')

    if not g.unitTesting:
        g.es_print('inserting @ignore',color='blue')
#@-node:ekr.20070705085335:insertIgnoreDirective
#@+node:ekr.20070707113832.1:putClass & helpers
def putClass (self,s,i,sigEnd,codeEnd,start,parent):

    '''Creates a child node c of parent for the class, and a child of c for each def in the class.'''

    # Enter a new class 1: save the old class info.
    oldMethodName = self.methodName
    oldStartSigIndent = self.startSigIndent

    # Enter a new class 2: init the new class info.
    self.indentRefFlag = None

    class_kind = self.classId
    class_name = self.sigId
    headline = '%s %s' % (class_kind,class_name)
    headline = headline.strip()
    self.methodName = headline

    # Compute the starting lines of the class.
    prefix = self.createClassNodePrefix()
    if not self.sigId:
        g.trace('Can not happen: no sigId')
        self.sigId = 'Unknown class name'
    classHead = s[start:sigEnd]
    i = self.extendSignature(s,sigEnd)
    extend = s[sigEnd:i]
    if extend:
        classHead = classHead + extend

    # Create the class node.
    class_node = self.createHeadline(parent,'',headline)

    # Remember the indentation of the class line.
    undentVal = self.getLeadingIndent(classHead,0)

    # Call the helper to parse the inner part of the class.
    putRef,bodyIndent,classDelim,decls,trailing = self.putClassHelper(
        s,i,codeEnd,class_node)
    # g.trace('bodyIndent',bodyIndent,'undentVal',undentVal)

    # Set the body of the class node.
    ref = putRef and self.getClassNodeRef(class_name) or ''

    # Give ref the same indentation as the body of the class.
    if ref:
        bodyWs = g.computeLeadingWhitespace (bodyIndent,self.tab_width)
        ref = '%s%s' % (bodyWs,ref)

    # Remove the leading whitespace.
    result = (
        prefix +
        self.undentBy(classHead,undentVal) +
        self.undentBy(classDelim,undentVal) +
        self.undentBy(decls,undentVal) +
        self.undentBy(ref,undentVal) +
        self.undentBy(trailing,undentVal))

    # Append the result to the class node.
    self.appendTextToClassNode(class_node,result)

    # Exit the new class: restore the previous class info.
    self.methodName = oldMethodName
    self.startSigIndent = oldStartSigIndent
#@+node:ekr.20070707190351:appendTextToClassNode
def appendTextToClassNode (self,class_node,s):

    c = self.c

    self.appendStringToBody(class_node,s) 
#@-node:ekr.20070707190351:appendTextToClassNode
#@+node:ekr.20070703122141.105:createClassNodePrefix
def createClassNodePrefix (self):

    '''Create the class node prefix.'''

    if  self.treeType == '@file':
        prefix = ''
    else:
        prefix = g.angleBrackets(' ' + self.methodName + ' methods ') + '=\n\n'
        self.methodsSeen = True

    return prefix
#@-node:ekr.20070703122141.105:createClassNodePrefix
#@+node:ekr.20070703122141.106:getClassNodeRef
def getClassNodeRef (self,class_name):

    '''Insert the proper body text in the class_vnode.'''

    if self.treeType == '@file':
        s = '@others'
    else:
        s = g.angleBrackets(' class %s methods ' % (class_name))

    return '%s\n' % (s)
#@-node:ekr.20070703122141.106:getClassNodeRef
#@+node:ekr.20070707171329:putClassHelper
def putClassHelper(self,s,i,end,class_node):

    '''s contains the body of a class, not including the signature.

    Parse s for inner methods and classes, and create nodes.'''

    # Increase the output indentation (used only in startsHelper).
    # This allows us to detect over-indented classes and functions.
    old_output_indent = self.output_indent
    self.output_indent += abs(self.tab_width)

    # Parse the decls.
    j = i ; i = self.skipDecls(s,i,end,inClass=True)
    decls = s[j:i]

    # Set the body indent if there are real decls.
    bodyIndent = decls.strip() and self.getIndent(s,i) or None

    # Parse the rest of the class.
    delim1, delim2 = self.outerBlockDelim1, self.outerBlockDelim2
    if g.match(s,i,delim1):
        # Do *not* use g.skip_ws_and_nl here!
        j = g.skip_ws(s,i + len(delim1))
        if g.is_nl(s,j): j = g.skip_nl(s,j)
        classDelim = s[i:j]
        end2 = self.skipBlock(s,i,delim1=delim1,delim2=delim2)
        start,putRef,bodyIndent2 = self.scanHelper(s,j,end=end2,parent=class_node,kind='class')
    else:
        classDelim = ''
        start,putRef,bodyIndent2 = self.scanHelper(s,i,end=end,parent=class_node,kind='class')

    if bodyIndent is None: bodyIndent = bodyIndent2

    # Restore the output indentation.
    self.output_indent = old_output_indent

    # Return the results.
    trailing = s[start:end]
    return putRef,bodyIndent,classDelim,decls,trailing
#@-node:ekr.20070707171329:putClassHelper
#@-node:ekr.20070707113832.1:putClass & helpers
#@+node:ekr.20070707082432:putFunction (baseScannerClass)
def putFunction (self,s,sigStart,codeEnd,start,parent):

    '''Create a node of parent for a function defintion.'''

    trace = False and not g.unitTesting
    verbose = False

    if trace: g.trace(parent.h)

    # Enter a new function: save the old function info.
    oldStartSigIndent = self.startSigIndent

    if self.sigId:
        headline = self.sigId
    else:
        g.trace('Can not happen: no sigId')
        headline = 'unknown function'

    body1 = s[start:sigStart]
    # Adjust start backwards to get a better undent.
    if body1.strip():
        while start > 0 and s[start-1] in (' ','\t'):
            start -= 1

    body1 = self.undentBody(s[start:sigStart],ignoreComments=False)

    body2 = self.undentBody(s[sigStart:codeEnd])
    body = body1 + body2
    if trace and verbose: g.trace('body\n%s' % body)

    tail = body[len(body.rstrip()):]
    if not '\n' in tail:
        self.warning(
            '%s %s does not end with a newline; one will be added\n%s' % (
            self.functionSpelling,self.sigId,g.get_line(s,codeEnd)))

    parent = self.adjustParent(parent,headline)
    self.lastParent = self.createFunctionNode(headline,body,parent)

    # Exit the function: restore the function info.
    self.startSigIndent = oldStartSigIndent
#@-node:ekr.20070707082432:putFunction (baseScannerClass)
#@+node:ekr.20070705094630:putRootText
def putRootText (self,p):

    c = self.c

    self.appendStringToBody(p,'%s@language %s\n@tabwidth %d\n' % (
        self.rootLine,self.language,self.tab_width))
#@-node:ekr.20070705094630:putRootText
#@+node:ekr.20090122201952.5:setBodyString
#@-node:ekr.20090122201952.5:setBodyString
#@+node:ekr.20070703122141.88:undentBody
def undentBody (self,s,ignoreComments=True):

    '''Remove the first line's leading indentation from all lines of s.'''

    trace = False
    if trace: g.trace('before...\n',g.listToString(g.splitLines(s)))

    # Copy an @code line as is.
    # i = 0
    # if g.match(s,i,'@code'):
        # j = i ; i = g.skip_line(s,i) # don't use get_line: it is only for dumping.
        # result += s[j:i]

    # Calculate the amount to be removed from each line.
    undentVal = self.getLeadingIndent(s,0,ignoreComments=ignoreComments)
    if undentVal == 0:
        return s
    else:
        result = self.undentBy(s,undentVal)
        if trace: g.trace('after...\n',g.listToString(g.splitLines(result)))
        return result
#@nonl
#@-node:ekr.20070703122141.88:undentBody
#@+node:ekr.20081216090156.1:undentBy
def undentBy (self,s,undentVal):

    '''Remove leading whitespace equivalent to undentVal from each line.
    add an underindentEscapeString for underindented line.'''

    # return ''.join(
        # [g.removeLeadingWhitespace(line,undentVal,self.tab_width)
            # for line in g.splitLines(s)])

    trace = False and not g.app.unitTesting
    tag = self.c.atFileCommands.underindentEscapeString
    result = [] ; tab_width = self.tab_width
    for line in g.splitlines(s):
        lws_s = g.get_leading_ws(line)
        lws = g.computeWidth(lws_s,tab_width)
        s = g.removeLeadingWhitespace(line,undentVal,tab_width)
        n = lws - undentVal
        if s.strip() and lws < undentVal:
            if trace: g.trace('undentVal: %s, lws: %s, %s' % (
                undentVal,lws,repr(line)))
            result.append("%s%s%s" % (tag,undentVal-lws,s.lstrip()))
        else:
            result.append(s)

    return ''.join(result)

#@-node:ekr.20081216090156.1:undentBy
#@+node:ekr.20070801074524:underindentedComment & underindentedLine
def underindentedComment (self,line):

    if self.atAutoWarnsAboutLeadingWhitespace:
        self.warning(
            'underindented python comments.\nExtra leading whitespace will be added\n' + line)

def underindentedLine (self,line):

    self.error(
        'underindented line.\nExtra leading whitespace will be added\n' + line)
#@-node:ekr.20070801074524:underindentedComment & underindentedLine
#@-node:ekr.20070706084535:Code generation
#@+node:ekr.20070703122141.78:error, oops, report and warning
def error (self,s):
    self.errors += 1
    self.importCommands.errors += 1
    if g.unitTesting:
        if self.errors == 1:
            g.app.unitTestDict ['actualErrorMessage'] = s
        g.app.unitTestDict ['actualErrors'] = self.errors
        if 0: # For debugging unit tests.
            g.trace(g.callers())
            g.es_print('',s,color='red')
    else:
        g.es_print('error:',s,color='red')

def oops (self):
    g.pr('baseScannerClass oops: %s must be overridden in subclass' % g.callers())

def report (self,message):
    if self.strict: self.error(message)
    else:           self.warning(message)

def warning (self,s):
    if not g.unitTesting:
        g.es_print('warning:',s,color='red')
#@-node:ekr.20070703122141.78:error, oops, report and warning
#@+node:ekr.20070706084535.1:Parsing
@ Scan and skipDecls would typically not be overridden.
#@+node:ekr.20071201072917:adjustDefStart
def adjustDefStart (self,unused_s,i):

    '''A hook to allow the Python importer to adjust the 
    start of a class or function to include decorators.'''

    return i
#@-node:ekr.20071201072917:adjustDefStart
#@+node:ekr.20070707150022:extendSignature
def extendSignature(self,unused_s,i):

    '''Extend the signature line if appropriate.
    The text *must* end with a newline.

    For example, the Python scanner appends docstrings if they exist.'''

    return i
#@-node:ekr.20070707150022:extendSignature
#@+node:ekr.20071017132056:getIndent
def getIndent (self,s,i):

    j,junk = g.getLine(s,i)
    junk,indent = g.skip_leading_ws_with_indent(s,j,self.tab_width)
    return indent
#@nonl
#@-node:ekr.20071017132056:getIndent
#@+node:ekr.20070706101600:scan & scanHelper
def scan (self,s,parent):

    '''A language independent scanner: it uses language-specific helpers.

    Create a child of self.root for:
    - Leading outer-level declarations.
    - Outer-level classes.
    - Outer-level functions.
    '''

    # Init the parser status ivars.
    self.methodsSeen = False

    # Create the initial body text in the root.
    self.putRootText(parent)

    # Parse the decls.
    i = self.skipDecls(s,0,len(s),inClass=False)
    decls = s[:i]

    # Create the decls node.
    if decls: self.createDeclsNode(parent,decls)

    # Scan the rest of the file.
    start,junk,junk = self.scanHelper(s,i,end=len(s),parent=parent,kind='outer')

    # Finish adding to the parent's body text.
    self.addRef(parent)
    if start < len(s):
        self.appendStringToBody(parent,s[start:])

    # Do any language-specific post-processing.
    self.endGen(s)
#@+node:ekr.20071018084830:scanHelper
def scanHelper(self,s,i,end,parent,kind):

    '''Common scanning code used by both scan and putClassHelper.'''

    # g.trace(g.callers())
    # g.trace('i',i,g.get_line(s,i))
    assert kind in ('class','outer')
    start = i ; putRef = False ; bodyIndent = None
    while i < end:
        progress = i
        if s[i] in (' ','\t','\n'):
            i += 1 # Prevent lookahead below, and speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif self.startsClass(s,i):  # Sets sigStart,sigEnd & codeEnd ivars.
            putRef = True
            if bodyIndent is None: bodyIndent = self.getIndent(s,i)
            end2 = self.codeEnd # putClass may change codeEnd ivar.
            self.putClass(s,i,self.sigEnd,self.codeEnd,start,parent)
            i = start = end2
        elif self.startsFunction(s,i): # Sets sigStart,sigEnd & codeEnd ivars.
            putRef = True
            if bodyIndent is None: bodyIndent = self.getIndent(s,i)
            self.putFunction(s,self.sigStart,self.codeEnd,start,parent)
            i = start = self.codeEnd
        elif self.startsId(s,i):
            i = self.skipId(s,i)
        elif kind == 'outer' and g.match(s,i,self.outerBlockDelim1): # Do this after testing for classes.
            i = self.skipBlock(s,i,delim1=self.outerBlockDelim1,delim2=self.outerBlockDelim2)
            # Bug fix: 2007/11/8: do *not* set start: we are just skipping the block.
        else: i += 1
        assert progress < i,'i: %d, ch: %s' % (i,repr(s[i]))

    return start,putRef,bodyIndent
#@-node:ekr.20071018084830:scanHelper
#@-node:ekr.20070706101600:scan & scanHelper
#@+node:ekr.20070712075148:skipArgs
def skipArgs (self,s,i,kind):

    '''Skip the argument or class list.  Return i, ok

    kind is in ('class','function')'''

    start = i
    i = g.skip_ws_and_nl(s,i)
    if not g.match(s,i,'('):
        return start,kind == 'class'

    i = self.skipParens(s,i)
    # skipParens skips the ')'
    if i >= len(s):
        return start,False
    else:
        return i,True 
#@-node:ekr.20070712075148:skipArgs
#@+node:ekr.20070707073859:skipBlock
def skipBlock(self,s,i,delim1=None,delim2=None):

    '''Skip from the opening delim to *past* the matching closing delim.

    If no matching is found i is set to len(s)'''

    trace = False and not g.unitTesting
    start = i
    if delim1 is None: delim1 = self.blockDelim1
    if delim2 is None: delim2 = self.blockDelim2
    match1 = g.choose(len(delim1)==1,g.match,g.match_word)
    match2 = g.choose(len(delim2)==1,g.match,g.match_word)
    assert match1(s,i,delim1)
    level = 0 ; start = i
    startIndent = self.startSigIndent
    if trace: g.trace('***','startIndent',startIndent,g.callers())
    while i < len(s):
        progress = i
        if g.is_nl(s,i):
            backslashNewline = i > 0 and g.match(s,i-1,'\\\n')
            i = g.skip_nl(s,i)
            if not backslashNewline and not g.is_nl(s,i):
                j, indent = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                line = g.get_line(s,j)
                if trace: g.trace('indent',indent,line)
                if indent < startIndent and line.strip():
                    # An non-empty underindented line.
                    # Issue an error unless it contains just the closing bracket.
                    if level == 1 and match2(s,j,delim2):
                        pass
                    else:
                        if j not in self.errorLines: # No error yet given.
                            self.errorLines.append(j)
                            self.underindentedLine(line)
        elif s[i] in (' ','\t',):
            i += 1 # speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif match1(s,i,delim1):
            level += 1 ; i += len(delim1)
        elif match2(s,i,delim2):
            level -= 1 ; i += len(delim2)
            # Skip junk following Pascal 'end'
            for z in self.blockDelim2Cruft:
                i2 = g.skip_ws(s,i)
                if g.match(s,i2,z):
                    i = i2 + len(z)
                    break
            if level <= 0:
                if trace: g.trace('returns:',repr(s[start:i]))
                return i

        else: i += 1
        assert progress < i

    self.error('no block')
    if 1:
        g.pr('** no block **')
        i,j = g.getLine(s,start)
        g.trace(i,s[i:j])
    else:
        if trace: g.trace('** no block')
    return start
#@-node:ekr.20070707073859:skipBlock
#@+node:ekr.20070712091019:skipCodeBlock
def skipCodeBlock (self,s,i,kind):

    '''Skip the code block in a function or class definition.'''

    trace = False
    start = i
    i = self.skipBlock(s,i,delim1=None,delim2=None)

    if self.sigFailTokens:
        i = g.skip_ws(s,i)
        for z in self.sigFailTokens:
            if g.match(s,i,z):
                if trace: g.trace('failtoken',z)
                return start,False

    if i > start:
        i = self.skipNewline(s,i,kind)

    if trace:
        g.trace(g.callers())
        g.trace('returns...\n',g.listToString(g.splitLines(s[start:i])))

    return i,True
#@-node:ekr.20070712091019:skipCodeBlock
#@+node:ekr.20070711104014:skipComment & helper
def skipComment (self,s,i):

    '''Skip a comment and return the index of the following character.'''

    if g.match(s,i,self.lineCommentDelim) or g.match(s,i,self.lineCommentDelim2):
        return g.skip_to_end_of_line(s,i)
    else:
        return self.skipBlockComment(s,i)
#@+node:ekr.20070707074541:skipBlockComment
def skipBlockComment (self,s,i):

    '''Skip past a block comment.'''

    start = i

    # Skip the opening delim.
    if g.match(s,i,self.blockCommentDelim1):
        delim2 = self.blockCommentDelim2
        i += len(self.blockCommentDelim1)
    elif g.match(s,i,self.blockCommentDelim1_2):
        i += len(self.blockCommentDelim1_2)
        delim2 = self.blockCommentDelim2_2
    else:
        assert False

    # Find the closing delim.
    k = s.find(delim2,i)
    if k == -1:
        self.error('Run on block comment: ' + s[start:i])
        return len(s)
    else:
        return k + len(delim2)
#@-node:ekr.20070707074541:skipBlockComment
#@-node:ekr.20070711104014:skipComment & helper
#@+node:ekr.20070707080042:skipDecls
def skipDecls (self,s,i,end,inClass):

    '''Skip everything until the start of the next class or function.

    The decls *must* end in a newline.'''

    trace = False or self.trace
    start = i ; prefix = None
    classOrFunc = False
    if trace: g.trace(g.callers())
    while i < end:
        progress = i
        if s[i] in (' ','\t','\n'):
            i += 1 # Prevent lookahead below, and speed up the scan.
        elif self.startsComment(s,i):
            # Add the comment to the decl if it *doesn't* start the line.
            i2,junk = g.getLine(s,i)
            i2 = g.skip_ws(s,i2)
            if i2 == i and prefix is None:
                prefix = i2 # Bug fix: must include leading whitespace in the comment.
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
            prefix = None
        elif self.startsClass(s,i):
            # Important: do not include leading ws in the decls.
            classOrFunc = True
            i = g.find_line_start(s,i)
            i = self.adjustDefStart(s,i)
            break
        elif self.startsFunction(s,i):
            # Important: do not include leading ws in the decls.
            classOrFunc = True
            i = g.find_line_start(s,i)
            i = self.adjustDefStart(s,i)
            break
        elif self.startsId(s,i):
            i = self.skipId(s,i)
            prefix = None
        # Don't skip outer blocks: they may contain classes.
        elif g.match(s,i,self.outerBlockDelim1):
            if self.outerBlockEndsDecls:
                break
            else:
                i = self.skipBlock(s,i,delim1=self.outerBlockDelim1,delim2=self.outerBlockDelim2)
        else:
            i += 1 ;  prefix = None
        assert(progress < i)

    if prefix is not None:
        i = g.find_line_start(s,prefix) # i = prefix
    decls = s[start:i]
    if inClass and not classOrFunc:
        # Don't return decls if a class contains nothing but decls.
        if trace and decls.strip(): g.trace('**class is all decls...\n',decls)
        return start
    elif decls.strip(): 
        if trace or self.trace: g.trace('\n'+decls)
        return i
    else: # Ignore empty decls.
        return start
#@-node:ekr.20070707080042:skipDecls
#@+node:ekr.20070707094858.1:skipId
def skipId (self,s,i):

    return g.skip_id(s,i,chars=self.extraIdChars)
#@nonl
#@-node:ekr.20070707094858.1:skipId
#@+node:ekr.20070730134936:skipNewline
def skipNewline(self,s,i,kind):

    '''Skip whitespace and comments up to a newline, then skip the newline.
    Issue an error if no newline is found.'''

    while i < len(s):
        i = g.skip_ws(s,i)
        if self.startsComment(s,i):
            i = self.skipComment(s,i)
        else: break

    if i >= len(s):
        return len(s)

    if g.match(s,i,'\n'):
        i += 1
    else:
        self.error(
            '%s %s does not end in a newline; one will be added\n%s' % (
                kind,self.sigId,g.get_line(s,i)))
        # g.trace(g.callers())

    return i
#@-node:ekr.20070730134936:skipNewline
#@+node:ekr.20070712081451:skipParens
def skipParens (self,s,i):

    '''Skip a parenthisized list, that might contain strings or comments.'''

    return self.skipBlock(s,i,delim1='(',delim2=')')
#@-node:ekr.20070712081451:skipParens
#@+node:ekr.20070707073627.2:skipString
def skipString (self,s,i):

    # Returns len(s) on unterminated string.
    return g.skip_string(s,i,verbose=False)
#@-node:ekr.20070707073627.2:skipString
#@+node:ekr.20070711132314:startsClass/Function (baseClass) & helpers
# We don't expect to override this code, but subclasses may override the helpers.

def startsClass (self,s,i):
    '''Return True if s[i:] starts a class definition.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    val = self.hasClasses and self.startsHelper(s,i,kind='class',tags=self.classTags)
    return val

def startsFunction (self,s,i):
    '''Return True if s[i:] starts a function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    val = self.hasFunctions and self.startsHelper(s,i,kind='function',tags=self.functionTags)
    return val
#@+node:ekr.20070711134534:getSigId
def getSigId (self,ids):

    '''Return the signature's id.

    By default, this is the last id in the ids list.'''

    return ids and ids[-1]
#@-node:ekr.20070711134534:getSigId
#@+node:ekr.20070711140703:skipSigStart
def skipSigStart (self,s,i,kind,tags):

    '''Skip over the start of a function/class signature.

    tags is in (self.classTags,self.functionTags).

    Return (i,ids) where ids is list of all ids found, in order.'''

    trace = False and self.trace # or kind =='function'
    ids = [] ; classId = None
    if trace: g.trace('*entry',kind,i,s[i:i+20])
    start = i
    while i < len(s):
        j = g.skip_ws_and_nl(s,i)
        for z in self.sigFailTokens:
            if g.match(s,j,z):
                if trace: g.trace('failtoken',z,'ids',ids)
                return start, [], None
        for z in self.sigHeadExtraTokens:
            if g.match(s,j,z):
                i += len(z) ; break
        else:
            i = self.skipId(s,j)
            theId = s[j:i]
            if theId and theId in tags: classId = theId
            if theId: ids.append(theId)
            else: break

    if trace: g.trace('*exit ',kind,i,i < len(s) and s[i],ids,classId)
    return i, ids, classId
#@-node:ekr.20070711140703:skipSigStart
#@+node:ekr.20070712082913:skipSigTail
def skipSigTail(self,s,i,kind):

    '''Skip from the end of the arg list to the start of the block.'''

    trace = False and self.trace
    start = i
    i = g.skip_ws(s,i)
    for z in self.sigFailTokens:
        if g.match(s,i,z):
            if trace: g.trace('failToken',z,'line',g.skip_line(s,i))
            return i,False
    while i < len(s):
        if self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif g.match(s,i,self.blockDelim1):
            if trace: g.trace(repr(s[start:i]))
            return i,True
        else:
            i += 1
    if trace: g.trace('no block delim')
    return i,False
#@-node:ekr.20070712082913:skipSigTail
#@+node:ekr.20070712112008:startsHelper
def startsHelper(self,s,i,kind,tags):
    '''return True if s[i:] starts a class or function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''

    # if not tags: return False

    trace = False or self.trace
    verbose = False # kind=='function'
    self.codeEnd = self.sigEnd = self.sigId = None
    self.sigStart = i

    # Underindented lines can happen in any language, not just Python.
    # The skipBlock method of the base class checks for such lines.
    self.startSigIndent = self.getLeadingIndent(s,i)

    # Get the tag that starts the class or function.
    j = g.skip_ws_and_nl(s,i)
    i = self.skipId(s,j)
    self.sigId = theId = s[j:i] # Set sigId ivar 'early' for error messages.
    if not theId: return False

    if tags:
        if theId not in tags:
            if trace and verbose: g.trace('**** %s theId: %s not in tags: %s' % (kind,theId,tags))
            return False

    if trace and verbose: g.trace('kind',kind,'id',theId)

    # Get the class/function id.
    if kind == 'class' and self.sigId in self.anonymousClasses:
        # A hack for Delphi Pascal: interfaces have no id's.
        # g.trace('anonymous',self.sigId)
        classId = theId
        sigId = ''
    else:
        i, ids, classId = self.skipSigStart(s,j,kind,tags) # Rescan the first id.
        sigId = self.getSigId(ids)
        if not sigId:
            if trace and verbose: g.trace('**no sigId',g.get_line(s,i))
            return False

    if self.output_indent < self.startSigIndent:
        if trace: g.trace('**over-indent',sigId)
            #,'output_indent',self.output_indent,'startSigIndent',self.startSigIndent)
        return False

    # Skip the argument list.
    i, ok = self.skipArgs(s,i,kind)
    if not ok:
        if trace and verbose: g.trace('no args',g.get_line(s,i))
        return False
    i = g.skip_ws_and_nl(s,i)

    # Skip the tail of the signature
    i, ok = self.skipSigTail(s,i,kind)
    if not ok:
        if trace and verbose: g.trace('no tail',g.get_line(s,i))
        return False
    sigEnd = i

    # A trick: make sure the signature ends in a newline,
    # even if it overlaps the start of the block.
    if not g.match(s,sigEnd,'\n') and not g.match(s,sigEnd-1,'\n'):
        if trace and verbose: g.trace('extending sigEnd')
        sigEnd = g.skip_line(s,sigEnd)

    if self.blockDelim1:
        i = g.skip_ws_and_nl(s,i)
        if kind == 'class' and self.sigId in self.anonymousClasses:
            pass # Allow weird Pascal unit's.
        elif not g.match(s,i,self.blockDelim1):
            if trace and verbose: g.trace('no block',g.get_line(s,i))
            return False

    i,ok = self.skipCodeBlock(s,i,kind)
    if not ok: return False
        # skipCodeBlock skips the trailing delim.

    # Success: set the ivars.
    self.sigStart = self.adjustDefStart(s,self.sigStart)
    self.codeEnd = i
    self.sigEnd = sigEnd
    self.sigId = sigId
    self.classId = classId

    # Note: backing up here is safe because
    # we won't back up past scan's 'start' point.
    # Thus, characters will never be output twice.
    k = self.sigStart
    if not g.match(s,k,'\n'):
        self.sigStart = g.find_line_start(s,k)

    # Issue this warning only if we have a real class or function.
    if 0: # wrong.
        if s[self.sigStart:k].strip():
            self.error('%s definition does not start a line\n%s' % (
                kind,g.get_line(s,k)))

    if trace: g.trace(kind,'returns\n'+s[self.sigStart:i])
    return True
#@-node:ekr.20070712112008:startsHelper
#@-node:ekr.20070711132314:startsClass/Function (baseClass) & helpers
#@+node:ekr.20070711104014.1:startsComment
def startsComment (self,s,i):

    return (
        g.match(s,i,self.lineCommentDelim) or
        g.match(s,i,self.lineCommentDelim2) or
        g.match(s,i,self.blockCommentDelim1) or
        g.match(s,i,self.blockCommentDelim1_2)
    )
#@-node:ekr.20070711104014.1:startsComment
#@+node:ekr.20070707094858.2:startsId
def startsId(self,s,i):

    return g.is_c_id(s[i:i+1])
#@-node:ekr.20070707094858.2:startsId
#@+node:ekr.20070707172732.1:startsString
def startsString(self,s,i):

    return g.match(s,i,'"') or g.match(s,i,"'")
#@-node:ekr.20070707172732.1:startsString
#@-node:ekr.20070706084535.1:Parsing
#@+node:ekr.20070707072749:run (baseScannerClass)
def run (self,s,parent):

    c = self.c
    self.root = root = parent.copy()
    self.file_s = s
    self.tab_width = self.importCommands.getTabWidth(p=root)
    # g.trace('tab_width',self.tab_width)
    # Create the ws equivalent to one tab.
    if self.tab_width < 0:
        self.tab_ws = ' '*abs(self.tab_width)
    else:
        self.tab_ws = '\t'

    # Init the error/status info.
    self.errors = 0
    self.errorLines = []
    self.mismatchWarningGiven = False
    changed = c.isChanged()

    # Use @verbatim to escape section references
    s = self.escapeFalseSectionReferences(s)

    # Check for intermixed blanks and tabs.
    if self.strict or self.atAutoWarnsAboutLeadingWhitespace:
        self.checkBlanksAndTabs(s)

    # Regularize leading whitespace for strict languages only.
    if self.strict: s = self.regularizeWhitespace(s) 

    # Generate the nodes, including directive and section references.
    self.scan(s,parent)

    # Check the generated nodes.
    # Return True if the result is equivalent to the original file.
    ok = self.errors == 0 and self.check(s,parent)
    g.app.unitTestDict ['result'] = ok

    # Insert an @ignore directive if there were any serious problems.
    if not ok: self.insertIgnoreDirective(parent)

    if self.atAuto and ok:
        for p in root.self_and_subtree_iter():
            p.clearDirty()
        c.setChanged(changed)
    else:
        root.setDirty(setDescendentsDirty=False)
        c.setChanged(True)
#@+node:ekr.20071110105107:checkBlanksAndTabs
def checkBlanksAndTabs(self,s):

    '''Check for intermixed blank & tabs.'''

    # Do a quick check for mixed leading tabs/blanks.
    blanks = tabs = 0

    for line in g.splitLines(s):
        lws = line[0:g.skip_ws(line,0)]
        blanks += lws.count(' ')
        tabs += lws.count('\t')

    ok = blanks == 0 or tabs == 0

    if not ok:
        self.report('intermixed blanks and tabs')

    return ok
#@-node:ekr.20071110105107:checkBlanksAndTabs
#@+node:ekr.20070808115837.1:regularizeWhitespace
def regularizeWhitespace (self,s):

    '''Regularize leading whitespace in s:
    Convert tabs to blanks or vice versa depending on the @tabwidth in effect.
    This is only called for strict languages.'''

    changed = False ; lines = g.splitLines(s) ; result = [] ; tab_width = self.tab_width

    if tab_width < 0: # Convert tabs to blanks.
        for line in lines:
            i, w = g.skip_leading_ws_with_indent(line,0,tab_width)
            s = g.computeLeadingWhitespace(w,-abs(tab_width)) + line [i:] # Use negative width.
            if s != line: changed = True
            result.append(s)
    elif tab_width > 0: # Convert blanks to tabs.
        for line in lines:
            s = g.optimizeLeadingWhitespace(line,abs(tab_width)) # Use positive width.
            if s != line: changed = True
            result.append(s)

    if changed:
        action = g.choose(self.tab_width < 0,'tabs converted to blanks','blanks converted to tabs')
        message = 'inconsistent leading whitespace. %s' % action
        self.report(message)

    return ''.join(result)
#@-node:ekr.20070808115837.1:regularizeWhitespace
#@-node:ekr.20070707072749:run (baseScannerClass)
#@-node:ekr.20070703122141.65:<< class baseScannerClass >>
#@+node:ekr.20070707082432:putFunction (baseScannerClass)
def putFunction (self,s,sigStart,codeEnd,start,parent):

    '''Create a node of parent for a function defintion.'''

    trace = False and not g.unitTesting
    verbose = False

    if trace: g.trace(parent.h)

    # Enter a new function: save the old function info.
    oldStartSigIndent = self.startSigIndent

    if self.sigId:
        headline = self.sigId
    else:
        g.trace('Can not happen: no sigId')
        headline = 'unknown function'

    body1 = s[start:sigStart]
    # Adjust start backwards to get a better undent.
    if body1.strip():
        while start > 0 and s[start-1] in (' ','\t'):
            start -= 1

    body1 = self.undentBody(s[start:sigStart],ignoreComments=False)

    body2 = self.undentBody(s[sigStart:codeEnd])
    body = body1 + body2
    if trace and verbose: g.trace('body\n%s' % body)

    tail = body[len(body.rstrip()):]
    if not '\n' in tail:
        self.warning(
            '%s %s does not end with a newline; one will be added\n%s' % (
            self.functionSpelling,self.sigId,g.get_line(s,codeEnd)))

    parent = self.adjustParent(parent,headline)
    self.lastParent = self.createFunctionNode(headline,body,parent)

    # Exit the function: restore the function info.
    self.startSigIndent = oldStartSigIndent
#@-node:ekr.20070707082432:putFunction (baseScannerClass)
#@+node:ekr.20090501095634.41:class rstScanner
class rstScanner (baseScannerClass):

    @others
#@+node:ekr.20090501095634.42: __init__
def __init__ (self,importCommands,atAuto):

    # Init the base class.
    baseScannerClass.__init__(self,importCommands,atAuto=atAuto,language='rst')

    # Scanner overrides
    self.blockDelim1 = self.blockDelim2 = None
    self.classTags = []
    self.functionSpelling = 'section'
    self.functionTags = []
    self.hasClasses = False
    self.lineCommentDelim = '..'
    self.outerBlockDelim1 = None
    self.sigFailTokens = []
    self.strict = True # We want to preserve whitespace

    # Ivars unique to rst scanning & code generation.
    self.lastParent = None # The previous parent.
    self.lastSectionLevel = 0 # The section level of previous section.
    self.sectionLevel = 0 # The section level of the just-parsed section.
    self.underlineCh = '' # The underlining character of the last-parsed section.
    self.underlines = "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~" # valid rst underlines.
    self.underlines1 = [] # Underlining characters for underlines.
    self.underlines2 = [] # Underlining characters for over/underlines.
#@-node:ekr.20090501095634.42: __init__
#@+node:ekr.20090512080015.5798:adjustParent
def adjustParent (self,parent,headline):
    # parent not used here (it is used by the base-class method).
    # headline used only for traces.

    '''Return the proper parent of the new node.'''

    trace = False and not g.unitTesting

    if not self.lastParent: self.lastParent = self.root
    level,lastLevel = self.sectionLevel,self.lastSectionLevel
    lastParent = self.lastParent

    if level == 0:
        parent = self.root
    elif level <= lastLevel:
        parent = lastParent.parent()
        while level < lastLevel:
            level += 1
            parent = parent.parent()
    else: # level > lastLevel.
        level -= 1
        parent = lastParent
        while level > lastLevel:
            level -= 1
            h2 = '@rst-no-head' ; body = ''
            parent = self.createFunctionNode(h2,body,parent)

    if not parent: parent = self.root

    if trace: g.trace('level %s lastLevel %s %s returns %s' % (
        level,lastLevel,headline,parent.h))

    return parent
#@-node:ekr.20090512080015.5798:adjustParent
#@+node:ekr.20090512080015.5797:computeSectionLevel
def computeSectionLevel (self,ch,kind):

    '''Return the section level of the underlining character ch.'''

    # Can't use g.choose here.
    if kind == 'over':
        assert ch in self.underlines2
        level = 0
    else:
        level = 1 + self.underlines1.index(ch)

    # g.trace('kind: %s ch: %s under2: %s under1: %s' % (
        # kind,ch,self.underlines2,self.underlines1))

    return level
#@-node:ekr.20090512080015.5797:computeSectionLevel
#@+node:ekr.20090502071837.2:endGen
def endGen (self,s):

    '''Remember the underlining characters in the root's uA.'''

    p = self.root
    if p:
        tag = 'rst-import'
        d = p.v.u.get(tag,{})
        d ['underlines1'] = ''.join(str(self.underlines1))
        d ['underlines2'] = ''.join(str(self.underlines2))
        p.v.u [tag] = d

#@-node:ekr.20090502071837.2:endGen
#@+node:ekr.20090501095634.46:isUnderLine
def isUnderLine(self,s):

    '''Return True if s consists of only rST underline characters.'''

    if not s: return False

    for ch in s:
        if ch not in self.underlines:
            return False

    return True
#@-node:ekr.20090501095634.46:isUnderLine
#@+node:ekr.20090501095634.50:startsComment/ID/String
# These do not affect parsing.

def startsComment (self,s,i):
    return False

def startsID (self,s,i):
    return False

def startsString (self,s,i):
    return False
#@-node:ekr.20090501095634.50:startsComment/ID/String
#@+node:ekr.20090501095634.45:startsHelper
def startsHelper(self,s,i,kind,tags):

    '''return True if s[i:] starts a class or function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''

    trace = False and not g.unitTesting
    verbose = False
    kind,name,next,ch = self.startsSection(s,i)
    if kind == 'plain': return False

    self.underlineCh = ch
    self.lastSectionLevel = self.sectionLevel
    self.sectionLevel = self.computeSectionLevel(ch,kind)
    self.sigStart = g.find_line_start(s,i)
    self.sigEnd = next
    self.sigId = name.strip()
    i = next + 1

    while i < len(s):
        progress = i
        i,j = g.getLine(s,i)
        # if trace: g.trace(repr(s[i:j]))
        kind,name,next,ch = self.startsSection(s,i)
        if kind in ('over','under'):
            self.codeEnd = i
            break
        else:
            i = j
        assert i > progress
    else:
        self.codeEnd = len(s)

    if trace:
        if verbose:
            g.trace('found...\n%s' % s[self.sigStart:self.codeEnd])
        else:
            g.trace('level %s %s' % (self.sectionLevel,self.sigId))
    return True
#@nonl
#@-node:ekr.20090501095634.45:startsHelper
#@+node:ekr.20090501095634.47:startsSection
def startsSection (self,s,i):

    '''Scan a line and possible one or two other lines,
    looking for an underlined or overlined/underlined name.

    Return (kind,name,i):
        kind: in ('under','over','plain')
        name: the name of the underlined or overlined line.
        i: the following character if kind is not 'plain'
        ch: the underlining and possibly overlining character.
    '''

    trace = False and not g.unitTesting
    i1,j = g.getLine(s,i)
    line = s[i1:j].strip()
    ch,kind = '','plain' # defaults.

    if self.isUnderLine(line): # an overline.
        name_i = g.skip_line(s,i1)
        name_i,name_j = g.getLine(s,name_i)
        name = s[name_i:name_j].strip()
        next_i = g.skip_line(s,name_i)
        i,j = g.getLine(s,next_i)
        line2 = s[i:j].strip()
        n1,n2,n3 = len(line),len(name),len(line2)
        ch1,ch3 = line[0],line2 and line2[0]
        ok = (self.isUnderLine(line2) and
            n1 >= n2 and n2 > 0 and n3 >= n2 and ch1 == ch3)
        if ok:
            ch,kind = ch1,'over'
            if ch1 not in self.underlines2:
                self.underlines2.append(ch1)
                if trace: g.trace('underlines2',self.underlines2,name)
            if trace: g.trace('\nline  %s\nname  %s\nline2 %s' % (
                repr(line),repr(name),repr(line2)))
    else:
        name = line.strip()
        i = g.skip_line(s,i1)
        i,j = g.getLine(s,i)
        line2 = s[i:j].strip()
        n1,n2 = len(name),len(line2)
        # look ahead two lines.
        i3,j3 = g.getLine(s,j)
        name2 = s[i3:j3].strip()
        i4,j4 = g.getLine(s,j3)
        line4 = s[i4:j4].strip()
        n3,n4 = len(name2),len(line4)
        overline = (
            self.isUnderLine(line2) and
            self.isUnderLine(line4) and
            n3 > 0 and n2 >= n3 and n4 >= n3)
        ok = (not overline and self.isUnderLine(line2) and
            n1 > 0 and n2 >= n1)
        if ok:
            ch,kind = line2[0],'under'
            if ch not in self.underlines1:
                self.underlines1.append(ch)
                if trace: g.trace('underlines1',self.underlines1,name)
            if trace: g.trace('\nname  %s\nline2 %s' % (
                repr(name),repr(line2)))
    return kind,name,i,ch
#@-node:ekr.20090501095634.47:startsSection
#@-node:ekr.20090501095634.41:class rstScanner
#@-node:ekr.20090512080015.5794:Indent rst3 nodes based on underlining level
#@-node:ekr.20090511055302.5784:Integrate leoRst.py into Leo
#@-node:ekr.20080917153158.11:4.6 b2
#@-all
#@nonl
#@-node:EKR.20040429143933:@thin leoProjects.txt
#@-leo
