#@+leo-ver=4-thin
#@+node:ekr.20100120072650.6089:@thin leoProjects.txt
#@+at
# This part of the tree shows views of the outline related to specific 
# projects or
# tasks. I put such headlines in parentheses, and that is just my convention.
# 
# I create a new view by cloning headlines that relate to its task, and moving 
# the
# cloned headlines under the task headline. This greatly increases my focus. 
# Any
# changes made in a task view to clone headlines affect the other clones 
# scattered
# throughout the outline. In particular, all @file nodes containing changed 
# clones
# become marked as dirty, so they will be written when the entire outline is
# saved.
#@-at
#@@c

#@@language python 
#@@tabwidth -4

#@+all
#@+node:ekr.20100118163110.6256:Leo 4.7 b2 projects
#@+node:ekr.20100121105450.6175:Bugs
#@+node:ekr.20100119024225.6107:Fixed colorizer bug affecting per-language @font settings
@nocolor-node

It looks like you should be able to put the following in an
@font node, and get restructured text bold to appear in bold onscreen:

rest_keyword2_font_size = 16
rest_keyword2_font_family = Bitstream Charter
rest_keyword2_font_slant = roman
rest_keyword2_font_weight = bold

However nothing happens when I do this. The python examples in the
test.leo file work fine for me, so I'm not sure what's gone wrong.

I think that the following should also work, but it's also currently
not doing anything for me:

@color rest_keyword2_color = black

==================

Rev 2706 fixes a significant colorizer bug that caused your problem.
Previously, the colorizer inited the so-called configuration tags only
once, which is wrong. These tags are what the @font settings specify.
Now, the colorizer inits the tags when the language changes when
switching nodes.  Usually the language doesn't change, so the new code
will be approximately as fast as the old. 
#@-node:ekr.20100119024225.6107:Fixed colorizer bug affecting per-language @font settings
#@+node:ekr.20100119024225.6108:support extend-mode for several commands
'backward-find-character'
'find-character'
#@-node:ekr.20100119024225.6108:support extend-mode for several commands
#@+node:ekr.20100119024225.6106:Fixed qttab problem
@nocolor-node

On Mon, Jan 18, 2010 at 9:25 PM, tfer <tfetherston@aol.com> wrote:

cmd.exe /k C:\PyDev\leo-editor\trunk\launchLeo.py --gui=qttabs -- ipython

1) (??) the button removal menu just flash on right mouse click, disappears immediately.

2) Leo opens up the workbook, I open a new doc in a tab, 'untitled', save it,
   get saved ... in log, however, tab title does not change unless I close and
   reload it.
#@-node:ekr.20100119024225.6106:Fixed qttab problem
#@+node:ekr.20100115091643.6249:<alt-x> select-all crashes python when focus is in headline
@
The problem occurs because the QtGui.QLineEdit object goes away
when the minibuffer gets focus and the QTreeWidget loses focus.

The fix: add a 'permanent' ivar to leoQtTextWidgets, and set
this ivar to False for headline widgets.
#@nonl
#@-node:ekr.20100115091643.6249:<alt-x> select-all crashes python when focus is in headline
#@+node:ekr.20080412053100.1:Allow saving .leo files with undefined-sections
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/db797dd1d4dddffb

1) Create an @thin file based outline.
2) In the @thin file, create an unreferenced section (something like a
  header <<This Section Is Bogus>>).
3) Now, File->Exit
4) A dialog box pops up
  (Save changes to leo_file.leo before quitting? Yes/No/Cancel)
5) Click "Yes"
6) In the log pane, you will see: "undefined section" and "saved: leo_file.leo"
  and in the console window, you see "undefined section: ..."

The point is that I can't kill Leo if I keep saying "Yes" to the
"Save change before quitting" dialog. This is definitely not the
intended behavior. The correct behavior would be to save the file,
give me the warning about the undefined section, and exit.

EKR: The fix was simple: write_leo_file ignores the status returned from
c.atFileCommands.writeAll.

Note that Leo writes the write error to the console as well as the log pane,
so this should be safe enough.
#@nonl
#@-node:ekr.20080412053100.1:Allow saving .leo files with undefined-sections
#@+node:ekr.20100119175348.6127:Refactored write_Leo_file
#@-node:ekr.20100119175348.6127:Refactored write_Leo_file
#@+node:ekr.20100119175348.6128:Fixed print-bindings crasher w/ leo3k
#@-node:ekr.20100119175348.6128:Fixed print-bindings crasher w/ leo3k
#@+node:ekr.20080406075855.2:Fixed problem with already-existing .leo.bak files
@nocolor-node

I also unhappily discovered that any file named somedoc.leo.bak will
get deleted whenever you save a file named somedoc.leo.

===========

This turned into a major refactoring of write_Leo_file.
#@nonl
#@-node:ekr.20080406075855.2:Fixed problem with already-existing .leo.bak files
#@+node:ekr.20100120095741.6135:Fixed sort children bug
https://bugs.launchpad.net/leo-editor/+bug/510148

The fix was in sortSiblings.
#@-node:ekr.20100120095741.6135:Fixed sort children bug
#@+node:ekr.20100120073530.6083:Fixed unicode problems
@nocolor-node

- 'encoding' arg removed from appendStringToBody, setBodyString

- There are too many usages of _bodyString !!

- There is no way to give an encoding to setBodyString:
    It should give an internal error if the s arg is not unicode.
#@nonl
#@+node:ekr.20080710101653.1:g.pr
# see: http://www.diveintopython.org/xml_processing/unicode.html

pr_warning_given = False

def pr(*args,**keys):

    '''Print all non-keyword args, and put them to the log pane.
    The first, third, fifth, etc. arg translated by g.translateString.
    Supports color, comma, newline, spaces and tabName keyword arguments.
    '''

    # Compute the effective args.
    d = {'commas':False,'newline':True,'spaces':True}
    d = g.doKeywordArgs(keys,d)
    newline = d.get('newline')
    nl = g.choose(newline,'\n','')
    if hasattr(sys.stdout,'encoding') and sys.stdout.encoding:
        encoding = sys.stdout.encoding
    else:
        encoding = 'utf-8'

    # Important:  Python's print statement *can* handle unicode.
    # However, the following must appear in Python\Lib\sitecustomize.py:
    #    sys.setdefaultencoding('utf-8')
    s = g.translateArgs(args,d) # Translates everything to unicode.
    if app.logInited:
        s = s + '\n'

    if g.isPython3:
        s2 = s
    else:
        s2 = g.toEncodedString(s,encoding)

    if app.logInited:
        try: # We can't use any print keyword args in Python 2.x!
            sys.stdout.write(s2)
        except Exception:
            if not g.pr_warning_given:
                g.pr_warning_given = True
                # print('unexpected Exception in g.pr')
                # print('make sure your sitecustomize.py contains::')
                # print('    sys.setdefaultencoding("utf-8")')
                g.es_exception()
                g.trace(g.callers())
            s2 = s.encode('ascii',"replace")
            if g.isPython3:
                s2 = str(s2,'ascii','replace')
            sys.stdout.write(s2)
    else:
        app.printWaiting.append(s2)
#@-node:ekr.20080710101653.1:g.pr
#@+node:ekr.20100120095741.6136:qtGui diff

c:\leo.repo\trunk>bzr di -r2685..2686 leo\plugins\qtGui.py   
=== modified file 'leo/plugins/qtGui.py'
--- leo/plugins/qtGui.py	2010-01-15 15:18:58 +0000
+++ leo/plugins/qtGui.py	2010-01-16 14:51:14 +0000
@@ -429,7 +429,7 @@
         newText = w.getAllText() # Converts to unicode.

         # Get the previous values from the vnode.
-        oldText = g.app.gui.toUnicode(p.v._bodyString)
+        oldText = p.v._bodyString ### already unicode ### g.app.gui.toUnicode(p.v._bodyString)
         if oldText == newText:
             # This can happen as the result of undo.
             # g.trace('*** unexpected non-change',color="red")
@@ -669,7 +669,7 @@

         w = self.widget
         s = w.text()
-        return g.app.gui.toUnicode(s)
+        return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@nonl
#@verbatim
     #@-node:ekr.20081121105001.551:getAllText
#@verbatim
     #@+node:ekr.20081121105001.552:getInsertPoint
@@ -687,7 +687,7 @@
         if w.hasSelectedText():
             i = w.selectionStart()
             s = w.selectedText()
-            s = g.app.gui.toUnicode(s)
+            s = g.u(s) ### (s)
             j = i + len(s)
         else:
             i = j = w.cursorPosition()
@@ -722,7 +722,7 @@

         w = self.widget
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         i = w.toPythonIndex(i)
         i = max(0,min(i,len(s)))
         w.setCursorPosition(i)
@@ -734,7 +734,7 @@
         # g.trace(i,j,insert,w)
         if i > j: i,j = j,i
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         n = len(s)
         i = max(0,min(i,n))
         j = max(0,min(j,n))
@@ -1407,7 +1407,7 @@

         w = self.widget
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         return s
#@verbatim
     #@-node:ekr.20081121105001.564:getAllText
#@verbatim
     #@+node:ekr.20081121105001.565:getInsertPoint
@@ -1538,7 +1538,7 @@
         if self.check():
             w = self.widget
             s = w.text()
-            return g.app.gui.toUnicode(s)
+            return g.u(s) ### g.app.gui.toUnicode(s)
         else:
             return ''
#@verbatim
     #@nonl
@@ -1561,7 +1561,7 @@
             if w.hasSelectedText():
                 i = w.selectionStart()
                 s = w.selectedText()
-                s = g.app.gui.toUnicode(s)
+                s = g.u(s) ### g.app.gui.toUnicode(s)
                 j = i + len(s)
             else:
                 i = j = w.cursorPosition()
@@ -1608,7 +1608,7 @@

         w = self.widget
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         i = self.toPythonIndex(i)
         i = max(0,min(i,len(s)))
         w.setCursorPosition(i)
@@ -1621,7 +1621,7 @@
         # g.trace(i,j,insert,w)
         if i > j: i,j = j,i
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         n = len(s)
         i = max(0,min(i,n))
         j = max(0,min(j,n))
@@ -5551,7 +5551,6 @@
     def setMenuLabel (self,menu,name,label,underline=-1):

         def munge(s):
-            # s = g.app.gui.toUnicode(s)
             return g.u(s or '').replace('&','')

         # menu is a qtMenuWrapper.
@@ -6878,8 +6877,9 @@
         cb = self.qtApp.clipboard()
         if cb:
             # cb.clear()  # unnecessary, breaks on some Qt versions
-            if type(s) == type(''):
-                s = g.app.gui.toUnicode(s)
+            ###
+            ###if type(s) == type(''):
+            ###    s = g.app.gui.toUnicode(s)

             QtGui.QApplication.processEvents()
             cb.setText(s)
@@ -6898,7 +6898,7 @@
             QtGui.QApplication.processEvents()
             s = cb.text()
             if trace: g.trace (len(s),type(s))
-            s = g.app.gui.toUnicode(s)
+            s = g.app.gui.toUnicode(s) # Assume nothing about the type of s.
             return s
         else:
             g.trace('no clipboard!')
@@ -7017,7 +7017,7 @@
         parent = None
         title = 'Enter Leo id'
         s,ok = QtGui.QInputDialog.getText(parent,title,message)
-        return g.app.gui.toUnicode(s)
+        return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@nonl
#@verbatim
     #@-node:ekr.20081121105001.484:runAskLeoIDDialog
#@verbatim
     #@+node:ekr.20081121105001.485:runAskOkDialog
@@ -7099,9 +7099,7 @@
             return [g.u(s) for s in lst]
         else:
             s = QtGui.QFileDialog.getOpenFileName(parent,title,os.curdir,filter)
-            s = g.app.gui.toUnicode(s)
-            return s
-    #@nonl
+            return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@-node:ekr.20081121105001.488:runOpenFileDialog
#@verbatim
     #@+node:ekr.20090722094828.3653:runPropertiesDialog (qtGui)
     def runPropertiesDialog(self,
@@ -7125,7 +7123,7 @@
         parent = None
         filter_ = self.makeFilter(filetypes)
         s = QtGui.QFileDialog.getSaveFileName(parent,title,os.curdir,filter_)
-        return g.app.gui.toUnicode(s)
+        return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@-node:ekr.20081121105001.489:runSaveFileDialog
#@verbatim
     #@+node:ekr.20081121105001.490:runScrolledMessageDialog
     def runScrolledMessageDialog (self, title='Message', label= '', msg='', c=None, **kw):
@@ -7421,7 +7419,7 @@
             s = g.u(s)
             return s
         except Exception:
-            g.trace('*** Unicode Error: bugs possible')
+            # g.trace('*** Unicode Error: bugs possible')
             return g.toUnicode(s,'utf-8',reportErrors='replace')
#@verbatim
     #@-node:ekr.20081121105001.502:toUnicode (qtGui)
#@verbatim
     #@+node:ekr.20081121105001.503:widget_name (qtGui)

#@-node:ekr.20100120095741.6136:qtGui diff
#@+node:ekr.20060919110638.14:parse_leo_file
def parse_leo_file (self,theFile,inputFileName,silent,inClipboard,s=None):

    c = self.c
    try:
        if g.isPython3:
            if theFile:
                # Use the open binary file, opened by g.openLeoOrZipFile.
                s = theFile.read() # type(s) is bytes.
                s = self.cleanSaxInputString(s)
                theFile = BytesIO(s)
            else:
                s = str(s,encoding='utf-8')
                s = self.cleanSaxInputString(s)
                theFile = StringIO(s)
        else:
            if theFile: s = theFile.read()
            s = self.cleanSaxInputString(s)
            theFile = cStringIO.StringIO(s)
        parser = xml.sax.make_parser()
        parser.setFeature(xml.sax.handler.feature_external_ges,1)
            # Include external general entities, esp. xml-stylesheet lines.
        if 0: # Expat does not read external features.
            parser.setFeature(xml.sax.handler.feature_external_pes,1)
                # Include all external parameter entities
                # Hopefully the parser can figure out the encoding from the <?xml> element.
        handler = saxContentHandler(c,inputFileName,silent,inClipboard)
        parser.setContentHandler(handler)
        parser.parse(theFile) # expat does not support parseString
        # g.trace('parsing done')
        sax_node = handler.getRootNode()
    except xml.sax.SAXParseException:
        g.es_print('error parsing',inputFileName,color='red')
        g.es_exception()
        sax_node = None
    except Exception:
        g.es_print('unexpected exception parsing',inputFileName,color='red')
        g.es_exception()
        sax_node = None

    return sax_node
#@-node:ekr.20060919110638.14:parse_leo_file
#@-node:ekr.20100120073530.6083:Fixed unicode problems
#@+node:ekr.20100121050224.6141:Fixed crash in writeToFileHelper
#@+node:ekr.20031218072017.1470:put
def put (self,s):

    '''Put string s to self.outputFile. All output eventually comes here.'''

    # Improved code: self.outputFile (a cStringIO object) always exists.
    # g.trace(g.callers(1),repr(s))
    if s:
        self.putCount += 1
        if not g.isPython3:
            s = g.toEncodedString(s,self.leo_file_encoding,reportErrors=True)
        self.outputFile.write(s)

def put_dquote (self):
    self.put('"')

def put_dquoted_bool (self,b):
    if b: self.put('"1"')
    else: self.put('"0"')

def put_flag (self,a,b):
    if a:
        self.put(" ") ; self.put(b) ; self.put('="1"')

def put_in_dquotes (self,a):
    self.put('"')
    if a: self.put(a) # will always be True if we use backquotes.
    else: self.put('0')
    self.put('"')

def put_nl (self):
    self.put("\n")

def put_tab (self):
    self.put("\t")

def put_tabs (self,n):
    while n > 0:
        self.put("\t")
        n -= 1
#@nonl
#@-node:ekr.20031218072017.1470:put
#@+node:ekr.20100119145629.6111:writeToFileHelper & helpers
def writeToFileHelper (self,fileName,toOPML):

    c = self.c ; toZip = c.isZipped
    ok,backupName = self.createBackupFile(fileName)
    if not ok: return False
    fileName,theActualFile = self.createActualFile(fileName,toOPML,toZip)
    self.mFileName = fileName
    self.outputFile = StringIO() # Always write to a string.

    try:
        if toOPML:
            self.putToOPML()
        else:
            self.putLeoFile()
        s = self.outputFile.getvalue()
        g.app.write_Leo_file_string = s # 2010/01/19: always set this.
        if toZip:
            self.writeZipFile(s)
        else:
            if g.isPython3:
                s = bytes(s,self.leo_file_encoding,'replace')
            theActualFile.write(s)
            theActualFile.close()
            c.setFileTimeStamp(fileName)
            # raise AttributeError # To test handleWriteLeoFileException.
            # Delete backup file.
            if backupName and g.os_path_exists(backupName):
                self.deleteFileWithMessage(backupName,'backup')
        return True
    except Exception:
        self.handleWriteLeoFileException(
            fileName,backupName,theActualFile)
        return False
#@+node:ekr.20100119145629.6106:createActualFile
def createActualFile (self,fileName,toOPML,toZip):

    c = self.c

    if toOPML and not self.mFileName.endswith('opml'):
        fileName = self.mFileName + '.opml'

    if toZip:
        self.toString = True
        theActualFile = None
    else:
        try:
            # 2010/01/21: always write in binary mode.
            theActualFile = open(fileName,'wb')
        except IOError:
            theActualFile = None

    return fileName,theActualFile
#@-node:ekr.20100119145629.6106:createActualFile
#@+node:ekr.20031218072017.3047:createBackupFile
def createBackupFile (self,fileName):

    '''
        Create a closed backup file and copy the file to it,
        but only if the original file exists.
    '''

    c = self.c

    if g.os_path_exists(fileName):
        # backupName = g.os_path_join(g.app.loadDir,fileName+'.bak')
        fd,backupName = tempfile.mkstemp(text=False)
        os.close(fd)
        ok = g.utils_rename(c,fileName,backupName)
        if not ok and self.read_only:
            g.es("read only",color="red")
    else:
        ok,backupName = True,None

    return ok,backupName
#@-node:ekr.20031218072017.3047:createBackupFile
#@+node:ekr.20100119145629.6108:handleWriteLeoFileException
def handleWriteLeoFileException(self,fileName,backupName,theActualFile):

    c = self.c

    g.es("exception writing:",fileName)
    g.es_exception(full=True)

    if theActualFile:
        theActualFile.close()

    # Delete fileName.
    if fileName and g.os_path_exists(fileName):
        self.deleteFileWithMessage(fileName,'')

    # Rename backupName to fileName.
    if backupName and g.os_path_exists(backupName):
        g.es("restoring",fileName,"from",backupName)
        g.utils_rename(c,backupName,fileName)
    else:
        g.es_print('does not exist!',backupName)

#@-node:ekr.20100119145629.6108:handleWriteLeoFileException
#@-node:ekr.20100119145629.6111:writeToFileHelper & helpers
#@-node:ekr.20100121050224.6141:Fixed crash in writeToFileHelper
#@+node:ekr.20100121105450.6173:Add warnings when @file logic happens
#@+node:ekr.20041005105605.73:findChild4
def findChild4 (self,headline):

    """Return the next vnode in at.root.tnodeLisft.
    This is called only for @file/@noref nodes"""

    # Note: tnodeLists are used _only_ when reading @file (not @thin) nodes.
    # tnodeLists compensate (a hack) for not having gnx's in derived files! 

    trace = False and not g.unitTesting
    at = self ; v = at.root.v

    if not g.unitTesting:
        if v.isAtFileNode():
            g.es_print('Warning: @file logic',v.h)

    if trace: g.trace('%s %s %s' % (
        at.tnodeListIndex,
        v.tnodeList[at.tnodeListIndex],headline))

    if not hasattr(v,"tnodeList"):
        at.readError("no tnodeList for " + repr(v))
        g.es("write the @file node or use the Import Derived File command")
        g.trace("no tnodeList for ",v,g.callers())
        return None

    if at.tnodeListIndex >= len(v.tnodeList):
        at.readError("bad tnodeList index: %d, %s" % (at.tnodeListIndex,repr(v)))
        g.trace("bad tnodeList index",at.tnodeListIndex,len(v.tnodeList),v)
        return None

    v = v.tnodeList[at.tnodeListIndex]
    assert(v)
    at.tnodeListIndex += 1

    # Don't check the headline.  It simply causes problems.
    v.setVisited() # Supress warning/deletion of unvisited nodes.
    return v
#@-node:ekr.20041005105605.73:findChild4
#@-node:ekr.20100121105450.6173:Add warnings when @file logic happens
#@+node:ekr.20100120095741.6134:Fixed mkstemp bug
@nocolor-node

https://bugs.launchpad.net/leo-editor/+bug/510145

Current leo trunk, r2732, Slackware Linux

- I go to /tmp in terminal
- there is no aaa.leo there (this is important, see below why)
- I launch leo (the current working directory is /tmp)
- I select "File->Save as" menu item
- the save file dialog opens in /tmp, this is correct
- I type in the file name "aaa" then hit "Save" button
- leo dumps an error in the log pane:

exception renaming /tmp/aaa.leo to /tmp/tmpbNydoS
IOError: [Errno 2] No such file or directory: u'/tmp/aaa.leo'

=============

The solution was to create the backup file only if fileName exists.
#@nonl
#@+node:ekr.20100119145629.6111:writeToFileHelper & helpers
def writeToFileHelper (self,fileName,toOPML):

    c = self.c ; toZip = c.isZipped
    ok,backupName = self.createBackupFile(fileName)
    if not ok: return False
    fileName,theActualFile = self.createActualFile(fileName,toOPML,toZip)
    self.mFileName = fileName
    self.outputFile = StringIO() # Always write to a string.

    try:
        if toOPML:
            self.putToOPML()
        else:
            self.putLeoFile()
        s = self.outputFile.getvalue()
        g.app.write_Leo_file_string = s # 2010/01/19: always set this.
        if toZip:
            self.writeZipFile(s)
        else:
            if g.isPython3:
                s = bytes(s,self.leo_file_encoding,'replace')
            theActualFile.write(s)
            theActualFile.close()
            c.setFileTimeStamp(fileName)
            # raise AttributeError # To test handleWriteLeoFileException.
            # Delete backup file.
            if backupName and g.os_path_exists(backupName):
                self.deleteFileWithMessage(backupName,'backup')
        return True
    except Exception:
        self.handleWriteLeoFileException(
            fileName,backupName,theActualFile)
        return False
#@+node:ekr.20100119145629.6106:createActualFile
def createActualFile (self,fileName,toOPML,toZip):

    c = self.c

    if toOPML and not self.mFileName.endswith('opml'):
        fileName = self.mFileName + '.opml'

    if toZip:
        self.toString = True
        theActualFile = None
    else:
        try:
            # 2010/01/21: always write in binary mode.
            theActualFile = open(fileName,'wb')
        except IOError:
            theActualFile = None

    return fileName,theActualFile
#@-node:ekr.20100119145629.6106:createActualFile
#@+node:ekr.20031218072017.3047:createBackupFile
def createBackupFile (self,fileName):

    '''
        Create a closed backup file and copy the file to it,
        but only if the original file exists.
    '''

    c = self.c

    if g.os_path_exists(fileName):
        # backupName = g.os_path_join(g.app.loadDir,fileName+'.bak')
        fd,backupName = tempfile.mkstemp(text=False)
        os.close(fd)
        ok = g.utils_rename(c,fileName,backupName)
        if not ok and self.read_only:
            g.es("read only",color="red")
    else:
        ok,backupName = True,None

    return ok,backupName
#@-node:ekr.20031218072017.3047:createBackupFile
#@+node:ekr.20100119145629.6108:handleWriteLeoFileException
def handleWriteLeoFileException(self,fileName,backupName,theActualFile):

    c = self.c

    g.es("exception writing:",fileName)
    g.es_exception(full=True)

    if theActualFile:
        theActualFile.close()

    # Delete fileName.
    if fileName and g.os_path_exists(fileName):
        self.deleteFileWithMessage(fileName,'')

    # Rename backupName to fileName.
    if backupName and g.os_path_exists(backupName):
        g.es("restoring",fileName,"from",backupName)
        g.utils_rename(c,backupName,fileName)
    else:
        g.es_print('does not exist!',backupName)

#@-node:ekr.20100119145629.6108:handleWriteLeoFileException
#@-node:ekr.20100119145629.6111:writeToFileHelper & helpers
#@-node:ekr.20100120095741.6134:Fixed mkstemp bug
#@+node:ekr.20100121162122.6142:Removed most usage of _bodyString & _headString
@nocolor-node

Made sure _bodyString _headString used only in leoNodes.py.

We allow setting this vars in file reading code.

*** p.b/p.h setters call c.setBody/HeadString,
    which are very slow!
#@+node:ekr.20040306220230:p.Headline & body strings
def bodyString (self):

    return self.v.bodyString()

def headString (self):

    return self.v.headString()

def cleanHeadString (self):

    return self.v.cleanHeadString()
#@-node:ekr.20040306220230:p.Headline & body strings
#@+node:ekr.20090128083459.74:p.Properties
#@+node:ekr.20090128083459.75:p.b property
def __get_b(self):

    p = self
    return p.bodyString()

def __set_b(self,val):

    p = self ; c = p.v and p.v.context
    if c:
        c.setBodyString(p, val)
        # Don't redraw the screen: p.b must be fast.
        # c.redraw_after_icons_changed()

b = property(
    __get_b, __set_b,
    doc = "position body string property")
#@-node:ekr.20090128083459.75:p.b property
#@+node:ekr.20090128083459.76:p.h property
def __get_h(self):

    p = self
    return p.headString()

def __set_h(self,val):

    p = self ; c = p.v and p.v.context
    if c:
        c.setHeadString(p,val)
        # Don't redraw the screen: p.h must be fast.
        # c.redraw_after_head_changed()

h = property(
    __get_h, __set_h,
    doc = "position headline string property")  
#@-node:ekr.20090128083459.76:p.h property
#@+node:ekr.20090215165030.3:p.gnx property
def __get_gnx(self):
    p = self
    return g.app.nodeIndices.toString(p.v.fileIndex)

gnx = property(
    __get_gnx, # __set_gnx,
    doc = "position gnx property")
#@-node:ekr.20090215165030.3:p.gnx property
#@-node:ekr.20090128083459.74:p.Properties
#@+node:ekr.20090130065000.1:v.Properties
#@+node:ekr.20090130114732.5:v.b Property
def __get_b(self):

    v = self
    return v.bodyString()

def __set_b(self,val):

    v = self
    v.setBodyString(val)

b = property(
    __get_b, __set_b,
    doc = "vnode body string property")
#@-node:ekr.20090130114732.5:v.b Property
#@+node:ekr.20090130125002.1:v.h property
def __get_h(self):

    v = self
    return v.headString()

def __set_h(self,val):

    v = self
    v.setHeadString(val)

h = property(
    __get_h, __set_h,
    doc = "vnode headline string property")  
#@-node:ekr.20090130125002.1:v.h property
#@+node:ekr.20090130114732.6:v.u Property
def __get_u(self):
    v = self
    if not hasattr(v,'unknownAttributes'):
        v.unknownAttributes = {}
    return v.unknownAttributes

def __set_u(self,val):
    v = self
    if val is None:
        if hasattr(v,'unknownAttributes'):
            delattr(v,'unknownAttributes')
    elif type(val) == type({}):
        v.unknownAttributes = val
    else:
        raise ValueError

u = property(
    __get_u, __set_u,
    doc = "vnode unknownAttribute property")
#@-node:ekr.20090130114732.6:v.u Property
#@+node:ekr.20090215165030.1:v.gnx Property
def __get_gnx(self):
    v = self
    return g.app.nodeIndices.toString(v.fileIndex)

gnx = property(
    __get_gnx, # __set_gnx,
    doc = "vnode gnx property")
#@-node:ekr.20090215165030.1:v.gnx Property
#@-node:ekr.20090130065000.1:v.Properties
#@+node:ekr.20040315032144:v .setBodyString & v.setHeadString
def setBodyString (self,s):

    # trace = False and not g.unitTesting
    v = self
    # if trace and v._bodyString != s:
        # g.trace('v %s %s -> %s %s\nold: %s\nnew: %s' % (
            # v.h, len(v._bodyString),len(s),g.callers(5),
            # v._bodyString,s))
    v._bodyString = g.toUnicode(s,reportErrors=True)

def setHeadString (self,s):
    v = self
    v._headString = g.toUnicode(s,reportErrors=True)

initBodyString = setBodyString
initHeadString = setHeadString
setHeadText = setHeadString
setTnodeText = setBodyString
#@-node:ekr.20040315032144:v .setBodyString & v.setHeadString
#@+node:ekr.20040305223522:c.setBodyString
def setBodyString (self,p,s):

    c = self ; v = p.v
    if not c or not v: return

    s = g.toUnicode(s)
    current = c.p
    # 1/22/05: Major change: the previous test was: 'if p == current:'
    # This worked because commands work on the presently selected node.
    # But setRecentFiles may change a _clone_ of the selected node!
    if current and p.v==current.v:
        # Revert to previous code, but force an empty selection.
        c.frame.body.setSelectionAreas(s,None,None)
        w = c.frame.body.bodyCtrl
        i = w.getInsertPoint()
        w.setSelectionRange(i,i)
        # This code destoys all tags, so we must recolor.
        c.recolor()

    # Keep the body text in the vnode up-to-date.
    if v.b != s:
        v.setBodyString(s)
        v.setSelection(0,0)
        p.setDirty()
        if not c.isChanged():
            c.setChanged(True)
        c.redraw_after_icons_changed()
#@nonl
#@-node:ekr.20040305223522:c.setBodyString
#@+node:ekr.20050411193627.9:afterInsertNode
def afterInsertNode (self,p,command,bunch,dirtyVnodeList=[]):

    u = self ; c = u.c
    if u.redoing or u.undoing: return

    # Set types & helpers
    bunch.kind = 'insert'
    bunch.undoType = command
    # g.trace(repr(command),g.callers())

    # Set helpers
    bunch.undoHelper = u.undoInsertNode
    bunch.redoHelper = u.redoInsertNode

    bunch.newP = p.copy()
    bunch.dirtyVnodeList = dirtyVnodeList

    bunch.newBack = p.back()
    bunch.newParent = p.parent()

    bunch.newChanged = c.isChanged()
    bunch.newDirty = p.isDirty()
    bunch.newMarked = p.isMarked()

    if bunch.pasteAsClone:
        beforeTree=bunch.beforeTree
        afterTree = []
        for bunch2 in beforeTree:
            v = bunch2.v
            afterTree.append(
                g.Bunch(v=v,head=v.h[:],body=v.b[:]))
        bunch.afterTree=afterTree
        # g.trace(afterTree)

    u.pushBead(bunch)
#@-node:ekr.20050411193627.9:afterInsertNode
#@-node:ekr.20100121162122.6142:Removed most usage of _bodyString & _headString
#@+node:ekr.20100122073254.6165:Don't use tnodeList to separate old/new @file nodes
@nocolor-node

- Removed thinFile arg from atFile.read.
  atFile.read can uncache *any* cached file.
- Removed thinfile arg from initReadIvars.
- self.thinFile ivar set only in readOpenFile.
- atFile.read no longer calls scanHeaderForThin:
  we simply use the thinFile value returned by scanHeader.
- atFile.readOpenFile deletes children as needed.
#@nonl
#@+node:ekr.20041005105605.21:read (atFile) & helpers
# This code no longer reads @noref trees.

def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    # g.trace(root.h,len(root.b))
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    if at.errors:
        return False
    fileName = at.openFileForReading(fromString=fromString)
    if at.inputFile:
        c.setFileTimeStamp(fileName)
    else:
        return False
    root.v.at_read = True # Remember that we have read this file.
    # Get the file from the cache if possible.
    ok,cachefile = self.readFromCache(fileName,force,root)
    if ok:
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    root.clearVisitedInTree()
    d = at.scanAllDirectives(root,importing=at.importing,reading=True)
    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.warnAboutUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        self.copyAllTempBodyStringsToTnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if at.errors == 0:
        self.writeCachedTree(root,cachefile)

    return at.errors == 0
#@+node:ekr.20041005105605.25:deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
#@-node:ekr.20041005105605.25:deleteAllTempBodyStrings
#@+node:ekr.20100122130101.6174:deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@-node:ekr.20100122130101.6174:deleteTnodeList
#@+node:ekr.20041005105605.22:initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName

    # isAtFile = (
        # not thinFile and
        # not importFileName and
        # not atShadow and
        # not fromString and
        # root.h.startswith('@file'))
#@-node:ekr.20041005105605.22:initFileName
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20071105164407:warnAboutUnvisitedNodes
def warnAboutUnvisitedNodes (self,root):

    resurrected = 0

    for p in root.self_and_subtree():
        if not p.v.isVisited():
            g.trace('**** not visited',p.v,p.h)
            g.es('resurrected node:',p.h,color='blue')
            g.es('in file:',root.h,color='blue')
            resurrected += 1

    if resurrected:
        g.es('you may want to delete ressurected nodes')
#@-node:ekr.20071105164407:warnAboutUnvisitedNodes
#@-node:ekr.20041005105605.21:read (atFile) & helpers
#@+node:ekr.20041005105605.27:readOpenFile
def readOpenFile(self,root,theFile,fileName,deleteNodes=False):

    '''Read an open derived file.

    Leo 4.5 and later can only read 4.x derived files.'''

    at = self

    firstLines,read_new,thinFile = at.scanHeader(theFile,fileName)
    at.thinFile = thinFile
        # 2010/01/22: use *only* the header to set self.thinFile.

    if deleteNodes and at.shouldDeleteChildren(root,thinFile):
        root.v.at_read = True # Create the attribute for all clones.
        while root.hasChildren():
            root.firstChild().doDelete()

    if read_new:
        lastLines = at.scanText4(theFile,fileName,root)
    else:
        firstLines = [] ; lastLines = []
        if at.atShadow:
            g.trace(g.callers())
            g.trace('invalid @shadow private file',fileName)
            at.error('invalid @shadow private file',fileName)
        else:
            at.error('can not read 3.x derived file',fileName)
            g.es('you may upgrade these file using Leo 4.0 through 4.4.x')
            g.trace('root',root and root.h,fileName)

    if root:
        root.v.setVisited() # Disable warning about set nodes.

    << handle first and last lines >>

    return thinFile
#@+node:ekr.20041005105605.28:<< handle first and last lines >>
try:
    body = root.v.tempBodyString
except Exception:
    body = ""

lines = body.split('\n')
at.completeFirstDirectives(lines,firstLines)
at.completeLastDirectives(lines,lastLines)
s = '\n'.join(lines).replace('\r', '')
root.v.tempBodyString = s
#@-node:ekr.20041005105605.28:<< handle first and last lines >>
#@+node:ekr.20100122130101.6175:shouldDeleteChildren
def shouldDeleteChildren (self,root,thinFile):

    '''Return True if we should delete all children before a read.'''

    # Delete all children except for old-style @file nodes

    if root.isAtNoSentFileNode():
        return False
    elif root.isAtFileNode() and not thinFile:
        return False
    else:
        return True
#@-node:ekr.20100122130101.6175:shouldDeleteChildren
#@-node:ekr.20041005105605.27:readOpenFile
#@+node:ekr.20041005105605.13:initReadIvars
def initReadIvars(self,root,fileName,
    importFileName=None,
    perfectImportRoot=None,
    atShadow=False,
):

    importing = importFileName is not None

    self.initCommonIvars()

    << init ivars for reading >>

    self.scanDefaultDirectory(root,importing=importing)
    if self.errors: return

    # Init state from arguments.
    self.perfectImportRoot = perfectImportRoot
    self.importing = importing
    self.root = root
    self.targetFileName = fileName
    self.thinFile = False # 2010/01/22: was thinFile
    self.atShadow = atShadow
#@+node:ekr.20041005105605.14:<< init ivars for reading >>
self.atAllFlag = False # True if @all seen.
self.cloneSibCount = 0 # n > 1: Make sure n cloned sibs exists at next @+node sentinel
self.correctedLines = 0
self.docOut = [] # The doc part being accumulated.
self.done = False # True when @-leo seen.
self.endSentinelStack = []
self.importing = False
self.importRootSeen = False
self.indentStack = []
self.inputFile = None
self.lastLines = [] # The lines after @-leo
self.lastThinNode = None # Used by createThinChild4.
self.leadingWs = ""
self.lineNumber = 0 # New in Leo 4.4.8.
self.out = None
self.outStack = []
self.rootSeen = False
self.tnodeList = [] # Needed until old-style @file nodes are no longer supported.
self.tnodeListIndex = 0
self.v = None
self.tStack = []
self.thinNodeStack = [] # Used by createThinChild4.
self.updateWarningGiven = False
#@-node:ekr.20041005105605.14:<< init ivars for reading >>
#@-node:ekr.20041005105605.13:initReadIvars
#@+node:ekr.20041005105605.129:at.scanHeader
def scanHeader(self,theFile,fileName):

    """Scan the @+leo sentinel.

    Sets self.encoding, and self.start/endSentinelComment.

    Returns (firstLines,new_df,isThinDerivedFile) where:
    firstLines        contains all @first lines,
    new_df            is True if we are reading a new-format derived file.
    isThinDerivedFile is True if the file is an @thin file."""

    trace = False
    at = self
    firstLines = [] # The lines before @+leo.
    tag = "@+leo"
    valid = True ; new_df = False ; isThinDerivedFile = False
    << skip any non @+leo lines >>
    if valid:
        valid,new_df,start,end,isThinDerivedFile = at.parseLeoSentinel(s)
    if valid:
        at.startSentinelComment = start
        at.endSentinelComment = end
        # g.trace('start',repr(start),'end',repr(end))
    else:
        at.error("No @+leo sentinel in: %s" % fileName)
    # g.trace("start,end",repr(at.startSentinelComment),repr(at.endSentinelComment))
    return firstLines,new_df,isThinDerivedFile
#@+node:ekr.20041005105605.130:<< skip any non @+leo lines >>
@ Queue up the lines before the @+leo.

These will be used to add as parameters to the @first directives, if any.
Empty lines are ignored (because empty @first directives are ignored).
NOTE: the function now returns a list of the lines before @+leo.

We can not call sentinelKind here because that depends on
the comment delimiters we set here.

at-first lines are written "verbatim", so nothing more needs to be done!
@c

s = at.readLine(theFile)
if trace: g.trace('first line',repr(s))
while len(s) > 0:
    j = s.find(tag)
    if j != -1: break
    firstLines.append(s) # Queue the line
    s = at.readLine(theFile)

n = len(s)
valid = n > 0
#@-node:ekr.20041005105605.130:<< skip any non @+leo lines >>
#@-node:ekr.20041005105605.129:at.scanHeader
#@+node:ekr.20041005105605.120:at.parseLeoSentinel
def parseLeoSentinel (self,s):

    at = self ; c = at.c
    new_df = False ; valid = True ; n = len(s)
    start = '' ; end = '' ; isThinDerivedFile = False
    encoding_tag = "-encoding="
    version_tag = "-ver="
    tag = "@+leo"
    thin_tag = "-thin"
    << set the opening comment delim >>
    << make sure we have @+leo >>
    << read optional version param >>
    << read optional thin param >>
    << read optional encoding param >>
    << set the closing comment delim >>
    if not new_df and not g.unitTesting:
        g.trace('not new_df(!)',repr(s))
    return valid,new_df,start,end,isThinDerivedFile
#@+node:ekr.20041005105605.121:<< set the opening comment delim >>
# s contains the tag
i = j = g.skip_ws(s,0)

# The opening comment delim is the initial non-tag
while i < n and not g.match(s,i,tag) and not g.is_nl(s,i):
    i += 1

if j < i:
    start = s[j:i]
else:
    valid = False

#@-node:ekr.20041005105605.121:<< set the opening comment delim >>
#@+node:ekr.20041005105605.122:<< make sure we have @+leo >>
@ REM hack: leading whitespace is significant before the @+leo.  We do this so that sentinelKind need not skip whitespace following self.startSentinelComment.  This is correct: we want to be as restrictive as possible about what is recognized as a sentinel.  This minimizes false matches.
@c

if 0: # Make leading whitespace significant.
    i = g.skip_ws(s,i)

if g.match(s,i,tag):
    i += len(tag)
else: valid = False
#@-node:ekr.20041005105605.122:<< make sure we have @+leo >>
#@+node:ekr.20041005105605.123:<< read optional version param >>
new_df = g.match(s,i,version_tag)

if new_df:
    # Pre Leo 4.4.1: Skip to the next minus sign or end-of-line.
    # Leo 4.4.1 +:   Skip to next minus sign, end-of-line, or non numeric character.
    # This is required to handle trailing comment delims properly.
    i += len(version_tag)
    j = i
    while i < len(s) and (s[i] == '.' or s[i].isdigit()):
        i += 1

    if j < i:
        pass
    else:
        valid = False
#@-node:ekr.20041005105605.123:<< read optional version param >>
#@+node:ekr.20041005105605.124:<< read optional thin param >>
if g.match(s,i,thin_tag):
    i += len(tag)
    isThinDerivedFile = True
#@-node:ekr.20041005105605.124:<< read optional thin param >>
#@+node:ekr.20041005105605.125:<< read optional encoding param >>
# Set the default encoding
at.encoding = c.config.default_derived_file_encoding

if g.match(s,i,encoding_tag):
    # Read optional encoding param, e.g., -encoding=utf-8,
    i += len(encoding_tag)
    # Skip to the next end of the field.
    j = s.find(",.",i)
    if j > -1:
        # The encoding field was written by 4.2 or after:
        encoding = s[i:j]
        i = j + 2 # 6/8/04, 1/11/05 (was i = j + 1)
    else:
        # The encoding field was written before 4.2.
        j = s.find('.',i)
        if j > -1:
            encoding = s[i:j]
            i = j + 1 # 6/8/04
        else:
            encoding = None
    # g.trace("encoding:",encoding)
    if encoding:
        if g.isValidEncoding(encoding):
            at.encoding = encoding
        else:
            g.es_print("bad encoding in derived file:",encoding)
    else:
        valid = False
#@-node:ekr.20041005105605.125:<< read optional encoding param >>
#@+node:ekr.20041005105605.126:<< set the closing comment delim >>
# The closing comment delim is the trailing non-whitespace.
i = j = g.skip_ws(s,i)
while i < n and not g.is_ws(s[i]) and not g.is_nl(s,i):
    i += 1
end = s[j:i]
#@-node:ekr.20041005105605.126:<< set the closing comment delim >>
#@-node:ekr.20041005105605.120:at.parseLeoSentinel
#@+node:ekr.20041005105605.74:scanText4 & allies
def scanText4 (self,theFile,fileName,p,verbose=False):

    """Scan a 4.x derived file non-recursively."""

    trace = False and not g.unitTesting
    at = self
    << init ivars for scanText4 >>
    if trace: g.trace(fileName)
    try:
        while at.errors == 0 and not at.done:
            s = at.readLine(theFile)
            self.lineNumber += 1
            if len(s) == 0: break
            kind = at.sentinelKind4(s)
            if kind == at.noSentinel:
                i = 0
            else:
                i = at.skipSentinelStart4(s,0)
            func = at.dispatch_dict[kind]
            if trace: g.trace('%15s %16s %s' % (
                at.sentinelName(kind),func.__name__,repr(s)))
            func(s,i)
    except AssertionError:
        junk, message, junk = sys.exc_info()
        at.error('unexpected assertion failure in',fileName,'\n',message)

    if at.errors == 0 and not at.done:
        << report unexpected end of text >>

    return at.lastLines
#@+node:ekr.20041005105605.75:<< init ivars for scanText4 >>
# Unstacked ivars...
at.cloneSibCount = 0
at.done = False
at.inCode = True
at.indent = 0 # Changed only for sentinels.
at.lastLines = [] # The lines after @-leo
at.leadingWs = ""
at.lineNumber = 0
at.root = p.copy() # Bug fix: 12/10/05
at.rootSeen = False
at.updateWarningGiven = False

# Stacked ivars...
at.endSentinelStack = [at.endLeo] # We have already handled the @+leo sentinel.
at.out = [] ; at.outStack = []
at.v = p.v
at.tStack = []
# New code: always identify root @thin node with self.root:
at.lastThinNode = None
at.thinNodeStack = []
#@nonl
#@-node:ekr.20041005105605.75:<< init ivars for scanText4 >>
#@+node:ekr.20041005105605.76:<< report unexpected end of text >>
assert at.endSentinelStack,'empty sentinel stack'

at.readError(
    "Unexpected end of file. Expecting %s sentinel" %
    at.sentinelName(at.endSentinelStack[-1]))
#@-node:ekr.20041005105605.76:<< report unexpected end of text >>
#@+node:ekr.20041005105605.77:readNormalLine
def readNormalLine (self,s,i):

    at = self

    if at.inCode:
        if not at.raw:
            s = g.removeLeadingWhitespace(s,at.indent,at.tab_width)
        at.out.append(s)
    else:
        << Skip the leading stuff >>
        << Append s to docOut >>
#@+node:ekr.20041005105605.78:<< Skip the leading stuff >>
if len(at.endSentinelComment) == 0:
    # Skip the single comment delim and a blank.
    i = g.skip_ws(s,0)
    if g.match(s,i,at.startSentinelComment):
        i += len(at.startSentinelComment)
        if g.match(s,i," "): i += 1
else:
    i = at.skipIndent(s,0,at.indent)
#@-node:ekr.20041005105605.78:<< Skip the leading stuff >>
#@+node:ekr.20041005105605.79:<< Append s to docOut >>
line = s[i:-1] # remove newline for rstrip.

if line == line.rstrip():
    # no trailing whitespace: the newline is real.
    at.docOut.append(line + '\n')
else:
    # trailing whitespace: the newline is fake.
    at.docOut.append(line)
#@-node:ekr.20041005105605.79:<< Append s to docOut >>
#@-node:ekr.20041005105605.77:readNormalLine
#@+node:ekr.20041005105605.80:start sentinels
#@+node:ekr.20041005105605.81:at.readStartAll
def readStartAll (self,s,i):

    """Read an @+all sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert g.match(s,j,"@+all"),'missing @+all'
    else:
        assert g.match(s,j,"+all"),'missing +all'

    # g.trace('root_seen',at.root_seen,at.root.h,repr(s))
    at.atAllFlag = True

    # Make sure that the generated at-all is properly indented.
    at.out.append(leadingWs + "@all\n")

    at.endSentinelStack.append(at.endAll)
#@-node:ekr.20041005105605.81:at.readStartAll
#@+node:ekr.20041005105605.82:readStartAt & readStartDoc
def readStartAt (self,s,i):
    """Read an @+at sentinel."""
    at = self ; assert g.match(s,i,"+at"),'missing +at'
    if 0:# new code: append whatever follows the sentinel.
        i += 3 ; j = at.skipToEndSentinel(s,i) ; follow = s[i:j]
        at.out.append('@' + follow) ; at.docOut = []
    else:
        i += 3 ; j = g.skip_ws(s,i) ; ws = s[i:j]
        at.docOut = ['@' + ws + '\n'] # This newline may be removed by a following @nonl
    at.inCode = False
    at.endSentinelStack.append(at.endAt)

def readStartDoc (self,s,i):
    """Read an @+doc sentinel."""
    at = self ; assert g.match(s,i,"+doc"),'missing +doc'
    if 0: # new code: append whatever follows the sentinel.
        i += 4 ; j = at.skipToEndSentinel(s,i) ; follow = s[i:j]
        at.out.append('@' + follow) ; at.docOut = []
    else:
        i += 4 ; j = g.skip_ws(s,i) ; ws = s[i:j]
        at.docOut = ["@doc" + ws + '\n'] # This newline may be removed by a following @nonl
    at.inCode = False
    at.endSentinelStack.append(at.endDoc)

def skipToEndSentinel(self,s,i):
    at = self
    end = at.endSentinelComment
    if end:
        j = s.find(end,i)
        if j == -1:
            return g.skip_to_end_of_line(s,i)
        else:
            return j
    else:
        return g.skip_to_end_of_line(s,i)
#@-node:ekr.20041005105605.82:readStartAt & readStartDoc
#@+node:ekr.20041005105605.83:readStartLeo
def readStartLeo (self,s,i):

    """Read an unexpected @+leo sentinel."""

    at = self
    assert g.match(s,i,"+leo"),'missing +leo sentinel'
    at.readError("Ignoring unexpected @+leo sentinel")
#@-node:ekr.20041005105605.83:readStartLeo
#@+node:ekr.20041005105605.84:readStartMiddle
def readStartMiddle (self,s,i):

    """Read an @+middle sentinel."""

    at = self

    at.readStartNode(s,i,middle=True)
#@-node:ekr.20041005105605.84:readStartMiddle
#@+node:ekr.20041005105605.85:at.readStartNode
def readStartNode (self,s,i,middle=False):

    """Read an @+node or @+middle sentinel."""

    trace = False and not g.unitTesting
    at = self
    if middle:
        assert g.match(s,i,"+middle:"),'missing +middle'
        i += 8
    else:
        assert g.match(s,i,"+node:"),'missing +node'
        i += 6

    if at.thinFile:
        << set gnx and bump i >>
    << Set headline, undoing the CWEB hack >>
    if not at.root_seen:
        # g.trace(repr(s[0:i+20]))
        at.root_seen = True

    i,newIndent = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    at.indentStack.append(at.indent) ; at.indent = newIndent

    at.outStack.append(at.out) ; at.out = []
    at.tStack.append(at.v)

    if trace: g.trace(at.root)
    if at.importing:
        p = at.createImportedNode(at.root,headline)
        at.v = p.v
    elif at.thinFile:
        if at.thinNodeStack:
            at.thinNodeStack.append(at.lastThinNode)
            v = at.createThinChild4(gnx,headline)
        else:
            v = at.root.v
            at.thinNodeStack.append(v)
        at.lastThinNode = v
        at.v = v
    else:
        at.v = at.findChild4(headline)

    if trace: g.trace('scanning',at.v)

    at.endSentinelStack.append(at.endNode)
#@+node:ekr.20041005105605.86:<< set gnx and bump i >>
# We have skipped past the opening colon of the gnx.
j = s.find(':',i)
if j == -1:
    g.trace("no closing colon",g.get_line(s,i))
    at.readError("Expecting gnx in @+node sentinel")
    return # 5/17/04
else:
    gnx = s[i:j]
    i = j + 1 # Skip the i
#@-node:ekr.20041005105605.86:<< set gnx and bump i >>
#@+node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
# Set headline to the rest of the line.
# Don't strip leading whitespace."

if len(at.endSentinelComment) == 0:
    headline = s[i:-1].rstrip()
else:
    k = s.rfind(at.endSentinelComment,i)
    headline = s[i:k].rstrip() # works if k == -1

# Undo the CWEB hack: undouble @ signs if the opening comment delim ends in '@'.
if at.startSentinelComment[-1:] == '@':
    headline = headline.replace('@@','@')
#@-node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
#@-node:ekr.20041005105605.85:at.readStartNode
#@+node:ekr.20041005105605.89:readStartOthers
def readStartOthers (self,s,i):

    """Read an @+others sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert g.match(s,j,"@+others"),'missing @+others'
    else:
        assert g.match(s,j,"+others"),'missing +others'

    # Make sure that the generated at-others is properly indented.
    at.out.append(leadingWs + "@others\n")

    at.endSentinelStack.append(at.endOthers)
#@-node:ekr.20041005105605.89:readStartOthers
#@-node:ekr.20041005105605.80:start sentinels
#@+node:ekr.20041005105605.90:end sentinels
#@+node:ekr.20041005105605.91:readEndAll (4.2)
def readEndAll (self,unused_s,unused_i):

    """Read an @-all sentinel."""

    at = self
    at.popSentinelStack(at.endAll)
#@-node:ekr.20041005105605.91:readEndAll (4.2)
#@+node:ekr.20041005105605.92:readEndAt & readEndDoc
def readEndAt (self,unused_s,unused_i):

    """Read an @-at sentinel."""

    at = self
    at.readLastDocLine("@")
    at.popSentinelStack(at.endAt)
    at.inCode = True

def readEndDoc (self,unused_s,unused_i):

    """Read an @-doc sentinel."""

    at = self
    at.readLastDocLine("@doc")
    at.popSentinelStack(at.endDoc)
    at.inCode = True
#@-node:ekr.20041005105605.92:readEndAt & readEndDoc
#@+node:ekr.20041005105605.93:readEndLeo
def readEndLeo (self,unused_s,unused_i):

    """Read an @-leo sentinel."""

    at = self

    # Ignore everything after @-leo.
    # Such lines were presumably written by @last.
    while 1:
        s = at.readLine(at.inputFile)
        if len(s) == 0: break
        at.lastLines.append(s) # Capture all trailing lines, even if empty.

    at.done = True
#@-node:ekr.20041005105605.93:readEndLeo
#@+node:ekr.20041005105605.94:readEndMiddle
def readEndMiddle (self,s,i):

    """Read an @-middle sentinel."""

    at = self

    at.readEndNode(s,i,middle=True)
#@-node:ekr.20041005105605.94:readEndMiddle
#@+node:ekr.20041005105605.95:at.readEndNode
def readEndNode (self,unused_s,unused_i,middle=False):

    """Handle end-of-node processing for @-others and @-ref sentinels."""

    trace = False and not g.unitTesting
    at = self ; c = at.c

    # End raw mode.
    at.raw = False

    # Set the temporary body text.
    s = ''.join(at.out)
    s = g.toUnicode(s)

    # g.trace(repr(s))

    if at.importing:
        at.v._bodyString = s # Allowed use of _bodyString.
    elif middle: 
        pass # Middle sentinels never alter text.
    else:
        if hasattr(at.v,"tempBodyString") and s != at.v.tempBodyString:
            old = at.v.tempBodyString
        elif at.v.hasBody() and s != at.v.getBody():
            old = at.v.getBody()
        else:
            old = None
        # 9/4/04: Suppress this warning for the root: @first complicates matters.
        if old and at.v != at.root.v: # and not g.app.unitTesting
            << indicate that the node has been changed >>
        if old and at.atAllFlag:
            # Don't change.
            if trace: g.trace('*** no update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
        else:
            if trace: g.trace('*** update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
            at.v.tempBodyString = s

    # Indicate that the vnode has been set in the derived file.
    at.v.setVisited()
    # g.trace('visit',at.v)

    # End the previous node sentinel.
    at.indent = at.indentStack.pop()
    at.out = at.outStack.pop()
    at.v = at.tStack.pop()
    if at.thinFile and not at.importing:
        at.lastThinNode = at.thinNodeStack.pop()

    at.popSentinelStack(at.endNode)
#@+node:ekr.20041005105605.96:<< indicate that the node has been changed >>
if at.perfectImportRoot:
    << bump at.correctedLines and tell about the correction >>
    at.v._bodyString = s # Allowed use of _bodyString.
        # Just setting at.v.tempBodyString won't work here.
    at.v.setDirty() # Mark the node dirty.  Ancestors will be marked dirty later.
    at.c.setChanged(True)
else:
    # New in Leo 4.4.1 final.  This warning can be very confusing.
    # New in Leo 4.7 b2: We suppress warning for trees containing '@all'
    if at.atAllFlag: # Give the warning if we are not in an '@all' tree.
        pass
    # elif not at.updateWarningGiven:
    else:
        # at.updateWarningGiven = True
        # g.pr("***",at.v,at.root.v)
        g.es_print("uncached read node changed",at.v.h,color="red") # was at.root.h
    # Just set the dirty bit. Ancestors will be marked dirty later.
    at.v.setDirty()
    # Important: the dirty bits won't stick unless we set c.changed here.
    # Do *not* call c.setChanged(True) here: that would be too slow.
    c.changed = True
#@nonl
#@+node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
# Report the number of corrected nodes.
at.correctedLines += 1

found = False
for p in at.perfectImportRoot.self_and_subtree():
    if p.v == at.v:
        found = True ; break

if found:
    if 0: # For debugging.
        g.pr('\n','-' * 40)
        g.pr("old",len(old))
        for line in g.splitLines(old):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
        g.pr("new",len(s))
        for line in g.splitLines(s):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
else:
    # This should never happen.
    g.es("correcting hidden node: v=",repr(at.v),color="red")
#@-node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
#@-node:ekr.20041005105605.96:<< indicate that the node has been changed >>
#@-node:ekr.20041005105605.95:at.readEndNode
#@+node:ekr.20041005105605.98:readEndOthers
def readEndOthers (self,unused_s,unused_i):

    """Read an @-others sentinel."""

    at = self
    at.popSentinelStack(at.endOthers)
#@-node:ekr.20041005105605.98:readEndOthers
#@+node:ekr.20041005105605.99:readLastDocLine
def readLastDocLine (self,tag):

    """Read the @c line that terminates the doc part.
    tag is @doc or @."""

    at = self
    end = at.endSentinelComment
    start = at.startSentinelComment
    s = ''.join(at.docOut)

    # Remove the @doc or @space.  We'll add it back at the end.
    if g.match(s,0,tag):
        s = s[len(tag):]
    else:
        at.readError("Missing start of doc part")
        return

    # Bug fix: Append any whitespace following the tag to tag.
    while s and s[0] in (' ','\t'):
        tag = tag + s[0] ; s = s[1:]

    if end:
        # Remove leading newline.
        if s[0] == '\n': s = s[1:]
        # Remove opening block delim.
        if g.match(s,0,start):
            s = s[len(start):]
        else:
            at.readError("Missing open block comment")
            g.trace('tag',repr(tag),'start',repr(start),'s',repr(s))
            return
        # Remove trailing newline.
        if s[-1] == '\n': s = s[:-1]
        # Remove closing block delim.
        if s[-len(end):] == end:
            s = s[:-len(end)]
        else:
            at.readError("Missing close block comment")
            g.trace(s)
            g.trace(end)
            g.trace(start)
            return

    at.out.append(tag + s)
    at.docOut = []
#@-node:ekr.20041005105605.99:readLastDocLine
#@-node:ekr.20041005105605.90:end sentinels
#@+node:ekr.20041005105605.100:Unpaired sentinels
# Ooops: shadow files are cleared if there is a read error!!
#@nonl
#@+node:ekr.20041005105605.101:ignoreOldSentinel
def  ignoreOldSentinel (self,s,unused_i):

    """Ignore an 3.x sentinel."""

    g.es("ignoring 3.x sentinel:",s.strip(),color="blue")
#@-node:ekr.20041005105605.101:ignoreOldSentinel
#@+node:ekr.20041005105605.102:readAfterRef
def  readAfterRef (self,s,i):

    """Read an @afterref sentinel."""

    at = self
    assert g.match(s,i,"afterref"),'missing afterref'

    # Append the next line to the text.
    s = at.readLine(at.inputFile)
    at.out.append(s)
#@-node:ekr.20041005105605.102:readAfterRef
#@+node:ekr.20041005105605.103:readClone
def readClone (self,s,i):

    at = self ; tag = "clone"

    assert g.match(s,i,tag),'missing clone sentinel'

    # Skip the tag and whitespace.
    i = g.skip_ws(s,i+len(tag))

    # Get the clone count.
    junk,val = g.skip_long(s,i)

    if val == None:
        at.readError("Invalid count in @clone sentinel")
    else:
        at.cloneSibCount = val
#@-node:ekr.20041005105605.103:readClone
#@+node:ekr.20041005105605.104:readComment
def readComment (self,s,i):

    """Read an @comment sentinel."""

    assert g.match(s,i,"comment"),'missing comment sentinel'

    # Just ignore the comment line!
#@-node:ekr.20041005105605.104:readComment
#@+node:ekr.20041005105605.105:readDelims
def readDelims (self,s,i):

    """Read an @delims sentinel."""

    at = self
    assert g.match(s,i-1,"@delims"),'missing @delims'

    # Skip the keyword and whitespace.
    i0 = i-1
    i = g.skip_ws(s,i-1+7)

    # Get the first delim.
    j = i
    while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
        i += 1

    if j < i:
        at.startSentinelComment = s[j:i]
        # g.pr("delim1:", at.startSentinelComment)

        # Get the optional second delim.
        j = i = g.skip_ws(s,i)
        while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
            i += 1
        end = g.choose(j<i,s[j:i],"")
        i2 = g.skip_ws(s,i)
        if end == at.endSentinelComment and (i2 >= len(s) or g.is_nl(s,i2)):
            at.endSentinelComment = "" # Not really two params.
            line = s[i0:j]
            line = line.rstrip()
            at.out.append(line+'\n')
        else:
            at.endSentinelComment = end
            # g.pr("delim2:",end)
            line = s[i0:i]
            line = line.rstrip()
            at.out.append(line+'\n')
    else:
        at.readError("Bad @delims")
        # Append the bad @delims line to the body text.
        at.out.append("@delims")
#@-node:ekr.20041005105605.105:readDelims
#@+node:ekr.20041005105605.106:readDirective (@@)
def readDirective (self,s,i):

    """Read an @@sentinel."""

    trace = False and not g.unitTesting
    at = self
    assert g.match(s,i,"@"),'missing @@ sentinel' # The first '@' has already been eaten.

    if trace: g.trace(repr(s[i:]))
        # g.trace(g.get_line(s,i))

    if g.match_word(s,i,"@raw"):
        at.raw = True
    elif g.match_word(s,i,"@end_raw"):
        at.raw = False

    e = at.endSentinelComment
    s2 = s[i:]
    if len(e) > 0:
        k = s.rfind(e,i)
        if k != -1:
            s2 = s[i:k] + '\n'

    start = at.startSentinelComment
    if start and len(start) > 0 and start[-1] == '@':
        s2 = s2.replace('@@','@')

    if 0: # New in 4.2.1: never change comment delims here...
        if g.match_word(s,i,"@language"):
            << handle @language >>
        elif g.match_word(s,i,"@comment"):
            << handle @comment >>

    at.out.append(s2)
#@+node:ekr.20041005105605.107:<< handle @language >>
# Skip the keyword and whitespace.
i += len("@language")
i = g.skip_ws(s,i)
j = g.skip_c_id(s,i)
language = s[i:j]

delim1,delim2,delim3 = g.set_delims_from_language(language)

if trace:
    g.trace(g.get_line(s,i))
    g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("ignoring bad @language sentinel:",line,color="red")
#@-node:ekr.20041005105605.107:<< handle @language >>
#@+node:ekr.20041005105605.108:<< handle @comment >>
j = g.skip_line(s,i)
line = s[i:j]
delim1,delim2,delim3 = g.set_delims_from_string(line)

#g.trace(g.get_line(s,i))
#g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    self.startSentinelComment = delim1
    self.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    self.startSentinelComment = delim2
    self.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("ignoring bad @comment sentinel:",line,color="red")
#@-node:ekr.20041005105605.108:<< handle @comment >>
#@-node:ekr.20041005105605.106:readDirective (@@)
#@+node:ekr.20041005105605.109:readNl
def readNl (self,s,i):

    """Handle an @nonl sentinel."""

    at = self
    assert g.match(s,i,"nl"),'missing nl sentinel'

    if at.inCode:
        at.out.append('\n')
    else:
        at.docOut.append('\n')
#@-node:ekr.20041005105605.109:readNl
#@+node:ekr.20041005105605.110:readNonl
def readNonl (self,s,i):

    """Handle an @nonl sentinel."""

    at = self
    assert g.match(s,i,"nonl"),'missing nonl sentinel'

    if at.inCode:
        s = ''.join(at.out)
        # 2010/01/07: protect against a mostly-harmless read error.
        if s:
            if s[-1] == '\n':
                at.out = [s[:-1]]
            else:
                g.trace("out:",s)
                at.readError("unexpected @nonl directive in code part")
    else:
        s = ''.join(at.pending)
        if s:
            if s[-1] == '\n':
                at.pending = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in pending doc part")
        else:
            s = ''.join(at.docOut)
            if s and s[-1] == '\n':
                at.docOut = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in doc part")
#@-node:ekr.20041005105605.110:readNonl
#@+node:ekr.20041005105605.111:readRef
@ The sentinel contains an @ followed by a section name in angle brackets.  This code is different from the code for the @@ sentinel: the expansion of the reference does not include a trailing newline.
@c

def readRef (self,s,i):

    """Handle an @<< sentinel."""

    at = self
    j = g.skip_ws(s,i)
    assert g.match(s,j,"<<"),'missing @<< sentinel'

    if len(at.endSentinelComment) == 0:
        line = s[i:-1] # No trailing newline
    else:
        k = s.find(at.endSentinelComment,i)
        line = s[i:k] # No trailing newline, whatever k is.

    # Undo the cweb hack.
    start = at.startSentinelComment
    if start and len(start) > 0 and start[-1] == '@':
        line = line.replace('@@','@')

    at.out.append(line)
#@-node:ekr.20041005105605.111:readRef
#@+node:ekr.20041005105605.112:readVerbatim
def readVerbatim (self,s,i):

    """Read an @verbatim sentinel."""

    at = self
    assert g.match(s,i,"verbatim"),'missing verbatim sentinel'

    # Append the next line to the text.
    s = at.readLine(at.inputFile) 
    i = at.skipIndent(s,0,at.indent)
    # Do **not** insert the verbatim line itself!
        # at.out.append("@verbatim\n")
    at.out.append(s[i:])
#@+node:ekr.20090620101138.6072:@test verbatim sentinel
if g.unitTesting:
    c,p = g.getTestVars()

    # Here is something that should generate a verbtim sentinel::

#@verbatim
    #@+leo-encoding=iso-8859-1.

    # The length of this node should remain constant.

    assert len(p.b) == 235,len(p.b)
#@nonl
#@-node:ekr.20090620101138.6072:@test verbatim sentinel
#@-node:ekr.20041005105605.112:readVerbatim
#@-node:ekr.20041005105605.100:Unpaired sentinels
#@+node:ekr.20041005105605.113:badEndSentinel, popSentinelStack
def badEndSentinel (self,expectedKind):

    """Handle a mismatched ending sentinel."""

    at = self
    assert at.endSentinelStack,'empty sentinel stack'
    s = "Ignoring %s sentinel.  Expecting %s" % (
        at.sentinelName(at.endSentinelStack[-1]),
        at.sentinelName(expectedKind))
    at.readError(s)

def popSentinelStack (self,expectedKind):

    """Pop an entry from endSentinelStack and check it."""

    at = self
    if at.endSentinelStack and at.endSentinelStack[-1] == expectedKind:
        at.endSentinelStack.pop()
    else:
        at.badEndSentinel(expectedKind)
#@-node:ekr.20041005105605.113:badEndSentinel, popSentinelStack
#@-node:ekr.20041005105605.74:scanText4 & allies
#@+node:ekr.20050103163224:scanHeaderForThin (used by import code)
# Note: Import code uses this.

def scanHeaderForThin (self,theFile,fileName):

    '''Scan the header of a derived file and return True if it is a thin file.

    N.B. We are not interested in @first lines, so any encoding will do.'''

    at = self

    # The encoding doesn't matter.  No error messages are given.
    at.encoding = at.c.config.default_derived_file_encoding

    junk,junk,isThin = at.scanHeader(theFile,fileName)

    return isThin
#@-node:ekr.20050103163224:scanHeaderForThin (used by import code)
#@-node:ekr.20100122073254.6165:Don't use tnodeList to separate old/new @file nodes
#@+node:ekr.20100123180019.6314:Eliminated warning re orphan nodes
#@+node:ekr.20041005105605.216:warnAboutOrpanAndIgnoredNodes
# Called from writeOpenFile.

def warnAboutOrphandAndIgnoredNodes (self):

    # Always warn, even when language=="cweb"
    at = self ; root = at.root

    for p in root.self_and_subtree():
        if not p.v.isVisited():
            at.writeError("Orphan node:  " + p.h)
            if p.hasParent():
                g.es("parent node:",p.parent().h,color="blue")
            if not at.thinFile and p.isAtIgnoreNode():
                at.writeError("@ignore node: " + p.h)

    if at.thinFile:
        p = root.copy() ; after = p.nodeAfterTree()
        while p and p != after:
            if p.isAtAllNode():
                p.moveToNodeAfterTree()
            else:
                if p.isAtIgnoreNode():
                    at.writeError("@ignore node: " + p.h)
                p.moveToThreadNext()
#@-node:ekr.20041005105605.216:warnAboutOrpanAndIgnoredNodes
#@+node:ekr.20041005105605.169:putAtAllChild
@
This code puts only the first of two or more cloned siblings, preceding the
clone with an @clone n sentinel.

This is a debatable choice: the cloned tree appears only once in the external
file. This should be benign; the text created by @all is likely to be used only
for recreating the outline in Leo. The representation in the derived file
doesn't matter much.
@c

def putAtAllChild(self,p):

    at = self

    parent_v = p._parentVnode()

    if False: # 2010/01/23: This generates atFile errors about orphan nodes.
        clonedSibs,thisClonedSibIndex = at.scanForClonedSibs(parent_v,p.v)
        if clonedSibs > 1:
            at.putSentinel("@clone %d" % (clonedSibs))
        else:
            g.trace('**** ignoring',p.h)
            p.v.setVisited() # 2010/01/23
            return # Don't write second or greater trees.

    at.putOpenNodeSentinel(p,inAtAll=True) # Suppress warnings about @file nodes.
    at.putAtAllBody(p) 

    for child in p.children():
        at.putAtAllChild(child)

    at.putCloseNodeSentinel(p)
#@-node:ekr.20041005105605.169:putAtAllChild
#@-node:ekr.20100123180019.6314:Eliminated warning re orphan nodes
#@-node:ekr.20100121105450.6175:Bugs
#@+node:ekr.20100121105450.6174:Added --debug switch
#@+node:ekr.20091007103358.6061:scanOptions
def scanOptions():

    '''Handle all options and remove them from sys.argv.'''
    trace = False

    # Note: this automatically implements the --help option.
    parser = optparse.OptionParser()
    parser.add_option('-c', '--config', dest="one_config_path")
    parser.add_option('--debug',        action="store_true",dest="debug")
    parser.add_option('-f', '--file',   dest="fileName")
    parser.add_option('--gui',          dest="gui",help = 'gui to use (qt/tk/qttabs)')
    #parser.add_option('--help',         action="store_true",dest="help_option")
    parser.add_option('--ipython',      action="store_true",dest="use_ipython")
    parser.add_option('--no-cache',     action="store_true",dest='no_cache')
    parser.add_option('--silent',       action="store_true",dest="silent")
    parser.add_option('--script',       dest="script")
    parser.add_option('--script-window',dest="script_window")
    parser.add_option('--version',      action="store_true",dest="version")

    # Parse the options, and remove them from sys.argv.
    options, args = parser.parse_args()
    sys.argv = [sys.argv[0]] ; sys.argv.extend(args)
    if trace: print('scanOptions',sys.argv)

    # Handle the args...

    # -c or --config
    path = options.one_config_path
    if path:
        path = g.os_path_finalize_join(os.getcwd(),path)
        if g.os_path_exists(path):
            g.app.oneConfigFilename = path
        else:
            g.es_print('Invalid -c option: file not found:',path,color='red')

    # --debug
    if options.debug:
        g.debug = True
        g.trace('*** debug mode on')

    # -f or --file
    fileName = options.fileName

    # --gui
    gui = options.gui
    g.app.qt_use_tabs = False
    if gui:
        gui = gui.lower()
        if gui == 'qttabs':
            gui = 'qt'
            g.app.qt_use_tabs = True

        if gui not in ('tk','qt','wx'):
            g.trace('unknown gui: %s' % gui)
            gui = None

    # --ipython
    g.app.useIpython = options.use_ipython

    # --no-cache
    if options.no_cache:
        g.trace('disabling caching')
        g.enableDB = False

    # --script
    script_path = options.script
    script_path_w = options.script_window
    if script_path and script_path_w:
        parser.error("--script and script-window are mutually exclusive")

    script_name = script_path or script_path_w
    if script_name:
        script_name = g.os_path_finalize_join(g.app.loadDir,script_name)
        script,e = g.readFileIntoString(script_name,kind='script:')
    else:
        script = None
        # if trace: print('scanOptions: no script')

    # --silent
    g.app.silentMode = options.silent
    # g.trace('silentMode',g.app.silentMode)

    # --version: print the version and exit.
    versionFlag = options.version

    # Compute the return values.
    windowFlag = script and script_path_w
    if trace:
        print('scanOptions: fileName',fileName)
        print('scanOptions: argv',sys.argv)
    return fileName,gui,script,versionFlag,windowFlag
#@-node:ekr.20091007103358.6061:scanOptions
#@-node:ekr.20100121105450.6174:Added --debug switch
#@+node:ekr.20100122073254.6162:Eliminated node-changed marks
# These marks are just annoying.
#@nonl
#@+node:ekr.20050301105854:copyAllTempBodyStringsToTnodes
def  copyAllTempBodyStringsToTnodes (self,root,thinFile):

    c = self.c
    for p in root.self_and_subtree():
        try: s = p.v.tempBodyString
        except Exception: s = ""
        old_body = p.b
        if s != old_body:
            if False and old_body: # For debugging.
                g.pr("\nchanged: " + p.h)
                g.pr("\nnew:",s)
                g.pr("\nold:",p.b)
            if thinFile:
                p.v.setBodyString(s)
                if p.v.isDirty():
                    p.setAllAncestorAtFileNodesDirty()
            else:
                c.setBodyString(p,s) # Sets c and p dirty.

            if not thinFile or (thinFile and p.v.isDirty()):
                # New in Leo 4.3: support for mod_labels plugin:
                try:
                    c.mod_label_controller.add_label(p,"before change:",old_body)
                except Exception:
                    pass
                g.es("changed:",p.h,color="blue")
                # p.setMarked()
#@-node:ekr.20050301105854:copyAllTempBodyStringsToTnodes
#@+node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
def tabNannyNode (self,p,body):

    import parser,tabnanny,tokenize

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))
    except parser.ParserError:
        junk, msg, junk = sys.exc_info()
        g.es("ParserError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        g.es("TokenError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        badline = nag.get_lineno()
        line    = nag.get_line()
        message = nag.get_msg()
        g.es("indentation error in",p.h,"line",badline,color="red")
        g.es(message)
        line2 = repr(str(line))[1:-1]
        g.es("offending line:\n",line2)
        # p.setMarked()
    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
#@nonl
#@-node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
#@-node:ekr.20100122073254.6162:Eliminated node-changed marks
#@+node:ekr.20100123044506.6237:Eliminated support for @noref
@nocolor-node

Changes:

- putOpenNodeSentinel now *never* sets tnodeList.
#@nonl
#@+node:ekr.20100123044506.6247:changed
#@+node:ekr.20061002095711:c.navHelper
def navHelper (self,p,ch,extend):

    c = self ; h = p.h.lower()

    if extend:
        prefix = c.navPrefix + ch
        return h.startswith(prefix.lower()) and prefix

    if h.startswith(ch):
        return ch

    # New feature: search for first non-blank character after @x for common x.
    if ch != '@' and h.startswith('@'):
        for s in ('button','command','file','thin','asis','nosent',): # 'noref'):
            prefix = '@'+s
            if h.startswith('@'+s):
                while 1:
                    n = len(prefix)
                    ch2 = n < len(h) and h[n] or ''
                    if ch2.isspace():
                        prefix = prefix + ch2
                    else: break
                if len(prefix) < len(h) and h.startswith(prefix + ch.lower()):
                    return prefix + ch
    return ''
#@nonl
#@-node:ekr.20061002095711:c.navHelper
#@+node:ekr.20031218072017.2989:c.setChanged
def setChanged (self,changedFlag):

    trace = False and not g.unitTesting
    c = self
    if not c.frame: return
    c.changed = changedFlag
    if c.loading: return # don't update while loading.

    if trace: g.trace('Commands',changedFlag,c,g.callers(4))

    # Clear all dirty bits _before_ setting the caption.
    if not changedFlag:
        for v in c.all_unique_nodes():
            if v.isDirty():
                v.clearDirty()

    if g.app.qt_use_tabs and hasattr(c.frame,'top'):
        c.frame.top.master.setChanged(c,changedFlag)

    s = c.frame.getTitle()
    if len(s) > 2:
        if changedFlag:
            if s [0] != '*': c.frame.setTitle("* " + s)
        else:
            if s[0:2]=="* ": c.frame.setTitle(s[2:])
#@-node:ekr.20031218072017.2989:c.setChanged
#@-node:ekr.20100123044506.6247:changed
#@+node:ekr.20100123044506.6246:recognition...
#@+node:ekr.20040306211032:p.Comparisons
def anyAtFileNodeName         (self): return self.v.anyAtFileNodeName()
def atAutoNodeName            (self): return self.v.atAutoNodeName()
def atEditNodeName            (self): return self.v.atEditNodeName()
def atFileNodeName            (self): return self.v.atFileNodeName()
def atNoSentinelsFileNodeName (self): return self.v.atNoSentinelsFileNodeName()
# def atRawFileNodeName         (self): return self.v.atRawFileNodeName()
def atShadowFileNodeName      (self): return self.v.atShadowFileNodeName()
def atSilentFileNodeName      (self): return self.v.atSilentFileNodeName()
def atThinFileNodeName        (self): return self.v.atThinFileNodeName()

# New names, less confusing
atNoSentFileNodeName  = atNoSentinelsFileNodeName
#atNorefFileNodeName   = atRawFileNodeName
atAsisFileNodeName    = atSilentFileNodeName

def isAnyAtFileNode         (self): return self.v.isAnyAtFileNode()
def isAtAllNode             (self): return self.v.isAtAllNode()
def isAtAutoNode            (self): return self.v.isAtAutoNode()
def isAtAutoRstNode         (self): return self.v.isAtAutoRstNode()
def isAtEditNode            (self): return self.v.isAtEditNode()
def isAtFileNode            (self): return self.v.isAtFileNode()
def isAtIgnoreNode          (self): return self.v.isAtIgnoreNode()
def isAtNoSentinelsFileNode (self): return self.v.isAtNoSentinelsFileNode()
def isAtOthersNode          (self): return self.v.isAtOthersNode()
# def isAtRawFileNode         (self): return self.v.isAtRawFileNode()
def isAtSilentFileNode      (self): return self.v.isAtSilentFileNode()
def isAtShadowFileNode      (self): return self.v.isAtShadowFileNode()
def isAtThinFileNode        (self): return self.v.isAtThinFileNode()

# New names, less confusing:
isAtNoSentFileNode = isAtNoSentinelsFileNode
# isAtNorefFileNode  = isAtRawFileNode
isAtAsisFileNode   = isAtSilentFileNode

# Utilities.
def matchHeadline (self,pattern): return self.v.matchHeadline(pattern)
#@-node:ekr.20040306211032:p.Comparisons
#@+node:ekr.20031218072017.3350:anyAtFileNodeName
def anyAtFileNodeName (self):

    """Return the file name following an @file node or an empty string."""

    names = (
        "@auto",
        "@auto-rst",
        "@edit",
        "@file",
        "@thin",   "@file-thin",   "@thinfile",
        "@asis",   "@file-asis",   "@silentfile",
        # "@noref",  "@file-noref",  "@rawfile",
        "@nosent", "@file-nosent", "@nosentinelsfile",
        "@shadow",)

    return self.findAtFileName(names)
#@-node:ekr.20031218072017.3350:anyAtFileNodeName
#@+node:ekr.20031218072017.3348:at...FileNodeName & tests
# These return the filename following @xxx, in v.headString.
# Return the the empty string if v is not an @xxx node.

def atAutoNodeName (self,h=None):
    # # Prevent conflicts with autotrees plugin: don't allow @auto-whatever to match.
    # return g.match_word(h,0,tag) and not g.match(h,0,tag+'-') and h[len(tag):].strip()
    names = ("@auto","@auto-rst",)
    return self.findAtFileName(names,h=h)

def atAutoRstNodeName (self,h=None):
    names = ("@auto-rst",)
    return self.findAtFileName(names,h=h)

def atEditNodeName (self):
    names = ("@edit",)
    return self.findAtFileName(names)

def atFileNodeName (self):
    names = ("@file",)
    return self.findAtFileName(names)

def atNoSentinelsFileNodeName (self):
    names = ("@nosent", "@file-nosent", "@nosentinelsfile")
    return self.findAtFileName(names)

# def atRawFileNodeName (self):
    # names = ("@noref", "@file-noref", "@rawfile")
    # return self.findAtFileName(names)

def atShadowFileNodeName (self):
    names = ("@shadow",)
    return self.findAtFileName(names)

def atSilentFileNodeName (self):
    names = ("@asis", "@file-asis", "@silentfile")
    return self.findAtFileName(names)

def atThinFileNodeName (self):
    names = ("@thin", "@file-thin", "@thinfile")
    return self.findAtFileName(names)

# New names, less confusing
atNoSentFileNodeName  = atNoSentinelsFileNodeName
# atNorefFileNodeName   = atRawFileNodeName
atAsisFileNodeName    = atSilentFileNodeName
#@+node:ekr.20090521064955.5905:@test v.atAutoNodeName & v.atAutoRstNodeName
if g.unitTesting:

    c,p = g.getTestVars()

    table = (
        ('@auto-rst rst-file','rst-file','rst-file'),
        ('@auto x','x',''),
        ('xyz','',''),
    )

    for s,expected1,expected2 in table:
        result1 = p.v.atAutoNodeName(h=s)
        result2 = p.v.atAutoRstNodeName(h=s)
        assert result1 == expected1,'fail1: given %s expected %s got %s' % (
            repr(s),repr(expected1),repr(result1))
        assert result2 == expected2,'fail2: given %s expected %s got %s' % (
            repr(s),repr(expected2),repr(result2))
#@-node:ekr.20090521064955.5905:@test v.atAutoNodeName & v.atAutoRstNodeName
#@-node:ekr.20031218072017.3348:at...FileNodeName & tests
#@+node:ekr.20040325073709:isAt...FileNode (vnode)
def isAtAutoNode (self):
    return g.choose(self.atAutoNodeName(),True,False)

def isAtAutoRstNode (self):
    return g.choose(self.atAutoRstNodeName(),True,False)

def isAtEditNode (self):
    return g.choose(self.atEditNodeName(),True,False)

def isAtFileNode (self):
    return g.choose(self.atFileNodeName(),True,False)

def isAtNoSentinelsFileNode (self):
    return g.choose(self.atNoSentinelsFileNodeName(),True,False)

# def isAtRawFileNode (self): # @file-noref
    # return g.choose(self.atRawFileNodeName(),True,False)

def isAtSilentFileNode (self): # @file-asis
    return g.choose(self.atSilentFileNodeName(),True,False)

def isAtShadowFileNode (self):
    return g.choose(self.atShadowFileNodeName(),True,False)

def isAtThinFileNode (self):
    return g.choose(self.atThinFileNodeName(),True,False)

# New names, less confusing:
isAtNoSentFileNode = isAtNoSentinelsFileNode
# isAtNorefFileNode  = isAtRawFileNode
isAtAsisFileNode   = isAtSilentFileNode
#@-node:ekr.20040325073709:isAt...FileNode (vnode)
#@-node:ekr.20100123044506.6246:recognition...
#@+node:ekr.20100123044506.6248:reading...
#@+node:ekr.20041005105605.21:read (atFile) & helpers
# This code no longer reads @noref trees.

def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    # g.trace(root.h,len(root.b))
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    if at.errors:
        return False
    fileName = at.openFileForReading(fromString=fromString)
    if at.inputFile:
        c.setFileTimeStamp(fileName)
    else:
        return False
    root.v.at_read = True # Remember that we have read this file.
    # Get the file from the cache if possible.
    ok,cachefile = self.readFromCache(fileName,force,root)
    if ok:
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    root.clearVisitedInTree()
    d = at.scanAllDirectives(root,importing=at.importing,reading=True)
    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.warnAboutUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        self.copyAllTempBodyStringsToTnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if at.errors == 0:
        self.writeCachedTree(root,cachefile)

    return at.errors == 0
#@+node:ekr.20041005105605.25:deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
#@-node:ekr.20041005105605.25:deleteAllTempBodyStrings
#@+node:ekr.20100122130101.6174:deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@-node:ekr.20100122130101.6174:deleteTnodeList
#@+node:ekr.20041005105605.22:initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName

    # isAtFile = (
        # not thinFile and
        # not importFileName and
        # not atShadow and
        # not fromString and
        # root.h.startswith('@file'))
#@-node:ekr.20041005105605.22:initFileName
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20071105164407:warnAboutUnvisitedNodes
def warnAboutUnvisitedNodes (self,root):

    resurrected = 0

    for p in root.self_and_subtree():
        if not p.v.isVisited():
            g.trace('**** not visited',p.v,p.h)
            g.es('resurrected node:',p.h,color='blue')
            g.es('in file:',root.h,color='blue')
            resurrected += 1

    if resurrected:
        g.es('you may want to delete ressurected nodes')
#@-node:ekr.20071105164407:warnAboutUnvisitedNodes
#@-node:ekr.20041005105605.21:read (atFile) & helpers
#@-node:ekr.20100123044506.6248:reading...
#@+node:ekr.20100123044506.6244:writing...
#@+node:ekr.20041005105605.193:putOpenNodeSentinel
def putOpenNodeSentinel(self,p,inAtAll=False,middle=False):

    """Write @+node sentinel for p."""

    at = self

    if not inAtAll and p.isAtFileNode() and p != at.root:
        at.writeError("@file not valid in: " + p.h)
        return

    # g.trace(at.thinFile,p)

    s = at.nodeSentinelText(p)

    if middle:
        at.putSentinel("@+middle:" + s)
    else:
        at.putSentinel("@+node:" + s)

    # Leo 4.7 b2: we never write tnodeLists.
#@nonl
#@-node:ekr.20041005105605.193:putOpenNodeSentinel
#@+node:ekr.20041005105605.136:norefWrite (deleted)
def norefWrite(self,root,toString=False):

    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    try:
        targetFileName = root.atNorefFileNodeName()
        at.initWriteIvars(root,targetFileName,nosentinels=False,toString=toString)
        if at.errors: return
        if not at.openFileForWriting(root,targetFileName,toString):
            # openFileForWriting calls root.setDirty() if there are errors.
            return
        << write root's tree >>
        at.closeWriteFile()
        at.replaceTargetFileIfDifferent(root) # Sets/clears dirty and orphan bits.
    except Exception:
        at.writeException(root) # Sets dirty and orphan bits.

rawWrite = norefWrite
#@+node:ekr.20041005105605.137:<< write root's tree >>
<< put all @first lines in root >>
at.putOpenLeoSentinel("@+leo-ver=4")
<< put optional @comment sentinel lines >>

for p in root.self_and_subtree():
    << Write p's node >>

at.putSentinel("@-leo")
<< put all @last lines in root >>
#@+node:ekr.20041005105605.138:<< put all @first lines in root >>
# Write any @first lines.  These lines are also converted to @verbatim lines,
# so the read logic simply ignores lines preceding the @+leo sentinel.

s = root.v.b
tag = "@first"
i = 0
while g.match(s,i,tag):
    i += len(tag)
    i = g.skip_ws(s,i)
    j = i
    i = g.skip_to_end_of_line(s,i)
    # Write @first line, whether empty or not
    line = s[j:i]
    at.putBuffered(line) ; at.onl()
    i = g.skip_nl(s,i)
#@-node:ekr.20041005105605.138:<< put all @first lines in root >>
#@+node:ekr.20041005105605.139:<< put optional @comment sentinel lines >>
s2 = c.config.output_initial_comment
if s2:
    lines = s2.split("\\n")
    for line in lines:
        line = line.replace("@date",time.asctime())
        if len(line)> 0:
            at.putSentinel("@comment " + line)
#@-node:ekr.20041005105605.139:<< put optional @comment sentinel lines >>
#@+node:ekr.20041005105605.140:<< Write p's node >>
at.putOpenNodeSentinel(p)

s = p.b
s = self.cleanLines(p,s)

if s:
    s = g.toEncodedString(s,at.encoding,reportErrors=True)
    at.outputStringWithLineEndings(s)

# Put an @nonl sentinel if s does not end in a newline.
if s and s[-1] != '\n':
    at.onl_sent() ; at.putSentinel("@nonl")

at.putCloseNodeSentinel(p)
#@-node:ekr.20041005105605.140:<< Write p's node >>
#@+node:ekr.20041005105605.141:<< put all @last lines in root >>
@ Write any @last lines.  These lines are also converted to @verbatim lines, so the read logic simply ignores lines following the @-leo sentinel.
@c

tag = "@last"
lines = root.v.b.split('\n')
n = len(lines) ; j = k = n - 1
# Don't write an empty last line.
if j >= 0 and len(lines[j])==0:
    j = k = n - 2
# Scan backwards for @last directives.
while j >= 0:
    line = lines[j]
    if g.match(line,0,tag): j -= 1
    else: break
# Write the @last lines.
for line in lines[j+1:k+1]:
    i = len(tag) ; i = g.skip_ws(line,i)
    at.putBuffered(line[i:]) ; at.onl()
#@-node:ekr.20041005105605.141:<< put all @last lines in root >>
#@-node:ekr.20041005105605.137:<< write root's tree >>
#@-node:ekr.20041005105605.136:norefWrite (deleted)
#@+node:ekr.20051104075904.44:at-File test code (leoTest.py)
def runAtFileTest(c,p):

    """Common code for testing output of @file, @thin, etc."""

    at = c.atFileCommands
    child1 = p.firstChild()
    child2 = child1.next()
    h1 = child1.h.lower().strip()
    h2 = child2.h.lower().strip()
    assert(g.match(h1,0,"#@"))
    assert(g.match(h2,0,"output"))
    expected = child2.b

    # Compute the type from child1's headline.
    j = g.skip_c_id(h1,2)
    theType = h1[1:j]
    assert theType in ("@auto","@edit","@file","@thin","@nosent",
        # "@noref",
        "@asis","@root",), "bad type: %s" % type

    thinFile = theType == "@thin"
    nosentinels = theType in ("@asis","edit","@nosent")

    if theType == "@root":
        c.tangleCommands.tangle_output = ''
        c.tangleCommands.tangle(event=None,p=child1)
        at.stringOutput = c.tangleCommands.tangle_output
    elif theType == "@asis":
        at.asisWrite(child1,toString=True)
    elif theType == "@auto":
        at.writeOneAtAutoNode(child1,toString=True,force=True)
    elif theType == "@edit":
        at.writeOneAtEditNode(child1,toString=True)
    # elif theType == "@noref":
        # at.norefWrite(child1,toString=True)
    else:
        at.write(child1,thinFile=thinFile,nosentinels=nosentinels,toString=True)
    try:
        result = g.toUnicode(at.stringOutput)
        assert(result == expected)
    except AssertionError:
        << dump result and expected >>
        raise
#@+node:ekr.20051104075904.45:<< dump result and expected >>
print('\n','-' * 20)
print("result...")
for line in g.splitLines(result):
    print("%3d" % len(line),repr(line))
print('-' * 20)
print("expected...")
for line in g.splitLines(expected):
    print("%3d" % len(line),repr(line))
print('-' * 20)
#@-node:ekr.20051104075904.45:<< dump result and expected >>
#@-node:ekr.20051104075904.44:at-File test code (leoTest.py)
#@+node:ekr.20041005105605.147:writeAll (atFile) & helper
def writeAll(self,
    writeAtFileNodesFlag=False,
    writeDirtyAtFileNodesFlag=False,
    toString=False
):

    """Write @file nodes in all or part of the outline"""

    trace = False and not g.unitTesting
    at = self ; c = at.c
    if trace: scanAtPathDirectivesCount = c.scanAtPathDirectivesCount
    writtenFiles = [] # Files that might be written again.
    force = writeAtFileNodesFlag

    if writeAtFileNodesFlag:
        # The Write @<file> Nodes command.
        # Write all nodes in the selected tree.
        p = c.p
        after = p.nodeAfterTree()
    else:
        # Write dirty nodes in the entire outline.
        p =  c.rootPosition()
        after = c.nullPosition()

    << Clear all orphan bits >>
    while p and p != after:
        if p.isAnyAtFileNode() or p.isAtIgnoreNode():
            self.writeAllHelper(p,force,toString,writeAtFileNodesFlag,writtenFiles)
            p.moveToNodeAfterTree()
        else:
            p.moveToThreadNext()

    << say the command is finished >>
    if trace: g.trace('%s calls to c.scanAtPathDirectives()' % (
        c.scanAtPathDirectivesCount-scanAtPathDirectivesCount))

#@+node:ekr.20041005105605.148:<< Clear all orphan bits >>
@ We must clear these bits because they may have been set on a previous write.
Calls to atFile::write may set the orphan bits in @file nodes.
If so, write_Leo_file will write the entire @file tree.
@c

for v2 in p.self_and_subtree():
    v2.clearOrphan()
#@-node:ekr.20041005105605.148:<< Clear all orphan bits >>
#@+node:ekr.20041005105605.150:<< say the command is finished >>
if writeAtFileNodesFlag or writeDirtyAtFileNodesFlag:
    if len(writtenFiles) > 0:
        g.es("finished")
    elif writeAtFileNodesFlag:
        g.es("no @<file> nodes in the selected tree")
    else:
        g.es("no dirty @<file> nodes")
#@-node:ekr.20041005105605.150:<< say the command is finished >>
#@+node:ekr.20041005105605.149:writeAllHelper (atFile)
def writeAllHelper (self,p,
    force,toString,writeAtFileNodesFlag,writtenFiles
):

    trace = False and not g.unitTesting
    at = self ; c = at.c

    if p.isAtIgnoreNode() and not p.isAtAsisFileNode():
        pathChanged = False
    else:
        oldPath = at.getPathUa(p).lower()
        newPath = at.fullPath(p).lower()
        pathChanged = oldPath and oldPath != newPath
        # 2010/01/27: suppress this message during save-as and save-to commands.
        if pathChanged and not c.ignoreChangedPaths:
            at.setPathUa(p,newPath) # Remember that we have changed paths.
            g.es_print('path changed for',p.h,color='blue')
            if trace: g.trace('p %s\noldPath %s\nnewPath %s' % (
                p.h,repr(oldPath),repr(newPath)))

    if p.v.isDirty() or pathChanged or writeAtFileNodesFlag or p.v in writtenFiles:

        # Tricky: @ignore not recognised in @asis nodes.
        if p.isAtAsisFileNode():
            at.asisWrite(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtIgnoreNode():
            pass
        elif p.isAtAutoNode():
            at.writeOneAtAutoNode(p,toString=toString,force=force)
            writtenFiles.append(p.v)
        elif p.isAtEditNode():
            at.writeOneAtEditNode(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtNoSentFileNode():
            at.write(p,kind='@nosent',nosentinels=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtShadowFileNode():
            at.writeOneAtShadowNode(p,toString=toString,force=force or pathChanged)
            writtenFiles.append(p.v)
        elif p.isAtThinFileNode():
            at.write(p,kind='@thin',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtFileNode():
            # Write old @file nodes using @thin format.
            at.write(p,kind='@file',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
#@-node:ekr.20041005105605.149:writeAllHelper (atFile)
#@-node:ekr.20041005105605.147:writeAll (atFile) & helper
#@+node:ekr.20041005105605.151:writeMissing
def writeMissing(self,p,toString=False):

    at = self ; c = at.c
    writtenFiles = False

    p = p.copy()
    after = p.nodeAfterTree()
    while p and p != after: # Don't use iterator.
        if p.isAtAsisFileNode() or (p.isAnyAtFileNode() and not p.isAtIgnoreNode()):
            at.targetFileName = p.anyAtFileNodeName()
            if at.targetFileName:
                at.targetFileName = c.os_path_finalize_join(
                    self.default_directory,at.targetFileName)
                if not g.os_path_exists(at.targetFileName):
                    ok = at.openFileForWriting(p,at.targetFileName,toString)
                    # openFileForWriting calls p.setDirty() if there are errors.
                    if ok:
                        << write the @file node >>
                        at.closeWriteFile()
            p.moveToNodeAfterTree()
        elif p.isAtIgnoreNode():
            p.moveToNodeAfterTree()
        else:
            p.moveToThreadNext()

    if writtenFiles > 0:
        g.es("finished")
    else:
        g.es("no @file node in the selected tree")
#@+node:ekr.20041005105605.152:<< write the @file node >> (writeMissing)
if p.isAtAsisFileNode():
    at.asisWrite(p)
# elif p.isAtNorefFileNode():
    # at.norefWrite(p)
elif p.isAtNoSentFileNode():
    at.write(p,kind='@nosent',nosentinels=True)
elif p.isAtFileNode():
    at.write(p,kind='@file')
else: assert(0)

writtenFiles = True
#@-node:ekr.20041005105605.152:<< write the @file node >> (writeMissing)
#@-node:ekr.20041005105605.151:writeMissing
#@-node:ekr.20100123044506.6244:writing...
#@-node:ekr.20100123044506.6237:Eliminated support for @noref
#@+node:ekr.20100123044506.6238:Eliminated tnodeLists
#@+node:ekr.20100123044506.6240:Keep
#@+node:ekr.20041005105605.14:<< init ivars for reading >>
self.atAllFlag = False # True if @all seen.
self.cloneSibCount = 0 # n > 1: Make sure n cloned sibs exists at next @+node sentinel
self.correctedLines = 0
self.docOut = [] # The doc part being accumulated.
self.done = False # True when @-leo seen.
self.endSentinelStack = []
self.importing = False
self.importRootSeen = False
self.indentStack = []
self.inputFile = None
self.lastLines = [] # The lines after @-leo
self.lastThinNode = None # Used by createThinChild4.
self.leadingWs = ""
self.lineNumber = 0 # New in Leo 4.4.8.
self.out = None
self.outStack = []
self.rootSeen = False
self.tnodeList = [] # Needed until old-style @file nodes are no longer supported.
self.tnodeListIndex = 0
self.v = None
self.tStack = []
self.thinNodeStack = [] # Used by createThinChild4.
self.updateWarningGiven = False
#@-node:ekr.20041005105605.14:<< init ivars for reading >>
#@+node:ekr.20041005105605.73:findChild4
def findChild4 (self,headline):

    """Return the next vnode in at.root.tnodeLisft.
    This is called only for @file/@noref nodes"""

    # Note: tnodeLists are used _only_ when reading @file (not @thin) nodes.
    # tnodeLists compensate (a hack) for not having gnx's in derived files! 

    trace = False and not g.unitTesting
    at = self ; v = at.root.v

    if not g.unitTesting:
        if v.isAtFileNode():
            g.es_print('Warning: @file logic',v.h)

    if trace: g.trace('%s %s %s' % (
        at.tnodeListIndex,
        v.tnodeList[at.tnodeListIndex],headline))

    if not hasattr(v,"tnodeList"):
        at.readError("no tnodeList for " + repr(v))
        g.es("write the @file node or use the Import Derived File command")
        g.trace("no tnodeList for ",v,g.callers())
        return None

    if at.tnodeListIndex >= len(v.tnodeList):
        at.readError("bad tnodeList index: %d, %s" % (at.tnodeListIndex,repr(v)))
        g.trace("bad tnodeList index",at.tnodeListIndex,len(v.tnodeList),v)
        return None

    v = v.tnodeList[at.tnodeListIndex]
    assert(v)
    at.tnodeListIndex += 1

    # Don't check the headline.  It simply causes problems.
    v.setVisited() # Supress warning/deletion of unvisited nodes.
    return v
#@-node:ekr.20041005105605.73:findChild4
#@+node:ekr.20100122130101.6174:deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@-node:ekr.20100122130101.6174:deleteTnodeList
#@+node:ekr.20031218072017.2072:c.checkOutline
def checkOutline (self,event=None,verbose=True,unittest=False,full=True,root=None):

    """Report any possible clone errors in the outline.

    Remove any tnodeLists."""

    c = self ; count = 1 ; errors = 0
    isTkinter = g.app.gui and g.app.gui.guiName() == "tkinter"

    if full and not unittest:
        g.es("all tests enabled: this may take awhile",color="blue")

    if root: iter = root.self_and_subtree
    else:    iter = c.all_positions

    for p in iter():
        try:
            count += 1
            << remove tnodeList >>
            if full: # Unit tests usually set this false.
                << do full tests >>
        except AssertionError:
            errors += 1
            << give test failed message >>
    if verbose or not unittest:
        << print summary message >>
    return errors
#@+node:ekr.20040313150633:<< remove tnodeList >>
# Empty tnodeLists are not errors.
v = p.v

if hasattr(v,"tnodeList"): # and len(v.tnodeList) > 0 and not v.isAnyAtFileNode():
    if 0:
        s = "deleting tnodeList for " + repr(v)
        g.es_print(s,color="blue")
    delattr(v,"tnodeList")
    v._p_changed = True
#@-node:ekr.20040313150633:<< remove tnodeList >>
#@+node:ekr.20040323155951:<< do full tests >>
if not unittest:
    if count % 1000 == 0:
        g.es('','.',newline=False)
    if count % 8000 == 0:
        g.enl()

@others
#@+node:ekr.20040314035615:assert consistency of threadNext & threadBack links
threadBack = p.threadBack()
threadNext = p.threadNext()

if threadBack:
    assert p == threadBack.threadNext(), "p==threadBack.threadNext"

if threadNext:
    assert p == threadNext.threadBack(), "p==threadNext.threadBack"
#@-node:ekr.20040314035615:assert consistency of threadNext & threadBack links
#@+node:ekr.20040314035615.1:assert consistency of next and back links
back = p.back()
next = p.next()

if back:
    assert p == back.next(), 'p!=back.next(),  back: %s back.next: %s' % (
        back,back.next())

if next:
    assert p == next.back(), 'p!=next.back, next: %s next.back: %s' % (
        next,next.back())
#@-node:ekr.20040314035615.1:assert consistency of next and back links
#@+node:ekr.20040314035615.2:assert consistency of parent and child links
if p.hasParent():
    n = p.childIndex()
    assert p == p.parent().moveToNthChild(n), "p==parent.moveToNthChild"

for child in p.children():
    assert p == child.parent(), "p==child.parent"

if p.hasNext():
    assert p.next().parent() == p.parent(), "next.parent==parent"

if p.hasBack():
    assert p.back().parent() == p.parent(), "back.parent==parent"
#@-node:ekr.20040314035615.2:assert consistency of parent and child links
#@+node:ekr.20080426051658.1:assert consistency of parent and children arrays
@
Every nodes gets visited, so we only check consistency
between p and its parent, not between p and its children.

In other words, this is a strong test.
@c

parent_v = p._parentVnode()
n = p.childIndex()

assert parent_v.children[n] == p.v,'fail 1'
#@-node:ekr.20080426051658.1:assert consistency of parent and children arrays
#@-node:ekr.20040323155951:<< do full tests >>
#@+node:ekr.20040314044652:<< give test failed message >>
junk, value, junk = sys.exc_info()

s = "test failed at position %s\n%s" % (repr(p),value)

g.es_print(s,color="red")
#@-node:ekr.20040314044652:<< give test failed message >>
#@+node:ekr.20040314043900:<<print summary message >>
if full:
    g.enl()

if errors or verbose:
    color = g.choose(errors,'red','blue')
    g.es_print('',count,'nodes checked',errors,'errors',color=color)
#@-node:ekr.20040314043900:<<print summary message >>
#@-node:ekr.20031218072017.2072:c.checkOutline
#@+node:ekr.20060919110638.44:vnodeAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded and descendentTnodeUnknownAttributes.

def vnodeAttributes (self,attrs):

    node = self.node

    for bunch in self.attrsToList(attrs):
        name = bunch.name ; val = bunch.val
        if name == 't':
            aList = self.tnxToListDict.get(val,[])
            aList.append(self.node)
            self.tnxToListDict[val] = aList
            node.tnx = str(val) # nodeIndices.toString returns a string.
        else:
            node.attributes[name] = val
#@nonl
#@-node:ekr.20060919110638.44:vnodeAttributes
#@+node:ekr.20060919110638.16: node.__init__
def __init__ (self):

    self.attributes = {}
    self.bodyString = ''
    self.headString = ''
    self.children = []
    self.tnodeAttributes = {}
    self.tnodeList = []
    self.tnx = None
#@nonl
#@-node:ekr.20060919110638.16: node.__init__
#@+node:ekr.20031218072017.3019:leoFileCommands._init_
def __init__(self,c):

    # g.trace("__init__", "fileCommands.__init__")
    self.c = c
    self.frame = c.frame

    self.nativeTnodeAttributes = ('tx',)
    self.nativeVnodeAttributes = (
        'a',
        'descendentTnodeUnknownAttributes',
        'descendentVnodeUnknownAttributes', # New in Leo 4.5.
        'expanded','marks','t','tnodeList',
        # 'vtag',
    )

    self.checkOutlineBeforeSave = c.config.getBool(
        'check_outline_before_save',default=False)

    self.initIvars()
#@-node:ekr.20031218072017.3019:leoFileCommands._init_
#@+node:ekr.20061004053644:handleVnodeSaxAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded, and descendentTnodeUnknownAttributes.
# New in Leo 4.5: added descendentVnodeUnknownAttributes to native attributes.

def handleVnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.attributes
    # if trace and d: g.trace(d)

    s = d.get('a')
    if s:
        # g.trace('%s a=%s %s' % (id(sax_node),s,v.headString()))
        # 'C' (clone) and 'D' bits are not used.
        if 'M' in s: v.setMarked()
        if 'E' in s: v.expand()
        if 'O' in s: v.setOrphan()
        # if 'T' in s: self.topVnode = v
        if 'V' in s:
            # g.trace('setting currentVnode',v,color='red')
            self.currentVnode = v

    s = d.get('tnodeList','')
    tnodeList = s and s.split(',')
    if tnodeList:
        # This tnodeList will be resolved later.
        if trace: g.trace('found tnodeList',v.headString(),tnodeList)
        v.tempTnodeList = tnodeList

    s = d.get('descendentTnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentTnodeUaDictList',aDict)
            self.descendentTnodeUaDictList.append(aDict)

    s = d.get('descendentVnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentVnodeUaDictList',aDict)
            self.descendentVnodeUaDictList.append((v,aDict),)

    s = d.get('expanded')
    if s:
        aList = self.getDescendentAttributes(s,tag="expanded")
        # g.trace('expanded list',len(aList))
        self.descendentExpandedList.extend(aList)

    s = d.get('marks')
    if s:
        aList = self.getDescendentAttributes(s,tag="marks")
        # g.trace('marks list',len(aList))
        self.descendentMarksList.extend(aList)

    aDict = {}
    for key in d:
        if key in self.nativeVnodeAttributes:
            # This is not a bug.
            if False and trace: g.trace(
                '****ignoring***',key,d.get(key))
        else:
            val = d.get(key)
            val2 = self.getSaxUa(key,val)
            aDict[key] = val2
            # g.trace(key,val,val2)
    if aDict:
        # if trace: g.trace('uA',v,aDict)
        v.unknownAttributes = aDict
#@+node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()
    sax_node = g.bunch(
        attributes={
'a':'M',
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
    })
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleVnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr) is not None,attr
        # The a:M attribute should mark the node.
        assert d.get('a') is None
        assert v.isMarked()
        aList = d.get('icons')
        assert aList
        assert len(aList) == 2
        for d2 in aList:
            for key in ('on','where','yoffset','file'):
                assert d2.get(key) is not None,key
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
#@-node:ekr.20061004053644:handleVnodeSaxAttributes
#@+node:ekr.20060919110638.11:resolveTnodeLists
def resolveTnodeLists (self):

    trace = False and not g.unitTesting
    c = self.c

    for p in c.all_unique_positions():
        if hasattr(p.v,'tempTnodeList'):
            # g.trace(p.v.headString())
            result = []
            for tnx in p.v.tempTnodeList:
                index = self.canonicalTnodeIndex(tnx)
                v = self.gnxDict.get(index)
                if v:
                    if trace: g.trace(tnx,v)
                    result.append(v)
                else:
                    g.trace('*** No vnode for %s' % tnx)
            if result:
                p.v.tnodeList = result
                # g.trace('*** tnodeList for',p.h,result)
            delattr(p.v,'tempTnodeList')
#@nonl
#@-node:ekr.20060919110638.11:resolveTnodeLists
#@-node:ekr.20100123044506.6240:Keep
#@+node:ekr.20100123044506.6243:changed
#@+node:ekr.20031218072017.1863:putVnode
def putVnode (self,p,isIgnore=False):

    """Write a <v> element corresponding to a vnode."""

    fc = self ; c = fc.c ; v = p.v
    isAuto = p.isAtAutoNode() and p.atAutoNodeName().strip()
    isEdit = p.isAtEditNode() and p.atEditNodeName().strip()
    isShadow = p.isAtShadowFileNode()
    isThin = p.isAtThinFileNode()
    isOrphan = p.isOrphan()
    if not isIgnore: isIgnore = p.isAtIgnoreNode()

    if   isIgnore: forceWrite = True      # Always write full @ignore trees.
    elif isAuto:   forceWrite = False     # Never write non-ignored @auto trees.
    elif isEdit:   forceWrite = False     # Never write non-ignored @edit trees.
    elif isShadow: forceWrite = False     # Never write non-ignored @shadow trees.
    elif isThin:   forceWrite = isOrphan  # Only write orphan @thin trees.
    else:          forceWrite = True      # Write all other @<file> trees.

    << Set gnx = vnode index >>
    attrs = []
    << Append attribute bits to attrs >>
    << Append unKnownAttributes to attrs >>
    attrs = ''.join(attrs)
    v_head = '<v t="%s"%s>' % (gnx,attrs)
    if gnx in fc.vnodesDict:
        fc.put(v_head+'</v>\n')
    else:
        fc.vnodesDict[gnx]=True
        v_head += '<vh>%s</vh>' % (xml.sax.saxutils.escape(p.v.headString()or''))
        # The string catentation is faster than repeated calls to fc.put.
        if not self.usingClipboard:
            << issue informational messages >>
        # New in 4.2: don't write child nodes of @file-thin trees (except when writing to clipboard)
        if p.hasChildren() and (forceWrite or self.usingClipboard):
            fc.put('%s\n' % v_head)
            # This optimization eliminates all "recursive" copies.
            p.moveToFirstChild()
            while 1:
                fc.putVnode(p,isIgnore)
                if p.hasNext(): p.moveToNext()
                else:           break
            p.moveToParent() # Restore p in the caller.
            fc.put('</v>\n')
        else:
            fc.put('%s</v>\n' % v_head) # Call put only once.
#@+node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
gnx = g.app.nodeIndices.toString(v.fileIndex)

if forceWrite or self.usingClipboard:
    v.setWriteBit() # 4.2: Indicate we wrote the body text.
#@-node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
# v.unknownAttributes are now put in <t> elements.

if p.hasChildren() and not forceWrite and not self.usingClipboard:
    # We put the entire tree when using the clipboard, so no need for this.
    if not isAuto: # Bug fix: 2008/8/7.
        attrs.append(self.putDescendentVnodeUas(p)) # New in Leo 4.5.
        attrs.append(self.putDescendentAttributes(p))
#@nonl
#@-node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
#@+node:ekr.20040702085529:<< issue informational messages >>
if isOrphan and isThin:
    g.es("writing erroneous:",p.h,color="blue")
    p.clearOrphan()
#@-node:ekr.20040702085529:<< issue informational messages >>
#@-node:ekr.20031218072017.1863:putVnode
#@+node:ekr.20041005105605.193:putOpenNodeSentinel
def putOpenNodeSentinel(self,p,inAtAll=False,middle=False):

    """Write @+node sentinel for p."""

    at = self

    if not inAtAll and p.isAtFileNode() and p != at.root:
        at.writeError("@file not valid in: " + p.h)
        return

    # g.trace(at.thinFile,p)

    s = at.nodeSentinelText(p)

    if middle:
        at.putSentinel("@+middle:" + s)
    else:
        at.putSentinel("@+node:" + s)

    # Leo 4.7 b2: we never write tnodeLists.
#@nonl
#@-node:ekr.20041005105605.193:putOpenNodeSentinel
#@+node:ekr.20031218072017.2012:writeAtFileNodes (fileCommands)
def writeAtFileNodes (self,event=None):

    '''Write all @file nodes in the selected outline.'''

    self.c.atFileCommands.writeAll(writeAtFileNodesFlag=True)
#@-node:ekr.20031218072017.2012:writeAtFileNodes (fileCommands)
#@+node:ekr.20080801071227.5:writeAtShadowNodes (fileCommands)
def writeAtShadowNodes (self,event=None):

    '''Write all @file nodes in the selected outline.'''

    self.c.atFileCommands.writeAll(writeAtFileNodesFlag=True)
#@-node:ekr.20080801071227.5:writeAtShadowNodes (fileCommands)
#@+node:ekr.20031218072017.1666:writeDirtyAtFileNodes (fileCommands)
def writeDirtyAtFileNodes (self,event=None):

    '''Write all changed @file Nodes.'''

    self.c.atFileCommands.writeAll(writeDirtyAtFileNodesFlag=True)
#@-node:ekr.20031218072017.1666:writeDirtyAtFileNodes (fileCommands)
#@+node:ekr.20080801071227.6:writeDirtyAtShadowNodes (fileCommands)
def writeDirtyAtShadowNodes (self,event=None):

    '''Write all changed @shadow Nodes.'''

    self.c.atFileCommands.writeDirtyAtShadowNodes()

#@-node:ekr.20080801071227.6:writeDirtyAtShadowNodes (fileCommands)
#@+node:ekr.20031218072017.2013:writeMissingAtFileNodes
def writeMissingAtFileNodes (self,event=None):

    '''Write all missing @file nodes.'''

    c = self.c

    if c.p:
        c.atFileCommands.writeMissing(c.p)
#@-node:ekr.20031218072017.2013:writeMissingAtFileNodes
#@+node:ekr.20041005105605.15:initWriteIvars
def initWriteIvars(self,root,targetFileName,
    atAuto=False,
    atEdit=False,
    atShadow=False,
    nosentinels=False,
    thinFile=False,
    scriptWrite=False,
    toString=False,
    forcePythonSentinels=None,
):

    self.initCommonIvars()
    << init ivars for writing >>

    if forcePythonSentinels is None:
        forcePythonSentinels = scriptWrite

    if root:
        self.scanAllDirectives(root,
            scripting=scriptWrite,
            forcePythonSentinels=forcePythonSentinels)

    # g.trace(forcePythonSentinels,self.startSentinelComment,self.endSentinelComment)

    if forcePythonSentinels:
        # Force Python comment delims for g.getScript.
        self.startSentinelComment = "#"
        self.endSentinelComment = None

    # Init state from arguments.
    self.targetFileName = targetFileName
    self.sentinels = not nosentinels
    self.thinFile = thinFile
    self.toString = toString
    self.root = root

    # Ignore config settings for unit testing.
    if toString and g.app.unitTesting: self.output_newline = '\n'

    # Init all other ivars even if there is an error.
    if not self.errors and self.root:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        self.root.v._p_changed = True
#@+node:ekr.20041005105605.16:<< init ivars for writing >>>
@
When tangling, we first write to a temporary output file. After tangling is
temporary file. Otherwise we delete the old target file and rename the temporary
file to be the target file.
@c

self.docKind = None
self.explicitLineEnding = False # True: an @lineending directive specifies the ending.
self.fileChangedFlag = False # True: the file has actually been updated.
self.atAuto = atAuto
self.atEdit = atEdit
self.atShadow = atShadow
self.shortFileName = "" # short version of file name used for messages.
self.thinFile = False
self.force_newlines_in_at_nosent_bodies = self.c.config.getBool(
    'force_newlines_in_at_nosent_bodies')

if toString:
    self.outputFile = g.fileLikeObject()
    self.stringOutput = ""
    self.targetFileName = self.outputFileName = "<string-file>"
else:
    self.outputFile = None # The temporary output file.
    self.stringOutput = None
    self.targetFileName = self.outputFileName = g.u('')
#@-node:ekr.20041005105605.16:<< init ivars for writing >>>
#@-node:ekr.20041005105605.15:initWriteIvars
#@+node:ekr.20041005105605.144:write & helper (atFile)
def write (self,root,
    kind = '@unknown', # Should not happen.
    nosentinels = False,
    thinFile = False,
    scriptWrite = False,
    toString = False,
):
    """Write a 4.x derived file.
    root is the position of an @<file> node"""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    << set at.targetFileName >>
    at.initWriteIvars(root,at.targetFileName,
        nosentinels = nosentinels, thinFile = thinFile,
        scriptWrite = scriptWrite, toString = toString)

    # "look ahead" computation of eventual fileName.
    eventualFileName = c.os_path_finalize_join(
        at.default_directory,at.targetFileName)
    exists = g.os_path_exists(eventualFileName)
    # g.trace('eventualFileName',eventualFileName,
        # 'at.targetFileName',at.targetFileName)

    if not scriptWrite and not toString:
        if nosentinels:
            if not self.shouldWriteAtNosentNode(root,exists):
                return
        elif not hasattr(root.v,'at_read') and exists:
            # Prompt if writing a new @file or @thin node would
            # overwrite an existing file.
            ok = self.promptForDangerousWrite(eventualFileName,kind)
            if ok:
                root.v.at_read = True # Create the attribute for all clones.
            else:
                g.es("not written:",eventualFileName)
                return

    if not at.openFileForWriting(root,at.targetFileName,toString):
        # openFileForWriting calls root.setDirty() if there are errors.
        return

    try:
        at.writeOpenFile(root,nosentinels=nosentinels,toString=toString)
        assert root==at.root
        if toString:
            at.closeWriteFile() # sets self.stringOutput
            # Major bug: failure to clear this wipes out headlines!
            # Minor bug: sometimes this causes slight problems...
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
        else:
            at.closeWriteFile()
            if at.errors > 0 or root.isOrphan():
                << set dirty and orphan bits >>
                g.es("not written:",at.outputFileName)
            else:
                at.replaceTargetFileIfDifferent(root)
                    # Sets/clears dirty and orphan bits.

    except Exception:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        if toString:
            at.exception("exception preprocessing script")
            root.v._p_changed = True
        else:
            at.writeException() # Sets dirty and orphan bits.
#@+node:ekr.20041005105605.145:<< set at.targetFileName >>
if toString:
    at.targetFileName = "<string-file>"
elif nosentinels:
    at.targetFileName = root.atNoSentFileNodeName()
elif thinFile:
    at.targetFileName = root.atThinFileNodeName()
    if not at.targetFileName:
        # We have an @file node.
        at.targetFileName = root.atFileNodeName()
else:
    at.targetFileName = root.atFileNodeName()
#@-node:ekr.20041005105605.145:<< set at.targetFileName >>
#@+node:ekr.20041005105605.146:<< set dirty and orphan bits >>
# Setting the orphan and dirty flags tells Leo to write the tree..
root.setOrphan()
root.setDirty()
# Delete the temp file.
self.remove(at.outputFileName) 

#@-node:ekr.20041005105605.146:<< set dirty and orphan bits >>
#@+node:ekr.20080620095343.1:shouldWriteAtNosentNode
@ Much thought went into this decision tree:

- We do not want decisions to depend on past history.That ' s too confusing.
- We must ensure that the file will be written if the user does significant work.
- We must ensure that the user can create an @auto x node at any time
  without risk of of replacing x with empty or insignificant information.
- We want the user to be able to create an @auto node which will be populated the next time the.leo file is opened.
- We don't want minor import imperfections to be written to the @auto file.
- The explicit commands that read and write @auto trees must always be honored.
@c

def shouldWriteAtNosentNode (self,p,exists):

    '''Return True if we should write the @auto node at p.'''

    if not exists: # We can write a non-existent file without danger.
        return True
    elif self.isSignificantTree(p):
        return True # Assume the tree contains what should be written.
    else:
        g.es_print(p.h,'not written:',color='red')
        g.es_print('no children and less than 10 characters (excluding directives)',color='blue')
        return False
#@-node:ekr.20080620095343.1:shouldWriteAtNosentNode
#@-node:ekr.20041005105605.144:write & helper (atFile)
#@+node:ekr.20050506084734:writeFromString
# This is at.write specialized for scripting.

def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):

    """Write a 4.x derived file from a string.

    This is used by the scripting logic."""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline, but don't change the focus!

    at.initWriteIvars(root,"<string-file>",
        nosentinels=not useSentinels,thinFile=False,scriptWrite=True,toString=True,
        forcePythonSentinels=forcePythonSentinels)

    try:
        ok = at.openFileForWriting(root,at.targetFileName,toString=True)
        if g.app.unitTesting: assert ok # string writes never fail.
        # Simulate writing the entire file so error recovery works.
        at.writeOpenFile(root,nosentinels=not useSentinels,toString=True,fromString=s)
        at.closeWriteFile()
        # Major bug: failure to clear this wipes out headlines!
        # Minor bug: sometimes this causes slight problems...
        if root:
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
    except Exception:
        at.exception("exception preprocessing script")

    return at.stringOutput
#@-node:ekr.20050506084734:writeFromString
#@+node:ekr.20041005105605.147:writeAll (atFile) & helper
def writeAll(self,
    writeAtFileNodesFlag=False,
    writeDirtyAtFileNodesFlag=False,
    toString=False
):

    """Write @file nodes in all or part of the outline"""

    trace = False and not g.unitTesting
    at = self ; c = at.c
    if trace: scanAtPathDirectivesCount = c.scanAtPathDirectivesCount
    writtenFiles = [] # Files that might be written again.
    force = writeAtFileNodesFlag

    if writeAtFileNodesFlag:
        # The Write @<file> Nodes command.
        # Write all nodes in the selected tree.
        p = c.p
        after = p.nodeAfterTree()
    else:
        # Write dirty nodes in the entire outline.
        p =  c.rootPosition()
        after = c.nullPosition()

    << Clear all orphan bits >>
    while p and p != after:
        if p.isAnyAtFileNode() or p.isAtIgnoreNode():
            self.writeAllHelper(p,force,toString,writeAtFileNodesFlag,writtenFiles)
            p.moveToNodeAfterTree()
        else:
            p.moveToThreadNext()

    << say the command is finished >>
    if trace: g.trace('%s calls to c.scanAtPathDirectives()' % (
        c.scanAtPathDirectivesCount-scanAtPathDirectivesCount))

#@+node:ekr.20041005105605.148:<< Clear all orphan bits >>
@ We must clear these bits because they may have been set on a previous write.
Calls to atFile::write may set the orphan bits in @file nodes.
If so, write_Leo_file will write the entire @file tree.
@c

for v2 in p.self_and_subtree():
    v2.clearOrphan()
#@-node:ekr.20041005105605.148:<< Clear all orphan bits >>
#@+node:ekr.20041005105605.150:<< say the command is finished >>
if writeAtFileNodesFlag or writeDirtyAtFileNodesFlag:
    if len(writtenFiles) > 0:
        g.es("finished")
    elif writeAtFileNodesFlag:
        g.es("no @<file> nodes in the selected tree")
    else:
        g.es("no dirty @<file> nodes")
#@-node:ekr.20041005105605.150:<< say the command is finished >>
#@+node:ekr.20041005105605.149:writeAllHelper (atFile)
def writeAllHelper (self,p,
    force,toString,writeAtFileNodesFlag,writtenFiles
):

    trace = False and not g.unitTesting
    at = self ; c = at.c

    if p.isAtIgnoreNode() and not p.isAtAsisFileNode():
        pathChanged = False
    else:
        oldPath = at.getPathUa(p).lower()
        newPath = at.fullPath(p).lower()
        pathChanged = oldPath and oldPath != newPath
        # 2010/01/27: suppress this message during save-as and save-to commands.
        if pathChanged and not c.ignoreChangedPaths:
            at.setPathUa(p,newPath) # Remember that we have changed paths.
            g.es_print('path changed for',p.h,color='blue')
            if trace: g.trace('p %s\noldPath %s\nnewPath %s' % (
                p.h,repr(oldPath),repr(newPath)))

    if p.v.isDirty() or pathChanged or writeAtFileNodesFlag or p.v in writtenFiles:

        # Tricky: @ignore not recognised in @asis nodes.
        if p.isAtAsisFileNode():
            at.asisWrite(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtIgnoreNode():
            pass
        elif p.isAtAutoNode():
            at.writeOneAtAutoNode(p,toString=toString,force=force)
            writtenFiles.append(p.v)
        elif p.isAtEditNode():
            at.writeOneAtEditNode(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtNoSentFileNode():
            at.write(p,kind='@nosent',nosentinels=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtShadowFileNode():
            at.writeOneAtShadowNode(p,toString=toString,force=force or pathChanged)
            writtenFiles.append(p.v)
        elif p.isAtThinFileNode():
            at.write(p,kind='@thin',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtFileNode():
            # Write old @file nodes using @thin format.
            at.write(p,kind='@file',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
#@-node:ekr.20041005105605.149:writeAllHelper (atFile)
#@-node:ekr.20041005105605.147:writeAll (atFile) & helper
#@-node:ekr.20100123044506.6243:changed
#@-node:ekr.20100123044506.6238:Eliminated tnodeLists
#@+node:ekr.20100124092134.6247:checked for p.setDirty
@
This is surprising. It should be the same as p.v.setDirty, but it calls
c.setDirty instead! However, in Leo's code p.setDirty is used by commands, so it
can't be changed. We must make *sure* not to call p.setDirty when reading files.
#@+node:ekr.20040303163330:p.setDirty
def setDirty (self,setDescendentsDirty=True):

    '''Mark a node and all ancestor @file nodes dirty.'''

    p = self ; dirtyVnodeList = []

    # g.trace(p.h,g.callers(4))

    if not p.v.isDirty():
        p.v.setDirty()
        dirtyVnodeList.append(p.v)

    # Important: this must be called even if p.v is already dirty.
    # Typing can change the @ignore state!
    dirtyVnodeList2 = p.setAllAncestorAtFileNodesDirty(setDescendentsDirty)
    dirtyVnodeList.extend(dirtyVnodeList2)

    return dirtyVnodeList
#@-node:ekr.20040303163330:p.setDirty
#@+node:ekr.20040315034158:p.setBodyString & setHeadString
def setBodyString (self,s):

    p = self
    return p.v.setBodyString(s)

initBodyString = setBodyString
setTnodeText = setBodyString
scriptSetBodyString = setBodyString

def initHeadString (self,s):

    p = self
    p.v.initHeadString(s)

def setHeadString (self,s):

    p = self
    p.v.initHeadString(s)
    # Note: p.setDirty is expensive.
    # We can't change this because Leo's core uses
    # p.setDirty and c.setDirty interchangeably.
    p.setDirty()
#@nonl
#@-node:ekr.20040315034158:p.setBodyString & setHeadString
#@+node:ekr.20041005105605.72:at.createThinChild4
def createThinChild4 (self,gnxString,headline):

    """Find or create a new *vnode* whose parent (also a vnode) is at.lastThinNode.
    This is called only for @thin trees."""

    trace = False and not g.unitTesting
    verbose = False
    at = self ; c = at.c ; indices = g.app.nodeIndices
    last = at.lastThinNode
    lastIndex = last.fileIndex
    gnx = indices.scanGnx(gnxString,0)

    if trace and verbose: g.trace("last %s, gnx %s %s" % (
        last,gnxString,headline))

    parent = at.lastThinNode # A vnode.
    children = parent.children
    for child in children:
        if gnx == child.fileIndex:
            break
    else:
        child = None

    if at.cloneSibCount > 1:
        n = at.cloneSibCount ; at.cloneSibCount = 0
        if child: clonedSibs,junk = at.scanForClonedSibs(parent,child)
        else: clonedSibs = 0
        copies = n - clonedSibs
        if trace: g.trace(copies,headline)
    else:
        if gnx == lastIndex:
            last.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace:g.trace('found last',last)
            return last
        if child:
            child.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace: g.trace('found child',child)
            return child
        copies = 1 # Create exactly one copy.

    while copies > 0:
        copies -= 1
        # Create the vnode only if it does not already exist.
        gnxDict = c.fileCommands.gnxDict
        v = gnxDict.get(gnxString)
        if v:
            if gnx != v.fileIndex:
                g.trace('can not happen: v.fileIndex: %s gnx: %s' % (v.fileIndex,gnx))
        else:
            v = leoNodes.vnode(context=c)
            v._headString = headline # Allowed use of v._headString.
            v.fileIndex = gnx
            gnxDict[gnxString] = v

        child = v
        child._linkAsNthChild(parent,parent.numberOfChildren())

    if trace and verbose: g.trace('new node: %s' % child)
    child.setVisited() # Supress warning/deletion of unvisited nodes.
    return child
#@-node:ekr.20041005105605.72:at.createThinChild4
#@-node:ekr.20100124092134.6247:checked for p.setDirty
#@+node:ekr.20100122162421.6240:Clones in @all files now have low priority
To do: create cloneTest.leo and related files.
#@nonl
#@+node:ekr.20100124110832.6214:unchanged...
# These may have changed, but not for this particular project.
#@nonl
#@+node:ekr.20041005105605.72:at.createThinChild4
def createThinChild4 (self,gnxString,headline):

    """Find or create a new *vnode* whose parent (also a vnode) is at.lastThinNode.
    This is called only for @thin trees."""

    trace = False and not g.unitTesting
    verbose = False
    at = self ; c = at.c ; indices = g.app.nodeIndices
    last = at.lastThinNode
    lastIndex = last.fileIndex
    gnx = indices.scanGnx(gnxString,0)

    if trace and verbose: g.trace("last %s, gnx %s %s" % (
        last,gnxString,headline))

    parent = at.lastThinNode # A vnode.
    children = parent.children
    for child in children:
        if gnx == child.fileIndex:
            break
    else:
        child = None

    if at.cloneSibCount > 1:
        n = at.cloneSibCount ; at.cloneSibCount = 0
        if child: clonedSibs,junk = at.scanForClonedSibs(parent,child)
        else: clonedSibs = 0
        copies = n - clonedSibs
        if trace: g.trace(copies,headline)
    else:
        if gnx == lastIndex:
            last.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace:g.trace('found last',last)
            return last
        if child:
            child.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace: g.trace('found child',child)
            return child
        copies = 1 # Create exactly one copy.

    while copies > 0:
        copies -= 1
        # Create the vnode only if it does not already exist.
        gnxDict = c.fileCommands.gnxDict
        v = gnxDict.get(gnxString)
        if v:
            if gnx != v.fileIndex:
                g.trace('can not happen: v.fileIndex: %s gnx: %s' % (v.fileIndex,gnx))
        else:
            v = leoNodes.vnode(context=c)
            v._headString = headline # Allowed use of v._headString.
            v.fileIndex = gnx
            gnxDict[gnxString] = v

        child = v
        child._linkAsNthChild(parent,parent.numberOfChildren())

    if trace and verbose: g.trace('new node: %s' % child)
    child.setVisited() # Supress warning/deletion of unvisited nodes.
    return child
#@-node:ekr.20041005105605.72:at.createThinChild4
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20041005105605.85:at.readStartNode
def readStartNode (self,s,i,middle=False):

    """Read an @+node or @+middle sentinel."""

    trace = False and not g.unitTesting
    at = self
    if middle:
        assert g.match(s,i,"+middle:"),'missing +middle'
        i += 8
    else:
        assert g.match(s,i,"+node:"),'missing +node'
        i += 6

    if at.thinFile:
        << set gnx and bump i >>
    << Set headline, undoing the CWEB hack >>
    if not at.root_seen:
        # g.trace(repr(s[0:i+20]))
        at.root_seen = True

    i,newIndent = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    at.indentStack.append(at.indent) ; at.indent = newIndent

    at.outStack.append(at.out) ; at.out = []
    at.tStack.append(at.v)

    if trace: g.trace(at.root)
    if at.importing:
        p = at.createImportedNode(at.root,headline)
        at.v = p.v
    elif at.thinFile:
        if at.thinNodeStack:
            at.thinNodeStack.append(at.lastThinNode)
            v = at.createThinChild4(gnx,headline)
        else:
            v = at.root.v
            at.thinNodeStack.append(v)
        at.lastThinNode = v
        at.v = v
    else:
        at.v = at.findChild4(headline)

    if trace: g.trace('scanning',at.v)

    at.endSentinelStack.append(at.endNode)
#@+node:ekr.20041005105605.86:<< set gnx and bump i >>
# We have skipped past the opening colon of the gnx.
j = s.find(':',i)
if j == -1:
    g.trace("no closing colon",g.get_line(s,i))
    at.readError("Expecting gnx in @+node sentinel")
    return # 5/17/04
else:
    gnx = s[i:j]
    i = j + 1 # Skip the i
#@-node:ekr.20041005105605.86:<< set gnx and bump i >>
#@+node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
# Set headline to the rest of the line.
# Don't strip leading whitespace."

if len(at.endSentinelComment) == 0:
    headline = s[i:-1].rstrip()
else:
    k = s.rfind(at.endSentinelComment,i)
    headline = s[i:k].rstrip() # works if k == -1

# Undo the CWEB hack: undouble @ signs if the opening comment delim ends in '@'.
if at.startSentinelComment[-1:] == '@':
    headline = headline.replace('@@','@')
#@-node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
#@-node:ekr.20041005105605.85:at.readStartNode
#@+node:ekr.20031218072017.2989:c.setChanged
def setChanged (self,changedFlag):

    trace = False and not g.unitTesting
    c = self
    if not c.frame: return
    c.changed = changedFlag
    if c.loading: return # don't update while loading.

    if trace: g.trace('Commands',changedFlag,c,g.callers(4))

    # Clear all dirty bits _before_ setting the caption.
    if not changedFlag:
        for v in c.all_unique_nodes():
            if v.isDirty():
                v.clearDirty()

    if g.app.qt_use_tabs and hasattr(c.frame,'top'):
        c.frame.top.master.setChanged(c,changedFlag)

    s = c.frame.getTitle()
    if len(s) > 2:
        if changedFlag:
            if s [0] != '*': c.frame.setTitle("* " + s)
        else:
            if s[0:2]=="* ": c.frame.setTitle(s[2:])
#@-node:ekr.20031218072017.2989:c.setChanged
#@+node:ekr.20060919110638.5:fc.createSaxChildren & helpers
def createSaxChildren (self, sax_node, parent_v):

    c = self.c
    trace = False and not g.unitTesting # and c.shortFileName().find('small') > -1
    children = []

    for sax_child in sax_node.children:
        tnx = sax_child.tnx
        v = self.gnxDict.get(tnx)

        if v: # A clone.
            if trace: g.trace('**clone',v)
            v = self.createSaxVnode(sax_child,parent_v,v=v)   
        else:
            v = self.createSaxVnode(sax_child,parent_v)
            self.createSaxChildren(sax_child,v)

        children.append(v)

    parent_v.children = children
    for child in children:
        child.parents.append(parent_v)
        if trace: g.trace(
            '*** added parent',parent_v,'to',child,
            'len(child.parents)',len(child.parents))

    return children
#@+node:ekr.20060919110638.7:fc.createSaxVnode & helpers
def createSaxVnode (self,sax_node,parent_v,v=None):

    c = self.c
    trace = False and not g.unitTesting and c.shortFileName().find('test') > -1
    verbose = False
    h = sax_node.headString
    b = sax_node.bodyString

    if v:
        # The body of the later node overrides the earlier.
        # Don't set t.h: h is always empty.
        # This may be an internal error.
        if v.b == b:
            if trace and verbose: g.trace(
                '***no update\nold: %s\nnew: %s' % (v.b,b))
        else:
            if trace: g.trace(
                '***update\nold: %s\nnew: %s' % (v.b,b))
            v.b = b 
    else:
        v = leoNodes.vnode(context=c)
        v.setBodyString(b)
        v.setHeadString(h)

        if sax_node.tnx:
            v.fileIndex = g.app.nodeIndices.scanGnx(sax_node.tnx,0)

    index = self.canonicalTnodeIndex(sax_node.tnx)
    self.gnxDict [index] = v

    if trace and verbose: g.trace(
        'tnx','%-22s' % (index),'v',id(v),
        'len(body)','%-4d' % (len(b)),h)

    self.handleVnodeSaxAttributes(sax_node,v)
    self.handleTnodeSaxAttributes(sax_node,v)

    return v
#@+node:ekr.20060919110638.8:handleTnodeSaxAttributes
def handleTnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.tnodeAttributes
    if trace and d: g.trace(sax_node,list(d.keys()))

    aDict = {}
    for key in d:
        val = d.get(key)
        val2 = self.getSaxUa(key,val)
        # g.trace(key,val,val2)
        aDict[key] = val2

    if aDict:
        if trace: g.trace('uA',v,list(aDict.keys()))
        v.unknownAttributes = aDict
#@+node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()

    sax_node = g.bunch(
        tnodeAttributes={
# The 'tx' attribute is handled by contentHandler.tnodeAttributes.
# 'tx':"ekr.20090701133940.1767",
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
})
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleTnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr),attr
        for attr in ('tx','a'):
            assert d.get(attr) is None,attr # A known attribute.
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
#@-node:ekr.20060919110638.8:handleTnodeSaxAttributes
#@+node:ekr.20061004053644:handleVnodeSaxAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded, and descendentTnodeUnknownAttributes.
# New in Leo 4.5: added descendentVnodeUnknownAttributes to native attributes.

def handleVnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.attributes
    # if trace and d: g.trace(d)

    s = d.get('a')
    if s:
        # g.trace('%s a=%s %s' % (id(sax_node),s,v.headString()))
        # 'C' (clone) and 'D' bits are not used.
        if 'M' in s: v.setMarked()
        if 'E' in s: v.expand()
        if 'O' in s: v.setOrphan()
        # if 'T' in s: self.topVnode = v
        if 'V' in s:
            # g.trace('setting currentVnode',v,color='red')
            self.currentVnode = v

    s = d.get('tnodeList','')
    tnodeList = s and s.split(',')
    if tnodeList:
        # This tnodeList will be resolved later.
        if trace: g.trace('found tnodeList',v.headString(),tnodeList)
        v.tempTnodeList = tnodeList

    s = d.get('descendentTnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentTnodeUaDictList',aDict)
            self.descendentTnodeUaDictList.append(aDict)

    s = d.get('descendentVnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentVnodeUaDictList',aDict)
            self.descendentVnodeUaDictList.append((v,aDict),)

    s = d.get('expanded')
    if s:
        aList = self.getDescendentAttributes(s,tag="expanded")
        # g.trace('expanded list',len(aList))
        self.descendentExpandedList.extend(aList)

    s = d.get('marks')
    if s:
        aList = self.getDescendentAttributes(s,tag="marks")
        # g.trace('marks list',len(aList))
        self.descendentMarksList.extend(aList)

    aDict = {}
    for key in d:
        if key in self.nativeVnodeAttributes:
            # This is not a bug.
            if False and trace: g.trace(
                '****ignoring***',key,d.get(key))
        else:
            val = d.get(key)
            val2 = self.getSaxUa(key,val)
            aDict[key] = val2
            # g.trace(key,val,val2)
    if aDict:
        # if trace: g.trace('uA',v,aDict)
        v.unknownAttributes = aDict
#@+node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()
    sax_node = g.bunch(
        attributes={
'a':'M',
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
    })
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleVnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr) is not None,attr
        # The a:M attribute should mark the node.
        assert d.get('a') is None
        assert v.isMarked()
        aList = d.get('icons')
        assert aList
        assert len(aList) == 2
        for d2 in aList:
            for key in ('on','where','yoffset','file'):
                assert d2.get(key) is not None,key
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
#@-node:ekr.20061004053644:handleVnodeSaxAttributes
#@-node:ekr.20060919110638.7:fc.createSaxVnode & helpers
#@-node:ekr.20060919110638.5:fc.createSaxChildren & helpers
#@-node:ekr.20100124110832.6214:unchanged...
#@+node:ekr.20100124110832.6213:changed...
#@+node:ekr.20041005105605.95:at.readEndNode
def readEndNode (self,unused_s,unused_i,middle=False):

    """Handle end-of-node processing for @-others and @-ref sentinels."""

    trace = False and not g.unitTesting
    at = self ; c = at.c

    # End raw mode.
    at.raw = False

    # Set the temporary body text.
    s = ''.join(at.out)
    s = g.toUnicode(s)

    # g.trace(repr(s))

    if at.importing:
        at.v._bodyString = s # Allowed use of _bodyString.
    elif middle: 
        pass # Middle sentinels never alter text.
    else:
        if hasattr(at.v,"tempBodyString") and s != at.v.tempBodyString:
            old = at.v.tempBodyString
        elif at.v.hasBody() and s != at.v.getBody():
            old = at.v.getBody()
        else:
            old = None
        # 9/4/04: Suppress this warning for the root: @first complicates matters.
        if old and at.v != at.root.v: # and not g.app.unitTesting
            << indicate that the node has been changed >>
        if old and at.atAllFlag:
            # Don't change.
            if trace: g.trace('*** no update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
        else:
            if trace: g.trace('*** update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
            at.v.tempBodyString = s

    # Indicate that the vnode has been set in the derived file.
    at.v.setVisited()
    # g.trace('visit',at.v)

    # End the previous node sentinel.
    at.indent = at.indentStack.pop()
    at.out = at.outStack.pop()
    at.v = at.tStack.pop()
    if at.thinFile and not at.importing:
        at.lastThinNode = at.thinNodeStack.pop()

    at.popSentinelStack(at.endNode)
#@+node:ekr.20041005105605.96:<< indicate that the node has been changed >>
if at.perfectImportRoot:
    << bump at.correctedLines and tell about the correction >>
    at.v._bodyString = s # Allowed use of _bodyString.
        # Just setting at.v.tempBodyString won't work here.
    at.v.setDirty() # Mark the node dirty.  Ancestors will be marked dirty later.
    at.c.setChanged(True)
else:
    # New in Leo 4.4.1 final.  This warning can be very confusing.
    # New in Leo 4.7 b2: We suppress warning for trees containing '@all'
    if at.atAllFlag: # Give the warning if we are not in an '@all' tree.
        pass
    # elif not at.updateWarningGiven:
    else:
        # at.updateWarningGiven = True
        # g.pr("***",at.v,at.root.v)
        g.es_print("uncached read node changed",at.v.h,color="red") # was at.root.h
    # Just set the dirty bit. Ancestors will be marked dirty later.
    at.v.setDirty()
    # Important: the dirty bits won't stick unless we set c.changed here.
    # Do *not* call c.setChanged(True) here: that would be too slow.
    c.changed = True
#@nonl
#@+node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
# Report the number of corrected nodes.
at.correctedLines += 1

found = False
for p in at.perfectImportRoot.self_and_subtree():
    if p.v == at.v:
        found = True ; break

if found:
    if 0: # For debugging.
        g.pr('\n','-' * 40)
        g.pr("old",len(old))
        for line in g.splitLines(old):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
        g.pr("new",len(s))
        for line in g.splitLines(s):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
else:
    # This should never happen.
    g.es("correcting hidden node: v=",repr(at.v),color="red")
#@-node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
#@-node:ekr.20041005105605.96:<< indicate that the node has been changed >>
#@-node:ekr.20041005105605.95:at.readEndNode
#@+node:ekr.20041005105605.81:at.readStartAll
def readStartAll (self,s,i):

    """Read an @+all sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert g.match(s,j,"@+all"),'missing @+all'
    else:
        assert g.match(s,j,"+all"),'missing +all'

    # g.trace('root_seen',at.root_seen,at.root.h,repr(s))
    at.atAllFlag = True

    # Make sure that the generated at-all is properly indented.
    at.out.append(leadingWs + "@all\n")

    at.endSentinelStack.append(at.endAll)
#@-node:ekr.20041005105605.81:at.readStartAll
#@+node:ekr.20060919110638.7:fc.createSaxVnode & helpers
def createSaxVnode (self,sax_node,parent_v,v=None):

    c = self.c
    trace = False and not g.unitTesting and c.shortFileName().find('test') > -1
    verbose = False
    h = sax_node.headString
    b = sax_node.bodyString

    if v:
        # The body of the later node overrides the earlier.
        # Don't set t.h: h is always empty.
        # This may be an internal error.
        if v.b == b:
            if trace and verbose: g.trace(
                '***no update\nold: %s\nnew: %s' % (v.b,b))
        else:
            if trace: g.trace(
                '***update\nold: %s\nnew: %s' % (v.b,b))
            v.b = b 
    else:
        v = leoNodes.vnode(context=c)
        v.setBodyString(b)
        v.setHeadString(h)

        if sax_node.tnx:
            v.fileIndex = g.app.nodeIndices.scanGnx(sax_node.tnx,0)

    index = self.canonicalTnodeIndex(sax_node.tnx)
    self.gnxDict [index] = v

    if trace and verbose: g.trace(
        'tnx','%-22s' % (index),'v',id(v),
        'len(body)','%-4d' % (len(b)),h)

    self.handleVnodeSaxAttributes(sax_node,v)
    self.handleTnodeSaxAttributes(sax_node,v)

    return v
#@+node:ekr.20060919110638.8:handleTnodeSaxAttributes
def handleTnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.tnodeAttributes
    if trace and d: g.trace(sax_node,list(d.keys()))

    aDict = {}
    for key in d:
        val = d.get(key)
        val2 = self.getSaxUa(key,val)
        # g.trace(key,val,val2)
        aDict[key] = val2

    if aDict:
        if trace: g.trace('uA',v,list(aDict.keys()))
        v.unknownAttributes = aDict
#@+node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()

    sax_node = g.bunch(
        tnodeAttributes={
# The 'tx' attribute is handled by contentHandler.tnodeAttributes.
# 'tx':"ekr.20090701133940.1767",
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
})
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleTnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr),attr
        for attr in ('tx','a'):
            assert d.get(attr) is None,attr # A known attribute.
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
#@-node:ekr.20060919110638.8:handleTnodeSaxAttributes
#@+node:ekr.20061004053644:handleVnodeSaxAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded, and descendentTnodeUnknownAttributes.
# New in Leo 4.5: added descendentVnodeUnknownAttributes to native attributes.

def handleVnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.attributes
    # if trace and d: g.trace(d)

    s = d.get('a')
    if s:
        # g.trace('%s a=%s %s' % (id(sax_node),s,v.headString()))
        # 'C' (clone) and 'D' bits are not used.
        if 'M' in s: v.setMarked()
        if 'E' in s: v.expand()
        if 'O' in s: v.setOrphan()
        # if 'T' in s: self.topVnode = v
        if 'V' in s:
            # g.trace('setting currentVnode',v,color='red')
            self.currentVnode = v

    s = d.get('tnodeList','')
    tnodeList = s and s.split(',')
    if tnodeList:
        # This tnodeList will be resolved later.
        if trace: g.trace('found tnodeList',v.headString(),tnodeList)
        v.tempTnodeList = tnodeList

    s = d.get('descendentTnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentTnodeUaDictList',aDict)
            self.descendentTnodeUaDictList.append(aDict)

    s = d.get('descendentVnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentVnodeUaDictList',aDict)
            self.descendentVnodeUaDictList.append((v,aDict),)

    s = d.get('expanded')
    if s:
        aList = self.getDescendentAttributes(s,tag="expanded")
        # g.trace('expanded list',len(aList))
        self.descendentExpandedList.extend(aList)

    s = d.get('marks')
    if s:
        aList = self.getDescendentAttributes(s,tag="marks")
        # g.trace('marks list',len(aList))
        self.descendentMarksList.extend(aList)

    aDict = {}
    for key in d:
        if key in self.nativeVnodeAttributes:
            # This is not a bug.
            if False and trace: g.trace(
                '****ignoring***',key,d.get(key))
        else:
            val = d.get(key)
            val2 = self.getSaxUa(key,val)
            aDict[key] = val2
            # g.trace(key,val,val2)
    if aDict:
        # if trace: g.trace('uA',v,aDict)
        v.unknownAttributes = aDict
#@+node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()
    sax_node = g.bunch(
        attributes={
'a':'M',
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
    })
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleVnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr) is not None,attr
        # The a:M attribute should mark the node.
        assert d.get('a') is None
        assert v.isMarked()
        aList = d.get('icons')
        assert aList
        assert len(aList) == 2
        for d2 in aList:
            for key in ('on','where','yoffset','file'):
                assert d2.get(key) is not None,key
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
#@-node:ekr.20061004053644:handleVnodeSaxAttributes
#@-node:ekr.20060919110638.7:fc.createSaxVnode & helpers
#@+node:ekr.20031218072017.1553:fc.getLeoFile & helpers
# The caller should follow this with a call to c.redraw().

def getLeoFile (self,theFile,fileName,readAtFileNodesFlag=True,silent=False):

    c = self.c
    c.setChanged(False) # May be set when reading @file nodes.
    self.warnOnReadOnlyFiles(fileName)
    self.checking = False
    self.mFileName = c.mFileName
    self.initReadIvars()

    try:
        c.loading = True # disable c.changed
        ok = self.getLeoFileHelper(theFile,fileName,silent)

        # Do this before reading derived files.
        self.resolveTnodeLists()

        if ok and readAtFileNodesFlag:
            # Redraw before reading the @file nodes so the screen isn't blank.
            # This is important for big files like LeoPy.leo.
            c.redraw()
            c.setFileTimeStamp(fileName)
            c.atFileCommands.readAll(c.rootVnode(),partialFlag=False)

        # Do this after reading derived files.
        if readAtFileNodesFlag:
            # The descendent nodes won't exist unless we have read the @thin nodes!
            self.restoreDescendentAttributes()

        self.setPositionsFromVnodes()
        c.selectVnode(c.p) # load body pane
        if c.config.getBool('check_outline_after_read'):
            c.checkOutline(event=None,verbose=True,unittest=False,full=True)
    finally:
        c.loading = False # reenable c.changed

    if c.changed:
        self.propegateDirtyNodes()
    c.setChanged(c.changed) # Refresh the changed marker.
    self.initReadIvars()
    return ok, c.frame.ratio
#@+node:ekr.20090526081836.5841:getLeoFileHelper
def getLeoFileHelper(self,theFile,fileName,silent):

    '''Read the .leo file and create the outline.'''

    c = self.c

    try:
        ok = True
        v = self.readSaxFile(theFile,fileName,silent,inClipboard=False,reassignIndices=False)
        if v: # v is None for minimal .leo files.
            c.setRootVnode(v)
            self.rootVnode = v
        else:
            v = leoNodes.vnode(context=c)
            v.setHeadString('created root node')
            p = leoNodes.position(v)
            p._linkAsRoot(oldRoot=None)
            self.rootVnode = v
            c.setRootPosition(p)
            c.changed = False
    except BadLeoFile:
        junk, message, junk = sys.exc_info()
        if not silent:
            g.es_exception()
            g.alert(self.mFileName + " is not a valid Leo file: " + str(message))
        ok = False

    return ok
#@-node:ekr.20090526081836.5841:getLeoFileHelper
#@+node:ekr.20100124110832.6212:propegateDirtyNodes
def propegateDirtyNodes (self):

    fc = self ; c = fc.c

    aList = [z.copy() for z in c.all_positions() if z.isDirty()]
    for p in aList:
        p.setAllAncestorAtFileNodesDirty()
#@-node:ekr.20100124110832.6212:propegateDirtyNodes
#@+node:ekr.20031218072017.1554:warnOnReadOnlyFiles
def warnOnReadOnlyFiles (self,fileName):

    # os.access may not exist on all platforms.

    try:
        self.read_only = not os.access(fileName,os.W_OK)
    except AttributeError:
        self.read_only = False
    except UnicodeError:
        self.read_only = False

    if self.read_only and not g.unitTesting:
        g.es("read only:",fileName,color="red")
#@+node:ekr.20090526102407.10049:@test g.warnOnReadOnlyFile
if g.unitTesting:

    import os,stat
    c,p = g.getTestVars()
    fc = c.fileCommands

    path = g.os_path_finalize_join(g.app.loadDir,'..','test','test-read-only.txt')
    if os.path.exists(path):
        os.chmod(path, stat.S_IREAD)
        fc.warnOnReadOnlyFiles(path)
        assert fc.read_only
    else:
        fc.warnOnReadOnlyFiles(path)
#@-node:ekr.20090526102407.10049:@test g.warnOnReadOnlyFile
#@-node:ekr.20031218072017.1554:warnOnReadOnlyFiles
#@-node:ekr.20031218072017.1553:fc.getLeoFile & helpers
#@+node:ekr.20090829064400.6040:v.createOutlineFromCacheList & helpers
def createOutlineFromCacheList(self,c,aList,top=True,atAll=None):
    """ Create outline structure from recursive aList
    built by p.makeCacheList.

    Clones will be automatically created by gnx,
    but *not* for the top-level node.
    """

    trace = False and not g.unitTesting
    parent_v = self

    #import pprint ; pprint.pprint(tree)
    parent_v = self
    h,b,gnx,children = aList
    if h is not None:
        v = parent_v
        v._headString = h    
        v._bodyString = b

    if top:
        # Scan the body for @all directives.
        for line in g.splitLines(b):
            if line.startswith('@all'):
                atAll = True ; break
        else:
            atAll = False
    else:
        assert atAll in (True,False,)

    for z in children:
        h,b,gnx,grandChildren = z
        isClone,child_v = parent_v.fastAddLastChild(c,gnx)
        if isClone:
            # The cached file can not have changed,
            # otherwise the file would not be in the cache!?
            if child_v.b != b: # or child_v.h
                if atAll: # Bug fix: the last seen clone rules.
                    if trace: g.trace('***not changed\nold: %s\nnew: %s' % (
                        child_v.b,b))
                else:
                    g.es_print("cached read node changed:",child_v.h,color="red")
                    # g.trace(g.callers(5))
                    child_v.h = h
                    child_v.b = b
                    child_v.setDirty()
                        # 2010/01/24: just mark chid_v dirty.
                        # getLeoFile will call setAllAncestorAtFileNodesDirty.
                    c.changed = True
                        # Tell getLeoFile that it must scan for dirty nodes.
        else:
            child_v.createOutlineFromCacheList(c,z,top=False,atAll=atAll)
#@+node:ekr.20090829064400.6042:v.fastAddLastChild
# Similar to createThinChild4
def fastAddLastChild(self,c,gnxString):
    '''Create new vnode as last child of the receiver.

    If the gnx exists already, create a clone instead of new vnode.
    '''

    trace = False and not g.unitTesting
    verbose = False
    parent_v = self
    indices = g.app.nodeIndices
    gnxDict = c.fileCommands.gnxDict

    if gnxString is None: v = None
    else:                 v = gnxDict.get(gnxString)
    is_clone = v is not None

    if trace: g.trace(
        'clone','%-5s' % (is_clone),
        'parent_v',parent_v,'gnx',gnxString,'v',repr(v))

    if is_clone:
        pass
    else:
        v = vnode(context=c)
        if gnxString:
            gnx = indices.scanGnx(gnxString,0)
            v.fileIndex = gnx
        gnxDict[gnxString] = v

    child_v = v
    child_v._linkAsNthChild(parent_v,parent_v.numberOfChildren())
    child_v.setVisited() # Supress warning/deletion of unvisited nodes.

    return is_clone,child_v
#@-node:ekr.20090829064400.6042:v.fastAddLastChild
#@-node:ekr.20090829064400.6040:v.createOutlineFromCacheList & helpers
#@-node:ekr.20100124110832.6213:changed...
#@-node:ekr.20100122162421.6240:Clones in @all files now have low priority
#@+node:ekr.20100125073206.8711:use g.readFileIntoString

    try:
        s = open(fn,'rb').read()
    except IOError:
        g.es("can not open %s" % (fn),color='red')
#@+node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
def readFileIntoString (fn,encoding='utf-8',kind=None,mode='rb',raw=False):

    '''Return the contents of the file whose full path is fn.

    Return (s,e)
    s is the string, converted to unicode, or None if there was an error.
    e the encoding line for Python files: it is usually None.
    '''

    try:
        e = None
        f = open(fn,mode)
        s = f.read()
        f.close()
        if raw:
            return s,None
        else:
            # Python's encoding comments override everything else.
            if s:
                junk,ext = g.os_path_splitext(fn)
                if ext == '.py':
                    e = g.getPythonEncodingFromString(s)
            s = g.toUnicode(s,encoding=e or encoding)
            return s,e
    except IOError:
        # Translate 'can not open' and kind, but not fn.
        if kind:
            g.es('can not open','',kind,fn,color='red')
        else:
            g.es('can not open',fn,color='red')
    except Exception:
        g.trace('unexpected exception reading %s' % (fn),color='red')
        g.es_exception()

    import leo.core.leoTest as leoTest
    leoTest.fail()
    return None,None
#@-node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
#@+node:ekr.20100125073206.8720:Changed...
#@+node:ekr.20031218072017.3300:removeSentinelsCommand
def removeSentinelsCommand (self,paths,toString=False):

    c = self.c

    self.setEncoding()

    for fileName in paths:
        g.setGlobalOpenDir(fileName)
        path, self.fileName = g.os_path_split(fileName)
        s,e = g.readFileIntoString(fileName,self.encoding)
        if s is None: return
        if e: self.encoding = e
        << set delims from the header line >>
        # g.trace("line: '%s', start: '%s', end: '%s'" % (line_delim,start_delim,end_delim))
        s = self.removeSentinelLines(s,line_delim,start_delim,end_delim)
        ext = c.config.remove_sentinels_extension
        if not ext:
            ext = ".txt"
        if ext[0] == '.':
            newFileName = c.os_path_finalize_join(path,fileName+ext)
        else:
            head,ext2 = g.os_path_splitext(fileName) 
            newFileName = c.os_path_finalize_join(path,head+ext+ext2)
        if toString:
            return s
        else:
            << Write s into newFileName >>
            return None
#@+node:ekr.20031218072017.3302:<< set delims from the header line >>
# Skip any non @+leo lines.
i = 0
while i < len(s) and g.find_on_line(s,i,"@+leo") == -1:
    i = g.skip_line(s,i)

# Get the comment delims from the @+leo sentinel line.
at = self.c.atFileCommands
j = g.skip_line(s,i) ; line = s[i:j]

valid,junk,start_delim,end_delim,junk = at.parseLeoSentinel(line)
if not valid:
    if not toString: g.es("invalid @+leo sentinel in",fileName)
    return

if end_delim:
    line_delim = None
else:
    line_delim,start_delim = start_delim,None
#@-node:ekr.20031218072017.3302:<< set delims from the header line >>
#@+node:ekr.20031218072017.1149:<< Write s into newFileName >>
try:
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    theFile = open(newFileName,mode)
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    theFile.write(s)
    theFile.close()
    if not g.unitTesting:
        g.es("created:",newFileName)
except Exception:
    g.es("exception creating:",newFileName)
    g.es_exception()
#@-node:ekr.20031218072017.1149:<< Write s into newFileName >>
#@-node:ekr.20031218072017.3300:removeSentinelsCommand
#@+node:ekr.20031218072017.3210:createOutline (leoImport)
def createOutline (self,fileName,parent,
    atAuto=False,atShadow=False,s=None,ext=None):

    c = self.c ; u = c.undoer ; s1 = s
    w = c.frame.body
    # New in Leo 4.4.7: honor @path directives.
    self.scanDefaultDirectory(parent) # sets .defaultDirectory.
    fileName = c.os_path_finalize_join(self.default_directory,fileName)
    junk,self.fileName = g.os_path_split(fileName)
    self.methodName,self.fileType = g.os_path_splitext(self.fileName)
    self.setEncoding(p=parent,atAuto=atAuto)
    if not ext: ext = self.fileType
    ext = ext.lower()
    if not s:
        if atShadow: kind = '@shadow '
        elif atAuto: kind = '@auto '
        else: kind = ''
        s,e = g.readFileIntoString(fileName,encoding=self.encoding,kind=kind)
        if s is None: return None
        if e: self.encoding = e

    # Create the top-level headline.
    if atAuto:
        p = parent.copy()
        p.setBodyString('')
    else:
        undoData = u.beforeInsertNode(parent)
        p = parent.insertAsLastChild()

        if self.treeType == "@file":
            p.initHeadString("@file " + fileName)
        else:
            # @root nodes don't have @root in the headline.
            p.initHeadString(fileName)
        u.afterInsertNode(p,'Import',undoData)

    self.rootLine = g.choose(self.treeType=="@file","","@root-code "+self.fileName+'\n')

    if p.isAtAutoRstNode(): # @auto-rst is independent of file extension.
        func = self.scanRstText
    else:
        func = self.importDispatchDict.get(ext)

    if func and not c.config.getBool('suppress_import_parsing',default=False):
        func(s,p,atAuto=atAuto)
    else:
        # Just copy the file to the parent node.
        self.scanUnknownFileType(s,p,ext,atAuto=atAuto)

    if atAuto:
        # Remember that we have read this file.
        # Fixes bug 488894: unsettling dialog when saving Leo file
        # after creating and populating an @auto node.
        # Important: this often sets the bit in the wrong node:
        # The caller may have to set the bit in the "real" root node.
        p.v.at_read = True # Create the attribute

    p.contract()
    w.setInsertPoint(0)
    w.seeInsertPoint()
    return p
#@-node:ekr.20031218072017.3210:createOutline (leoImport)
#@+node:ekr.20091007103358.6061:scanOptions
def scanOptions():

    '''Handle all options and remove them from sys.argv.'''
    trace = False

    # Note: this automatically implements the --help option.
    parser = optparse.OptionParser()
    parser.add_option('-c', '--config', dest="one_config_path")
    parser.add_option('--debug',        action="store_true",dest="debug")
    parser.add_option('-f', '--file',   dest="fileName")
    parser.add_option('--gui',          dest="gui",help = 'gui to use (qt/tk/qttabs)')
    #parser.add_option('--help',         action="store_true",dest="help_option")
    parser.add_option('--ipython',      action="store_true",dest="use_ipython")
    parser.add_option('--no-cache',     action="store_true",dest='no_cache')
    parser.add_option('--silent',       action="store_true",dest="silent")
    parser.add_option('--script',       dest="script")
    parser.add_option('--script-window',dest="script_window")
    parser.add_option('--version',      action="store_true",dest="version")

    # Parse the options, and remove them from sys.argv.
    options, args = parser.parse_args()
    sys.argv = [sys.argv[0]] ; sys.argv.extend(args)
    if trace: print('scanOptions',sys.argv)

    # Handle the args...

    # -c or --config
    path = options.one_config_path
    if path:
        path = g.os_path_finalize_join(os.getcwd(),path)
        if g.os_path_exists(path):
            g.app.oneConfigFilename = path
        else:
            g.es_print('Invalid -c option: file not found:',path,color='red')

    # --debug
    if options.debug:
        g.debug = True
        g.trace('*** debug mode on')

    # -f or --file
    fileName = options.fileName

    # --gui
    gui = options.gui
    g.app.qt_use_tabs = False
    if gui:
        gui = gui.lower()
        if gui == 'qttabs':
            gui = 'qt'
            g.app.qt_use_tabs = True

        if gui not in ('tk','qt','wx'):
            g.trace('unknown gui: %s' % gui)
            gui = None

    # --ipython
    g.app.useIpython = options.use_ipython

    # --no-cache
    if options.no_cache:
        g.trace('disabling caching')
        g.enableDB = False

    # --script
    script_path = options.script
    script_path_w = options.script_window
    if script_path and script_path_w:
        parser.error("--script and script-window are mutually exclusive")

    script_name = script_path or script_path_w
    if script_name:
        script_name = g.os_path_finalize_join(g.app.loadDir,script_name)
        script,e = g.readFileIntoString(script_name,kind='script:')
    else:
        script = None
        # if trace: print('scanOptions: no script')

    # --silent
    g.app.silentMode = options.silent
    # g.trace('silentMode',g.app.silentMode)

    # --version: print the version and exit.
    versionFlag = options.version

    # Compute the return values.
    windowFlag = script and script_path_w
    if trace:
        print('scanOptions: fileName',fileName)
        print('scanOptions: argv',sys.argv)
    return fileName,gui,script,versionFlag,windowFlag
#@-node:ekr.20091007103358.6061:scanOptions
#@+node:ekr.20090212054250.9:c.createNodeFromExternalFile
def createNodeFromExternalFile(self,fn):

    '''Read the file into a node.
    Return None, indicating that c.open should set focus.'''

    c = self

    s,e = g.readFileIntoString(fn)
    if s is None: return
    head,ext = g.os_path_splitext(fn)
    if ext.startswith('.'): ext = ext[1:]
    language = g.app.extension_dict.get(ext)
    if language:
        prefix = '@color\n@language %s\n\n' % language
    else:
        prefix = '@killcolor\n\n'
    p2 = c.insertHeadline(op_name='Open File', as_child=False)
    p2.h = '@edit %s' % fn # g.shortFileName(fn)
    p2.b = prefix + s
    w = c.frame.body.bodyCtrl
    if w: w.setInsertPoint(0)
    c.redraw()
    c.recolor()
#@nonl
#@-node:ekr.20090212054250.9:c.createNodeFromExternalFile
#@+node:ekr.20070915134101:readFileIntoNode
def readFileIntoNode (self,event=None):

    '''Read a file into a single node.'''

    c = self ; undoType = 'Read File Into Node'
    c.endEditing()

    filetypes = [("All files", "*"),("Python files","*.py"),("Leo files", "*.leo"),]
    fileName = g.app.gui.runOpenFileDialog(
        title="Read File Into Node",filetypes=filetypes,defaultextension=None)
    if not fileName:return
    s,e = g.readFileIntoString(fileName)
    if s is None: return

    g.chdir(fileName)
    s = '@nocolor\n' + s
    w = c.frame.body.bodyCtrl
    p = c.insertHeadline(op_name=undoType)
    p.setHeadString('@read-file-into-node ' + fileName)
    p.setBodyString(s)
    w.setAllText(s)
    c.redraw(p)
#@-node:ekr.20070915134101:readFileIntoNode
#@+node:ekr.20050920084036.166:getReadableTextFile
def getReadableTextFile (self):

    fn = g.app.gui.runOpenFileDialog(
        title = 'Open Text File',
        filetypes = [("Text","*.txt"), ("All files","*")],
        defaultextension = ".txt")

    return fn
#@-node:ekr.20050920084036.166:getReadableTextFile
#@+node:ekr.20050920084036.167:insertFile
def insertFile (self,event):

    '''Prompt for the name of a file and put the selected text into it.'''

    k = self.k ; c = k.c ; w = self.editWidget(event)
    if not w: return

    fn = self.getReadableTextFile()
    if not fn: return

    s,e = g.readFileIntoString(fn)
    if s is None: return

    self.beginCommand(undoType='insert-file')
    i = w.getInsertPoint()
    w.insert(i,s)
    w.seeInsertPoint()
    self.endCommand(changed=True,setLabel=True)
#@-node:ekr.20050920084036.167:insertFile
#@+node:ekr.20050920084036.165:diff (revise)
def diff (self,event):

    '''Creates a node and puts the diff between 2 files into it.'''

    k = self.k
    w = self.editWidget(event)
    if not w: return
    fn = self.getReadableTextFile()
    if not fn: return
    fn2 = self.getReadableTextFile()
    if not fn2: return
    s1,e = g.readFileIntoString(fn)
    if s1 is None: return
    s2,e = g.readFileIntoString(fn2)
    if s2 is None: return

    ### self.switchToBuffer(event,"*diff* of ( %s , %s )" % (name,name2))
    data = difflib.ndiff(s1,s2)
    idata = []
    for z in data:
        idata.append(z)
    w.delete(0,'end')
    w.insert(0,''.join(idata))
#@-node:ekr.20050920084036.165:diff (revise)
#@+node:ekr.20080921154026.1:g.openWrapperLeoFile
def openWrapperLeoFile (old_c,fileName,gui):

    '''Open a wrapper .leo file for the given file,
    and import the file into .leo file.'''

    # This code is similar to c.new, but different enough to be separate.
    if not g.os_path_exists(fileName):
        if not g.unitTesting:
            g.es_print("can not open:",fileName,color="blue")
        return None

    c,frame = g.app.newLeoCommanderAndFrame(
        fileName=None,relativeFileName=None,gui=gui)

    # Needed for plugins.
    if 0: # This causes duplicate common buttons.
        g.doHook("new",old_c=old_c,c=c,new_c=c)

    # Use the config params to set the size and location of the window.
    frame.setInitialWindowGeometry()
    frame.deiconify()
    frame.lift()
    frame.resizePanesToRatio(frame.ratio,frame.secondary_ratio) # Resize the _new_ frame.

    if True: # Just read the file into the node.
        fileName = g.os_path_finalize(fileName)
        s,e = g.readFileIntoString(fileName)
        if s is None: return None
        p = c.rootPosition()
        if p:
            p.setHeadString('@edit %s' % fileName)
            p.setBodyString(s)
            c.selectPosition(p)
    else:  # Import the file into the new outline.
        junk,ext = g.os_path_splitext(fileName)
        p = c.p
        p = c.importCommands.createOutline(fileName,parent=p,atAuto=False,ext=ext)
        c.setCurrentPosition(p)
        c.moveOutlineLeft()
        p = c.p
        c.setCurrentPosition(p.back())
        c.deleteOutline(op_name=None)
        p = c.p
        p.expand()

    # chapterController.finishCreate must be called after the first real redraw
    # because it requires a valid value for c.rootPosition().
    if c.config.getBool('use_chapters') and c.chapterController:
        c.chapterController.finishCreate()

    frame.c.setChanged(True) # Mark the outline dirty.
    return c
#@-node:ekr.20080921154026.1:g.openWrapperLeoFile
#@+node:ekr.20080713091247.1:x.replaceFileWithString & test
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    trace = False and not g.unitTesting
    x = self
    exists = g.os_path_exists(fn)

    if exists:
        # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s2 is None:
            return False
        if s == s2:
            if not g.unitTesting: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            x.error('not written: %s directory not found' % fn)
        return False

    # Replace the file.
    try:
        f = open(fn,'wb')
        f.write(g.toEncodedString(s,encoding='utf-8'))
        if trace: g.trace('fn',fn,
            '\nlines...\n%s' %(g.listToString(g.splitLines(s))),
            '\ncallers',g.callers(4))
        f.close()
        if not g.unitTesting:
            # g.trace('created:',fn,g.callers())
            if exists:  g.es('wrote:',fn)
            else:       g.es('created:',fn)
        return True
    except IOError:
        x.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20090530055015.6862:@test x.replaceFileWithString
if g.unitTesting:

    c,p = g.getTestVars()
    x = c.shadowController

    fn = 'does/not/exist'
    assert not g.os_path_exists(fn)
    assert not x.replaceFileWithString (fn,'abc')
#@-node:ekr.20090530055015.6862:@test x.replaceFileWithString
#@-node:ekr.20080713091247.1:x.replaceFileWithString & test
#@+node:ekr.20031218072017.3481:untangleRoot (calls cleanup)
@ This method untangles the derived files in a vnode known to contain at least one @root directive. The work is done in two passes. The first pass creates the UST by scanning the derived file. The second pass updates the outline using the UST and a TST that is created during the pass.

We assume that all sections from root to end are contained in the derived file, and we attempt to update all such sections. The begin/end params indicate the range of nodes to be scanned when building the TST.
@c

def untangleRoot(self,root,begin,end):

    # g.trace("root,begin,end:",root,begin,end)
    c = self.c
    << Set path & root_name to the file specified in the @root directive >>
    << return if @silent or unknown language >>
    path = c.os_path_finalize_join(self.tangle_directory,path)
    file_buf,e = g.readFileIntoString(path)
    if file_buf is None:
        self.cleanup()
        return
    else:
        file_buf = file_buf.replace('\r','')

    g.es('','@root ' + path)
    # Pass 1: Scan the C file, creating the UST
    self.scan_derived_file(file_buf)
    # g.trace(self.ust_dump())
    if self.errors + g.app.scanErrors == 0:
        << Pass 2: Untangle the outline using the UST and a newly-created TST >>
    self.cleanup()
#@+node:ekr.20031218072017.3483:<< Set path & root_name to the file specified in the @root directive >>
s = root.b
i = 0
while i < len(s):
    code, junk = self.token_type(s,i,report_errors=True)
    if code == at_root:
        # token_type sets root_name unless there is a syntax error.
        if self.root_name: path = self.root_name
        break
    else: i = g.skip_line(s,i)

if not self.root_name:
    # A bad @root command.  token_type has already given an error.
    self.cleanup()
    return
#@-node:ekr.20031218072017.3483:<< Set path & root_name to the file specified in the @root directive >>
#@+node:ekr.20031218072017.3482:<< return if @silent or unknown language >>
if self.language == "unknown":
    g.es("@comment disables untangle for",path, color="blue")
    return

if self.print_mode in ("quiet","silent"):
    g.es('','@%s' % (self.print_mode),"inhibits untangle for",path, color="blue")
    return
#@-node:ekr.20031218072017.3482:<< return if @silent or unknown language >>
#@+node:ekr.20031218072017.3485:<< Pass 2:  Untangle the outline using the UST and a newly-created TST >>
@
This code untangles the root and all its siblings. We don't call tangleTree here
because we must handle all siblings. tanglePass1 handles an entire tree. It also
handles @ignore.
@c

p = begin
while p and p != end: # Don't use iterator.
    self.tanglePass1(p)
    if self.errors + g.app.scanErrors != 0:
        break
    p.moveToNodeAfterTree()

self.ust_warn_about_orphans()
#@-node:ekr.20031218072017.3485:<< Pass 2:  Untangle the outline using the UST and a newly-created TST >>
#@-node:ekr.20031218072017.3481:untangleRoot (calls cleanup)
#@+node:ekr.20031218072017.3220:importFlattenedOutline
def importFlattenedOutline (self,files): # Not a command, so no event arg.

    c = self.c ; u = c.undoer ; current = c.p
    if current == None: return
    if len(files) < 1: return

    self.setEncoding()
    fileName = files[0] # files contains at most one file.
    g.setGlobalOpenDir(fileName)
    s,e = g.readFileIntoString(fileName)
    if s is None: return
    array = s.split("\n")

    # Convert the string to an outline and insert it after the current node.
    undoData = u.beforeInsertNode(current)
    p = self.convertMoreStringsToOutlineAfter(array,current)
    if p:
        c.endEditing()
        c.validateOutline()
        c.redrawAndEdit(p)
        p.setDirty()
        c.setChanged(True)
        u.afterInsertNode(p,'Import',undoData)
    else:
        g.es("not a valid MORE file",fileName)
#@-node:ekr.20031218072017.3220:importFlattenedOutline
#@+node:ekr.20031218072017.3231:scanWebFile (handles limbo)
def scanWebFile (self,fileName,parent):

    theType = self.webType
    lb = g.choose(theType=="cweb","@<","<<")
    rb = g.choose(theType=="cweb","@>",">>")

    s,e = g.readFileIntoString(fileName)
    if s is None: return

    << Create a symbol table of all section names >>
    << Create nodes for limbo text and the root section >>
    while i < len(s):
        outer_progress = i
        << Create a node for the next module >>
        assert(i > outer_progress)
#@+node:ekr.20031218072017.3232:<< Create a symbol table of all section names >>
i = 0 ; self.web_st = []

while i < len(s):
    progress = i
    i = g.skip_ws_and_nl(s,i)
    # line = g.get_line(s,i) ; g.trace(line)
    if self.isDocStart(s,i):
        if theType == "cweb": i += 2
        else: i = g.skip_line(s,i)
    elif theType == "cweb" and g.match(s,i,"@@"):
        i += 2
    elif g.match(s,i,lb):
        i += 2 ; j = i ; k = g.find_on_line(s,j,rb)
        if k > -1: self.cstEnter(s[j:k])
    else: i += 1
    assert (i > progress)

# g.trace(self.cstDump())
#@-node:ekr.20031218072017.3232:<< Create a symbol table of all section names >>
#@+node:ekr.20031218072017.3233:<< Create nodes for limbo text and the root section >>
i = 0
while i < len(s):
    progress = i
    i = g.skip_ws_and_nl(s,i)
    if self.isModuleStart(s,i) or g.match(s,i,lb):
        break
    else: i = g.skip_line(s,i)
    assert(i > progress)

j = g.skip_ws(s,0)
if j < i:
    self.createHeadline(parent,"@ " + s[j:i],"Limbo")

j = i
if g.match(s,i,lb):
    while i < len(s):
        progress = i
        i = g.skip_ws_and_nl(s,i)
        if self.isModuleStart(s,i):
            break
        else: i = g.skip_line(s,i)
        assert(i > progress)
    self.createHeadline(parent,s[j:i],g.angleBrackets(" @ "))

# g.trace(g.get_line(s,i))
#@-node:ekr.20031218072017.3233:<< Create nodes for limbo text and the root section >>
#@+node:ekr.20031218072017.3234:<< Create a node for the next module >>
if theType=="cweb":
    assert(self.isModuleStart(s,i))
    start = i
    if self.isDocStart(s,i):
        i += 2
        while i < len(s):
            progress = i
            i = g.skip_ws_and_nl(s,i)
            if self.isModuleStart(s,i): break
            else: i = g.skip_line(s,i)
            assert (i > progress)
    << Handle cweb @d, @f, @c and @p directives >>
else:
    assert(self.isDocStart(s,i)) # isModuleStart == isDocStart for noweb.
    start = i ; i = g.skip_line(s,i)
    while i < len(s):
        progress = i
        i = g.skip_ws_and_nl(s,i)
        if self.isDocStart(s,i): break
        else: i = g.skip_line(s,i)
        assert (i > progress)

body = s[start:i]
body = self.massageWebBody(body)
headline = self.scanBodyForHeadline(body)
self.createHeadline(parent,body,headline)
#@+node:ekr.20031218072017.3235:<< Handle cweb @d, @f, @c and @p directives >>
if g.match(s,i,"@d") or g.match(s,i,"@f"):
    i += 2 ; i = g.skip_line(s,i)
    # Place all @d and @f directives in the same node.
    while i < len(s):
        progress = i
        i = g.skip_ws_and_nl(s,i)
        if g.match(s,i,"@d") or g.match(s,i,"@f"): i = g.skip_line(s,i)
        else: break
        assert (i > progress)
    i = g.skip_ws_and_nl(s,i)

while i < len(s) and not self.isModuleStart(s,i):
    progress = i
    i = g.skip_line(s,i)
    i = g.skip_ws_and_nl(s,i)
    assert (i > progress)

if g.match(s,i,"@c") or g.match(s,i,"@p"):
    i += 2
    while i < len(s):
        progress = i
        i = g.skip_line(s,i)
        i = g.skip_ws_and_nl(s,i)
        if self.isModuleStart(s,i):
            break
        assert (i > progress)
#@-node:ekr.20031218072017.3235:<< Handle cweb @d, @f, @c and @p directives >>
#@-node:ekr.20031218072017.3234:<< Create a node for the next module >>
#@-node:ekr.20031218072017.3231:scanWebFile (handles limbo)
#@+node:ekr.20070919133659:checkDerivedFile (atFile)
def checkDerivedFile (self, event=None):

    at = self ; c = at.c ; p = c.p

    if not p.isAtFileNode() and not p.isAtThinFileNode():
        return g.es('Please select an @thin or @file node',color='red')

    fn = p.anyAtFileNodeName()
    path = g.os_path_dirname(c.mFileName)
    fn = g.os_path_finalize_join(g.app.loadDir,path,fn)
    if not g.os_path_exists(fn):
        return g.es_print('file not found: %s' % (fn),color='red')

    s,e = g.readFileIntoString(fn)
    if s is None: return

    # Create a dummy, unconnected, vnode as the root.
    root_v = leoNodes.vnode(context=c)
    root = leoNodes.position(root_v)
    theFile = g.fileLikeObject(fromString=s)
    # 2010/01/22: readOpenFiles now determines whether a file is thin or not.
    at.initReadIvars(root,fn)
    if at.errors: return
    at.openFileForReading(fromString=s)
    if not at.inputFile: return
    at.readOpenFile(root,at.inputFile,fn)
    at.inputFile.close()
    if at.errors == 0:
        g.es_print('check-derived-file passed',color='blue')
#@-node:ekr.20070919133659:checkDerivedFile (atFile)
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20070909100252:readOneAtAutoNode (atFile)
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None:
        cachefile = None
    else:
        cachefile = self._contentHashFile(p.h,s)

    # Remember that we have read this file.
    p.v.at_read = True # Create the attribute

    # Disable caching for test.leo.
    if c.shortFileName() != 'test.leo':
        if cachefile is not None and cachefile in c.db:        
            # g.es('uncache:',p.h)
            aList = c.db[cachefile]
            p.v.createOutlineFromCacheList(c,aList)
            return

    if not g.unitTesting:
        g.es("reading:",p.h)

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        # Note: the file contains an @ignore,
        # so no unintended write can happen.
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        self.writeCachedTree(p, cachefile)
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@-node:ekr.20070909100252:readOneAtAutoNode (atFile)
#@+node:ekr.20090225080846.3:readOneAtEditNode (atFile)
def readOneAtEditNode (self,fn,p):

    at = self ; c = at.c ; ic = c.importCommands
    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fn = c.os_path_finalize_join(at.default_directory,fn)
    junk,ext = g.os_path_splitext(fn)

    if not g.unitTesting:
        g.es("reading @edit:", g.shortFileName(fn))

    s,e = g.readFileIntoString(fn,kind='@edit')
    if s is None: return
    encoding = g.choose(e is None,'utf-8',e)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    changed = c.isChanged()
    head = ''
    ext = ext.lower()
    if ext in ('.html','.htm'):   head = '@language html\n'
    elif ext in ('.txt','.text'): head = '@nocolor\n'
    else:
        language = ic.languageForExtension(ext)
        if language and language != 'unknown_language':
            head = '@language %s\n' % language
        else:
            head = '@nocolor\n'

    p.b = g.u(head) + g.toUnicode(s,encoding=encoding,reportErrors='True')

    if not changed: c.setChanged(False)
    g.doHook('after-edit',p=p)
#@-node:ekr.20090225080846.3:readOneAtEditNode (atFile)
#@+node:ekr.20090514111518.5661:checkPythonCode (leoAtFile) & helpers
def checkPythonCode (self,root,s=None,targetFn=None):

    c = self.c

    if not targetFn: targetFn = self.targetFileName

    if targetFn and targetFn.endswith('.py') and self.checkPythonCodeOnWrite:

        if not s:
            s,e = g.readFileIntoString(self.outputFileName)
            if s is None: return

        # It's too slow to check each node separately.
        ok = self.checkPythonSyntax(root,s)

        # Syntax checking catches most indentation problems.
        if False and ok: self.tabNannyNode(root,s)
#@+node:ekr.20090514111518.5663:checkPythonSyntax (leoAtFile)
def checkPythonSyntax (self,p,body):

    try:
        ok = True
        if g.isPython3:
            code.compile_command(body + '\n')
        else:
            compiler.parse(body + '\n')
    except (parser.ParserError,SyntaxError):
        self.syntaxError(p,body)
        ok = False
    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
        ok = False

    return ok
#@+node:ekr.20090514111518.5666:syntaxError & test
def syntaxError(self,p,body):

    g.es_print("Syntax error in: %s" % (p.h),color="red")
    typ,val,tb = sys.exc_info()
    message = hasattr(val,'message') and val.message
    if message: g.es_print(message)
    lines = g.splitLines(body)
    n = val.lineno
    if n is None:
        # for z in dir(val): print z,repr(getattr(val,z))
        return
    i = val.lineno-1
    for j in range(max(0,i-3),min(i+3,len(lines)-1)):
        g.es_print('%5s:%s %s' % (
            j,g.choose(j==i,'*',' '),lines[j].rstrip()))
        if j == i:
            g.es_print(' '*(7+val.offset)+'^')
#@nonl
#@+node:ekr.20090620121836.6073:syntaxErrorTest
def syntaxErrorTest():

    '''Used to test Leo's handling of the following syntax error'''

    # xxx(c=None,'whatever')
#@nonl
#@-node:ekr.20090620121836.6073:syntaxErrorTest
#@-node:ekr.20090514111518.5666:syntaxError & test
#@-node:ekr.20090514111518.5663:checkPythonSyntax (leoAtFile)
#@+node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
def tabNannyNode (self,p,body):

    import parser,tabnanny,tokenize

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))
    except parser.ParserError:
        junk, msg, junk = sys.exc_info()
        g.es("ParserError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        g.es("TokenError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        badline = nag.get_lineno()
        line    = nag.get_line()
        message = nag.get_msg()
        g.es("indentation error in",p.h,"line",badline,color="red")
        g.es(message)
        line2 = repr(str(line))[1:-1]
        g.es("offending line:\n",line2)
        # p.setMarked()
    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
#@nonl
#@-node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
#@-node:ekr.20090514111518.5661:checkPythonCode (leoAtFile) & helpers
#@+node:ekr.20080712150045.1:replaceFileWithString (atFile)
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    at = self ; testing = g.app.unitTesting

    # g.trace('fn',fn,'s','\n',s)
    # g.trace(g.callers())

    exists = g.os_path_exists(fn)

    if exists: # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s is None:
            return False
        if s == s2:
            if not testing: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            g.es('not written: %s directory not found' % fn,color='red')
        return False

    # Replace
    try:
        f = open(fn,'wb')
        if g.isPython3:
            s = g.toEncodedString(s,encoding=self.encoding)
        f.write(s)
        f.close()
        if not testing:
            if exists:
                g.es('wrote:    ',fn)
            else:
                # g.trace('created:',fn,g.callers())
                g.es('created:',fn)
        return True
    except IOError:
        at.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20090530055015.6873:@test at.replaceFileWithString
if g.unitTesting:

    c,p = g.getTestVars()
    at = c.atFileCommands

    fn = 'does/not/exist'
    assert not g.os_path_exists(fn)
    assert not at.replaceFileWithString (fn,'abc')
#@-node:ekr.20090530055015.6873:@test at.replaceFileWithString
#@-node:ekr.20080712150045.1:replaceFileWithString (atFile)
#@-node:ekr.20100125073206.8720:Changed...
#@-node:ekr.20100125073206.8711:use g.readFileIntoString
#@+node:ekr.20100125143136.6235:Fixed unicode failures without sys.setdefaultencoding('utf-8')
#@+node:ekr.20031218072017.1498:Unicode utils...
#@+node:ekr.20100125073206.8709:g.getPythonEncodingFromString
def getPythonEncodingFromString(s):

    '''Return the encoding given by Python's encoding line.
    s is the entire file.
    '''

    encoding = None
    tag,tag2 = '# -*- coding:','-*-'
    n1,n2 = len(tag),len(tag2)

    if s:
        # For Python 3.x we must convert to unicode before calling startswith.
        # The encoding doesn't matter: we only look at the first line, and if
        # the first line is an encoding line, it will contain only ascii characters.
        s = g.toUnicode(s,encoding='ascii',reportErrors=False)
        lines = g.splitLines(s)
        line1 = lines[0].strip()
        if line1.startswith(tag) and line1.endswith(tag2):
            e = line1[n1:-n2].strip()
            if e and g.isValidEncoding(e):
                encoding = e

    return encoding
#@-node:ekr.20100125073206.8709:g.getPythonEncodingFromString
#@+node:ekr.20080816125725.2:g.isBytes, isChar, isString & isUnicode
# The syntax of these functions must be valid on Python2K and Python3K.

def isBytes(s):
    '''Return True if s is Python3k bytes type.'''
    if g.isPython3:
        # Generates a pylint warning, but that can't be helped.
        return type(s) == type(bytes('a','utf-8'))
    else:
        return False

def isChar(s):
    '''Return True if s is a Python2K character type.'''
    if g.isPython3:
        return False
    else:
        return type(s) == types.StringType

def isString(s):
    '''Return True if s is any string, but not bytes.'''
    if g.isPython3:
        return type(s) == type('a')
    else:
        return type(s) in types.StringTypes

def isUnicode(s):
    '''Return True if s is a unicode string.'''
    if g.isPython3:
        return type(s) == type('a')
    else:
        return type(s) == types.UnicodeType
#@-node:ekr.20080816125725.2:g.isBytes, isChar, isString & isUnicode
#@+node:ekr.20031218072017.1500:g.isValidEncoding
def isValidEncoding (encoding):

    if not encoding:
        return False

    if sys.platform == 'cli':
        return True

    import codecs

    try:
        codecs.lookup(encoding)
        return True
    except LookupError: # Windows.
        return False
    except AttributeError: # Linux.
        return False
#@nonl
#@-node:ekr.20031218072017.1500:g.isValidEncoding
#@+node:ekr.20061006152327:g.isWordChar & g.isWordChar1
def isWordChar (ch):

    '''Return True if ch should be considered a letter.'''

    return ch and (ch.isalnum() or ch == '_')

def isWordChar1 (ch):

    return ch and (ch.isalpha() or ch == '_')
#@nonl
#@-node:ekr.20061006152327:g.isWordChar & g.isWordChar1
#@+node:ekr.20031218072017.1501:g.reportBadChars
def reportBadChars (s,encoding):

    if g.isPython3:
        errors = 0
        if g.isUnicode(s):
            for ch in s:
                try: ch.encode(encoding,"strict")
                except UnicodeEncodeError:
                    errors += 1
            if errors:
                s2 = "%d errors converting %s to %s" % (
                    errors, s.encode(encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
        elif g.isChar(s):
            for ch in s:
                try: unicode(ch,encoding,"strict")
                except Exception: errors += 1
            if errors:
                s2 = "%d errors converting %s (%s encoding) to unicode" % (
                    errors, unicode(s,encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
    else:
        errors = 0
        if g.isUnicode(s):
            for ch in s:
                try: ch.encode(encoding,"strict")
                except UnicodeEncodeError:
                    errors += 1
            if errors:
                s2 = "%d errors converting %s to %s" % (
                    errors, s.encode(encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
        elif g.isChar(s):
            for ch in s:
                try: unicode(ch,encoding,"strict")
                except Exception: errors += 1
            if errors:
                s2 = "%d errors converting %s (%s encoding) to unicode" % (
                    errors, unicode(s,encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
#@-node:ekr.20031218072017.1501:g.reportBadChars
#@+node:ekr.20050208093800:g.toEncodedString
def toEncodedString (s,encoding=None,reportErrors=False):

    if encoding is None:
        encoding = g.app.defaultEncoding

    if g.isUnicode(s):
        try:
            s = s.encode(encoding,"strict")
        except UnicodeError:
            if reportErrors: g.reportBadChars(s,encoding)
            s = s.encode(encoding,"replace")
    return s
#@-node:ekr.20050208093800:g.toEncodedString
#@+node:ekr.20050208093800.1:g.toUnicode
def toUnicode (s,encoding=None,reportErrors=False):

    # The encoding is usually g.app.defaultEncoding,
    # but is may be different while importing or reading files.
    if encoding is None:
        encoding = g.app.defaultEncoding

    if isPython3:
        f,mustConvert = str,g.isBytes
    else:
        f = unicode
        def mustConvert (s):
            return type(s) != types.UnicodeType

    if not s:
        s = g.u('')
    elif mustConvert(s):
        try:
            s = f(s,encoding,'strict')
        except (UnicodeError,Exception):
            s = f(s,encoding,'replace')
            if reportErrors: g.reportBadChars(s,encoding)
    else:
        pass

    return s
#@-node:ekr.20050208093800.1:g.toUnicode
#@+node:ekr.20091206161352.6232:g.u & g.ue
if isPython3: # g.not defined yet.
    def u(s):
        return s
    def ue(s,encoding):
        return str(s,encoding)
else:
    def u(s):
        return unicode(s)
    def ue(s,encoding):
        return unicode(s,encoding)
#@-node:ekr.20091206161352.6232:g.u & g.ue
#@+node:ekr.20080919065433.2:toEncodedStringWithErrorCode (for unit testing)
def toEncodedStringWithErrorCode (s,encoding,reportErrors=False):

    ok = True

    if g.isUnicode(s):
        try:
            s = s.encode(encoding,"strict")
        except Exception:
            if reportErrors: g.reportBadChars(s,encoding)
            s = s.encode(encoding,"replace")
            ok = False
    return s, ok
#@-node:ekr.20080919065433.2:toEncodedStringWithErrorCode (for unit testing)
#@+node:ekr.20080919065433.1:toUnicodeWithErrorCode (for unit testing)
def toUnicodeWithErrorCode (s,encoding,reportErrors=False):

    ok = True
    if g.isPython3: f = str
    else: f = unicode
    if s is None:
        s = g.u('')
    if not g.isUnicode(s):
        try:
            s = f(s,encoding,'strict')
        except Exception:
            if reportErrors:
                g.reportBadChars(s,encoding)
            s = f(s,encoding,'replace')
            ok = False
    return s,ok
#@-node:ekr.20080919065433.1:toUnicodeWithErrorCode (for unit testing)
#@-node:ekr.20031218072017.1498:Unicode utils...
#@+node:ville.20090606150238.6351:_contentHashFile (atFile)
def _contentHashFile(self,s,content):

    '''Compute the hash of s (usually a headline) and content.
    s may be unicode, content must be bytes (or plain string in Python 2.x'''

    m = hashlib.md5()

    if g.isUnicode(s):
        s = g.toEncodedString(s)

    if g.isUnicode(content):
        g.internalError('content arg must be str/bytes')
        content = g.toEncodedString(content)

    m.update(s)
    m.update(content)
    return "fcache/" + m.hexdigest()

#@-node:ville.20090606150238.6351:_contentHashFile (atFile)
#@-node:ekr.20100125143136.6235:Fixed unicode failures without sys.setdefaultencoding('utf-8')
#@+node:ekr.20100125190708.6259:Fixed Leo3k problem with g.getPythonEncodingFromString
- g.getPythonEncodingFromString fails with Python 3.x on both Windows and ubuntu.
#@nonl
#@+node:ekr.20100125073206.8709:g.getPythonEncodingFromString
def getPythonEncodingFromString(s):

    '''Return the encoding given by Python's encoding line.
    s is the entire file.
    '''

    encoding = None
    tag,tag2 = '# -*- coding:','-*-'
    n1,n2 = len(tag),len(tag2)

    if s:
        # For Python 3.x we must convert to unicode before calling startswith.
        # The encoding doesn't matter: we only look at the first line, and if
        # the first line is an encoding line, it will contain only ascii characters.
        s = g.toUnicode(s,encoding='ascii',reportErrors=False)
        lines = g.splitLines(s)
        line1 = lines[0].strip()
        if line1.startswith(tag) and line1.endswith(tag2):
            e = line1[n1:-n2].strip()
            if e and g.isValidEncoding(e):
                encoding = e

    return encoding
#@-node:ekr.20100125073206.8709:g.getPythonEncodingFromString
#@-node:ekr.20100125190708.6259:Fixed Leo3k problem with g.getPythonEncodingFromString
#@+node:ekr.20100126062623.6237:Ensure the contents arg to _contentHashFile is bytes
#@+node:ekr.20100126062623.6240:g.internalError
def internalError (*args):

    callers = g.callers(5).split(',')
    caller = callers[-1]
    g.es_print('Internal Leo error in',caller,color='red')
    g.es_print(*args)
    g.es_print('Called from',','.join(callers[:-1]))
#@-node:ekr.20100126062623.6240:g.internalError
#@+node:ville.20090606150238.6351:_contentHashFile (atFile)
def _contentHashFile(self,s,content):

    '''Compute the hash of s (usually a headline) and content.
    s may be unicode, content must be bytes (or plain string in Python 2.x'''

    m = hashlib.md5()

    if g.isUnicode(s):
        s = g.toEncodedString(s)

    if g.isUnicode(content):
        g.internalError('content arg must be str/bytes')
        content = g.toEncodedString(content)

    m.update(s)
    m.update(content)
    return "fcache/" + m.hexdigest()

#@-node:ville.20090606150238.6351:_contentHashFile (atFile)
#@-node:ekr.20100126062623.6237:Ensure the contents arg to _contentHashFile is bytes
#@+node:ekr.20100126110826.6254:Removed unit test message
Check your configuration of script_file_path.
#@nonl
#@+node:ekr.20070115135502:writeScriptFile
def writeScriptFile (self,script):

    # Get the path to the file.
    c = self
    path = c.config.getString('script_file_path')
    if path:
        isAbsPath = os.path.isabs(path)
        driveSpec, path = os.path.splitdrive(path)
        parts = path.split('/')
        # xxx bad idea, loadDir is often read only!
        path = g.app.loadDir
        if isAbsPath:
            # make the first element absolute
            parts[0] = driveSpec + os.sep + parts[0]
        allParts = [path] + parts
        path = c.os_path_finalize_join(*allParts)
    else:
        path = c.os_path_finalize_join(
            g.app.homeLeoDir,'scriptFile.py')                    

    # Write the file.
    try:
        if g.isPython3:
            # Use the default encoding.
            f = open(path,encoding='utf-8',mode='w')
        else:
            f = open(path,'w')
        f.write(script)
        f.close()
    except Exception:
        g.es_exception()
        g.es("Failed to write script to %s" % path)
        # g.es("Check your configuration of script_file_path, currently %s" %
            # c.config.getString('script_file_path'))
        path = None

    return path
#@nonl
#@-node:ekr.20070115135502:writeScriptFile
#@-node:ekr.20100126110826.6254:Removed unit test message
#@+node:ekr.20100124142131.6222:Preserve expansion state of present node on startup
@nocolor-node

After much tracing, we see the bug was in selectChapterByNameHelper.
We must compare the vnodes, not the positions!
#@nonl
#@+node:ekr.20090306060344.2:selectChapterHelper
def selectChapterByNameHelper (self,chapter,collapse=True):

    cc = self ; c = cc.c

    if chapter != cc.selectedChapter:
        if cc.selectedChapter:
            cc.selectedChapter.unselect()
        chapter.select()
        c.setCurrentPosition(chapter.p)
        cc.selectedChapter = chapter

        # New in Leo 4.6 b2: clean up, but not initially.
        if collapse and chapter.name == 'main':
            for p in c.all_unique_positions():
                # 2010/01/26: compare vnodes, not positions.
                if p.v != c.p.v:
                    p.contract()

        # New in Leo 4.6 b2: *do* call c.redraw.
        c.redraw()
#@-node:ekr.20090306060344.2:selectChapterHelper
#@-node:ekr.20100124142131.6222:Preserve expansion state of present node on startup
#@+node:ekr.20100122104234.6167:cache current position
@nocolor-node

We write the archived position to the cache instead of root.v.uA.

This reduces false bzr diffs.
#@nonl
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20060919110638.13:setPositionsFromVnodes & helper
def setPositionsFromVnodes (self):

    trace = False and not g.unitTesting
    c = self.c ; p = c.rootPosition()
    current,str_pos = None,None
    use_db = g.enableDB and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        str_pos = c.db.get('current_position_%s' % key)
        if trace: g.trace('from c.db',str_pos,key)

    if not str_pos:
        d = hasattr(p.v,'unknownAttributes') and p.v.unknownAttributes
        if d: str_pos = d.get('str_leo_pos')
        if trace: g.trace('from p.v.u',str_pos)

    if str_pos:
        current = self.archivedPositionToPosition(str_pos)

    c.setCurrentPosition(current or c.rootPosition())
#@+node:ekr.20061006104837.1:archivedPositionToPosition
def archivedPositionToPosition (self,s):

    c = self.c
    aList = s.split(',')
    try:
        aList = [int(z) for z in aList]
    except Exception:
        # g.trace('oops: bad archived position. not an int:',aList,c)
        aList = None
    if not aList: return None
    p = c.rootPosition() ; level = 0
    while level < len(aList):
        i = aList[level]
        while i > 0:
            if p.hasNext():
                p.moveToNext()
                i -= 1
            else:
                # g.trace('oops: bad archived position. no sibling:',aList,p.h,c)
                return None
        level += 1
        if level < len(aList):
            p.moveToFirstChild()
            # g.trace('level',level,'index',aList[level],p.h)
    return p
#@nonl
#@-node:ekr.20061006104837.1:archivedPositionToPosition
#@-node:ekr.20060919110638.13:setPositionsFromVnodes & helper
#@-node:ekr.20100122104234.6167:cache current position
#@+node:ekr.20100126215837.15931:Suppress path changed message in save-as and save-to
#@+node:ekr.20031218072017.2813:<< initialize ivars >> (commands)
self._currentPosition = self.nullPosition()
self._rootPosition    = self.nullPosition()
self._topPosition     = self.nullPosition()

# Delayed focus.
self.doubleClickFlag = False
self.hasFocusWidget = None
self.requestedFocusWidget = None

# Official ivars.
self.gui = g.app.gui
self.ipythonController = None # Set only by the ipython plugin.

# Interlock to prevent setting c.changed when switching chapters.
c.suppressHeadChanged = False

# Interlocks to prevent premature closing of a window.
self.inCommand = False
self.requestCloseWindow = False

# For emacs/vim key handling.
self.commandsDict = None
self.keyHandler = self.k = None
self.miniBufferWidget = None

# per-document info...
self.disableCommandsMessage = ''
    # The presence of this message disables all commands.
self.hookFunction = None
self.openDirectory = None
self.timeStampDict = {} # New in Leo 4.6.

self.expansionLevel = 0  # The expansion level of this outline.
self.expansionNode = None # The last node we expanded or contracted.
self.changed = False # True if any data has been changed since the last save.
self.loading = False # True if we are loading a file: disables c.setChanged()
self.outlineToNowebDefaultFileName = "noweb.nw" # For Outline To Noweb dialog.
self.promptingForClose = False # To lock out additional closing dialogs.
self.ignoreChangedPaths = False # True: disable path changed message in at.WriteAllHelper.

# For tangle/untangle
self.tangle_errors = 0

# Global options
self.fixed = False
self.page_width = 132
self.tab_width = -4
self.tangle_batch_flag = False
self.untangle_batch_flag = False

# Default Tangle options
self.use_header_flag = False
self.output_doc_flag = False

# Default Target Language
self.target_language = "python" # Required if leoConfig.txt does not exist.

# For hoist/dehoist commands.
self.hoistStack = []
    # Stack of nodes to be root of drawn tree.
    # Affects drawing routines and find commands.
self.recentFiles = [] # List of recent files

# For outline navigation.
self.navPrefix = g.u('') # Must always be a string.
self.navTime = None

pth, bname = os.path.split(self.mFileName)
if pth and bname and g.enableDB:
    fn = self.mFileName.lower()
    fn = g.toEncodedString(fn,'utf-8') # Required for Python 3.x.
    dbdirname = '%s/db/%s_%s' % (
        g.app.homeLeoDir,bname,hashlib.md5(fn).hexdigest())
    # Use compressed pickles (handy for @thin caches)
    self.db = leo.external.pickleshare.PickleShareDB(dbdirname,protocol='picklez')
else:
    self.db = {}
#@nonl
#@-node:ekr.20031218072017.2813:<< initialize ivars >> (commands)
#@+node:ekr.20031218072017.3043:saveAs (leoFileCommands)
def saveAs(self,fileName):

    c = self.c ; v = c.currentVnode()

    if not g.doHook("save1",c=c,p=v,v=v,fileName=fileName):
        c.endEditing() # Set the current headline text.
        self.setDefaultDirectoryForNewFiles(fileName)
        # Disable path-changed messages in writeAllHelper.
        c.ignoreChangedPaths = True
        try:
            if self.write_Leo_file(fileName,outlineOnlyFlag=False):
                c.setChanged(False) # Clears all dirty bits.
                self.putSavedMessage(fileName)
        finally:
            c.ignoreChangedPaths = True

        c.redraw_after_icons_changed()

    g.doHook("save2",c=c,p=v,v=v,fileName=fileName)
#@-node:ekr.20031218072017.3043:saveAs (leoFileCommands)
#@+node:ekr.20031218072017.3044:saveTo (leoFileCommands)
def saveTo (self,fileName):

    c = self.c ; v = c.currentVnode()

    if not g.doHook("save1",c=c,p=v,v=v,fileName=fileName):
        c.endEditing()# Set the current headline text.
        self.setDefaultDirectoryForNewFiles(fileName)
        # Disable path-changed messages in writeAllHelper.
        c.ignoreChangedPaths = True
        try:
            self.write_Leo_file(fileName,outlineOnlyFlag=False)
        finally:
            c.ignoreChangedPaths = False
        self.putSavedMessage(fileName)

        c.redraw_after_icons_changed()

    g.doHook("save2",c=c,p=v,v=v,fileName=fileName)
#@-node:ekr.20031218072017.3044:saveTo (leoFileCommands)
#@+node:ekr.20041005105605.149:writeAllHelper (atFile)
def writeAllHelper (self,p,
    force,toString,writeAtFileNodesFlag,writtenFiles
):

    trace = False and not g.unitTesting
    at = self ; c = at.c

    if p.isAtIgnoreNode() and not p.isAtAsisFileNode():
        pathChanged = False
    else:
        oldPath = at.getPathUa(p).lower()
        newPath = at.fullPath(p).lower()
        pathChanged = oldPath and oldPath != newPath
        # 2010/01/27: suppress this message during save-as and save-to commands.
        if pathChanged and not c.ignoreChangedPaths:
            at.setPathUa(p,newPath) # Remember that we have changed paths.
            g.es_print('path changed for',p.h,color='blue')
            if trace: g.trace('p %s\noldPath %s\nnewPath %s' % (
                p.h,repr(oldPath),repr(newPath)))

    if p.v.isDirty() or pathChanged or writeAtFileNodesFlag or p.v in writtenFiles:

        # Tricky: @ignore not recognised in @asis nodes.
        if p.isAtAsisFileNode():
            at.asisWrite(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtIgnoreNode():
            pass
        elif p.isAtAutoNode():
            at.writeOneAtAutoNode(p,toString=toString,force=force)
            writtenFiles.append(p.v)
        elif p.isAtEditNode():
            at.writeOneAtEditNode(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtNoSentFileNode():
            at.write(p,kind='@nosent',nosentinels=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtShadowFileNode():
            at.writeOneAtShadowNode(p,toString=toString,force=force or pathChanged)
            writtenFiles.append(p.v)
        elif p.isAtThinFileNode():
            at.write(p,kind='@thin',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtFileNode():
            # Write old @file nodes using @thin format.
            at.write(p,kind='@file',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
#@-node:ekr.20041005105605.149:writeAllHelper (atFile)
#@-node:ekr.20100126215837.15931:Suppress path changed message in save-as and save-to
#@+node:ekr.20100127045907.6221:Fixed 3.x crash when replacing files
@nocolor-node

exception writing: C:\Users\edreamleo\Desktop\thin-unicode-test.txt
Traceback (most recent call last):
  File "c:\leo.repo\trunk\leo\core\leoAtFile.py", line 2424, in write
    at.replaceTargetFileIfDifferent(root)
  File "c:\leo.repo\trunk\leo\core\leoAtFile.py", line 4541, in replaceTargetFileIfDifferent
    ignoreBlankLines=ignoreBlankLines):
  File "c:\leo.repo\trunk\leo\core\leoAtFile.py", line 4035, in compareFiles
    s1,s2 = f1.read(), f2.read()
  File "c:\python31\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 326: character maps to <undefined>
exception removing: C:\Users\edreamleo\Desktop\thin-unicode-test.txt.tmp
#@+node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
def readFileIntoString (fn,encoding='utf-8',kind=None,mode='rb',raw=False):

    '''Return the contents of the file whose full path is fn.

    Return (s,e)
    s is the string, converted to unicode, or None if there was an error.
    e the encoding line for Python files: it is usually None.
    '''

    try:
        e = None
        f = open(fn,mode)
        s = f.read()
        f.close()
        if raw:
            return s,None
        else:
            # Python's encoding comments override everything else.
            if s:
                junk,ext = g.os_path_splitext(fn)
                if ext == '.py':
                    e = g.getPythonEncodingFromString(s)
            s = g.toUnicode(s,encoding=e or encoding)
            return s,e
    except IOError:
        # Translate 'can not open' and kind, but not fn.
        if kind:
            g.es('can not open','',kind,fn,color='red')
        else:
            g.es('can not open',fn,color='red')
    except Exception:
        g.trace('unexpected exception reading %s' % (fn),color='red')
        g.es_exception()

    import leo.core.leoTest as leoTest
    leoTest.fail()
    return None,None
#@-node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
#@+node:ekr.20041005105605.197:compareFiles
def compareFiles (self,path1,path2,ignoreLineEndings,ignoreBlankLines=False):

    """Compare two text files."""
    at = self

    # We can't use 'U' mode because of encoding issues (Python 2.x only).
    s1,e = g.readFileIntoString(path1,mode='rb',raw=True)
    if s1 is None: return False # Should never happen.
    s2,e = g.readFileIntoString(path2,mode='rb',raw=True)
    if s2 is None: return False # Should never happen.
    equal = s1 == s2
    if ignoreBlankLines and not equal:
        s1 = g.removeBlankLines(s1)
        s2 = g.removeBlankLines(s2)
        equal = s1 == s2
    if ignoreLineEndings and not equal:
        s1 = g.toUnicode(s1,encoding=at.encoding)
        s2 = g.toUnicode(s2,encoding=at.encoding)
        s1 = s1.replace('\n','').replace('\r','')
        s2 = s2.replace('\n','').replace('\r','')
        equal = s1 == s2
    # g.trace('equal',equal,'ignoreLineEndings',ignoreLineEndings,'encoding',at.encoding)
    return equal
#@nonl
#@-node:ekr.20041005105605.197:compareFiles
#@-node:ekr.20100127045907.6221:Fixed 3.x crash when replacing files
#@+node:ekr.20100127074338.6249:Fixed Tangle problem with latext files
tangle.scanAllDirectives now properly updates the delim ivars.
#@nonl
#@+node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
def scanAtWrapDirectives(aList,issue_error_flag=False):

    '''Scan aList for @wrap and @nowrap directives.'''

    for d in aList:
        if d.get('wrap') is not None:
            return True
        elif d.get('nowrap') is not None:
            return False

    return None

def scanAllAtWrapDirectives(c,p):

    '''Scan p and all ancestors looking for @wrap/@nowrap directives.'''

    if c and p:
        default = c and c.config.getBool("body_pane_wraps")
        aList = g.get_directives_dict_list(p)

        val = g.scanAtWrapDirectives(aList)
        ret = g.choose(val is None,default,val)
    else:
        ret = None
    # g.trace(ret,p.h)
    return ret
#@-node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
#@+node:ekr.20080923124254.16:tangle.scanAllDirectives
def scanAllDirectives(self,p):

    """Scan vnode p and p's ancestors looking for directives,
    setting corresponding tangle ivars and globals.
    """

    c = self.c
    self.init_directive_ivars()
    if p:
        s = p.b
        << Collect @first attributes >>

    # delims = (self.single_comment_string,self.start_comment_string,self.end_comment_string)
    lang_dict = {'language':self.language,'delims':None,} # Delims not used

    table = (
        ('encoding',    self.encoding,  g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives), 
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process.
    lang_dict       = d.get('lang-dict')
    lineending      = d.get('lineending')
    if lineending:
        self.output_newline = lineending
    self.encoding             = d.get('encoding')
    self.language             = lang_dict.get('language')
    self.page_width           = d.get('pagewidth')
    self.tangle_directory     = d.get('path')
    self.tab_width            = d.get('tabwidth')

    # Handle the print-mode directives.
    self.print_mode = None
    for d in aList:
        for key in ('verbose','terse','quiet','silent'):
            if d.get(key) is not None:
                self.print_mode = key ; break
        if self.print_mode: break
    if not self.print_mode: self.print_mode = 'verbose'

    # 2010/01/27: bug fix: make sure to set the ivars.
    delim1,delim2,delim3 = g.set_delims_from_language(self.language)
    self.single_comment_string = delim1
    self.start_comment_string = delim2
    self.end_comment_string = delim3

    # g.trace(self.tangle_directory)

    # For unit testing.
    return {
        "encoding"  : self.encoding,
        "language"  : self.language,
        "lineending": self.output_newline,
        "pagewidth" : self.page_width,
        "path"      : self.tangle_directory,
        "tabwidth"  : self.tab_width,
    }
#@+node:ekr.20080923124254.17:<< Collect @first attributes >>
@ Stephen P. Schaefer 9/13/2002: Add support for @first.
Unlike other root attributes, does *NOT* inherit from parent nodes.
@c
tag = "@first"
sizeString = len(s) # DTHEIN 13-OCT-2002: use to detect end-of-string
i = 0
while 1:
    # DTHEIN 13-OCT-2002: directives must start at beginning of a line
    if not g.match_word(s,i,tag):
        i = g.skip_line(s,i)
    else:
        i = i + len(tag)
        j = i = g.skip_ws(s,i)
        i = g.skip_to_end_of_line(s,i)
        if i>j:
            self.first_lines += s[j:i] + '\n'
        i = g.skip_nl(s,i)
    if i >= sizeString:  # DTHEIN 13-OCT-2002: get out when end of string reached
        break
#@-node:ekr.20080923124254.17:<< Collect @first attributes >>
#@-node:ekr.20080923124254.16:tangle.scanAllDirectives
#@-node:ekr.20100127074338.6249:Fixed Tangle problem with latext files
#@+node:ekr.20100127113901.6244:created g.scanAllAtTabWidthDirectives
#@+node:ekr.20080827175609.39:c.scanAllDirectives
def scanAllDirectives(self,p=None):

    '''Scan p and ancestors for directives.

    Returns a dict containing the results, including defaults.'''

    c = self ; p = p or c.p

    # Set defaults
    language = c.target_language and c.target_language.lower()
    lang_dict = {
        'language':language,
        'delims':g.set_delims_from_language(language),
    }
    wrap = c.config.getBool("body_pane_wraps")

    table = (
        ('encoding',    None,           g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
        ('wrap',        wrap,           g.scanAtWrapDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process: do *not* set commander ivars.
    lang_dict = d.get('lang-dict')

    return {
        "delims"        : lang_dict.get('delims'),
        "encoding"      : d.get('encoding'),
        "language"      : lang_dict.get('language'),
        "lineending"    : d.get('lineending'),
        "pagewidth"     : d.get('pagewidth'),
        "path"          : d.get('path') or g.getBaseDirectory(c),
        "tabwidth"      : d.get('tabwidth'),
        "pluginsList"   : [], # No longer used.
        "wrap"          : d.get('wrap'),
    }
#@nonl
#@-node:ekr.20080827175609.39:c.scanAllDirectives
#@+node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
def scanAtWrapDirectives(aList,issue_error_flag=False):

    '''Scan aList for @wrap and @nowrap directives.'''

    for d in aList:
        if d.get('wrap') is not None:
            return True
        elif d.get('nowrap') is not None:
            return False

    return None

def scanAllAtWrapDirectives(c,p):

    '''Scan p and all ancestors looking for @wrap/@nowrap directives.'''

    if c and p:
        default = c and c.config.getBool("body_pane_wraps")
        aList = g.get_directives_dict_list(p)

        val = g.scanAtWrapDirectives(aList)
        ret = g.choose(val is None,default,val)
    else:
        ret = None
    # g.trace(ret,p.h)
    return ret
#@-node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
#@+node:ekr.20080827175609.37:g.scanAtTabwidthDirectives & scanAllTabWidthDirectives
def scanAtTabwidthDirectives(aList,issue_error_flag=False):

    '''Scan aList for @tabwidth directives.'''

    for d in aList:
        s = d.get('tabwidth')
        if s is not None:
            junk,val = g.skip_long(s,0)
            if val not in (None,0):
                return val
            else:
                if issue_error_flag and not g.app.unitTesting:
                    g.es("ignoring @tabwidth",s,color="red")
    return None

def scanAllAtTabWidthDirectives(c,p):

    '''Scan p and all ancestors looking for @tabwidth directives.'''

    if c and p:
        aList = g.get_directives_dict_list(p)
        val = g.scanAtTabwidthDirectives(aList)
        ret = g.choose(val is None,c.tab_width,val)
    else:
        ret = None
    # g.trace(ret,p and p.h,ret)
    return ret
#@-node:ekr.20080827175609.37:g.scanAtTabwidthDirectives & scanAllTabWidthDirectives
#@+node:ekr.20041126042730:getTabWidth
def getTabWidth (self,p=None):

    c = self.c
    if 1:
        # Faster, more self-contained.
        val = g.scanAllAtTabWidthDirectives(c,p)
        return val
    else:
        d = c.scanAllDirectives(p)
        w = d.get("tabwidth")
        if w not in (0,None):
            return w
        else:
            return self.c.tab_width
#@-node:ekr.20041126042730:getTabWidth
#@-node:ekr.20100127113901.6244:created g.scanAllAtTabWidthDirectives
#@+node:ekr.20100124142131.6223:Fixed Terry's unicode problem
@nocolor-node

Deleting a range of line containing unicode characters deletes too much.

Happens on both @edit and @thin files.
#@+node:ekr.20051125080855:selfInsertCommand, helpers
def selfInsertCommand(self,event,action='insert'):

    '''Insert a character in the body pane.
    This is the default binding for all keys in the body pane.'''

    trace = False and not g.unitTesting # or c.config.getBool('trace_masterCommand')
    verbose = True
    w = self.editWidget(event)
    if not w: return 'break'
    << set local vars >>
    if trace: g.trace('ch',repr(ch),'keysym',repr(keysym)) # ,'stroke',repr(stroke))
    if g.doHook("bodykey1",c=c,p=p,v=p,ch=ch,oldSel=oldSel,undoType=undoType):
        return "break" # The hook claims to have handled the event.
    if ch == '\t':
        self.updateTab(p,w)
    elif ch == '\b':
        # This is correct: we only come here if there no bindngs for this key. 
        self.backwardDeleteCharacter(event)
    elif ch in ('\r','\n'):
        ch = '\n'
        self.insertNewlineHelper(w,oldSel,undoType)
    elif inBrackets and self.autocompleteBrackets:
        self.updateAutomatchBracket(p,w,ch,oldSel)
    elif ch: # Null chars must not delete the selection.
        i,j = oldSel
        if i > j: i,j = j,i
        # Use raw insert/delete to retain the coloring.
        if i != j:                  w.delete(i,j)
        elif action == 'overwrite': w.delete(i)
        w.insert(i,ch)
        w.setInsertPoint(i+1)
        if inBrackets and self.flashMatchingBrackets:
            self.flashMatchingBracketsHelper(w,i,ch)               
    else:
        return 'break' # This method *always* returns 'break'

    # Set the column for up and down keys.
    spot = w.getInsertPoint()
    c.editCommands.setMoveCol(w,spot)

    # Update the text and handle undo.
    newText = w.getAllText()
    changed = newText != oldText
    if trace and verbose:
        g.trace('ch',repr(ch),'changed',changed,'newText',repr(newText[-10:]))
    if changed:
        # g.trace('ins',w.getInsertPoint())
        c.frame.body.onBodyChanged(undoType=undoType,
            oldSel=oldSel,oldText=oldText,oldYview=None)

    g.doHook("bodykey2",c=c,p=p,v=p,ch=ch,oldSel=oldSel,undoType=undoType)
    return 'break'
#@+node:ekr.20061103114242:<< set local vars >>
c = self.c
p = c.p
gui = g.app.gui
ch = gui.eventChar(event)
keysym = gui.eventKeysym(event)
# stroke = gui.eventStroke(event)
if keysym == 'Return':
    ch = '\n' # This fixes the MacOS return bug.
if keysym == 'Tab': # Support for wx_alt_gui plugin.
    ch = '\t'
name = c.widget_name(w)
oldSel =  name.startswith('body') and w.getSelectionRange() or (None,None)
oldText = name.startswith('body') and p.b or ''
undoType = 'Typing'
brackets = self.openBracketsList + self.closeBracketsList
inBrackets = ch and g.toUnicode(ch) in brackets
# if trace: g.trace(name,repr(ch),ch and ch in brackets)
#@nonl
#@-node:ekr.20061103114242:<< set local vars >>
#@+node:ekr.20090213065933.14:doPlainTab
def doPlainTab(self,s,i,tab_width,w):

    '''Insert spaces equivalent to one tab.'''

    start,end = g.getLine(s,i)
    s2 = s[start:i]
    width = g.computeWidth(s2,tab_width)

    if tab_width > 0:
        w.insert(i,'\t')
        ins = i+1
    else:
        n = abs(tab_width) - (width % abs(tab_width))
        w.insert(i,' ' * n)
        ins = i+n

    w.setSelectionRange(ins,ins,insert=ins)
#@-node:ekr.20090213065933.14:doPlainTab
#@+node:ekr.20060627091557:flashCharacter
def flashCharacter(self,w,i):

    bg      = self.bracketsFlashBg or 'DodgerBlue1'
    fg      = self.bracketsFlashFg or 'white'
    flashes = self.bracketsFlashCount or 3
    delay   = self.bracketsFlashDelay or 75

    w.flashCharacter(i,bg,fg,flashes,delay)
#@-node:ekr.20060627091557:flashCharacter
#@+node:ekr.20060627083506:flashMatchingBracketsHelper
def flashMatchingBracketsHelper (self,w,i,ch):

    d = {}
    if ch in self.openBracketsList:
        for z in range(len(self.openBracketsList)):
            d [self.openBracketsList[z]] = self.closeBracketsList[z]
        reverse = False # Search forward
    else:
        for z in range(len(self.openBracketsList)):
            d [self.closeBracketsList[z]] = self.openBracketsList[z]
        reverse = True # Search backward

    delim2 = d.get(ch)

    s = w.getAllText()
    j = g.skip_matching_python_delims(s,i,ch,delim2,reverse=reverse)
    if j != -1:
        self.flashCharacter(w,j)
#@-node:ekr.20060627083506:flashMatchingBracketsHelper
#@+node:ekr.20060804095512:initBracketMatcher
def initBracketMatcher (self,c):

    if len(self.openBracketsList) != len(self.closeBracketsList):

        g.es_print('bad open/close_flash_brackets setting: using defaults')
        self.openBracketsList  = '([{'
        self.closeBracketsList = ')]}'

    # g.trace('self.openBrackets',openBrackets)
    # g.trace('self.closeBrackets',closeBrackets)
#@-node:ekr.20060804095512:initBracketMatcher
#@+node:ekr.20051026171121:insertNewlineHelper
def insertNewlineHelper (self,w,oldSel,undoType):

    trace = False and not g.unitTesting
    c = self.c ; p = c.p
    i,j = oldSel ; ch = '\n'
    if trace:
        s = w.widget.toPlainText()
        g.trace(i,j,len(s),w)

    if i != j:
        # No auto-indent if there is selected text.
        w.delete(i,j)
        w.insert(i,ch)
        w.setInsertPoint(i+1)
    else:
        w.insert(i,ch)
        w.setInsertPoint(i+1)

        if (c.autoindent_in_nocolor or 
            (c.frame.body.colorizer.useSyntaxColoring(p) and
            undoType != "Change")
        ):
            # No auto-indent if in @nocolor mode or after a Change command.
            self.updateAutoIndent(p,w)

    w.seeInsertPoint()
#@-node:ekr.20051026171121:insertNewlineHelper
#@+node:ekr.20051026171121.1:updateAutoIndent (leoEditCommands)
def updateAutoIndent (self,p,w):

    c = self.c ; d = c.scanAllDirectives(p)
    tab_width = d.get("tabwidth",c.tab_width)
    # Get the previous line.
    s = w.getAllText()
    ins = w.getInsertPoint()
    i = g.skip_to_start_of_line(s,ins)
    i,j = g.getLine(s,i-1)
    s = s[i:j-1]
    # g.trace(i,j,repr(s))

    # Add the leading whitespace to the present line.
    junk, width = g.skip_leading_ws_with_indent(s,0,tab_width)
    # g.trace('width',width,'tab_width',tab_width)

    if s and s [-1] == ':':
        # For Python: increase auto-indent after colons.
        if g.findLanguageDirectives(c,p) == 'python':
            width += abs(tab_width)
    if self.smartAutoIndent:
        # Determine if prev line has unclosed parens/brackets/braces
        bracketWidths = [width] ; tabex = 0
        for i in range(0,len(s)):
            if s [i] == '\t':
                tabex += tab_width-1
            if s [i] in '([{':
                bracketWidths.append(i+tabex+1)
            elif s [i] in '}])' and len(bracketWidths) > 1:
                bracketWidths.pop()
        width = bracketWidths.pop()
    ws = g.computeLeadingWhitespace(width,tab_width)
    if ws:
        i = w.getInsertPoint()
        w.insert(i,ws)
        w.setInsertPoint(i+len(ws))
#@-node:ekr.20051026171121.1:updateAutoIndent (leoEditCommands)
#@+node:ekr.20051027172949:updateAutomatchBracket
def updateAutomatchBracket (self,p,w,ch,oldSel):

    # assert ch in ('(',')','[',']','{','}')

    c = self.c ; d = c.scanAllDirectives(p)
    i,j = oldSel
    language = d.get('language')
    s = w.getAllText()

    if ch in ('(','[','{',):
        automatch = language not in ('plain',)
        if automatch:
            ch = ch + {'(':')','[':']','{':'}'}.get(ch)
        if i != j: w.delete(i,j)
        w.insert(i,ch)
        if automatch:
            ins = w.getInsertPoint()
            w.setInsertPoint(ins-1)
    else:
        ins = w.getInsertPoint()
        ch2 = ins<len(s) and s[ins] or ''
        if ch2 in (')',']','}'):
            ins = w.getInsertPoint()
            w.setInsertPoint(ins+1)
        else:
            if i != j: w.delete(i,j)
            w.insert(i,ch)
            w.setInsertPoint(i+1)
#@-node:ekr.20051027172949:updateAutomatchBracket
#@+node:ekr.20051026092433:updateTab
def updateTab (self,p,w,smartTab=True):

    c = self.c

    # g.trace('tab_width',tab_width)
    i,j = w.getSelectionRange()
        # Returns insert point if no selection, with i <= j.

    if i != j:
        # w.delete(i,j)
        c.indentBody()
    else:
        d = c.scanAllDirectives(p)
        tab_width = d.get("tabwidth",c.tab_width)
        # Get the preceeding characters.
        s = w.getAllText()
        # start = g.skip_to_start_of_line(s,i)
        start,end = g.getLine(s,i)
        before = s[start:i]
        after = s[i:end]
        if after.endswith('\n'): after = after[:-1]
        ws = g.get_leading_ws(before)
        s2 = s[start:i] # The characters before the insert point.

        # Only do smart tab at the start of a blank line.
        doSmartTab = (smartTab and c.smart_tab and i == start)
            # Truly at the start of the line.
            # and not after # Nothing *at all* after the cursor.
        # g.trace(doSmartTab,'i %s start %s after %s' % (i,start,repr(after)))

        if doSmartTab:
            self.updateAutoIndent(p,w)
            # Add a tab if otherwise nothing would happen.
            if s == w.getAllText():
                self.doPlainTab(s,i,tab_width,w)
        else:
            self.doPlainTab(s,i,tab_width,w)
#@-node:ekr.20051026092433:updateTab
#@-node:ekr.20051125080855:selfInsertCommand, helpers
#@+node:ekr.20050920084036.138:insertNewLine
def insertNewLine (self,event):

    '''Insert a newline at the cursor.'''

    c = self.c ; k = c.k ; w = self.editWidget(event)
    if not w: return

    assert g.app.gui.isTextWidget(w)
    name = c.widget_name(w)
    if name.startswith('head'): return

    oldSel = w.getSelectionRange()
    # g.trace('oldSel',oldSel)

    self.beginCommand(undoType='newline')

    # New in Leo 4.5: use the same logic as in selfInsertCommand.
    self.insertNewlineHelper(w=w,oldSel=oldSel,undoType=None)
    k.setInputState('insert')
    k.showStateAndMode()

    self.endCommand()

insertNewline = insertNewLine
#@-node:ekr.20050920084036.138:insertNewLine
#@+node:ekr.20051026171121:insertNewlineHelper
def insertNewlineHelper (self,w,oldSel,undoType):

    trace = False and not g.unitTesting
    c = self.c ; p = c.p
    i,j = oldSel ; ch = '\n'
    if trace:
        s = w.widget.toPlainText()
        g.trace(i,j,len(s),w)

    if i != j:
        # No auto-indent if there is selected text.
        w.delete(i,j)
        w.insert(i,ch)
        w.setInsertPoint(i+1)
    else:
        w.insert(i,ch)
        w.setInsertPoint(i+1)

        if (c.autoindent_in_nocolor or 
            (c.frame.body.colorizer.useSyntaxColoring(p) and
            undoType != "Change")
        ):
            # No auto-indent if in @nocolor mode or after a Change command.
            self.updateAutoIndent(p,w)

    w.seeInsertPoint()
#@-node:ekr.20051026171121:insertNewlineHelper
#@-node:ekr.20100124142131.6223:Fixed Terry's unicode problem
#@+node:ekr.20100129054823.17686:Fix crasher in rst3 command
TypeError: string argument expected, got 'bytes'
--------------------
  line 1364: 
* line 1365:         self.outputFile.write(s)
  line 1366:     #@-node:ekr.20090502071837.94:write (leoRst)
  line 1367:     #@+node:ekr.20090502071837.71:writeBody
saved: LeoDocs.leo
#@nonl
#@+node:ekr.20090502071837.94:write (leoRst)
def write (self,s):

    if self.trialWrite:
        pass
    elif g.isPython3:
        pass
    else:
        s = self.encode(s)

    # g.trace(repr(s),g.callers(2))

    self.outputFile.write(s)
#@-node:ekr.20090502071837.94:write (leoRst)
#@+node:ekr.20090502071837.65:writeToDocutils (sets argv) & helper
def writeToDocutils (self,s):

    '''Send s to docutils using the writer implied by self.ext and return the result.'''

    trace = False and not g.unitTesting

    if not docutils:
        g.es('docutils not present',color='red')
        return

    openDirectory = self.c.frame.openDirectory
    overrides = {'output_encoding': self.encoding }

    # Compute the args list if the stylesheet path does not exist.
    styleSheetArgsDict = self.handleMissingStyleSheetArgs()

    for ext,writer in (
        ('.html','html'),
        ('.htm','html'),
        ('.tex','latex'),
        ('.pdf','leo_pdf'),
    ):
        if self.ext == ext:
            break
    else:
        g.es_print('unknown docutils extension: %s' % (self.ext),color='red')
        return ''

    # Make the stylesheet path relative to the directory containing the output file.
    rel_stylesheet_path = self.getOption('stylesheet_path') or ''

    # New in Leo 4.5: The rel_stylesheet_path is relative to the open directory.
    stylesheet_path = g.os_path_finalize_join(
        self.c.frame.openDirectory,rel_stylesheet_path)

    path = g.os_path_finalize_join(
        stylesheet_path,self.getOption('stylesheet_name'))

    res = ""
    if self.getOption('stylesheet_embed') == False:
        rel_path = g.os_path_join(
            rel_stylesheet_path,self.getOption('stylesheet_name'))
        rel_path = rel_path.replace('\\','/') # 2010/01/28
        overrides['stylesheet'] = rel_path
        overrides['stylesheet_path'] = None
        overrides['embed_stylesheet'] = None
    elif g.os_path_exists(path):
        if self.ext != '.pdf':
            overrides['stylesheet'] = path
            overrides['stylesheet_path'] = None
    elif styleSheetArgsDict:
        g.es_print('using publish_argv_for_missing_stylesheets',
            styleSheetArgsDict)
        overrides.update(styleSheetArgsDict)
            # MWC add args to settings
    elif rel_stylesheet_path == stylesheet_path:
        g.es_print('stylesheet not found: %s' % (path),color='red')
    else:
        g.es_print('stylesheet not found\n',path,color='red')
        if self.path:g.es_print('@path:', self.path)
        g.es_print('open path:',self.c.frame.openDirectory)
        if rel_stylesheet_path:
            g.es_print('relative path:', rel_stylesheet_path)
    try:
        # All paths now come through here.
        if trace: g.trace('overrides',overrides)
        result = None # Ensure that result is defined.
        result = docutils.core.publish_string(source=s,
                reader_name='standalone',
                parser_name='restructuredtext',
                writer_name=writer,
                settings_overrides=overrides)
    except docutils.ApplicationError as error:
        # g.es_print('Docutils error (%s):' % (
            # error.__class__.__name__),color='red')
        g.es_print('Docutils error:',color='red')
        g.es_print(error,color='blue')
    except Exception:
        g.es_print('Unexpected docutils exception')
        g.es_exception()
    return result
#@+node:ekr.20090502071837.66:handleMissingStyleSheetArgs
def handleMissingStyleSheetArgs (self,s=None):

    '''Parse the publish_argv_for_missing_stylesheets option,
    returning a dict containing the parsed args.'''

    force = False
    if force:
        # See http://docutils.sourceforge.net/docs/user/config.html#documentclass
        return {'documentclass':'report', 'documentoptions':'english,12pt,lettersize'}

    if not s:
        s = self.getOption('publish_argv_for_missing_stylesheets')
    if not s: return {}

    # Handle argument lists such as this:
    # --language=en,--documentclass=report,--documentoptions=[english,12pt,lettersize]
    d = {}
    while s:
        s = s.strip()
        if not s.startswith('--'): break
        s = s[2:].strip()
        eq = s.find('=')
        cm = s.find(',')
        if eq == -1 or (-1 < cm < eq): # key[nl] or key,
            val = ''
            cm = s.find(',')
            if cm == -1:
                key = s.strip()
                s = ''
            else:
                key = s[:cm].strip()
                s = s[cm+1:].strip()
        else: # key = val
            key = s[:eq].strip()
            s = s[eq+1:].strip()
            if s.startswith('['): # [...]
                rb = s.find(']')
                if rb == -1: break # Bad argument.
                val = s[:rb+1]
                s = s[rb+1:].strip()
                if s.startswith(','):
                    s = s[1:].strip()
            else: # val[nl] or val,
                cm = s.find(',')
                if cm == -1:
                    val = s
                    s = ''
                else:
                    val = s[:cm].strip()
                    s = s[cm+1:].strip()

        # g.trace('key',repr(key),'val',repr(val),'s',repr(s))
        if not key: break
        if not val.strip(): val = '1'
        d[str(key)] = str(val)

    return d
#@nonl
#@-node:ekr.20090502071837.66:handleMissingStyleSheetArgs
#@-node:ekr.20090502071837.65:writeToDocutils (sets argv) & helper
#@-node:ekr.20100129054823.17686:Fix crasher in rst3 command
#@-node:ekr.20100118163110.6256:Leo 4.7 b2 projects
#@+node:ekr.20100129131524.6188:Leo 4.7 b3 projects
#@+node:ekr.20100129131524.6187:Disable caching during unit tests
#@+node:ekr.20031218072017.3037:putGlobals
# Changed for Leo 4.0.

def putGlobals (self):

    trace = False and not g.unitTesting
    c = self.c

    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        if trace: g.trace(len(list(c.db.keys())),c.mFileName,key)
        << put all data to c.db >>

    # Always put positions, to trigger sax methods.
    self.put("<globals")
    << put the body/outline ratios >>
    self.put(">") ; self.put_nl()
    << put the position of this frame >>
    << put the position of the log window >>
    self.put("</globals>") ; self.put_nl()
#@+node:ekr.20100112095623.6267:<< put all data to c.db >>
c.db['body_outline_ratio_%s' % key] = str(c.frame.ratio)
c.db['body_secondary_ratio_%s' % key] = str(c.frame.secondary_ratio)

if trace: g.trace('ratios: %1.2f %1.2f' % (
    c.frame.ratio,c.frame.secondary_ratio))

width,height,left,top = c.frame.get_window_info()

c.db['window_position_%s' % key] = (
    str(top),str(left),str(height),str(width))

if trace: g.trace('top',top,'left',left,'height',height,'width',width)
#@-node:ekr.20100112095623.6267:<< put all data to c.db >>
#@+node:ekr.20031218072017.3038:<< put the body/outline ratios >>
self.put(" body_outline_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.ratio)))

self.put(" body_secondary_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.secondary_ratio)))

if trace: g.trace('fixed or use_db',c.fixed or use_db,
    '%1.2f %1.2f' % (c.frame.ratio,c.frame.secondary_ratio))
#@-node:ekr.20031218072017.3038:<< put the body/outline ratios >>
#@+node:ekr.20031218072017.3039:<< put the position of this frame >>
# New in Leo 4.5: support fixed .leo files.

if c.fixed or use_db:
    width,height,left,top = 700,500,50,50
        # Put fixed, immutable, reasonable defaults.
        # Leo 4.5 and later will ignore these when reading.
        # These should be reasonable defaults so that the
        # file will be opened properly by older versions
        # of Leo that do not support fixed .leo files.
else:
    width,height,left,top = c.frame.get_window_info()

# g.trace(width,height,left,top)

self.put_tab()
self.put("<global_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3039:<< put the position of this frame >>
#@+node:ekr.20031218072017.3040:<< put the position of the log window >>
top = left = height = width = 0 # no longer used

self.put_tab()
self.put("<global_log_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3040:<< put the position of the log window >>
#@-node:ekr.20031218072017.3037:putGlobals
#@+node:ekr.20031218072017.1863:putVnode
def putVnode (self,p,isIgnore=False):

    """Write a <v> element corresponding to a vnode."""

    fc = self ; c = fc.c ; v = p.v
    isAuto = p.isAtAutoNode() and p.atAutoNodeName().strip()
    isEdit = p.isAtEditNode() and p.atEditNodeName().strip()
    isShadow = p.isAtShadowFileNode()
    isThin = p.isAtThinFileNode()
    isOrphan = p.isOrphan()
    if not isIgnore: isIgnore = p.isAtIgnoreNode()

    if   isIgnore: forceWrite = True      # Always write full @ignore trees.
    elif isAuto:   forceWrite = False     # Never write non-ignored @auto trees.
    elif isEdit:   forceWrite = False     # Never write non-ignored @edit trees.
    elif isShadow: forceWrite = False     # Never write non-ignored @shadow trees.
    elif isThin:   forceWrite = isOrphan  # Only write orphan @thin trees.
    else:          forceWrite = True      # Write all other @<file> trees.

    << Set gnx = vnode index >>
    attrs = []
    << Append attribute bits to attrs >>
    << Append unKnownAttributes to attrs >>
    attrs = ''.join(attrs)
    v_head = '<v t="%s"%s>' % (gnx,attrs)
    if gnx in fc.vnodesDict:
        fc.put(v_head+'</v>\n')
    else:
        fc.vnodesDict[gnx]=True
        v_head += '<vh>%s</vh>' % (xml.sax.saxutils.escape(p.v.headString()or''))
        # The string catentation is faster than repeated calls to fc.put.
        if not self.usingClipboard:
            << issue informational messages >>
        # New in 4.2: don't write child nodes of @file-thin trees (except when writing to clipboard)
        if p.hasChildren() and (forceWrite or self.usingClipboard):
            fc.put('%s\n' % v_head)
            # This optimization eliminates all "recursive" copies.
            p.moveToFirstChild()
            while 1:
                fc.putVnode(p,isIgnore)
                if p.hasNext(): p.moveToNext()
                else:           break
            p.moveToParent() # Restore p in the caller.
            fc.put('</v>\n')
        else:
            fc.put('%s</v>\n' % v_head) # Call put only once.
#@+node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
gnx = g.app.nodeIndices.toString(v.fileIndex)

if forceWrite or self.usingClipboard:
    v.setWriteBit() # 4.2: Indicate we wrote the body text.
#@-node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
# v.unknownAttributes are now put in <t> elements.

if p.hasChildren() and not forceWrite and not self.usingClipboard:
    # We put the entire tree when using the clipboard, so no need for this.
    if not isAuto: # Bug fix: 2008/8/7.
        attrs.append(self.putDescendentVnodeUas(p)) # New in Leo 4.5.
        attrs.append(self.putDescendentAttributes(p))
#@nonl
#@-node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
#@+node:ekr.20040702085529:<< issue informational messages >>
if isOrphan and isThin:
    g.es("writing erroneous:",p.h,color="blue")
    p.clearOrphan()
#@-node:ekr.20040702085529:<< issue informational messages >>
#@-node:ekr.20031218072017.1863:putVnode
#@-node:ekr.20100129131524.6187:Disable caching during unit tests
#@+node:ekr.20100128124511.6236:Eliminate most imports from leo/extensions
@nocolor-node

Eliminated cruft in leo/extensions
- sets folder
- subprocess folder
- optparse.py
- aspell23/24.pyd files can also go.

Eliminated calls to g.importExtenion for zlib,optparse,subprocess.

Don't know about Gato.
#@nonl
#@-node:ekr.20100128124511.6236:Eliminate most imports from leo/extensions
#@+node:ekr.20100130042842.9007:better traces for ctors
#@+node:ekr.20051023083258:callers & _callerName
def callers (n=8,count=0,excludeCaller=True,files=False):

    '''Return a list containing the callers of the function that called g.callerList.

    If the excludeCaller keyword is True (the default), g.callers is not on the list.

    If the files keyword argument is True, filenames are included in the list.
    '''

    # sys._getframe throws ValueError in both cpython and jython if there are less than i entries.
    # The jython stack often has less than 8 entries,
    # so we must be careful to call g._callerName with smaller values of i first.
    result = []
    i = g.choose(excludeCaller,3,2)
    while 1:
        s = g._callerName(i,files=files)
        if s:
            result.append(s)
        if not s or len(result) >= n: break
        i += 1

    result.reverse()
    if count > 0: result = result[:count]
    sep = g.choose(files,'\n',',')
    return sep.join(result)
#@+node:ekr.20031218072017.3107:_callerName
def _callerName (n=1,files=False):

    try: # get the function name from the call stack.
        f1 = sys._getframe(n) # The stack frame, n levels up.
        code1 = f1.f_code # The code object
        name = code1.co_name
        if name == '__init__':
            name = '__init__(%s,line %s)' % (
                g.shortFileName(code1.co_filename),code1.co_firstlineno)
        if files:
            return '%s:%s' % (g.shortFilename(code1.co_filename),name)
        else:
            return name # The code name
    except ValueError:
        return '' # The stack is not deep enough.
    except Exception:
        g.es_exception()
        return '' # "<no caller name>"
#@-node:ekr.20031218072017.3107:_callerName
#@-node:ekr.20051023083258:callers & _callerName
#@-node:ekr.20100130042842.9007:better traces for ctors
#@+node:ekr.20100130164946.8693:Removed encoding arg from g.os_path_xxx
g.os_path.*\(.*,encoding=.*\)
#@nonl
#@+node:ekr.20031218072017.2145:os.path wrappers (leoGlobals.py)
@ Note: all these methods return Unicode strings. It is up to the user to
convert to an encoded string as needed, say when opening a file.
#@+node:ekr.20031218072017.2146:os_path_abspath
def os_path_abspath(path):

    """Convert a path to an absolute path."""

    path = g.toUnicodeFileEncoding(path)

    path = os.path.abspath(path)

    path = g.toUnicodeFileEncoding(path)

    return path
#@-node:ekr.20031218072017.2146:os_path_abspath
#@+node:ekr.20031218072017.2147:os_path_basename
def os_path_basename(path):

    """Return the second half of the pair returned by split(path)."""

    path = g.toUnicodeFileEncoding(path)

    path = os.path.basename(path)

    path = g.toUnicodeFileEncoding(path)

    return path
#@-node:ekr.20031218072017.2147:os_path_basename
#@+node:ekr.20031218072017.2148:os_path_dirname
def os_path_dirname(path):

    """Return the first half of the pair returned by split(path)."""

    path = g.toUnicodeFileEncoding(path)

    path = os.path.dirname(path)

    path = g.toUnicodeFileEncoding(path)

    return path
#@-node:ekr.20031218072017.2148:os_path_dirname
#@+node:ekr.20031218072017.2149:os_path_exists
def os_path_exists(path):

    """Normalize the path and convert it to an absolute path."""

    path = g.toUnicodeFileEncoding(path)

    return os.path.exists(path)
#@-node:ekr.20031218072017.2149:os_path_exists
#@+node:ekr.20080922124033.6:os_path_expandExpression
def os_path_expandExpression (s,**keys):

    '''Expand {{anExpression}} in c's context.'''

    c = keys.get('c')
    if not c:
        g.trace('can not happen: no c',g.callers())
        return s

    if not s: return ''

    i = s.find('{{')
    j = s.find('}}')
    if -1 < i < j:
        exp = s[i+2:j].strip()
        if exp:
            try:
                import os
                import sys
                p = c.p
                d = {'c':c,'g':g,'p':p,'os':os,'sys':sys,}
                val = eval(exp,d)
                s = s[:i] + str(val) + s[j+2:]
            except Exception:
                g.trace(g.callers())
                g.es_exception(full=True, c=c, color='red')

    return s
#@-node:ekr.20080922124033.6:os_path_expandExpression
#@+node:ekr.20080921060401.13:os_path_expanduser
def os_path_expanduser(path):

    """wrap os.path.expanduser"""

    path = g.toUnicodeFileEncoding(path)

    result = os.path.normpath(os.path.expanduser(path))

    return result
#@-node:ekr.20080921060401.13:os_path_expanduser
#@+node:ekr.20080921060401.14:g.os_path_finalize & os_path_finalize_join
def os_path_finalize (path,**keys):

    '''
    Expand '~', then return os.path.normpath, os.path.abspath of the path.

    There is no corresponding os.path method'''

    c = keys.get('c')

    if c: path = g.os_path_expandExpression(path,**keys)

    path = g.os_path_expanduser(path)
    return os.path.normpath(os.path.abspath(path))

def os_path_finalize_join (*args,**keys):

    '''Do os.path.join(*args), then finalize the result.'''

    c = keys.get('c')

    if c:
        args = [g.os_path_expandExpression(path,**keys)
            for path in args if path]

    return os.path.normpath(os.path.abspath(
        g.os_path_join(*args,**keys))) # Handles expanduser
#@-node:ekr.20080921060401.14:g.os_path_finalize & os_path_finalize_join
#@+node:ekr.20031218072017.2150:os_path_getmtime
def os_path_getmtime(path):

    """Normalize the path and convert it to an absolute path."""

    path = g.toUnicodeFileEncoding(path)

    return os.path.getmtime(path)
#@-node:ekr.20031218072017.2150:os_path_getmtime
#@+node:ekr.20080729142651.2:os_path_getsize
def os_path_getsize (path):

    path = g.toUnicodeFileEncoding(path)

    return os.path.getsize(path)
#@-node:ekr.20080729142651.2:os_path_getsize
#@+node:ekr.20031218072017.2151:os_path_isabs
def os_path_isabs(path):

    """Normalize the path and convert it to an absolute path."""

    path = g.toUnicodeFileEncoding(path)

    return os.path.isabs(path)
#@-node:ekr.20031218072017.2151:os_path_isabs
#@+node:ekr.20031218072017.2152:os_path_isdir
def os_path_isdir(path):

    """Normalize the path and convert it to an absolute path."""

    path = g.toUnicodeFileEncoding(path)

    return os.path.isdir(path)
#@-node:ekr.20031218072017.2152:os_path_isdir
#@+node:ekr.20031218072017.2153:os_path_isfile
def os_path_isfile(path):

    """Normalize the path and convert it to an absolute path."""

    path = g.toUnicodeFileEncoding(path)

    return os.path.isfile(path)
#@-node:ekr.20031218072017.2153:os_path_isfile
#@+node:ekr.20031218072017.2154:os_path_join
def os_path_join(*args,**keys):

    c = keys.get('c')

    uargs = [g.toUnicodeFileEncoding(arg) for arg in args]

    # Note:  This is exactly the same convention as used by getBaseDirectory.
    if uargs and uargs[0] == '!!':
        uargs[0] = g.app.loadDir
    elif uargs and uargs[0] == '.':
        c = keys.get('c')
        if c and c.openDirectory:
            uargs[0] = c.openDirectory
            # g.trace(c.openDirectory)

    uargs = [g.os_path_expanduser(z) for z in uargs if z]

    path = os.path.join(*uargs)

    # May not be needed on some Pythons.
    path = g.toUnicodeFileEncoding(path)
    return path
#@-node:ekr.20031218072017.2154:os_path_join
#@+node:ekr.20031218072017.2156:os_path_normcase
def os_path_normcase(path):

    """Normalize the path's case."""

    path = g.toUnicodeFileEncoding(path)

    path = os.path.normcase(path)

    path = g.toUnicodeFileEncoding(path)

    return path
#@-node:ekr.20031218072017.2156:os_path_normcase
#@+node:ekr.20031218072017.2157:os_path_normpath
def os_path_normpath(path):

    """Normalize the path."""

    path = g.toUnicodeFileEncoding(path)

    path = os.path.normpath(path)

    path = g.toUnicodeFileEncoding(path)

    return path
#@-node:ekr.20031218072017.2157:os_path_normpath
#@+node:ekr.20080605064555.2:os_path_realpath
def os_path_realpath(path):


    path = g.toUnicodeFileEncoding(path)

    path = os.path.realpath(path)

    path = g.toUnicodeFileEncoding(path)

    return path
#@-node:ekr.20080605064555.2:os_path_realpath
#@+node:ekr.20031218072017.2158:os_path_split
def os_path_split(path):

    path = g.toUnicodeFileEncoding(path)

    head,tail = os.path.split(path)

    head = g.toUnicodeFileEncoding(head)
    tail = g.toUnicodeFileEncoding(tail)

    return head,tail
#@-node:ekr.20031218072017.2158:os_path_split
#@+node:ekr.20031218072017.2159:os_path_splitext
def os_path_splitext(path):

    path = g.toUnicodeFileEncoding(path)

    head,tail = os.path.splitext(path)

    head = g.toUnicodeFileEncoding(head)
    tail = g.toUnicodeFileEncoding(tail)

    return head,tail
#@-node:ekr.20031218072017.2159:os_path_splitext
#@+node:ekr.20090829140232.6036:os_startfile
def os_startfile(fname):
    if sys.platform.startswith('win'):
        os.startfile(fname)
    elif sys.platform == 'darwin':
        # From Marc-Antoine Parent.
        try:
            subprocess.call(['open', fname])
        except OSError:
            pass # There may be a spurious "Interrupted system call"
        except ImportError:
            os.system("open '%s'" % (fname,))
    else:
        os.system('xdg-open ' + fname)
#@nonl
#@-node:ekr.20090829140232.6036:os_startfile
#@+node:ekr.20031218072017.2160:toUnicodeFileEncoding
def toUnicodeFileEncoding(path):

    if path: path = path.replace('\\', os.sep)

    # Yes, this is correct.  All os_path_x functions return Unicode strings.
    return g.toUnicode(path)
#@-node:ekr.20031218072017.2160:toUnicodeFileEncoding
#@-node:ekr.20031218072017.2145:os.path wrappers (leoGlobals.py)
#@-node:ekr.20100130164946.8693:Removed encoding arg from g.os_path_xxx
#@+node:ekr.20100130164946.8694:Removed all uses of mbcs encoding
#@+node:ekr.20041124083125:completeFileName
def completeFileName (fileName):

    trace = False
    if trace: print('completeFileName',fileName)

    if not (fileName and fileName.strip()):
        return None,None

    # This does not depend on config settings.
    # try:
        # if sys.platform.lower().startswith('win'):
            # fileName = g.toUnicode(fileName,'mbcs')
        # else:
            # fileName = g.toUnicode(fileName,'utf-8')
    # except Exception: pass

    fileName = g.toUnicode(fileName,'utf-8')

    relativeFileName = fileName
    fileName = g.os_path_finalize(fileName)

    junk,ext = g.os_path_splitext(fileName)

    # Bug fix: don't add .leo to existing files.
    if g.os_path_exists(fileName):
        pass # use the fileName as is.
    elif ext != '.leo':
        fileName = fileName + ".leo"
        relativeFileName = relativeFileName + ".leo"

    if trace: print('completeFileName',fileName)

    return fileName,relativeFileName
#@-node:ekr.20041124083125:completeFileName
#@-node:ekr.20100130164946.8694:Removed all uses of mbcs encoding
#@-node:ekr.20100129131524.6188:Leo 4.7 b3 projects
#@+node:ekr.20100130164410.6332:Recent
#@+node:ekr.20100129131524.6190:improve caching
@nocolor-node

- Cache expansion states.
- Use common key for globals??
#@nonl
#@+node:ekr.20060919110638.14:parse_leo_file
def parse_leo_file (self,theFile,inputFileName,silent,inClipboard,s=None):

    c = self.c
    try:
        if g.isPython3:
            if theFile:
                # Use the open binary file, opened by g.openLeoOrZipFile.
                s = theFile.read() # type(s) is bytes.
                s = self.cleanSaxInputString(s)
                theFile = BytesIO(s)
            else:
                s = str(s,encoding='utf-8')
                s = self.cleanSaxInputString(s)
                theFile = StringIO(s)
        else:
            if theFile: s = theFile.read()
            s = self.cleanSaxInputString(s)
            theFile = cStringIO.StringIO(s)
        parser = xml.sax.make_parser()
        parser.setFeature(xml.sax.handler.feature_external_ges,1)
            # Include external general entities, esp. xml-stylesheet lines.
        if 0: # Expat does not read external features.
            parser.setFeature(xml.sax.handler.feature_external_pes,1)
                # Include all external parameter entities
                # Hopefully the parser can figure out the encoding from the <?xml> element.
        handler = saxContentHandler(c,inputFileName,silent,inClipboard)
        parser.setContentHandler(handler)
        parser.parse(theFile) # expat does not support parseString
        # g.trace('parsing done')
        sax_node = handler.getRootNode()
    except xml.sax.SAXParseException:
        g.es_print('error parsing',inputFileName,color='red')
        g.es_exception()
        sax_node = None
    except Exception:
        g.es_print('unexpected exception parsing',inputFileName,color='red')
        g.es_exception()
        sax_node = None

    return sax_node
#@-node:ekr.20060919110638.14:parse_leo_file
#@+node:ekr.20100129133806.6242:Calls to _contentHashFile
#@+node:ekr.20100129133806.6243:Reading
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20070909100252:readOneAtAutoNode (atFile)
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None:
        cachefile = None
    else:
        cachefile = self._contentHashFile(p.h,s)

    # Remember that we have read this file.
    p.v.at_read = True # Create the attribute

    # Disable caching for test.leo.
    if c.shortFileName() != 'test.leo':
        if cachefile is not None and cachefile in c.db:        
            # g.es('uncache:',p.h)
            aList = c.db[cachefile]
            p.v.createOutlineFromCacheList(c,aList)
            return

    if not g.unitTesting:
        g.es("reading:",p.h)

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        # Note: the file contains an @ignore,
        # so no unintended write can happen.
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        self.writeCachedTree(p, cachefile)
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@-node:ekr.20070909100252:readOneAtAutoNode (atFile)
#@+node:ekr.20060919110638.36:getPositionAttributes
def getPositionAttributes (self,attrs):

    trace = False and not g.unitTesting
    c = self.c

    if trace: g.trace(len(list(c.db.keys())),c.mFileName,self.fileName)

    d = {}

    if g.enableDB and c.db and c.mFileName:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        data = c.db.get('window_position_%s' % (key))
        if data:
            top,left,height,width = data
            top,left,height,width = int(top),int(left),int(height),int(width)
            d = {'top':top,'left':left,'height':height,'width':width}

    if not d and c.fixed and c.fixedWindowPosition:
        width,height,left,top = c.fixedWindowPosition
        d = {'top':top,'left':left,'width':width,'height':height}

    if not d:
        for bunch in self.attrsToList(attrs):
            name = bunch.name ; val = bunch.val
            if name in ('top','left','width','height'):
                try:
                    d[name] = int(val)
                except ValueError:
                    d[name] = 100 # A reasonable default.
            else:
                g.trace(name,len(val))

    # if trace: g.trace(d)
    return d
#@-node:ekr.20060919110638.36:getPositionAttributes
#@+node:ekr.20060919110638.13:setPositionsFromVnodes & helper
def setPositionsFromVnodes (self):

    trace = False and not g.unitTesting
    c = self.c ; p = c.rootPosition()
    current,str_pos = None,None
    use_db = g.enableDB and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        str_pos = c.db.get('current_position_%s' % key)
        if trace: g.trace('from c.db',str_pos,key)

    if not str_pos:
        d = hasattr(p.v,'unknownAttributes') and p.v.unknownAttributes
        if d: str_pos = d.get('str_leo_pos')
        if trace: g.trace('from p.v.u',str_pos)

    if str_pos:
        current = self.archivedPositionToPosition(str_pos)

    c.setCurrentPosition(current or c.rootPosition())
#@+node:ekr.20061006104837.1:archivedPositionToPosition
def archivedPositionToPosition (self,s):

    c = self.c
    aList = s.split(',')
    try:
        aList = [int(z) for z in aList]
    except Exception:
        # g.trace('oops: bad archived position. not an int:',aList,c)
        aList = None
    if not aList: return None
    p = c.rootPosition() ; level = 0
    while level < len(aList):
        i = aList[level]
        while i > 0:
            if p.hasNext():
                p.moveToNext()
                i -= 1
            else:
                # g.trace('oops: bad archived position. no sibling:',aList,p.h,c)
                return None
        level += 1
        if level < len(aList):
            p.moveToFirstChild()
            # g.trace('level',level,'index',aList[level],p.h)
    return p
#@nonl
#@-node:ekr.20061006104837.1:archivedPositionToPosition
#@-node:ekr.20060919110638.13:setPositionsFromVnodes & helper
#@+node:ekr.20060919110638.37:startGlobals
def startGlobals (self,attrs):

    trace = False and not g.unitTesting
    c = self.c

    if self.inClipboard:
        return

    c.frame.ratio,c.frame.secondary_ratio = 0.5,0.5 # Set defaults.

    if trace: g.trace(len(list(c.db.keys())),c.mFileName)

    if g.enableDB and c.db and c.mFileName:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.frame.ratio = float(c.db.get(
            'body_outline_ratio_%s' % (key),'0.5'))
        c.frame.secondary_ratio = float(c.db.get(
            'body_secondary_ratio_%s' % (key),'0.5'))
        if trace: g.trace('key',key,
            '%1.2f %1.2f' % (c.frame.ratio,c.frame.secondary_ratio))
    else:
        try:
            for bunch in self.attrsToList(attrs):
                name = bunch.name ; val = bunch.val
                if name == 'body_outline_ratio':
                    c.frame.ratio = float(val) # 2010/01/11
                elif name == 'body_secondary_ratio':
                    c.frame.secondary_ratio = float(val) # 2010/01/11
            if trace: g.trace('** no c.db:','%1.2f %1.2f' % (
                c.frame.ratio,c.frame.secondary_ratio))
        except Exception:
            pass
#@-node:ekr.20060919110638.37:startGlobals
#@-node:ekr.20100129133806.6243:Reading
#@+node:ekr.20100129133806.6244:Writing
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20031218072017.3037:putGlobals
# Changed for Leo 4.0.

def putGlobals (self):

    trace = False and not g.unitTesting
    c = self.c

    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        if trace: g.trace(len(list(c.db.keys())),c.mFileName,key)
        << put all data to c.db >>

    # Always put positions, to trigger sax methods.
    self.put("<globals")
    << put the body/outline ratios >>
    self.put(">") ; self.put_nl()
    << put the position of this frame >>
    << put the position of the log window >>
    self.put("</globals>") ; self.put_nl()
#@+node:ekr.20100112095623.6267:<< put all data to c.db >>
c.db['body_outline_ratio_%s' % key] = str(c.frame.ratio)
c.db['body_secondary_ratio_%s' % key] = str(c.frame.secondary_ratio)

if trace: g.trace('ratios: %1.2f %1.2f' % (
    c.frame.ratio,c.frame.secondary_ratio))

width,height,left,top = c.frame.get_window_info()

c.db['window_position_%s' % key] = (
    str(top),str(left),str(height),str(width))

if trace: g.trace('top',top,'left',left,'height',height,'width',width)
#@-node:ekr.20100112095623.6267:<< put all data to c.db >>
#@+node:ekr.20031218072017.3038:<< put the body/outline ratios >>
self.put(" body_outline_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.ratio)))

self.put(" body_secondary_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.secondary_ratio)))

if trace: g.trace('fixed or use_db',c.fixed or use_db,
    '%1.2f %1.2f' % (c.frame.ratio,c.frame.secondary_ratio))
#@-node:ekr.20031218072017.3038:<< put the body/outline ratios >>
#@+node:ekr.20031218072017.3039:<< put the position of this frame >>
# New in Leo 4.5: support fixed .leo files.

if c.fixed or use_db:
    width,height,left,top = 700,500,50,50
        # Put fixed, immutable, reasonable defaults.
        # Leo 4.5 and later will ignore these when reading.
        # These should be reasonable defaults so that the
        # file will be opened properly by older versions
        # of Leo that do not support fixed .leo files.
else:
    width,height,left,top = c.frame.get_window_info()

# g.trace(width,height,left,top)

self.put_tab()
self.put("<global_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3039:<< put the position of this frame >>
#@+node:ekr.20031218072017.3040:<< put the position of the log window >>
top = left = height = width = 0 # no longer used

self.put_tab()
self.put("<global_log_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3040:<< put the position of the log window >>
#@-node:ekr.20031218072017.3037:putGlobals
#@-node:ekr.20100129133806.6244:Writing
#@-node:ekr.20100129133806.6242:Calls to _contentHashFile
#@-node:ekr.20100129131524.6190:improve caching
#@+node:ekr.20100129133806.6245:Found: c.db
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20070909100252:readOneAtAutoNode (atFile)
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None:
        cachefile = None
    else:
        cachefile = self._contentHashFile(p.h,s)

    # Remember that we have read this file.
    p.v.at_read = True # Create the attribute

    # Disable caching for test.leo.
    if c.shortFileName() != 'test.leo':
        if cachefile is not None and cachefile in c.db:        
            # g.es('uncache:',p.h)
            aList = c.db[cachefile]
            p.v.createOutlineFromCacheList(c,aList)
            return

    if not g.unitTesting:
        g.es("reading:",p.h)

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        # Note: the file contains an @ignore,
        # so no unintended write can happen.
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        self.writeCachedTree(p, cachefile)
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@-node:ekr.20070909100252:readOneAtAutoNode (atFile)
#@+node:ekr.20060919110638.13:setPositionsFromVnodes & helper
def setPositionsFromVnodes (self):

    trace = False and not g.unitTesting
    c = self.c ; p = c.rootPosition()
    current,str_pos = None,None
    use_db = g.enableDB and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        str_pos = c.db.get('current_position_%s' % key)
        if trace: g.trace('from c.db',str_pos,key)

    if not str_pos:
        d = hasattr(p.v,'unknownAttributes') and p.v.unknownAttributes
        if d: str_pos = d.get('str_leo_pos')
        if trace: g.trace('from p.v.u',str_pos)

    if str_pos:
        current = self.archivedPositionToPosition(str_pos)

    c.setCurrentPosition(current or c.rootPosition())
#@+node:ekr.20061006104837.1:archivedPositionToPosition
def archivedPositionToPosition (self,s):

    c = self.c
    aList = s.split(',')
    try:
        aList = [int(z) for z in aList]
    except Exception:
        # g.trace('oops: bad archived position. not an int:',aList,c)
        aList = None
    if not aList: return None
    p = c.rootPosition() ; level = 0
    while level < len(aList):
        i = aList[level]
        while i > 0:
            if p.hasNext():
                p.moveToNext()
                i -= 1
            else:
                # g.trace('oops: bad archived position. no sibling:',aList,p.h,c)
                return None
        level += 1
        if level < len(aList):
            p.moveToFirstChild()
            # g.trace('level',level,'index',aList[level],p.h)
    return p
#@nonl
#@-node:ekr.20061006104837.1:archivedPositionToPosition
#@-node:ekr.20060919110638.13:setPositionsFromVnodes & helper
#@+node:ekr.20031218072017.3037:putGlobals
# Changed for Leo 4.0.

def putGlobals (self):

    trace = False and not g.unitTesting
    c = self.c

    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        if trace: g.trace(len(list(c.db.keys())),c.mFileName,key)
        << put all data to c.db >>

    # Always put positions, to trigger sax methods.
    self.put("<globals")
    << put the body/outline ratios >>
    self.put(">") ; self.put_nl()
    << put the position of this frame >>
    << put the position of the log window >>
    self.put("</globals>") ; self.put_nl()
#@+node:ekr.20100112095623.6267:<< put all data to c.db >>
c.db['body_outline_ratio_%s' % key] = str(c.frame.ratio)
c.db['body_secondary_ratio_%s' % key] = str(c.frame.secondary_ratio)

if trace: g.trace('ratios: %1.2f %1.2f' % (
    c.frame.ratio,c.frame.secondary_ratio))

width,height,left,top = c.frame.get_window_info()

c.db['window_position_%s' % key] = (
    str(top),str(left),str(height),str(width))

if trace: g.trace('top',top,'left',left,'height',height,'width',width)
#@-node:ekr.20100112095623.6267:<< put all data to c.db >>
#@+node:ekr.20031218072017.3038:<< put the body/outline ratios >>
self.put(" body_outline_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.ratio)))

self.put(" body_secondary_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.secondary_ratio)))

if trace: g.trace('fixed or use_db',c.fixed or use_db,
    '%1.2f %1.2f' % (c.frame.ratio,c.frame.secondary_ratio))
#@-node:ekr.20031218072017.3038:<< put the body/outline ratios >>
#@+node:ekr.20031218072017.3039:<< put the position of this frame >>
# New in Leo 4.5: support fixed .leo files.

if c.fixed or use_db:
    width,height,left,top = 700,500,50,50
        # Put fixed, immutable, reasonable defaults.
        # Leo 4.5 and later will ignore these when reading.
        # These should be reasonable defaults so that the
        # file will be opened properly by older versions
        # of Leo that do not support fixed .leo files.
else:
    width,height,left,top = c.frame.get_window_info()

# g.trace(width,height,left,top)

self.put_tab()
self.put("<global_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3039:<< put the position of this frame >>
#@+node:ekr.20031218072017.3040:<< put the position of the log window >>
top = left = height = width = 0 # no longer used

self.put_tab()
self.put("<global_log_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3040:<< put the position of the log window >>
#@-node:ekr.20031218072017.3037:putGlobals
#@+node:ekr.20100112095623.6267:<< put all data to c.db >>
c.db['body_outline_ratio_%s' % key] = str(c.frame.ratio)
c.db['body_secondary_ratio_%s' % key] = str(c.frame.secondary_ratio)

if trace: g.trace('ratios: %1.2f %1.2f' % (
    c.frame.ratio,c.frame.secondary_ratio))

width,height,left,top = c.frame.get_window_info()

c.db['window_position_%s' % key] = (
    str(top),str(left),str(height),str(width))

if trace: g.trace('top',top,'left',left,'height',height,'width',width)
#@-node:ekr.20100112095623.6267:<< put all data to c.db >>
#@+node:ekr.20051104075904.4:doTests...
def doTests(c,all=None,p=None,verbosity=1):

    trace = False
    if all:
        p = c.rootPosition()
    elif not p:
        p = c.p
    p1 = p.copy()

    try:
        found = False ; verbose = True
        g.unitTesting = g.app.unitTesting = True
        g.app.unitTestDict["fail"] = False
        g.app.unitTestDict['c'] = c
        g.app.unitTestDict['g'] = g
        g.app.unitTestDict['p'] = p and p.copy()

        # c.undoer.clearUndoState() # New in 4.3.1.
        changed = c.isChanged()
        suite = unittest.makeSuite(unittest.TestCase)

        # New in Leo 4.4.8: ignore everything in @ignore trees.
        if all: last = None
        else:   last = p.nodeAfterTree()
        if trace: g.trace('all',all,'root',p.h)
        while p and p != last:
            if g.match_word(p.h,0,'@ignore'):
                if trace: g.trace('ignoring',p.h)
                p.moveToNodeAfterTree()
            elif isTestNode(p): # @test
                if trace: g.trace('adding',p.h)
                test = makeTestCase(c,p)
                if test:
                    suite.addTest(test) ; found = True
                p.moveToThreadNext()
            elif isSuiteNode(p): # @suite
                if trace: g.trace('adding',p.h)
                test = makeTestSuite(c,p)
                if test:
                    suite.addTest(test) ; found = True
                p.moveToThreadNext()
            else:
                if trace and verbose: g.trace('skipping',p.h)
                p.moveToThreadNext()

        # Verbosity: 1: print just dots.
        if found:
            res = unittest.TextTestRunner(verbosity=verbosity).run(suite)
            # put info to db as well
            if g.enableDB:
                key = 'unittest/cur/fail'
                archive = [(t.p.gnx, trace) for (t, trace) in res.errors]
                c.db[key] = archive
        else:
            g.es_print('no @test or @suite nodes in %s outline' % (
                g.choose(all,'entire','selected')),color='red')
    finally:
        c.setChanged(changed) # Restore changed state.
        if g.app.unitTestDict.get('restoreSelectedNode',True):
            c.redraw(p1)
        g.unitTesting = g.app.unitTesting = False
#@+node:ekr.20051104075904.5:class generalTestCase
class generalTestCase(unittest.TestCase):

    """Create a unit test from a snippet of code."""

    @others
#@+node:ekr.20051104075904.6:__init__
def __init__ (self,c,p):

     # Init the base class.
    unittest.TestCase.__init__(self)

    self.c = c
    self.p = p.copy()
#@-node:ekr.20051104075904.6:__init__
#@+node:ekr.20051104075904.7: fail
def fail (self,msg=None):

    """Mark a unit test as having failed."""

    import leo.core.leoGlobals as g

    g.app.unitTestDict["fail"] = g.callers()
#@-node:ekr.20051104075904.7: fail
#@+node:ekr.20051104075904.9:tearDown
def tearDown (self):

    pass

    # Restore the outline.
    self.c.outerUpdate()
#@nonl
#@-node:ekr.20051104075904.9:tearDown
#@+node:ekr.20051104075904.8:setUp
def setUp (self):

    c = self.c ; p = self.p

    c.selectPosition(p)
#@-node:ekr.20051104075904.8:setUp
#@+node:ekr.20051104075904.10:runTest
def runTest (self,define_g = True):

    c = self.c ; p = self.p.copy()
    script = g.getScript(c,p).strip()
    # print ('p',p,'len(script)',len(script))
    self.assert_(script)
    writeScriptFile = c.config.getBool('write_script_file')

    # import leo.core.leoGlobals as g

    # New in Leo 4.4.3: always define the entries in g.app.unitTestDict.
    g.app.unitTestDict = {'c':c,'g':g,'p':p and p.copy()}

    if define_g:
        d = {'c':c,'g':g,'p':p,'self':self,}
    else:
        d = {'self':self,}

    script = script + '\n'
    # g.trace(type(script),script)

    # Execute the script. Let unit test handle any errors!
    if writeScriptFile:
        scriptFile = c.writeScriptFile(script)

    exec(script,d)
#@-node:ekr.20051104075904.10:runTest
#@+node:ekr.20051104075904.11:shortDescription
def shortDescription (self):

    s = self.p.h

    # g.trace(s)

    return s + '\n'
#@-node:ekr.20051104075904.11:shortDescription
#@-node:ekr.20051104075904.5:class generalTestCase
#@+node:ekr.20051104075904.12:makeTestSuite
@ This code executes the script in an @suite node.  This code assumes:
- The script creates a one or more unit tests.
- The script puts the result in g.app.scriptDict["suite"]
@c

def makeTestSuite (c,p):

    """Create a suite of test cases by executing the script in an @suite node."""

    p = p.copy()

    script = g.getScript(c,p).strip()
    if not script:
        print("no script in %s" % h)
        return None
    try:
        if 0: #debugging
            n,lines = 0,g.splitLines(script)
            for line in lines:
                print(n,line)
                n += 1
        exec(script + '\n',{'c':c,'g':g,'p':p})
        suite = g.app.scriptDict.get("suite")
        if not suite:
            print("makeTestSuite: %s script did not set g.app.scriptDict" % p.h)
        return suite
    except Exception:
        print('makeTestSuite: exception creating test cases for %s' % p.h)
        g.es_exception()
        return None
#@-node:ekr.20051104075904.12:makeTestSuite
#@+node:ekr.20051104075904.13:makeTestCase
def makeTestCase (c,p):

    p = p.copy()

    if p.b.strip():
        return generalTestCase(c,p)
    else:
        return None
#@-node:ekr.20051104075904.13:makeTestCase
#@-node:ekr.20051104075904.4:doTests...
#@+node:ekr.20060919110638.36:getPositionAttributes
def getPositionAttributes (self,attrs):

    trace = False and not g.unitTesting
    c = self.c

    if trace: g.trace(len(list(c.db.keys())),c.mFileName,self.fileName)

    d = {}

    if g.enableDB and c.db and c.mFileName:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        data = c.db.get('window_position_%s' % (key))
        if data:
            top,left,height,width = data
            top,left,height,width = int(top),int(left),int(height),int(width)
            d = {'top':top,'left':left,'height':height,'width':width}

    if not d and c.fixed and c.fixedWindowPosition:
        width,height,left,top = c.fixedWindowPosition
        d = {'top':top,'left':left,'width':width,'height':height}

    if not d:
        for bunch in self.attrsToList(attrs):
            name = bunch.name ; val = bunch.val
            if name in ('top','left','width','height'):
                try:
                    d[name] = int(val)
                except ValueError:
                    d[name] = 100 # A reasonable default.
            else:
                g.trace(name,len(val))

    # if trace: g.trace(d)
    return d
#@-node:ekr.20060919110638.36:getPositionAttributes
#@+node:ekr.20060919110638.37:startGlobals
def startGlobals (self,attrs):

    trace = False and not g.unitTesting
    c = self.c

    if self.inClipboard:
        return

    c.frame.ratio,c.frame.secondary_ratio = 0.5,0.5 # Set defaults.

    if trace: g.trace(len(list(c.db.keys())),c.mFileName)

    if g.enableDB and c.db and c.mFileName:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.frame.ratio = float(c.db.get(
            'body_outline_ratio_%s' % (key),'0.5'))
        c.frame.secondary_ratio = float(c.db.get(
            'body_secondary_ratio_%s' % (key),'0.5'))
        if trace: g.trace('key',key,
            '%1.2f %1.2f' % (c.frame.ratio,c.frame.secondary_ratio))
    else:
        try:
            for bunch in self.attrsToList(attrs):
                name = bunch.name ; val = bunch.val
                if name == 'body_outline_ratio':
                    c.frame.ratio = float(val) # 2010/01/11
                elif name == 'body_secondary_ratio':
                    c.frame.secondary_ratio = float(val) # 2010/01/11
            if trace: g.trace('** no c.db:','%1.2f %1.2f' % (
                c.frame.ratio,c.frame.secondary_ratio))
        except Exception:
            pass
#@-node:ekr.20060919110638.37:startGlobals
#@+node:ville.20090606131405.6362:writeCachedTree (atFile)
def writeCachedTree(self, p, cachefile):

    trace = False and not g.unitTesting
    c = self.c

    if not g.enableDB or g.app.unitTesting:
        if trace: g.trace('cache disabled')
    elif cachefile in c.db:
        if trace: g.trace('already cached')
    else:
        if trace: g.trace('caching ',p.h)
        c.db[cachefile] = p.makeCacheList()
#@nonl
#@-node:ville.20090606131405.6362:writeCachedTree (atFile)
#@-node:ekr.20100129133806.6245:Found: c.db
#@+node:ekr.20100130042842.6404:Reading settings
Here are the calls to g.app.getxxx

# runLeo.createFrame
fileName = g.app.config.getString(c=None,setting='default_leo_file')

# c.configSettings.initIvar
# Why not init these settings by hand???
val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

# g.es and g.es_print
keys['color'] = g.app.config.getColor(None,"log_error_color") or 'red'

# leoPlugins.loadHandlers
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')
s = g.app.config.getEnabledPlugins()

# leoPlugins.loadOnePlugin
verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

#@+node:ekr.20041120064303:readSettingsFiles & helpers (g.app.config)
def readSettingsFiles (self,fileName,verbose=True):

    trace = False and not g.unitTesting
    seen = []
    self.write_recent_files_as_needed = False # Will be set later.
    << define localDirectory, localConfigFile & myLocalConfigFile >>

    if trace: g.trace(g.callers(5))
    table = (
        (self.globalConfigFile,False),
        (self.homeFile,False),
        (localConfigFile,False),
        (self.myGlobalConfigFile,False),
        (self.myHomeConfigFile,False),
        (self.machineConfigFile,False),
        (myLocalConfigFile,False),
        # New in Leo 4.6: the -c file is in *addition* to other config files.
        (g.app.oneConfigFilename,False),
        (fileName,True),
    )

    # Init settings from leoSettings.leo and myLeoSettings.leo files.
    for path,localFlag in table:
        if path:
            path = g.os_path_realpath(g.os_path_finalize(path))
            # Bug fix: 6/3/08: make sure we mark files seen no matter how they are specified.
        isZipped = path and zipfile.is_zipfile(path)
        isLeo = isZipped or (path and path.endswith('.leo'))
        if isLeo and path and path.lower() not in seen and g.os_path_exists(path):
            seen.append(path.lower())
            if verbose and not g.app.unitTesting and not self.silent and not g.app.batchMode:
                s = 'reading settings in %s' % path
                # This occurs early in startup, so use the following instead of g.es_print.
                if not g.isPython3:
                    s = g.toEncodedString(s,'ascii')
                g.es_print(s,color='blue')
            c = self.openSettingsFile(path)
            if c:
                self.updateSettings(c,localFlag)
                g.app.destroyWindow(c.frame)
                self.write_recent_files_as_needed = c.config.getBool(
                    'write_recent_files_as_needed')
                if 0:
                    # This is useless. setIvarsFromSettings does nothing
                    # until the self.inited flag is True.
                    g.trace('?' * 20,c)
                    self.setIvarsFromSettings(c)
    self.readRecentFiles(localConfigFile)
    # self.createMyLeoSettingsFile(myLocalConfigFile)
    self.inited = True
    self.setIvarsFromSettings(None)
#@+node:ekr.20061028082834:<< define localDirectory, localConfigFile & myLocalConfigFile >>
# This can't be done in initSettingsFiles because
# the local directory does not yet exist.
localDirectory = g.os_path_dirname(fileName)

#  Set the local leoSettings.leo file.
localConfigFile = g.os_path_join(localDirectory,'leoSettings.leo')
if not g.os_path_exists(localConfigFile):
    localConfigFile = None

# Set the local myLeoSetting.leo file.
myLocalConfigFile = g.os_path_join(localDirectory,'myLeoSettings.leo')
if not g.os_path_exists(myLocalConfigFile):
    myLocalConfigFile = None
#@nonl
#@-node:ekr.20061028082834:<< define localDirectory, localConfigFile & myLocalConfigFile >>
#@+node:ekr.20041117085625:openSettingsFile
def openSettingsFile (self,path):

    theFile,isZipped = g.openLeoOrZipFile(path)
    if not theFile: return None

    # Similar to g.openWithFileName except it uses a null gui.
    # Changing g.app.gui here is a major hack.
    oldGui = g.app.gui
    g.app.gui = leoGui.nullGui("nullGui")
    c,frame = g.app.newLeoCommanderAndFrame(
        fileName=path,relativeFileName=None,
        initEditCommanders=False,updateRecentFiles=False)
    frame.log.enable(False)
    c.setLog()
    g.app.lockLog()
    ok = frame.c.fileCommands.open(
        theFile,path,readAtFileNodesFlag=False,silent=True) # closes theFile.
    g.app.unlockLog()
    c.openDirectory = frame.openDirectory = g.os_path_dirname(path)
    g.app.gui = oldGui
    return ok and c
#@-node:ekr.20041117085625:openSettingsFile
#@+node:ekr.20051013161232:updateSettings
def updateSettings (self,c,localFlag):

    d = self.readSettings(c,localFlag)

    if d:
        d['_hash'] = theHash = c.hash()
        if localFlag:
            self.localOptionsDict[theHash] = d
        else:
            self.localOptionsList.insert(0,d)

    if 0: # Good trace.
        if localFlag:
            g.trace(c.fileName())
            g.trace(d and list(d.keys()))
#@-node:ekr.20051013161232:updateSettings
#@-node:ekr.20041120064303:readSettingsFiles & helpers (g.app.config)
#@+node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20041118104240:initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@-node:ekr.20041118104240:initIvar (c.configSettings)
#@+node:ekr.20041118104414:initEncoding
def initEncoding (self,key):

    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.encodingIvarsDict.get(key)
    encodingName = bunch.ivar
    encoding = g.app.config.get(c,encodingName,kind='string')

    # New in 4.4b3: use the global setting as a last resort.
    if encoding:
        # g.trace('c.configSettings',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)
    else:
        encoding = getattr(g.app.config,encodingName)
        # g.trace('g.app.config',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)

    if encoding and not g.isValidEncoding(encoding):
        g.es("bad", "%s: %s" % (encodingName,encoding))
#@-node:ekr.20041118104414:initEncoding
#@-node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
#@+node:ekr.20041118084146.1:set (g.app.config) To be deleted??
def set (self,c,setting,kind,val):

    '''Set the setting.  Not called during initialization.'''

    trace = False and not g.unitTesting
    found = False ;  key = self.munge(setting)
    if trace: g.trace(setting,kind,val)

    if c:
        d = self.localOptionsDict.get(c.hash())
        if d: found = True

    if not found:
        theHash = c.hash()
        for d in self.localOptionsList:
            hash2 = d.get('_hash')
            if theHash == hash2:
                found = True ; break

    if not found:
        d = self.dictList [0]

    d[key] = g.Bunch(setting=setting,kind=kind,val=val,tag='setting')

    if 0:
        dkind = d.get('_hash','<no hash: %s>' % c.hash())
        g.trace(dkind,setting,kind,val)
#@-node:ekr.20041118084146.1:set (g.app.config) To be deleted??
#@+node:ekr.20041118104240:initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@-node:ekr.20041118104240:initIvar (c.configSettings)
#@+node:ekr.20041228042224:setIvarsFromSettings (g.app.config)
def setIvarsFromSettings (self,c):

    '''Init g.app.config ivars or c's ivars from settings.

    - Called from readSettingsFiles with c = None to init g.app.config ivars.
    - Called from c.__init__ to init corresponding commmander ivars.'''

    trace = False and not g.unitTesting
    verbose = True

    # Ingore temporary commanders created by readSettingsFiles.
    if self.inited:
        if trace:
            if c:
                g.trace('=' * 10, 'inited',c.shortFileName(),g.callers(4))
            else:
                tag = '<no c: called at end of readSettingsFiles>'
                g.trace('=' * 10, 'inited',tag,g.callers(1))
    else:
        if trace and verbose: g.trace('*' * 10,'not inited.  do nothing')
        return

    d = self.ivarsDict
    keys = list(d.keys())
    keys.sort()
    for key in keys:
        if key != '_hash':
            bunch = d.get(key)
            if bunch:
                ivar = bunch.ivar # The actual name of the ivar.
                kind = bunch.kind
                val = self.get(c,key,kind) # Don't use bunch.val!
                if c:
                    if trace: g.trace("%20s %s = %s" % (
                        g.shortFileName(c.mFileName),ivar,val))
                    setattr(c,ivar,val)
                else:
                    if trace: g.trace("%20s %s = %s" % (
                        'g.app.config',ivar,val))
                    setattr(self,ivar,val)
#@-node:ekr.20041228042224:setIvarsFromSettings (g.app.config)
#@-node:ekr.20100130042842.6404:Reading settings
#@+node:ekr.20100130042842.9008:Using g.app.config ivars
@nocolor-node

colorizeAnyLanguage.
    g.app.config.defaultFontFamily

c.scanAtPathDirectives:
    relative_path_base_directory:

** Methods that write recent files:
    recentFileMessageWritten (Probabaly ok)

c.configSettings.__init__:

** copies these ivars by hand.
    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize
** calls initIvar and initEncoding to copy other ivars.

g.makeAllNonExistentDirectories:
    # Uses one or the other, depending on the c arg.
    c.create_nonexistent_directories
    g.app.config.create_nonexistent_directories

g.getOutputNewline:
    # Uses one or the other, depending on the c arg.
    c.config.output_newline
    g.app.config.output_newline

g.doHook:
    g.app.config.use_plugins

loadOnePlugin:
    g.app.config.enabledPluginsFileName

leoGui.getFontFromParams:
    g.app.config.defaultFont

k.addModeCommands and several other methods use:
    g.app.config.modeCommandsDict
#@nonl
#@+node:ekr.20031218072017.1880:colorizeAnyLanguage & allies
def colorizeAnyLanguage (self,p,leading=None,trailing=None):

    """Color the body pane either incrementally or non-incrementally"""

    c = self.c ; w = c.frame.body.bodyCtrl

    if not c.config.getBool('use_syntax_coloring'):
        # There have been reports of this trace causing crashes.
        # Certainly it is not necessary.
        # g.trace('no coloring')
        return

    if self.killFlag:
        self.removeAllTags()
        return
    try:
        # g.trace('incremental',self.incremental)
        << initialize ivars & tags >>
        g.doHook("init-color-markup",colorer=self,p=self.p,v=self.p)
        if self.incremental and (
            << all state ivars match >> ):
            << incrementally color the text >>
        else:
            << non-incrementally color the text >>
        << update state ivars >>
        return "ok" # for testing.
    except:
        << set state ivars to "unknown" >>
        if self.c:
            g.es_exception()
        else:
            import traceback ; traceback.print_exc()
        return "error" # for unit testing.
#@+node:ekr.20031218072017.1602:<< initialize ivars & tags >> colorizeAnyLanguage
# Copy the arguments.
self.p = p

# Get the body text, converted to unicode.
self.allBodyText = w.getAllText()
sel = w.getInsertPoint()
start,end = g.convertPythonIndexToRowCol(self.allBodyText,sel)
start += 1 # Simulate the old 1-based Tk scheme.  self.index undoes this hack.
# g.trace('new',start,end)

if self.language: self.language = self.language.lower()
# g.trace(self.count,self.p)
# g.trace(body.tag_names())

if not self.incremental:
    self.removeAllTags()
    # self.removeAllImages()

<< configure fonts >>
<< configure tags >>
<< configure language-specific settings >>

self.hyperCount = 0 # Number of hypertext tags
self.count += 1
lines = self.allBodyText.split('\n')
#@nonl
#@+node:ekr.20060829084924:<< configure fonts >> (revise,maybe)
# Get the default body font.
defaultBodyfont = self.fonts.get('default_body_font')
if not defaultBodyfont:
    defaultBodyfont = c.config.getFontFromParams(
        "body_text_font_family", "body_text_font_size",
        "body_text_font_slant",  "body_text_font_weight",
        c.config.defaultBodyFontSize)
    self.fonts['default_body_font'] = defaultBodyfont

# Configure fonts.
w = c.frame.body.bodyCtrl
keys = sorted(default_font_dict)
for key in keys:
    option_name = default_font_dict[key]
    # First, look for the language-specific setting, then the general setting.
    for name in ('%s_%s' % (self.language,option_name),(option_name)):
        font = self.fonts.get(name)
        if font:
            # g.trace('found',name,id(font))
            w.tag_config(key,font=font)
            break
        else:
            family = c.config.get(name + '_family','family')
            size   = c.config.get(name + '_size',  'size')   
            slant  = c.config.get(name + '_slant', 'slant')
            weight = c.config.get(name + '_weight','weight')
            if family or slant or weight or size:
                family = family or g.app.config.defaultFontFamily
                size   = size or str(c.config.defaultBodyFontSize)
                slant  = slant or 'roman'
                weight = weight or 'normal'
                font = c.config.getFontFromParams(family,size,slant,weight)
                # Save a reference to the font so it 'sticks'.
                self.fonts[name] = font 
                # g.trace(key,name,family,size,slant,weight,id(font))
                w.tag_config(key,font=font)
                break
    else: # Neither the general setting nor the language-specific setting exists.
        if len(list(self.fonts.keys())) > 1: # Restore the default font.
            # g.trace('default',key)
            w.tag_config(key,font=defaultBodyfont)
#@nonl
#@-node:ekr.20060829084924:<< configure fonts >> (revise,maybe)
#@+node:ekr.20031218072017.1603:<< configure tags >>
# g.trace('configure tags',self.c.frame.body.bodyCtrl)

for name in default_colors_dict:
    option_name,default_color = default_colors_dict[name]
    option_color = c.config.getColor(option_name)
    color = g.choose(option_color,option_color,default_color)
    # g.trace(name,color)
    # Must use foreground, not fg.
    try:
        c.frame.body.tag_configure(name, foreground=color)
    except: # Recover after a user error.
        c.frame.body.tag_configure(name, foreground=default_color)

underline_undefined = c.config.getBool("underline_undefined_section_names")
use_hyperlinks      = c.config.getBool("use_hyperlinks")
self.use_hyperlinks = use_hyperlinks

# underline=var doesn't seem to work.
if 0: # use_hyperlinks: # Use the same coloring, even when hyperlinks are in effect.
    c.frame.body.tag_configure("link",underline=1) # defined
    c.frame.body.tag_configure("name",underline=0) # undefined
else:
    c.frame.body.tag_configure("link",underline=0)
    if underline_undefined:
        c.frame.body.tag_configure("name",underline=1)
    else:
        c.frame.body.tag_configure("name",underline=0)

# 8/4/02: we only create tags for whitespace when showing invisibles.
if self.showInvisibles:
    for name,option_name,default_color in (
        ("blank","show_invisibles_space_background_color","Gray90"),
        ("tab",  "show_invisibles_tab_background_color",  "Gray80")):
        option_color = c.config.getColor(option_name)
        color = g.choose(option_color,option_color,default_color)
        try:
            c.frame.body.tag_configure(name,background=color)
        except: # Recover after a user error.
            c.frame.body.tag_configure(name,background=default_color)

# 11/15/02: Colors for latex characters.  Should be user options...

if 1: # Alas, the selection doesn't show if a background color is specified.
    c.frame.body.tag_configure("latexModeBackground",foreground="black")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue")
    c.frame.body.tag_configure("latexBackground",foreground="black")
    c.frame.body.tag_configure("latexKeyword",foreground="blue")
else: # Looks cool, and good for debugging.
    c.frame.body.tag_configure("latexModeBackground",foreground="black",background="seashell1")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue",background="seashell1")
    c.frame.body.tag_configure("latexBackground",foreground="black",background="white")
    c.frame.body.tag_configure("latexKeyword",foreground="blue",background="white")

# Tags for wiki coloring.
if self.showInvisibles:
    c.frame.body.tag_configure("elide",background="yellow")
else:
    c.frame.body.tag_configure("elide",elide="1")
c.frame.body.tag_configure("bold",font=self.bold_font)
c.frame.body.tag_configure("italic",font=self.italic_font)
c.frame.body.tag_configure("bolditalic",font=self.bolditalic_font)
for name in self.color_tags_list:
    c.frame.body.tag_configure(name,foreground=name)
#@-node:ekr.20031218072017.1603:<< configure tags >>
#@+node:ekr.20031218072017.370:<< configure language-specific settings >> colorizer
# Define has_string, keywords, single_comment_start, block_comment_start, block_comment_end.

if self.language == "cweb": # Use C comments, not cweb sentinel comments.
    delim1,delim2,delim3 = g.set_delims_from_language("c")
elif self.comment_string:
    delim1,delim2,delim3 = g.set_delims_from_string(self.comment_string)
elif self.language == "plain": # 1/30/03
    delim1,delim2,delim3 = None,None,None
else:
    delim1,delim2,delim3 = g.set_delims_from_language(self.language)

self.single_comment_start = delim1
self.block_comment_start = delim2
self.block_comment_end = delim3

# A strong case can be made for making this code as fast as possible.
# Whether this is compatible with general language descriptions remains to be seen.
self.case_sensitiveLanguage = self.language not in case_insensitiveLanguages
self.has_string = self.language != "plain"
if self.language == "plain":
    self.string_delims = ()
elif self.language in ("elisp","html"):
    self.string_delims = ('"')
else:
    self.string_delims = ("'",'"')
self.has_pp_directives = self.language in ("c","csharp","cweb","latex")

# The list of languages for which keywords exist.
# Eventually we might just use language_delims_dict.keys()
languages = [
    "actionscript","ada","c","csharp","css","cweb","elisp","html","java","latex","lua",
    "pascal","perl","perlpod","php","plsql","python","rapidq","rebol","ruby","shell","tcltk"]

self.keywords = []
if self.language == "cweb":
    for i in self.c_keywords:
        self.keywords.append(i)
    for i in self.cweb_keywords:
        self.keywords.append(i)
else:
    for name in languages:
        if self.language==name: 
            # g.trace("setting keywords for",name)
            self.keywords = getattr(self, name + "_keywords")

# Color plain text unless we are under the control of @nocolor.
# state = g.choose(self.flag,"normal","nocolor")
state = self.setFirstLineState()

if 1: # 10/25/02: we color both kinds of references in cweb mode.
    self.lb = "<<"
    self.rb = ">>"
else:
    self.lb = g.choose(self.language == "cweb","@<","<<")
    self.rb = g.choose(self.language == "cweb","@>",">>")
#@-node:ekr.20031218072017.370:<< configure language-specific settings >> colorizer
#@-node:ekr.20031218072017.1602:<< initialize ivars & tags >> colorizeAnyLanguage
#@+node:ekr.20031218072017.1881:<< all state ivars match >>
self.flag == self.last_flag and
self.last_language == self.language
#@-node:ekr.20031218072017.1881:<< all state ivars match >>
#@+node:ekr.20031218072017.1882:<< incrementally color the text >>
@  Each line has a starting state.  The starting state for the first line is always "normal".

We need remember only self.lines and self.states between colorizing.  It is not necessary to know where the text comes from, only what the previous text was!  We must always colorize everything when changing nodes, even if all lines match, because the context may be different.

We compute the range of lines to be recolored by comparing leading lines and trailing lines of old and new text.  All other lines (the middle lines) must be colorized, as well as any trailing lines whose states may have changed as the result of changes to the middle lines.
@c

if self.trace: g.trace("incremental",self.language)

# 6/30/03: make a copies of everything
old_lines = self.lines[:]
old_states = self.states[:]
new_lines = lines[:]
new_states = []

new_len = len(new_lines)
old_len = len(old_lines)

if new_len == 0:
    self.states = []
    self.lines = []
    return

# Bug fix: 11/21/02: must test against None.
if leading != None and trailing != None:
    # g.pr("leading,trailing:",leading,trailing)
    leading_lines = leading
    trailing_lines = trailing
else:
    << compute leading, middle & trailing lines >>

middle_lines = new_len - leading_lines - trailing_lines
# g.pr("middle lines", middle_lines)

<< clear leading_lines if middle lines involve @color or @recolor  >>
<< initialize new states >>
<< colorize until the states match >>
#@+node:ekr.20031218072017.1883:<< compute leading, middle & trailing  lines >>
@ The leading lines are the leading matching lines.  The trailing lines are the trailing matching lines.  The middle lines are all other new lines.  We will color at least all the middle lines.  There may be no middle lines if we delete lines.
@c

min_len = min(old_len,new_len)

i = 0
while i < min_len:
    if old_lines[i] != new_lines[i]:
        break
    i += 1
leading_lines = i

if leading_lines == new_len:
    # All lines match, and we must color _everything_.
    # (several routine delete, then insert the text again,
    # deleting all tags in the process).
    # g.pr("recolor all")
    leading_lines = trailing_lines = 0
else:
    i = 0
    while i < min_len - leading_lines:
        if old_lines[old_len-i-1] != new_lines[new_len-i-1]:
            break
        i += 1
    trailing_lines = i
#@-node:ekr.20031218072017.1883:<< compute leading, middle & trailing  lines >>
#@+node:ekr.20031218072017.1884:<< clear leading_lines if middle lines involve @color or @recolor  >>
@ 11/19/02: Changing @color or @nocolor directives requires we recolor all leading states as well.
@c

if trailing_lines == 0:
    m1 = new_lines[leading_lines:]
    m2 = old_lines[leading_lines:]
else:
    m1 = new_lines[leading_lines:-trailing_lines]
    m2 = old_lines[leading_lines:-trailing_lines]
m1.extend(m2) # m1 now contains all old and new middle lines.
if m1:
    for s in m1:
        ### s = g.toUnicode(s)
        i = g.skip_ws(s,0)
        if g.match_word(s,i,"@color") or g.match_word(s,i,"@nocolor"):
            leading_lines = 0
            break
#@-node:ekr.20031218072017.1884:<< clear leading_lines if middle lines involve @color or @recolor  >>
#@+node:ekr.20031218072017.1885:<< initialize new states >>
# Copy the leading states from the old to the new lines.
i = 0
while i < leading_lines and i < old_len: # 12/8/02
    new_states.append(old_states[i])
    i += 1

# We know the starting state of the first middle line!
if middle_lines > 0 and i < old_len:
    new_states.append(old_states[i])
    i += 1

# Set the state of all other middle lines to "unknown".
first_trailing_line = max(0,new_len - trailing_lines)
while i < first_trailing_line:
    new_states.append("unknown")
    i += 1

# Copy the trailing states from the old to the new lines.
i = max(0,old_len - trailing_lines)
while i < old_len and i < len(old_states):
    new_states.append(old_states[i])
    i += 1

# 1/8/03: complete new_states by brute force.
while len(new_states) < new_len:
    new_states.append("unknown")
#@-node:ekr.20031218072017.1885:<< initialize new states >>
#@+node:ekr.20031218072017.1886:<< colorize until the states match >>
# Colorize until the states match.
# All middle lines have "unknown" state, so they will all be colored.

# Start in the state _after_ the last leading line, which may be unknown.
i = leading_lines
while i > 0:
    if i < old_len and i < new_len:
        state = new_states[i]
        # assert(state!="unknown") # This can fail.
        break
    else:
        i -= 1

if i == 0:
    # Color plain text unless we are under the control of @nocolor.
    # state = g.choose(self.flag,"normal","nocolor")
    state = self.setFirstLineState()
    new_states[0] = state

# The new_states[] will be "unknown" unless the lines match,
# so we do not need to compare lines here.
while i < new_len:
    self.line_index = i + 1
    state = self.colorizeLine(new_lines[i],state)
    i += 1
    # Set the state of the _next_ line.
    if i < new_len and state != new_states[i]:
        new_states[i] = state
    else: break

# Update the ivars
self.states = new_states
self.lines = new_lines
#@-node:ekr.20031218072017.1886:<< colorize until the states match >>
#@-node:ekr.20031218072017.1882:<< incrementally color the text >>
#@+node:ekr.20031218072017.1887:<< non-incrementally color the text >>
if self.trace: g.trace("non-incremental",self.language)

self.line_index = 1 # The Tk line number for indices, as in n.i
for s in lines:
    state = self.colorizeLine(s,state)
    self.line_index += 1
#@-node:ekr.20031218072017.1887:<< non-incrementally color the text >>
#@+node:ekr.20031218072017.1888:<< update state ivars >>
self.last_flag = self.flag
self.last_language = self.language
#@nonl
#@-node:ekr.20031218072017.1888:<< update state ivars >>
#@+node:ekr.20031218072017.1889:<< set state ivars to "unknown" >>
self.last_flag = "unknown"
self.last_language = "unknown"
#@-node:ekr.20031218072017.1889:<< set state ivars to "unknown" >>
#@-node:ekr.20031218072017.1880:colorizeAnyLanguage & allies
#@+node:ekr.20080828103146.15:c.scanAtPathDirectives & test
def scanAtPathDirectives(self,aList,force=False,createPath=True):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and not g.unitTesting
    verbose = True

    c = self

    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and path not in paths: paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    if trace and verbose: g.trace('paths  ',paths)

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose: g.printList(paths,tag='c.scanAtPathDirectives: raw paths')
    path = c.os_path_finalize_join(*paths)
    if trace and verbose: g.trace('joined path:',path)

    # Step 4: Make the path if necessary.
    if path and createPath and not g.os_path_exists(path):
        ok = g.makeAllNonExistentDirectories(path,c=c,force=force)
        if not ok:
            if force:
                g.es_print('c.scanAtPathDirectives: invalid @path: %s' % (path),color='red')
            path = absbase # Bug fix: 2008/9/18

    if trace: g.trace('returns',path)

    return path
#@+node:ekr.20090527080219.5870:@test c.scanAtPathDirectives
if g.unitTesting:

    c,p = g.getTestVars()
    p2 = p.firstChild().firstChild().firstChild()

    aList = g.get_directives_dict_list(p2)
    path = c.scanAtPathDirectives(aList,createPath=False)
    # print (path,p2.h)
    endpath = g.os_path_normpath('one/two')
    assert path and path.endswith(endpath),'expected ending %s got %s' % (
        endpath,path)
#@+node:ekr.20090530055015.6121:@path one
#@+node:ekr.20090530055015.6073:@path two
#@+node:ekr.20090530055015.6074:xyz
#@-node:ekr.20090530055015.6074:xyz
#@-node:ekr.20090530055015.6073:@path two
#@-node:ekr.20090530055015.6121:@path one
#@-node:ekr.20090527080219.5870:@test c.scanAtPathDirectives
#@-node:ekr.20080828103146.15:c.scanAtPathDirectives & test
#@+node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20041118104240:initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@-node:ekr.20041118104240:initIvar (c.configSettings)
#@+node:ekr.20041118104414:initEncoding
def initEncoding (self,key):

    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.encodingIvarsDict.get(key)
    encodingName = bunch.ivar
    encoding = g.app.config.get(c,encodingName,kind='string')

    # New in 4.4b3: use the global setting as a last resort.
    if encoding:
        # g.trace('c.configSettings',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)
    else:
        encoding = getattr(g.app.config,encodingName)
        # g.trace('g.app.config',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)

    if encoding and not g.isValidEncoding(encoding):
        g.es("bad", "%s: %s" % (encodingName,encoding))
#@-node:ekr.20041118104414:initEncoding
#@-node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
#@+node:ekr.20031218072017.3119:g.makeAllNonExistentDirectories
# This is a generalization of os.makedir.

def makeAllNonExistentDirectories (theDir,c=None,force=False,verbose=True):

    """Attempt to make all non-existent directories"""

    trace = False and not g.unitTesting

    if force:
        create = True # Bug fix: g.app.config will not exist during startup.
    elif c:
        create = c.config and c.config.create_nonexistent_directories
    else:
        create = (g.app and g.app.config and
            g.app.config.create_nonexistent_directories)

    if trace: g.trace('c exists: %s force: %s create: %s dir: %s' % (
        c is not None,force,create,theDir))

    if not force and not create:
        return None

    if c: theDir = g.os_path_expandExpression(theDir,c=c)

    dir1 = theDir = g.os_path_normpath(theDir)

    # Split theDir into all its component parts.
    paths = []
    while len(theDir) > 0:
        head,tail=g.os_path_split(theDir)
        if len(tail) == 0:
            paths.append(head)
            break
        else:
            paths.append(tail)
            theDir = head
    path = ""
    paths.reverse()
    for s in paths:
        path = g.os_path_join(path,s)
        if not g.os_path_exists(path):
            try:
                os.mkdir(path)
                if verbose and not g.app.unitTesting:
                    # g.trace('***callers***',g.callers(5))
                    g.es_print("created directory:",path,color='red')
            except Exception:
                # g.trace(g.callers())
                if verbose: g.es_print("exception creating directory:",path,color='red')
                g.es_exception()
                return None
    return dir1 # All have been created.
#@-node:ekr.20031218072017.3119:g.makeAllNonExistentDirectories
#@+node:ekr.20031218072017.1386:g.getOutputNewline
def getOutputNewline (c=None,name=None):

    '''Convert the name of a line ending to the line ending itself.

    Priority:
    - Use name if name given
    - Use c.config.output_newline if c given,
    - Otherwise use g.app.config.output_newline.'''

    if name: s = name
    elif c:  s = c.config.output_newline
    else:    s = app.config.output_newline

    if not s: s = ''
    s = s.lower()
    if s in ( "nl","lf"): s = '\n'
    elif s == "cr": s = '\r'
    elif s == "platform": s = os.linesep  # 12/2/03: emakital
    elif s == "crlf": s = "\r\n"
    else: s = '\n' # Default for erroneous values.
    # g.trace(c,name,c.config.output_newline,'returns',repr(s))

    if g.isPython3:
        s = str(s)
    return s
#@-node:ekr.20031218072017.1386:g.getOutputNewline
#@+node:ekr.20031218072017.1596:g.doHook
@ This global function calls a hook routine.  Hooks are identified by the tag param.
Returns the value returned by the hook routine, or None if the there is an exception.

We look for a hook routine in three places:
1. c.hookFunction
2. app.hookFunction
3. leoPlugins.doPlugins()
We set app.hookError on all exceptions.  Scripts may reset app.hookError to try again.
@c

def doHook(tag,*args,**keywords):

    trace = False ; verbose = False

    if g.app.killed or g.app.hookError: # or (g.app.gui and g.app.gui.isNullGui):
        return None

    if args:
        # A minor error in Leo's core.
        g.pr("***ignoring args param.  tag = %s" % tag)

    if not g.app.config.use_plugins:
        if tag in ('open0','start1'):
            s = "Plugins disabled: use_plugins is 0 in a leoSettings.leo file."
            g.es_print(s,color="blue")
        return None

    # Get the hook handler function.  Usually this is doPlugins.
    c = keywords.get("c")
    f = (c and c.hookFunction) or g.app.hookFunction

    if trace and (verbose or tag != 'idle'):
        g.trace('tag',tag,'f',f and f.__name__)

    if not f:
        import leo.core.leoPlugins as leoPlugins
        g.app.hookFunction = f = leoPlugins.doPlugins

    try:
        # Pass the hook to the hook handler.
        # g.pr('doHook',f.__name__,keywords.get('c'))
        return f(tag,keywords)
    except Exception:
        g.es_exception()
        g.app.hookError = True # Supress this function.
        g.app.idleTimeHook = False # Supress idle-time hook
        return None # No return value
#@-node:ekr.20031218072017.1596:g.doHook
#@+node:ekr.20041113113140:loadOnePlugin & test
def loadOnePlugin (moduleOrFileName,tag='open0',verbose=False):

    trace = False # and not g.unitTesting

    global loadedModules,loadingModuleNameStack

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
        print ('No g.app.config, making stub...')
        class StubConfig(g.nullObject):
            pass
        g.app.config = StubConfig()

    # Fixed reversion: do this after possibly creating stub config class.
    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.endswith('.py'):
        moduleName = moduleOrFileName [:-3]
    else:
        moduleName = moduleOrFileName
    moduleName = g.shortFileName(moduleName)

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if trace or verbose:
            g.trace('plugin',moduleName,'already loaded',color="blue")
        return module

    assert g.app.loadDir

    plugins_path = g.os_path_finalize_join(g.app.loadDir,"..","plugins")
    moduleName = g.toUnicode(moduleName)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)
    result = g.importFromPath(moduleName,plugins_path,pluginName=moduleName,verbose=True)
    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)

        if tag == 'unit-test-load':
            pass # Keep the result, but do no more.
        elif hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es_print('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.

            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                g.trace('no init()',moduleName)
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.app.batchMode or g.app.inBridge: # or g.unitTesting
        pass
    elif result:
        if trace or verbose:
            g.trace('loaded plugin:',moduleName,color="blue")
    else:
        if trace or warn_on_failure or (verbose and not g.app.initing):
            if trace or tag == 'open0':
                g.trace('can not load enabled plugin:',moduleName,color="red")

    return result
#@+node:ekr.20090522161156.5886:@test class StubConfig
if g.unitTesting:

    c,p = g.getTestVars()

    class StubConfig(g.nullObject):
        pass

    x = StubConfig()
    assert not x.getBool(c,'mySetting')
    assert not x.enabledPluginsFileName
#@-node:ekr.20090522161156.5886:@test class StubConfig
#@-node:ekr.20041113113140:loadOnePlugin & test
#@+node:ekr.20061031131434.100:addModeCommands (enterModeCallback)
def addModeCommands (self):

    '''Add commands created by @mode settings to c.commandsDict and k.inverseCommandsDict.'''

    k = self ; c = k.c
    d = g.app.config.modeCommandsDict # Keys are command names: enter-x-mode.

    # Create the callback functions and update c.commandsDict and k.inverseCommandsDict.
    for key in d:

        def enterModeCallback (event=None,name=key):
            k.enterNamedMode(event,name)

        c.commandsDict[key] = f = enterModeCallback
        k.inverseCommandsDict [f.__name__] = key
        # g.trace('leoCommands %24s = %s' % (f.__name__,key))
#@-node:ekr.20061031131434.100:addModeCommands (enterModeCallback)
#@-node:ekr.20100130042842.9008:Using g.app.config ivars
#@+node:ekr.20100130042842.9009:Usage of g.app.config ivars
#@+node:ekr.20100130042842.9010:at_root_bodies_start_in_doc_mode
@nocolor-node

at_root_bodies_start_in_doc_mode

c.scanAtRootDirectives
    should use c.config.getBool instead of the weird code.

g.scanAtRootOptions
    Why doesn't this use c.config ivars??
    Actually, this should be tangle.scanAtRootOptions.  We know c!

leoImport.convertVnodeToWeb:
    Uses c.config.at_root_bodies_start_in_doc_mode
#@nonl
#@+node:ekr.20080828103146.12:c.scanAtRootDirectives
# Called only by scanColorDirectives.

def scanAtRootDirectives(self,aList):

    '''Scan aList for @root-code and @root-doc directives.'''

    c = self

    # To keep pylint happy.
    tag = 'at_root_bodies_start_in_doc_mode'
    start_in_doc = hasattr(c.config,tag) and getattr(c.config,tag)

    # New in Leo 4.6: dashes are valid in directive names.
    for d in aList:
        if 'root-code' in d:
            return 'code'
        elif 'root-doc' in d:
            return 'doc'
        elif 'root' in d:
            return g.choose(start_in_doc,'doc','code')

    return None
#@-node:ekr.20080828103146.12:c.scanAtRootDirectives
#@+node:ekr.20031218072017.3154:g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    return i,mode
#@+node:ekr.20031218072017.3155:<< scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@-node:ekr.20031218072017.3155:<< scan another @root option >>
#@-node:ekr.20031218072017.3154:g.scanAtRootOptions
#@-node:ekr.20100130042842.9010:at_root_bodies_start_in_doc_mode
#@-node:ekr.20100130042842.9009:Usage of g.app.config ivars
#@+node:ekr.20100130035231.6254:app.defaultEncoding
#@+node:ekr.20031218072017.2618:app.setEncoding
def setEncoding (self):

    """Set g.app.defaultEncoding.
    runLeo.doPrePluginsInit calls this just after reading settings files.
    """

    a = self ; c = None

    for (encoding,src) in (
        (g.app.config.getString(c,'default-encoding'),'from settings file'),
        ("utf-8","")
    ):
        if g.isValidEncoding (encoding):
            a.defaultEncoding = encoding
            g.es('default encoding %s%s' % (
                encoding,src),color='orange')
            break
        elif encoding:
            color = g.choose(a.defaultEncoding=="ascii","red","blue")
            g.trace("ignoring invalid %s encoding: %s" % (
                src,encoding),color=color)
#@-node:ekr.20031218072017.2618:app.setEncoding
#@+node:ekr.20100130164946.6289:simplified
# There is no need for an explicit encoding param now.
#@nonl
#@+node:ekr.20031218072017.2160:toUnicodeFileEncoding
def toUnicodeFileEncoding(path):

    if path: path = path.replace('\\', os.sep)

    # Yes, this is correct.  All os_path_x functions return Unicode strings.
    return g.toUnicode(path)
#@-node:ekr.20031218072017.2160:toUnicodeFileEncoding
#@+node:ekr.20040713064323:dumpLines
def dumpLines (self,p,lines):

    g.pr('\n','-'*10,p.cleanHeadString())

    if 0:
        for line in lines:
            line2 = g.toEncodedString(line,reportErrors=True)
            g.pr(line2,newline=False) # Don't add a trailing newline!)
    else:
        for i in range(len(lines)):
            line = lines[i]
            line = g.toEncodedString(line,reportErrors=True)
            g.pr("%3d" % i, repr(lines[i]))
#@-node:ekr.20040713064323:dumpLines
#@+node:ekr.20050208093800:g.toEncodedString
def toEncodedString (s,encoding=None,reportErrors=False):

    if encoding is None:
        encoding = g.app.defaultEncoding

    if g.isUnicode(s):
        try:
            s = s.encode(encoding,"strict")
        except UnicodeError:
            if reportErrors: g.reportBadChars(s,encoding)
            s = s.encode(encoding,"replace")
    return s
#@-node:ekr.20050208093800:g.toEncodedString
#@-node:ekr.20100130164946.6289:simplified
#@+node:ekr.20100130035231.6255:Found: .defaultEncoding
#@+node:ekr.20050208093800.1:g.toUnicode
def toUnicode (s,encoding=None,reportErrors=False):

    # The encoding is usually g.app.defaultEncoding,
    # but is may be different while importing or reading files.
    if encoding is None:
        encoding = g.app.defaultEncoding

    if isPython3:
        f,mustConvert = str,g.isBytes
    else:
        f = unicode
        def mustConvert (s):
            return type(s) != types.UnicodeType

    if not s:
        s = g.u('')
    elif mustConvert(s):
        try:
            s = f(s,encoding,'strict')
        except (UnicodeError,Exception):
            s = f(s,encoding,'replace')
            if reportErrors: g.reportBadChars(s,encoding)
    else:
        pass

    return s
#@-node:ekr.20050208093800.1:g.toUnicode
#@+node:ekr.20031218072017.1416:app.__init__
def __init__(self):

    # These ivars are the global vars of this program.
    self.afterHandler = None
    self.batchMode = False # True: run in batch mode.
    self.commandName = None # The name of the command being executed.
    self.config = None # The leoConfig instance.
    self.count = 0 # General purpose debugging count.
    self.debug = False # True: enable extra debugging tests (not used at present).
        # WARNING: this could greatly slow things down.
    self.debugSwitch = 0
        # 0: default behavior
        # 1: full traces in g.es_exception.
        # 2: call pdb.set_trace in g.es_exception, etc.
    self.defaultEncoding = 'utf-8' # set later during starup.
    self.disableSave = False
    self.enableUnitTest = True
    self.extensionsDir = None
    self.globalConfigDir = None # The directory that is assumed to contain the global configuration files.
    self.globalOpenDir = None # The directory last used to open a file.
    self.gui = None # The gui class.
    self.hasOpenWithMenu = False # True: open with plugin has been loaded.
    self.hookError = False # True: suppress further calls to hooks.
    self.hookFunction = None # Application wide hook function.
    self.homeDir = None # The user's home directory.
    self.homeLeoDir = None # The '.leo' subdirectory of the user's home directory. New in Leo 4.5b4.
    self.homeSettingsPrefix = '.' # prepend to "myLeoSettings.leo" and <machineName>LeoSettings.leo
    self.idle_imported = False # True: we have done an import idle
    self.idleTimeDelay = 100 # Delay in msec between calls to "idle time" hook.
    self.idleTimeHook = False # True: the global idleTimeHookHandler will reshedule itself.
    self.inBridge = False # True: running from leoBridge module.
    self.initing = True # True: we are initiing the app.
    self.killed = False # True: we are about to destroy the root window.
    self.leoID = None # The id part of gnx's.
    self.loadDir = None # The directory from which Leo was loaded.
    self.loadedPlugins = [] # List of loaded plugins that have signed on.
    self.log = None # The LeoFrame containing the present log.
    self.logInited = False # False: all log message go to logWaiting list.
    self.logIsLocked = False # True: no changes to log are allowed.
    self.logWaiting = [] # List of messages waiting to go to a log.
    self.menuWarningsGiven = False # True: supress warnings in menu code.
    self.nodeIndices = None # Singleton node indices instance.
    self.numberOfWindows = 0 # Number of opened windows.
    self.oneConfigFilename = '' # If non-empty, the name of a single configuration file.
    self.openWithFiles = [] # List of data used by Open With command.
    self.openWithFileNum = 0 # Used to generate temp file names for Open With command.
    self.openWithTable = None # The table passed to createOpenWithMenuFromTable.
    self.positions = 0 # Count of the number of positions generated.
    self.printWaiting = [] # Queue of messages to be sent to the printer.
    self.qt_use_tabs = False # True: allow tabbed main window.
    self.quitting = False # True if quitting.  Locks out some events.
    self.realMenuNameDict = {} # Contains translations of menu names and menu item names.
    self.root = None # The hidden main window. Set later.
    self.searchDict = {} # For communication between find/change scripts.
    self.scanErrors = 0 # The number of errors seen by g.scanError.
    self.scriptDict = {} # For communication between Execute Script command and scripts.
    self.silentMode = False # True if signon is more silent.
    self.statsDict = {} # Statistics dict used by g.stat, g.clear_stats, g.print_stats.
    self.trace = False # True: enable debugging traces.
    self.trace_gc = False # defined in run()
    self.trace_gc_calls = False # defined in run()
    self.trace_gc_verbose = False # defined in run()
    self.trace_gc_inited = False
    self.tracePositions = False
    self.trace_list = [] # "Sherlock" argument list for tracing().
    self.translateToUpperCase = False
    self.unicodeErrorGiven = True # True: suppres unicode tracebacks.
    self.unitTestDict = {} # For communication between unit tests and code.
    self.unitTesting = False # True if unit testing.
    self.useIpython = False
    self.use_psyco = False # Can't be a config param because it is used before config module can be inited.
    self.user_xresources_path = None # Resource file for Tk/tcl.
    self.windowList = [] # Global list of all frames.  Does not include hidden root window.

    # Global panels.  Destroyed when Leo ends.
    self.pythonFrame = None

    << Define global constants >>
    << Define global data structures >>
#@+node:ekr.20031218072017.1417:<< define global constants >>
# self.prolog_string = "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"

self.prolog_prefix_string = "<?xml version=\"1.0\" encoding="
self.prolog_postfix_string = "?>"
self.prolog_namespace_string = 'xmlns:leo="http://edreamleo.org/namespaces/leo-python-editor/1.1"'
#@nonl
#@-node:ekr.20031218072017.1417:<< define global constants >>
#@+node:ekr.20031218072017.368:<< define global data structures >> (leoApp.py)
# Internally, lower case is used for all language names.
self.language_delims_dict = {
    # Keys are languages, values are 1,2 or 3-tuples of delims.
    "ada"           : "--",
    "batch"         : "REM_", # Use the REM hack.
    "actionscript"  : "// /* */", #jason 2003-07-03
    "autohotkey"    : "; /* */", #TL - AutoHotkey language
    "c"             : "// /* */", # C, C++ or objective C.
    "config"        : "#", # Leo 4.5.1
    "csharp"        : "// /* */", # C#
    "cpp"           : "// /* */",# C++.
    "css"           : "/* */", # 4/1/04
    "cweb"          : "@q@ @>", # Use the "cweb hack"
    "elisp"         : ";",
    "forth"         : "\\_ _(_ _)", # Use the "REM hack"
    "fortran"       : "C",
    "fortran90"     : "!",
    "haskell"       : "--_ {-_ _-}",
    "haxe"          : "//",
    "html"          : "<!-- -->",
    "ini"           : ";",
    "java"          : "// /* */",
    "kshell"        : "#", # Leo 4.5.1.
    "latex"         : "%",
    "lua"           : "--",  # ddm 13/02/06
    "noweb"         : "%", # EKR: 2009-01-30. Use Latex for doc chunks.
    "pascal"        : "// { }",
    "perl"          : "#",
    "perlpod"       : "# __=pod__ __=cut__", # 9/25/02: The perlpod hack.
    "php"           : "// /* */", # 6/23/07: was "//",
    "plain"         : "#", # We must pick something.
    "plsql"         : "-- /* */", # SQL scripts qt02537 2005-05-27
    "python"        : "#",
    "rapidq"        : "'", # fil 2004-march-11
    "rebol"         : ";",  # jason 2003-07-03
    "rest"          : ".._",
    "rst"           : ".._",
    "ruby"          : "#",  # thyrsus 2008-11-05
    "shell"         : "#",  # shell scripts
    "tcltk"         : "#",
    "tex"           : "%", # Bug fix: 2008-1-30: Fixed Mark Edginton's bug.
    "unknown"       : "#", # Set when @comment is seen.
    "unknown_language" : '#--unknown-language--', # For unknown extensions in @shadow files.
    "vim"           : "\"",
    "vimoutline"    : "#",  #TL 8/25/08 Vim's outline plugin
    "xml"           : "<!-- -->",
    "xslt"          : "<!-- -->",
}

self.language_extension_dict = {
    # Keys are languages, values are extensions.
    "ada"           : "ada",
    "actionscript"  : "as", #jason 2003-07-03
    "autohotkey"    : "ahk", #TL - AutoHotkey language
    "batch"         : "bat", # Leo 4.5.1.
    "c"             : "c",
    "config"        : "cfg",
    "cpp"           : "cpp",
    "css"           : "css", # 4/1/04
    "cweb"          : "w",
    "elisp"         : "el",
    "forth"         : "forth",
    "fortran"       : "f",
    "fortran90"     : "f90",
    "haskell"       : "hs",
    "haxe"          : "hx",
    "html"          : "html",
    "ini"           : "ini",
    "java"          : "java",
    "kshell"        : "ksh", # Leo 4.5.1.
    "latex"         : "tex", # 1/8/04
    "lua"           : "lua",  # ddm 13/02/06
    "noweb"         : "nw",
    "pascal"        : "p",
    "perl"          : "pl",      # 11/7/05
    "perlpod"       : "pod",  # 11/7/05
    "php"           : "php",
    "plain"         : "txt",
    "python"        : "py",
    "plsql"         : "sql", # qt02537 2005-05-27
    "rapidq"        : "bas", # fil 2004-march-11
    "rebol"         : "r",    # jason 2003-07-03
    # "rst"           : "rst", # caught by pylint.
    "rst"           : "rest",
    "ruby"          : "rb",   # thyrsus 2008-11-05
    "shell"         : "sh",   # DS 4/1/04
    "tex"           : "tex",
    "tcltk"         : "tcl",
    "unknown"       : "txt", # Set when @comment is seen.
    "vim"           : "vim",
    "vimoutline"    : "otl",  #TL 8/25/08 Vim's outline plugin
    "xml"           : "xml",
    "xslt"          : "xsl",
}

self.extension_dict = {
    # Keys are extensions, values are languages.
    "ada"   : "ada",
    "adb"   : "ada",
    "ahk"   : "autohotkey",  # EKR: 2009-01-30.
    "as"    : "actionscript",
    "bas"   : "rapidq",
    "bat"   : "batch",
    "c"     : "c",
    "cfg"   : "config",
    "cpp"   : "cpp",
    "css"   : "css",
    "el"    : "elisp",
    "forth" : "forth",
    "f"     : "fortran",
    "f90"   : "fortran90",
    "h"     : "c",
    "html"  : "html",
    "hs"    : "haskell",
    "ini"   : "ini",
    "java"  : "java",
    "ksh"   : "kshell", # Leo 4.5.1.
    "lua"   : "lua",  # ddm 13/02/06
    "nw"    : "noweb",
    "otl"   : "vimoutline",  #TL 8/25/08 Vim's outline plugin
    "p"     : "pascal",
    "pl"    : "perl",   # 11/7/05
    "pod"   : "perlpod", # 11/7/05
    "php"   : "php",
    "py"    : "python",
    "sql"   : "plsql", # qt02537 2005-05-27
    "r"     : "rebol",
    "rb"    : "ruby", # thyrsus 2008-11-05
    "rest"  : "rst",
    "rst"   : "rst",
    "sh"    : "shell",
    "tex"   : "tex",
    "txt"   : "plain",
    "tcl"   : "tcltk",
    "vim"   : "vim",
    "w"     : "cweb",
    "xml"   : "xml",
    "xsl"   : "xslt",
    "hx"    : "haxe",
}

# Extra language extensions, used to associate extensions with mode files.
# Used by importCommands.languageForExtension.
# Keys are extensions, values are corresponding mode file (without .py)
# A value of 'none' is a signal to unit tests that no extension file exists.
self.extra_extension_dict = {
    'actionscript': 'actionscript',
    'ada'   : 'ada95',
    'adb'   : 'none', # ada??
    'awk'   : 'awk',
    'bas'   : 'none', # rapidq
    'bat'   : 'none', # batch
    'cfg'   : 'none', # Leo 4.5.1
    'cpp'   : 'c',
    'el'    : 'lisp',
    'f'     : 'fortran90',
    'hx'    : 'none',
    'ksh'   : 'none', # Leo 4.5.1
    'nw'    : 'none', # noweb.
    'otl'   : 'none', # vimoutline.
    'pod'   : 'perl',
    'tcl'   : 'tcl',
    'unknown_language': 'none',
    'w'     : 'none', # cweb
}

self.global_commands_dict = {}
#@-node:ekr.20031218072017.368:<< define global data structures >> (leoApp.py)
#@-node:ekr.20031218072017.1416:app.__init__
#@+node:ekr.20031218072017.2278:g.importFromPath
def importFromPath (name,path,pluginName=None,verbose=False):

    trace = False # and not g.unitTesting
    fn = g.shortFileName(name)
    moduleName,ext = g.os_path_splitext(fn)
    path = g.os_path_normpath(path)
    path = g.toEncodedString(path,app and app.defaultEncoding or 'ascii')

    module = sys.modules.get(moduleName)
    if module:
        if trace: g.trace('already loaded',moduleName,module)
        return module

    try:
        theFile = None
        import imp
        try:
            data = imp.find_module(moduleName,[path]) # This can open the file.
            theFile,pathname,description = data
            module = imp.load_module(moduleName,theFile,pathname,description)
        except ImportError:
            if trace: # or verbose:
                g.es_print("exception in g.importFromPath",color='blue')
                g.es_exception()
        except UiTypeException:
            g.es_print("Ui type not compatible for plugin (%s)" %
                (name),color='blue')            
        except Exception:
            g.es_print("unexpected exception in g.importFromPath(%s)" %
                (name),color='blue')
            g.es_exception()
    # Put no return statements before here!
    finally: 
        if theFile: theFile.close()

    if module:
        if trace: g.trace('loaded',moduleName)
    else:
        g.cantImport(moduleName,pluginName=pluginName,verbose=verbose)

    return module
#@-node:ekr.20031218072017.2278:g.importFromPath
#@+node:ekr.20031218072017.3207:import.__init__ & helper
def __init__ (self,c):

    self.c = c
    self.default_directory = None # For @path logic.
    self.encoding = g.app.defaultEncoding
    self.errors = 0
    self.fileName = None # The original file name, say x.cpp
    self.fileType = None # ".py", ".c", etc.
    self.methodName = None # x, as in < < x methods > > =
    self.output_newline = g.getOutputNewline(c=c) # Value of @bool output_newline
    self.rootLine = "" # Empty or @root + self.fileName
    self.tab_width = c.tab_width # The tab width in effect in the c.currentPosition.
    self.trace = c.config.getBool('trace_import')
    self.treeType = "@file" # "@root" or "@file"
    self.webType = "@noweb" # "cweb" or "noweb"
    self.web_st = [] # noweb symbol table.

    self.createImportDispatchDict()
#@+node:ekr.20080825131124.3:createImportDispatchDict
def createImportDispatchDict (self):

    self.importDispatchDict = {
        # Keys are file extensions, values are text scanners.
        # Text scanners must have the signature scanSomeText(self,s,parent,atAuto=False)
        '.c':       self.scanCText,
        '.h':       self.scanCText,
        '.h++':     self.scanCText,
        '.cc':      self.scanCText,
        '.c++':     self.scanCText,
        '.cpp':     self.scanCText,
        '.cxx':     self.scanCText,
        '.cs':      self.scanCSharpText,
        '.el':      self.scanElispText,
        '.htm':     self.scanXmlText,
        '.html':    self.scanXmlText,
        '.java':    self.scanJavaText,
        '.js':      self.scanJavaScriptText,
        '.php':     self.scanPHPText,
        '.pas':     self.scanPascalText,
        '.py':      self.scanPythonText,
        '.pyw':     self.scanPythonText,
        # '.txt':     self.scanRstText, # A reasonable default.
        # '.rest':    self.scanRstText,
        # '.rst':     self.scanRstText,
        '.xml':     self.scanXmlText,
    }
#@-node:ekr.20080825131124.3:createImportDispatchDict
#@-node:ekr.20031218072017.3207:import.__init__ & helper
#@+node:ekr.20031218072017.1463:setEncoding (leoImport)
def setEncoding (self,p=None,atAuto=False):

    # c.scanAllDirectives checks the encoding: may return None.
    c = self.c
    if p is None: p = c.p
    theDict = c.scanAllDirectives(p)
    encoding = theDict.get("encoding")
    if encoding and g.isValidEncoding(encoding):
        self.encoding = encoding
    elif atAuto:
        self.encoding = c.config.default_at_auto_file_encoding
    else:
        self.encoding = g.app.defaultEncoding

    # g.trace(self.encoding)
#@-node:ekr.20031218072017.1463:setEncoding (leoImport)
#@+node:ekr.20090502071837.36:<< init ivars >> (leoRst)
self.silverCityWarningGiven = False

# The options dictionary.
self.optionsDict = {}
self.option_prefix = '@rst-option'

# Formatting...
self.code_block_string = ''
self.node_counter = 0
self.topLevel = 0
self.topNode = None
self.use_alternate_code_block = SilverCity is None

# Http support...
self.nodeNumber = 0
# All nodes are numbered so that unique anchors can be generated.

self.http_map = {} 
# Keys are named hyperlink targets.  Value are positions.
# The targets mark the beginning of the html code specific
# for this position.

self.anchor_map = {}
# Maps anchors (generated by this module) to positions

self.rst3_all = False
# Set to True by the button which processes all @rst trees.

# For writing.
self.atAutoWrite = False # True, special cases for writeAtAutoFile.
self.atAutoWriteUnderlines = '' # Forced underlines for writeAtAutoFile.
self.leoDirectivesList = g.globalDirectiveList
self.encoding = g.app.defaultEncoding
self.ext = None # The file extension.
self.outputFileName = None # The name of the file being written.
self.outputFile = None # The open file being written.
self.path = '' # The path from any @path directive.
self.source = None # The written source as a string.
self.trialWrite = False # True if doing a trialWrite.
#@nonl
#@-node:ekr.20090502071837.36:<< init ivars >> (leoRst)
#@+node:ekr.20090502071837.60:initWrite (rstCommands)
def initWrite (self,p,encoding=None):

    self.initOptionsFromSettings() # Still needed.

    # Set the encoding from any parent @encoding directive.
    # This can be overridden by @rst-option encoding=whatever.
    c = self.c
    d = c.scanAllDirectives(p)
    self.encoding = encoding or d.get('encoding') or g.app.defaultEncoding
    self.path = d.get('path') or ''

    # g.trace('path:',self.path)
#@-node:ekr.20090502071837.60:initWrite (rstCommands)
#@-node:ekr.20100130035231.6255:Found: .defaultEncoding
#@+node:ekr.20050328133444:g.computeStandardDirectories & helpers
def computeStandardDirectories():

    '''Set g.app.loadDir, g.app.homeDir, g.app.homeLeoDir and g.app.globalConfigDir.'''

    g.app.loadDir = g.computeLoadDir()
    g.app.leoDir = g.computeLeoDir()
    g.app.homeDir = g.computeHomeDir()

    g.app.homeLeoDir = homeLeoDir = g.os_path_finalize(
        g.os_path_join(g.app.homeDir,'.leo'))

    if not g.os_path_exists(homeLeoDir):
        g.makeAllNonExistentDirectories(homeLeoDir,force=True)

    g.app.extensionsDir = g.os_path_finalize(
        g.os_path_join(g.app.loadDir,'..','extensions'))

    g.app.globalConfigDir = g.computeGlobalConfigDir()

    g.app.testDir = g.os_path_finalize(
        g.os_path_join(g.app.loadDir,'..','test'))

    g.app.user_xresources_path = g.os_path_join(
        g.app.homeDir,'.leo_xresources')
#@+node:ekr.20041117155521:computeGlobalConfigDir
def computeGlobalConfigDir():

    import leo.core.leoGlobals as g

    # To avoid pylint complaints that sys.leo_config_directory does not exist.
    leo_config_dir = (
        hasattr(sys,'leo_config_directory') and
        getattr(sys,'leo_config_directory'))

    if leo_config_dir:
        theDir = leo_config_dir
    else:
        theDir = g.os_path_join(g.app.loadDir,"..","config")

    if theDir:
        theDir = g.os_path_finalize(theDir)

    if (
        not theDir or
        not g.os_path_exists(theDir) or
        not g.os_path_isdir(theDir)
    ):
        theDir = None

    return theDir
#@-node:ekr.20041117155521:computeGlobalConfigDir
#@+node:ekr.20041117151301:computeHomeDir
def computeHomeDir():

    """Returns the user's home directory."""

    import leo.core.leoGlobals as g

    home = os.path.expanduser("~")
        # Windows searches the HOME, HOMEPATH and HOMEDRIVE environment vars, then gives up.

    if home and len(home) > 1 and home[0]=='%' and home[-1]=='%':
        # Get the indirect reference to the true home.
        home = os.getenv(home[1:-1],default=None)

    if home:
        # Important: This returns the _working_ directory if home is None!
        # This was the source of the 4.3 .leoID.txt problems.
        home = g.os_path_finalize(home)
        if (
            not g.os_path_exists(home) or
            not g.os_path_isdir(home)
        ):
            home = None

    return home
#@-node:ekr.20041117151301:computeHomeDir
#@+node:ekr.20060416113431:computeLeoDir
def computeLeoDir ():

    loadDir = g.app.loadDir
    theDir = g.os_path_dirname(loadDir)

    # xxx remove this, we don't want to have this in sys.path
    if theDir not in sys.path:
        sys.path.append(theDir)

    return theDir
#@-node:ekr.20060416113431:computeLeoDir
#@+node:ekr.20031218072017.1937:computeLoadDir
def computeLoadDir():

    """Returns the directory containing leo.py."""

    import leo.core.leoGlobals as g
    import sys

    try:
        # Fix a hangnail: on Windows the drive letter returned by
        # __file__ is randomly upper or lower case!
        # The made for an ugly recent files list.
        path = g.__file__ # was leo.__file__
        << resolve symlinks >>
        if sys.platform=='win32':
            if len(path) > 2 and path[1]==':':
                # Convert the drive name to upper case.
                path = path[0].upper() + path[1:]
        path = g.os_path_finalize(path)
        if path:
            loadDir = g.os_path_dirname(path)
        else: loadDir = None

        if (
            not loadDir or
            not g.os_path_exists(loadDir) or
            not g.os_path_isdir(loadDir)
        ):
            loadDir = os.getcwd()
            # From Marc-Antoine Parent.
            if loadDir.endswith("Contents/Resources"):
                loadDir += "/leo/plugins"
            else:
                g.pr("Exception getting load directory")
        loadDir = g.os_path_finalize(loadDir)
        # g.es("load dir:",loadDir,color="blue")
        return loadDir
    except:
        g.pr("Exception getting load directory")
        raise
#@+node:ville.20090703102253.6160:<< resolve symlinks >>
if path.endswith('pyc'):
    srcfile = path[:-1]
    if os.path.islink(srcfile):
        path = os.path.realpath(srcfile)    
#@-node:ville.20090703102253.6160:<< resolve symlinks >>
#@-node:ekr.20031218072017.1937:computeLoadDir
#@+node:dan.20080410121257.1:computeMachineName
def computeMachineName():
    """Returns the name of the current machine, i.e, HOSTNAME"""
    try:
        import os
        name = os.getenv('HOSTNAME')
        if not name:
            name = os.getenv('COMPUTERNAME')
        if not name:
            import socket
            name = socket.gethostname()
    except Exception:
        name = ''

    # g.trace(name)

    return name
#@-node:dan.20080410121257.1:computeMachineName
#@-node:ekr.20050328133444:g.computeStandardDirectories & helpers
#@-node:ekr.20100130035231.6254:app.defaultEncoding
#@+node:ekr.20100130180828.6272:writeSpecialTree uses ridiculous encoding defaults
#@+node:ekr.20090502071837.64:writeSpecialTree
def writeSpecialTree (self,p,toString,justOneFile):

    c = self.c
    isHtml = self.ext in ('.html','.htm')
    if isHtml and not SilverCity:
        if not self.silverCityWarningGiven:
            self.silverCityWarningGiven = True
            g.es('SilverCity not present so no syntax highlighting')

    self.initWrite(p,encoding=g.choose(isHtml,'utf-8','iso-8859-1'))
    self.outputFile = StringIO()
    self.writeTree(p)
    self.source = self.outputFile.getvalue()
    self.outputFile = None

    if not toString:
        # Compute this here for use by intermediate file.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)

        # Create the directory if it doesn't exist.
        theDir, junk = g.os_path_split(self.outputFileName)
        theDir = c.os_path_finalize(theDir)
        if not g.os_path_exists(theDir):
            ok = g.makeAllNonExistentDirectories(theDir,c=c,force=False)
            if not ok:
                g.es_print('did not create:',theDir,color='red')
                return False

        # if not os.access(theDir,os.F_OK):
            # os.mkdir(theDir)

        if self.getOption('write_intermediate_file'):
            name = self.outputFileName + '.txt'
            f = open(name,'w')
            f.write(self.source)
            f.close()
            self.report(name)

    try:
        output = self.writeToDocutils(self.source)
        ok = output is not None
    except Exception:
        g.pr('Exception in docutils')
        g.es_exception()
        ok = False

    if ok:
        if isHtml:
            import re
            idxTitle = output.find('<title></title>')
            if idxTitle > -1:
                m = re.search('<h1>([^<]*)</h1>', output)
                if not m:
                    m = re.search('<h1><[^>]+>([^<]*)</a></h1>', output)
                if m:
                    output = output.replace(
                        '<title></title>',
                        '<title>%s</title>' % m.group(1)
                    )


        if toString:
            self.stringOutput = output
        else:
            # Write the file to the directory containing the .leo file.
            f = open(self.outputFileName,'w')
            f.write(output)
            f.close()
            self.http_endTree(self.outputFileName, p, justOneFile=justOneFile)

    return ok
#@-node:ekr.20090502071837.64:writeSpecialTree
#@-node:ekr.20100130180828.6272:writeSpecialTree uses ridiculous encoding defaults
#@-node:ekr.20100130164410.6332:Recent
#@-all
#@-node:ekr.20100120072650.6089:@thin leoProjects.txt
#@-leo
