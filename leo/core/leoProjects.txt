#@+leo-ver=4-thin
#@+node:ekr.20100120072650.6089:@thin leoProjects.txt
#@+at
# This part of the tree shows views of the outline related to specific 
# projects or
# tasks. I put such headlines in parentheses, and that is just my convention.
# 
# I create a new view by cloning headlines that relate to its task, and moving 
# the
# cloned headlines under the task headline. This greatly increases my focus. 
# Any
# changes made in a task view to clone headlines affect the other clones 
# scattered
# throughout the outline. In particular, all @file nodes containing changed 
# clones
# become marked as dirty, so they will be written when the entire outline is
# saved.
#@-at
#@@c

#@@language python 
#@@tabwidth -4

#@+all
#@+node:ekr.20100118163110.6256:Leo 4.7 b2 projects
#@+node:ekr.20100121105450.6175:Bugs
#@+node:ekr.20100119024225.6107:Fixed colorizer bug affecting per-language @font settings
@nocolor-node

It looks like you should be able to put the following in an
@font node, and get restructured text bold to appear in bold onscreen:

rest_keyword2_font_size = 16
rest_keyword2_font_family = Bitstream Charter
rest_keyword2_font_slant = roman
rest_keyword2_font_weight = bold

However nothing happens when I do this. The python examples in the
test.leo file work fine for me, so I'm not sure what's gone wrong.

I think that the following should also work, but it's also currently
not doing anything for me:

@color rest_keyword2_color = black

==================

Rev 2706 fixes a significant colorizer bug that caused your problem.
Previously, the colorizer inited the so-called configuration tags only
once, which is wrong. These tags are what the @font settings specify.
Now, the colorizer inits the tags when the language changes when
switching nodes.  Usually the language doesn't change, so the new code
will be approximately as fast as the old. 
#@-node:ekr.20100119024225.6107:Fixed colorizer bug affecting per-language @font settings
#@+node:ekr.20100119024225.6108:support extend-mode for several commands
'backward-find-character'
'find-character'
#@-node:ekr.20100119024225.6108:support extend-mode for several commands
#@+node:ekr.20100119024225.6106:Fixed qttab problem
@nocolor-node

On Mon, Jan 18, 2010 at 9:25 PM, tfer <tfetherston@aol.com> wrote:

cmd.exe /k C:\PyDev\leo-editor\trunk\launchLeo.py --gui=qttabs -- ipython

1) (??) the button removal menu just flash on right mouse click, disappears immediately.

2) Leo opens up the workbook, I open a new doc in a tab, 'untitled', save it,
   get saved ... in log, however, tab title does not change unless I close and
   reload it.
#@-node:ekr.20100119024225.6106:Fixed qttab problem
#@+node:ekr.20100115091643.6249:<alt-x> select-all crashes python when focus is in headline
@
The problem occurs because the QtGui.QLineEdit object goes away
when the minibuffer gets focus and the QTreeWidget loses focus.

The fix: add a 'permanent' ivar to leoQtTextWidgets, and set
this ivar to False for headline widgets.
#@nonl
#@-node:ekr.20100115091643.6249:<alt-x> select-all crashes python when focus is in headline
#@+node:ekr.20080412053100.1:Allow saving .leo files with undefined-sections
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/db797dd1d4dddffb

1) Create an @thin file based outline.
2) In the @thin file, create an unreferenced section (something like a
  header <<This Section Is Bogus>>).
3) Now, File->Exit
4) A dialog box pops up
  (Save changes to leo_file.leo before quitting? Yes/No/Cancel)
5) Click "Yes"
6) In the log pane, you will see: "undefined section" and "saved: leo_file.leo"
  and in the console window, you see "undefined section: ..."

The point is that I can't kill Leo if I keep saying "Yes" to the
"Save change before quitting" dialog. This is definitely not the
intended behavior. The correct behavior would be to save the file,
give me the warning about the undefined section, and exit.

EKR: The fix was simple: write_leo_file ignores the status returned from
c.atFileCommands.writeAll.

Note that Leo writes the write error to the console as well as the log pane,
so this should be safe enough.
#@nonl
#@-node:ekr.20080412053100.1:Allow saving .leo files with undefined-sections
#@+node:ekr.20100119175348.6127:Refactored write_Leo_file
#@-node:ekr.20100119175348.6127:Refactored write_Leo_file
#@+node:ekr.20100119175348.6128:Fixed print-bindings crasher w/ leo3k
#@-node:ekr.20100119175348.6128:Fixed print-bindings crasher w/ leo3k
#@+node:ekr.20080406075855.2:Fixed problem with already-existing .leo.bak files
@nocolor-node

I also unhappily discovered that any file named somedoc.leo.bak will
get deleted whenever you save a file named somedoc.leo.

===========

This turned into a major refactoring of write_Leo_file.
#@nonl
#@-node:ekr.20080406075855.2:Fixed problem with already-existing .leo.bak files
#@+node:ekr.20100120095741.6135:Fixed sort children bug
https://bugs.launchpad.net/leo-editor/+bug/510148

The fix was in sortSiblings.
#@-node:ekr.20100120095741.6135:Fixed sort children bug
#@+node:ekr.20100120073530.6083:Fixed unicode problems
@nocolor-node

- 'encoding' arg removed from appendStringToBody, setBodyString

- There are too many usages of _bodyString !!

- There is no way to give an encoding to setBodyString:
    It should give an internal error if the s arg is not unicode.
#@nonl
#@+node:ekr.20080710101653.1:g.pr
# see: http://www.diveintopython.org/xml_processing/unicode.html

pr_warning_given = False

def pr(*args,**keys):

    '''Print all non-keyword args, and put them to the log pane.
    The first, third, fifth, etc. arg translated by g.translateString.
    Supports color, comma, newline, spaces and tabName keyword arguments.
    '''

    # Compute the effective args.
    d = {'commas':False,'newline':True,'spaces':True}
    d = g.doKeywordArgs(keys,d)
    newline = d.get('newline')
    nl = g.choose(newline,'\n','')
    if hasattr(sys.stdout,'encoding') and sys.stdout.encoding:
        encoding = sys.stdout.encoding
    else:
        encoding = 'utf-8'

    # Important:  Python's print statement *can* handle unicode.
    # However, the following must appear in Python\Lib\sitecustomize.py:
    #    sys.setdefaultencoding('utf-8')
    s = g.translateArgs(args,d) # Translates everything to unicode.
    if app.logInited:
        s = s + '\n'

    if g.isPython3:
        s2 = s
    else:
        s2 = g.toEncodedString(s,encoding)

    if app.logInited:
        try: # We can't use any print keyword args in Python 2.x!
            sys.stdout.write(s2)
        except Exception:
            if not g.pr_warning_given:
                g.pr_warning_given = True
                print('unexpected Exception in g.pr')
                print('make sure your sitecustomize.py contains::')
                print('    sys.setdefaultencoding("utf-8")')
                g.es_exception()
                g.trace(g.callers())
            s2 = s.encode('ascii',"replace")
            if g.isPython3:
                s2 = str(s2,'ascii','replace')
            sys.stdout.write(s2)
    else:
        app.printWaiting.append(s2)
#@-node:ekr.20080710101653.1:g.pr
#@+node:ekr.20100120095741.6136:qtGui diff

c:\leo.repo\trunk>bzr di -r2685..2686 leo\plugins\qtGui.py   
=== modified file 'leo/plugins/qtGui.py'
--- leo/plugins/qtGui.py	2010-01-15 15:18:58 +0000
+++ leo/plugins/qtGui.py	2010-01-16 14:51:14 +0000
@@ -429,7 +429,7 @@
         newText = w.getAllText() # Converts to unicode.

         # Get the previous values from the vnode.
-        oldText = g.app.gui.toUnicode(p.v._bodyString)
+        oldText = p.v._bodyString ### already unicode ### g.app.gui.toUnicode(p.v._bodyString)
         if oldText == newText:
             # This can happen as the result of undo.
             # g.trace('*** unexpected non-change',color="red")
@@ -669,7 +669,7 @@

         w = self.widget
         s = w.text()
-        return g.app.gui.toUnicode(s)
+        return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@nonl
#@verbatim
     #@-node:ekr.20081121105001.551:getAllText
#@verbatim
     #@+node:ekr.20081121105001.552:getInsertPoint
@@ -687,7 +687,7 @@
         if w.hasSelectedText():
             i = w.selectionStart()
             s = w.selectedText()
-            s = g.app.gui.toUnicode(s)
+            s = g.u(s) ### (s)
             j = i + len(s)
         else:
             i = j = w.cursorPosition()
@@ -722,7 +722,7 @@

         w = self.widget
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         i = w.toPythonIndex(i)
         i = max(0,min(i,len(s)))
         w.setCursorPosition(i)
@@ -734,7 +734,7 @@
         # g.trace(i,j,insert,w)
         if i > j: i,j = j,i
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         n = len(s)
         i = max(0,min(i,n))
         j = max(0,min(j,n))
@@ -1407,7 +1407,7 @@

         w = self.widget
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         return s
#@verbatim
     #@-node:ekr.20081121105001.564:getAllText
#@verbatim
     #@+node:ekr.20081121105001.565:getInsertPoint
@@ -1538,7 +1538,7 @@
         if self.check():
             w = self.widget
             s = w.text()
-            return g.app.gui.toUnicode(s)
+            return g.u(s) ### g.app.gui.toUnicode(s)
         else:
             return ''
#@verbatim
     #@nonl
@@ -1561,7 +1561,7 @@
             if w.hasSelectedText():
                 i = w.selectionStart()
                 s = w.selectedText()
-                s = g.app.gui.toUnicode(s)
+                s = g.u(s) ### g.app.gui.toUnicode(s)
                 j = i + len(s)
             else:
                 i = j = w.cursorPosition()
@@ -1608,7 +1608,7 @@

         w = self.widget
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         i = self.toPythonIndex(i)
         i = max(0,min(i,len(s)))
         w.setCursorPosition(i)
@@ -1621,7 +1621,7 @@
         # g.trace(i,j,insert,w)
         if i > j: i,j = j,i
         s = w.text()
-        s = g.app.gui.toUnicode(s)
+        s = g.u(s) ### g.app.gui.toUnicode(s)
         n = len(s)
         i = max(0,min(i,n))
         j = max(0,min(j,n))
@@ -5551,7 +5551,6 @@
     def setMenuLabel (self,menu,name,label,underline=-1):

         def munge(s):
-            # s = g.app.gui.toUnicode(s)
             return g.u(s or '').replace('&','')

         # menu is a qtMenuWrapper.
@@ -6878,8 +6877,9 @@
         cb = self.qtApp.clipboard()
         if cb:
             # cb.clear()  # unnecessary, breaks on some Qt versions
-            if type(s) == type(''):
-                s = g.app.gui.toUnicode(s)
+            ###
+            ###if type(s) == type(''):
+            ###    s = g.app.gui.toUnicode(s)

             QtGui.QApplication.processEvents()
             cb.setText(s)
@@ -6898,7 +6898,7 @@
             QtGui.QApplication.processEvents()
             s = cb.text()
             if trace: g.trace (len(s),type(s))
-            s = g.app.gui.toUnicode(s)
+            s = g.app.gui.toUnicode(s) # Assume nothing about the type of s.
             return s
         else:
             g.trace('no clipboard!')
@@ -7017,7 +7017,7 @@
         parent = None
         title = 'Enter Leo id'
         s,ok = QtGui.QInputDialog.getText(parent,title,message)
-        return g.app.gui.toUnicode(s)
+        return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@nonl
#@verbatim
     #@-node:ekr.20081121105001.484:runAskLeoIDDialog
#@verbatim
     #@+node:ekr.20081121105001.485:runAskOkDialog
@@ -7099,9 +7099,7 @@
             return [g.u(s) for s in lst]
         else:
             s = QtGui.QFileDialog.getOpenFileName(parent,title,os.curdir,filter)
-            s = g.app.gui.toUnicode(s)
-            return s
-    #@nonl
+            return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@-node:ekr.20081121105001.488:runOpenFileDialog
#@verbatim
     #@+node:ekr.20090722094828.3653:runPropertiesDialog (qtGui)
     def runPropertiesDialog(self,
@@ -7125,7 +7123,7 @@
         parent = None
         filter_ = self.makeFilter(filetypes)
         s = QtGui.QFileDialog.getSaveFileName(parent,title,os.curdir,filter_)
-        return g.app.gui.toUnicode(s)
+        return g.u(s) ### g.app.gui.toUnicode(s)
#@verbatim
     #@-node:ekr.20081121105001.489:runSaveFileDialog
#@verbatim
     #@+node:ekr.20081121105001.490:runScrolledMessageDialog
     def runScrolledMessageDialog (self, title='Message', label= '', msg='', c=None, **kw):
@@ -7421,7 +7419,7 @@
             s = g.u(s)
             return s
         except Exception:
-            g.trace('*** Unicode Error: bugs possible')
+            # g.trace('*** Unicode Error: bugs possible')
             return g.toUnicode(s,'utf-8',reportErrors='replace')
#@verbatim
     #@-node:ekr.20081121105001.502:toUnicode (qtGui)
#@verbatim
     #@+node:ekr.20081121105001.503:widget_name (qtGui)

#@-node:ekr.20100120095741.6136:qtGui diff
#@+node:ekr.20060919110638.14:parse_leo_file
def parse_leo_file (self,theFile,inputFileName,silent,inClipboard,s=None):

    c = self.c
    try:
        if g.isPython3:
            if theFile:
                # Use the open binary file, opened by g.openLeoOrZipFile.
                s = theFile.read() # type(s) is bytes.
                s = self.cleanSaxInputString(s)
                theFile = BytesIO(s)
            else:
                s = str(s,encoding='utf-8')
                s = self.cleanSaxInputString(s)
                theFile = StringIO(s)
        else:
            if theFile: s = theFile.read()
            s = self.cleanSaxInputString(s)
            theFile = cStringIO.StringIO(s)
        parser = xml.sax.make_parser()
        parser.setFeature(xml.sax.handler.feature_external_ges,1)
            # Include external general entities, esp. xml-stylesheet lines.
        if 0: # Expat does not read external features.
            parser.setFeature(xml.sax.handler.feature_external_pes,1)
                # Include all external parameter entities
                # Hopefully the parser can figure out the encoding from the <?xml> element.
        handler = saxContentHandler(c,inputFileName,silent,inClipboard)
        parser.setContentHandler(handler)
        parser.parse(theFile) # expat does not support parseString
        # g.trace('parsing done')
        sax_node = handler.getRootNode()
    except xml.sax.SAXParseException:
        g.es_print('error parsing',inputFileName,color='red')
        g.es_exception()
        sax_node = None
    except Exception:
        g.es_print('unexpected exception parsing',inputFileName,color='red')
        g.es_exception()
        sax_node = None

    return sax_node
#@-node:ekr.20060919110638.14:parse_leo_file
#@-node:ekr.20100120073530.6083:Fixed unicode problems
#@+node:ekr.20100121050224.6141:Fixed crash in writeToFileHelper
#@+node:ekr.20031218072017.1470:put
def put (self,s):

    '''Put string s to self.outputFile. All output eventually comes here.'''

    # Improved code: self.outputFile (a cStringIO object) always exists.
    # g.trace(g.callers(1),repr(s))
    if s:
        self.putCount += 1
        if not g.isPython3:
            s = g.toEncodedString(s,self.leo_file_encoding,reportErrors=True)
        self.outputFile.write(s)

def put_dquote (self):
    self.put('"')

def put_dquoted_bool (self,b):
    if b: self.put('"1"')
    else: self.put('"0"')

def put_flag (self,a,b):
    if a:
        self.put(" ") ; self.put(b) ; self.put('="1"')

def put_in_dquotes (self,a):
    self.put('"')
    if a: self.put(a) # will always be True if we use backquotes.
    else: self.put('0')
    self.put('"')

def put_nl (self):
    self.put("\n")

def put_tab (self):
    self.put("\t")

def put_tabs (self,n):
    while n > 0:
        self.put("\t")
        n -= 1
#@nonl
#@-node:ekr.20031218072017.1470:put
#@+node:ekr.20100119145629.6111:writeToFileHelper & helpers
def writeToFileHelper (self,fileName,toOPML):

    c = self.c ; toZip = c.isZipped
    ok,backupName = self.createBackupFile(fileName)
    if not ok: return False
    fileName,theActualFile = self.createActualFile(fileName,toOPML,toZip)
    self.mFileName = fileName
    self.outputFile = StringIO() # Always write to a string.

    try:
        if toOPML:
            self.putToOPML()
        else:
            self.putLeoFile()
        s = self.outputFile.getvalue()
        g.app.write_Leo_file_string = s # 2010/01/19: always set this.
        if toZip:
            self.writeZipFile(s)
        else:
            if g.isPython3:
                s = bytes(s,self.leo_file_encoding,'replace')
            theActualFile.write(s)
            theActualFile.close()
            c.setFileTimeStamp(fileName)
            # raise AttributeError # To test handleWriteLeoFileException.
            # Delete backup file.
            if backupName and g.os_path_exists(backupName):
                self.deleteFileWithMessage(backupName,'backup')
        return True
    except Exception:
        self.handleWriteLeoFileException(
            fileName,backupName,theActualFile)
        return False
#@+node:ekr.20100119145629.6106:createActualFile
def createActualFile (self,fileName,toOPML,toZip):

    c = self.c

    if toOPML and not self.mFileName.endswith('opml'):
        fileName = self.mFileName + '.opml'

    if toZip:
        self.toString = True
        theActualFile = None
    else:
        try:
            # 2010/01/21: always write in binary mode.
            theActualFile = open(fileName,'wb')
        except IOError:
            theActualFile = None

    return fileName,theActualFile
#@-node:ekr.20100119145629.6106:createActualFile
#@+node:ekr.20031218072017.3047:createBackupFile
def createBackupFile (self,fileName):

    '''
        Create a closed backup file and copy the file to it,
        but only if the original file exists.
    '''

    c = self.c

    if g.os_path_exists(fileName):
        # backupName = g.os_path_join(g.app.loadDir,fileName+'.bak')
        fd,backupName = tempfile.mkstemp(text=False)
        os.close(fd)
        ok = g.utils_rename(c,fileName,backupName)
        if not ok and self.read_only:
            g.es("read only",color="red")
    else:
        ok,backupName = True,None

    return ok,backupName
#@-node:ekr.20031218072017.3047:createBackupFile
#@+node:ekr.20100119145629.6108:handleWriteLeoFileException
def handleWriteLeoFileException(self,fileName,backupName,theActualFile):

    c = self.c

    g.es("exception writing:",fileName)
    g.es_exception(full=True)

    if theActualFile:
        theActualFile.close()

    # Delete fileName.
    if fileName and g.os_path_exists(fileName):
        self.deleteFileWithMessage(fileName,'')

    # Rename backupName to fileName.
    if backupName and g.os_path_exists(backupName):
        g.es("restoring",fileName,"from",backupName)
        g.utils_rename(c,backupName,fileName)
    else:
        g.es_print('does not exist!',backupName)

#@-node:ekr.20100119145629.6108:handleWriteLeoFileException
#@-node:ekr.20100119145629.6111:writeToFileHelper & helpers
#@-node:ekr.20100121050224.6141:Fixed crash in writeToFileHelper
#@+node:ekr.20100121105450.6173:Add warnings when @file logic happens
#@+node:ekr.20041005105605.73:findChild4
def findChild4 (self,headline):

    """Return the next vnode in at.root.tnodeLisft.
    This is called only for @file/@noref nodes"""

    # Note: tnodeLists are used _only_ when reading @file (not @thin) nodes.
    # tnodeLists compensate (a hack) for not having gnx's in derived files! 

    trace = False and not g.unitTesting
    at = self ; v = at.root.v

    if not g.unitTesting:
        if v.isAtFileNode():
            g.es_print('Warning: @file logic',v.h)

    if trace: g.trace('%s %s %s' % (
        at.tnodeListIndex,
        v.tnodeList[at.tnodeListIndex],headline))

    if not hasattr(v,"tnodeList"):
        at.readError("no tnodeList for " + repr(v))
        g.es("write the @file node or use the Import Derived File command")
        g.trace("no tnodeList for ",v,g.callers())
        return None

    if at.tnodeListIndex >= len(v.tnodeList):
        at.readError("bad tnodeList index: %d, %s" % (at.tnodeListIndex,repr(v)))
        g.trace("bad tnodeList index",at.tnodeListIndex,len(v.tnodeList),v)
        return None

    v = v.tnodeList[at.tnodeListIndex]
    assert(v)
    at.tnodeListIndex += 1

    # Don't check the headline.  It simply causes problems.
    v.setVisited() # Supress warning/deletion of unvisited nodes.
    return v
#@-node:ekr.20041005105605.73:findChild4
#@-node:ekr.20100121105450.6173:Add warnings when @file logic happens
#@+node:ekr.20100120095741.6134:Fixed mkstemp bug
@nocolor-node

https://bugs.launchpad.net/leo-editor/+bug/510145

Current leo trunk, r2732, Slackware Linux

- I go to /tmp in terminal
- there is no aaa.leo there (this is important, see below why)
- I launch leo (the current working directory is /tmp)
- I select "File->Save as" menu item
- the save file dialog opens in /tmp, this is correct
- I type in the file name "aaa" then hit "Save" button
- leo dumps an error in the log pane:

exception renaming /tmp/aaa.leo to /tmp/tmpbNydoS
IOError: [Errno 2] No such file or directory: u'/tmp/aaa.leo'

=============

The solution was to create the backup file only if fileName exists.
#@nonl
#@+node:ekr.20100119145629.6111:writeToFileHelper & helpers
def writeToFileHelper (self,fileName,toOPML):

    c = self.c ; toZip = c.isZipped
    ok,backupName = self.createBackupFile(fileName)
    if not ok: return False
    fileName,theActualFile = self.createActualFile(fileName,toOPML,toZip)
    self.mFileName = fileName
    self.outputFile = StringIO() # Always write to a string.

    try:
        if toOPML:
            self.putToOPML()
        else:
            self.putLeoFile()
        s = self.outputFile.getvalue()
        g.app.write_Leo_file_string = s # 2010/01/19: always set this.
        if toZip:
            self.writeZipFile(s)
        else:
            if g.isPython3:
                s = bytes(s,self.leo_file_encoding,'replace')
            theActualFile.write(s)
            theActualFile.close()
            c.setFileTimeStamp(fileName)
            # raise AttributeError # To test handleWriteLeoFileException.
            # Delete backup file.
            if backupName and g.os_path_exists(backupName):
                self.deleteFileWithMessage(backupName,'backup')
        return True
    except Exception:
        self.handleWriteLeoFileException(
            fileName,backupName,theActualFile)
        return False
#@+node:ekr.20100119145629.6106:createActualFile
def createActualFile (self,fileName,toOPML,toZip):

    c = self.c

    if toOPML and not self.mFileName.endswith('opml'):
        fileName = self.mFileName + '.opml'

    if toZip:
        self.toString = True
        theActualFile = None
    else:
        try:
            # 2010/01/21: always write in binary mode.
            theActualFile = open(fileName,'wb')
        except IOError:
            theActualFile = None

    return fileName,theActualFile
#@-node:ekr.20100119145629.6106:createActualFile
#@+node:ekr.20031218072017.3047:createBackupFile
def createBackupFile (self,fileName):

    '''
        Create a closed backup file and copy the file to it,
        but only if the original file exists.
    '''

    c = self.c

    if g.os_path_exists(fileName):
        # backupName = g.os_path_join(g.app.loadDir,fileName+'.bak')
        fd,backupName = tempfile.mkstemp(text=False)
        os.close(fd)
        ok = g.utils_rename(c,fileName,backupName)
        if not ok and self.read_only:
            g.es("read only",color="red")
    else:
        ok,backupName = True,None

    return ok,backupName
#@-node:ekr.20031218072017.3047:createBackupFile
#@+node:ekr.20100119145629.6108:handleWriteLeoFileException
def handleWriteLeoFileException(self,fileName,backupName,theActualFile):

    c = self.c

    g.es("exception writing:",fileName)
    g.es_exception(full=True)

    if theActualFile:
        theActualFile.close()

    # Delete fileName.
    if fileName and g.os_path_exists(fileName):
        self.deleteFileWithMessage(fileName,'')

    # Rename backupName to fileName.
    if backupName and g.os_path_exists(backupName):
        g.es("restoring",fileName,"from",backupName)
        g.utils_rename(c,backupName,fileName)
    else:
        g.es_print('does not exist!',backupName)

#@-node:ekr.20100119145629.6108:handleWriteLeoFileException
#@-node:ekr.20100119145629.6111:writeToFileHelper & helpers
#@-node:ekr.20100120095741.6134:Fixed mkstemp bug
#@+node:ekr.20100121162122.6142:Removed most usage of _bodyString & _headString
@nocolor-node

Made sure _bodyString _headString used only in leoNodes.py.

We allow setting this vars in file reading code.

*** p.b/p.h setters call c.setBody/HeadString,
    which are very slow!
#@+node:ekr.20040306220230:p.Headline & body strings
def bodyString (self):

    return self.v.bodyString()

def headString (self):

    return self.v.headString()

def cleanHeadString (self):

    return self.v.cleanHeadString()
#@-node:ekr.20040306220230:p.Headline & body strings
#@+node:ekr.20090128083459.74:p.Properties
#@+node:ekr.20090128083459.75:p.b property
def __get_b(self):

    p = self
    return p.bodyString()

def __set_b(self,val):

    p = self ; c = p.v and p.v.context
    if c:
        c.setBodyString(p, val)
        # Don't redraw the screen: p.b must be fast.
        # c.redraw_after_icons_changed()

b = property(
    __get_b, __set_b,
    doc = "position body string property")
#@-node:ekr.20090128083459.75:p.b property
#@+node:ekr.20090128083459.76:p.h property
def __get_h(self):

    p = self
    return p.headString()

def __set_h(self,val):

    p = self ; c = p.v and p.v.context
    if c:
        c.setHeadString(p,val)
        # Don't redraw the screen: p.h must be fast.
        # c.redraw_after_head_changed()

h = property(
    __get_h, __set_h,
    doc = "position headline string property")  
#@-node:ekr.20090128083459.76:p.h property
#@+node:ekr.20090215165030.3:p.gnx property
def __get_gnx(self):
    p = self
    return g.app.nodeIndices.toString(p.v.fileIndex)

gnx = property(
    __get_gnx, # __set_gnx,
    doc = "position gnx property")
#@-node:ekr.20090215165030.3:p.gnx property
#@-node:ekr.20090128083459.74:p.Properties
#@+node:ekr.20090130065000.1:v.Properties
#@+node:ekr.20090130114732.5:v.b Property
def __get_b(self):

    v = self
    return v.bodyString()

def __set_b(self,val):

    v = self
    v.setBodyString(val)

b = property(
    __get_b, __set_b,
    doc = "vnode body string property")
#@-node:ekr.20090130114732.5:v.b Property
#@+node:ekr.20090130125002.1:v.h property
def __get_h(self):

    v = self
    return v.headString()

def __set_h(self,val):

    v = self
    v.setHeadString(val)

h = property(
    __get_h, __set_h,
    doc = "vnode headline string property")  
#@-node:ekr.20090130125002.1:v.h property
#@+node:ekr.20090130114732.6:v.u Property
def __get_u(self):
    v = self
    if not hasattr(v,'unknownAttributes'):
        v.unknownAttributes = {}
    return v.unknownAttributes

def __set_u(self,val):
    v = self
    if val is None:
        if hasattr(v,'unknownAttributes'):
            delattr(v,'unknownAttributes')
    elif type(val) == type({}):
        v.unknownAttributes = val
    else:
        raise ValueError

u = property(
    __get_u, __set_u,
    doc = "vnode unknownAttribute property")
#@-node:ekr.20090130114732.6:v.u Property
#@+node:ekr.20090215165030.1:v.gnx Property
def __get_gnx(self):
    v = self
    return g.app.nodeIndices.toString(v.fileIndex)

gnx = property(
    __get_gnx, # __set_gnx,
    doc = "vnode gnx property")
#@-node:ekr.20090215165030.1:v.gnx Property
#@-node:ekr.20090130065000.1:v.Properties
#@+node:ekr.20040315032144:v .setBodyString & v.setHeadString
def setBodyString (self,s):

    # trace = False and not g.unitTesting
    v = self
    # if trace and v._bodyString != s:
        # g.trace('v %s %s -> %s %s\nold: %s\nnew: %s' % (
            # v.h, len(v._bodyString),len(s),g.callers(5),
            # v._bodyString,s))
    v._bodyString = g.toUnicode(s,reportErrors=True)

def setHeadString (self,s):
    v = self
    v._headString = g.toUnicode(s,reportErrors=True)

initBodyString = setBodyString
initHeadString = setHeadString
setHeadText = setHeadString
setTnodeText = setBodyString
#@-node:ekr.20040315032144:v .setBodyString & v.setHeadString
#@+node:ekr.20040305223522:c.setBodyString
def setBodyString (self,p,s):

    c = self ; v = p.v
    if not c or not v: return

    s = g.toUnicode(s)
    current = c.p
    # 1/22/05: Major change: the previous test was: 'if p == current:'
    # This worked because commands work on the presently selected node.
    # But setRecentFiles may change a _clone_ of the selected node!
    if current and p.v==current.v:
        # Revert to previous code, but force an empty selection.
        c.frame.body.setSelectionAreas(s,None,None)
        w = c.frame.body.bodyCtrl
        i = w.getInsertPoint()
        w.setSelectionRange(i,i)
        # This code destoys all tags, so we must recolor.
        c.recolor()

    # Keep the body text in the vnode up-to-date.
    if v.b != s:
        v.setBodyString(s)
        v.setSelection(0,0)
        p.setDirty()
        if not c.isChanged():
            c.setChanged(True)
        c.redraw_after_icons_changed()
#@nonl
#@-node:ekr.20040305223522:c.setBodyString
#@+node:ekr.20050411193627.9:afterInsertNode
def afterInsertNode (self,p,command,bunch,dirtyVnodeList=[]):

    u = self ; c = u.c
    if u.redoing or u.undoing: return

    # Set types & helpers
    bunch.kind = 'insert'
    bunch.undoType = command
    # g.trace(repr(command),g.callers())

    # Set helpers
    bunch.undoHelper = u.undoInsertNode
    bunch.redoHelper = u.redoInsertNode

    bunch.newP = p.copy()
    bunch.dirtyVnodeList = dirtyVnodeList

    bunch.newBack = p.back()
    bunch.newParent = p.parent()

    bunch.newChanged = c.isChanged()
    bunch.newDirty = p.isDirty()
    bunch.newMarked = p.isMarked()

    if bunch.pasteAsClone:
        beforeTree=bunch.beforeTree
        afterTree = []
        for bunch2 in beforeTree:
            v = bunch2.v
            afterTree.append(
                g.Bunch(v=v,head=v.h[:],body=v.b[:]))
        bunch.afterTree=afterTree
        # g.trace(afterTree)

    u.pushBead(bunch)
#@-node:ekr.20050411193627.9:afterInsertNode
#@-node:ekr.20100121162122.6142:Removed most usage of _bodyString & _headString
#@+node:ekr.20100122073254.6165:Don't use tnodeList to separate old/new @file nodes
@nocolor-node

- Removed thinFile arg from atFile.read.
  atFile.read can uncache *any* cached file.
- Removed thinfile arg from initReadIvars.
- self.thinFile ivar set only in readOpenFile.
- atFile.read no longer calls scanHeaderForThin:
  we simply use the thinFile value returned by scanHeader.
- atFile.readOpenFile deletes children as needed.
#@nonl
#@+node:ekr.20041005105605.21:read (atFile) & helpers
# This code no longer reads @noref trees.

def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    # g.trace(root.h,len(root.b))
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    if at.errors:
        return False
    fileName = at.openFileForReading(fromString=fromString)
    if at.inputFile:
        c.setFileTimeStamp(fileName)
    else:
        return False
    root.v.at_read = True # Remember that we have read this file.
    # Get the file from the cache if possible.
    ok,cachefile = self.readFromCache(fileName,force,root)
    if ok:
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    root.clearVisitedInTree()
    d = at.scanAllDirectives(root,importing=at.importing,reading=True)
    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.warnAboutUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        self.copyAllTempBodyStringsToTnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if at.errors == 0:
        self.writeCachedTree(root,cachefile)

    return at.errors == 0
#@+node:ekr.20041005105605.25:deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
#@-node:ekr.20041005105605.25:deleteAllTempBodyStrings
#@+node:ekr.20100122130101.6174:deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@-node:ekr.20100122130101.6174:deleteTnodeList
#@+node:ekr.20041005105605.22:initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName

    # isAtFile = (
        # not thinFile and
        # not importFileName and
        # not atShadow and
        # not fromString and
        # root.h.startswith('@file'))
#@-node:ekr.20041005105605.22:initFileName
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20071105164407:warnAboutUnvisitedNodes
def warnAboutUnvisitedNodes (self,root):

    resurrected = 0

    for p in root.self_and_subtree():
        if not p.v.isVisited():
            g.trace('**** not visited',p.v,p.h)
            g.es('resurrected node:',p.h,color='blue')
            g.es('in file:',root.h,color='blue')
            resurrected += 1

    if resurrected:
        g.es('you may want to delete ressurected nodes')
#@-node:ekr.20071105164407:warnAboutUnvisitedNodes
#@-node:ekr.20041005105605.21:read (atFile) & helpers
#@+node:ekr.20041005105605.27:readOpenFile
def readOpenFile(self,root,theFile,fileName,deleteNodes=False):

    '''Read an open derived file.

    Leo 4.5 and later can only read 4.x derived files.'''

    at = self

    firstLines,read_new,thinFile = at.scanHeader(theFile,fileName)
    at.thinFile = thinFile
        # 2010/01/22: use *only* the header to set self.thinFile.

    if deleteNodes and at.shouldDeleteChildren(root,thinFile):
        root.v.at_read = True # Create the attribute for all clones.
        while root.hasChildren():
            root.firstChild().doDelete()

    if read_new:
        lastLines = at.scanText4(theFile,fileName,root)
    else:
        firstLines = [] ; lastLines = []
        if at.atShadow:
            g.trace(g.callers())
            g.trace('invalid @shadow private file',fileName)
            at.error('invalid @shadow private file',fileName)
        else:
            at.error('can not read 3.x derived file',fileName)
            g.es('you may upgrade these file using Leo 4.0 through 4.4.x')
            g.trace('root',root and root.h,fileName)

    if root:
        root.v.setVisited() # Disable warning about set nodes.

    << handle first and last lines >>

    return thinFile
#@+node:ekr.20041005105605.28:<< handle first and last lines >>
try:
    body = root.v.tempBodyString
except Exception:
    body = ""

lines = body.split('\n')
at.completeFirstDirectives(lines,firstLines)
at.completeLastDirectives(lines,lastLines)
s = '\n'.join(lines).replace('\r', '')
root.v.tempBodyString = s
#@-node:ekr.20041005105605.28:<< handle first and last lines >>
#@+node:ekr.20100122130101.6175:shouldDeleteChildren
def shouldDeleteChildren (self,root,thinFile):

    '''Return True if we should delete all children before a read.'''

    # Delete all children except for old-style @file nodes

    if root.isAtNoSentFileNode():
        return False
    elif root.isAtFileNode() and not thinFile:
        return False
    else:
        return True
#@-node:ekr.20100122130101.6175:shouldDeleteChildren
#@-node:ekr.20041005105605.27:readOpenFile
#@+node:ekr.20041005105605.13:initReadIvars
def initReadIvars(self,root,fileName,
    importFileName=None,
    perfectImportRoot=None,
    atShadow=False,
):

    importing = importFileName is not None

    self.initCommonIvars()

    << init ivars for reading >>

    self.scanDefaultDirectory(root,importing=importing)
    if self.errors: return

    # Init state from arguments.
    self.perfectImportRoot = perfectImportRoot
    self.importing = importing
    self.root = root
    self.targetFileName = fileName
    self.thinFile = False # 2010/01/22: was thinFile
    self.atShadow = atShadow
#@+node:ekr.20041005105605.14:<< init ivars for reading >>
self.atAllFlag = False # True if @all seen.
self.cloneSibCount = 0 # n > 1: Make sure n cloned sibs exists at next @+node sentinel
self.correctedLines = 0
self.docOut = [] # The doc part being accumulated.
self.done = False # True when @-leo seen.
self.endSentinelStack = []
self.importing = False
self.importRootSeen = False
self.indentStack = []
self.inputFile = None
self.lastLines = [] # The lines after @-leo
self.lastThinNode = None # Used by createThinChild4.
self.leadingWs = ""
self.lineNumber = 0 # New in Leo 4.4.8.
self.out = None
self.outStack = []
self.rootSeen = False
self.tnodeList = [] # Needed until old-style @file nodes are no longer supported.
self.tnodeListIndex = 0
self.v = None
self.tStack = []
self.thinNodeStack = [] # Used by createThinChild4.
self.updateWarningGiven = False
#@-node:ekr.20041005105605.14:<< init ivars for reading >>
#@-node:ekr.20041005105605.13:initReadIvars
#@+node:ekr.20041005105605.129:at.scanHeader
def scanHeader(self,theFile,fileName):

    """Scan the @+leo sentinel.

    Sets self.encoding, and self.start/endSentinelComment.

    Returns (firstLines,new_df,isThinDerivedFile) where:
    firstLines        contains all @first lines,
    new_df            is True if we are reading a new-format derived file.
    isThinDerivedFile is True if the file is an @thin file."""

    trace = False
    at = self
    firstLines = [] # The lines before @+leo.
    tag = "@+leo"
    valid = True ; new_df = False ; isThinDerivedFile = False
    << skip any non @+leo lines >>
    if valid:
        valid,new_df,start,end,isThinDerivedFile = at.parseLeoSentinel(s)
    if valid:
        at.startSentinelComment = start
        at.endSentinelComment = end
        # g.trace('start',repr(start),'end',repr(end))
    else:
        at.error("No @+leo sentinel in: %s" % fileName)
    # g.trace("start,end",repr(at.startSentinelComment),repr(at.endSentinelComment))
    return firstLines,new_df,isThinDerivedFile
#@+node:ekr.20041005105605.130:<< skip any non @+leo lines >>
@ Queue up the lines before the @+leo.

These will be used to add as parameters to the @first directives, if any.
Empty lines are ignored (because empty @first directives are ignored).
NOTE: the function now returns a list of the lines before @+leo.

We can not call sentinelKind here because that depends on
the comment delimiters we set here.

at-first lines are written "verbatim", so nothing more needs to be done!
@c

s = at.readLine(theFile)
if trace: g.trace('first line',repr(s))
while len(s) > 0:
    j = s.find(tag)
    if j != -1: break
    firstLines.append(s) # Queue the line
    s = at.readLine(theFile)

n = len(s)
valid = n > 0
#@-node:ekr.20041005105605.130:<< skip any non @+leo lines >>
#@-node:ekr.20041005105605.129:at.scanHeader
#@+node:ekr.20041005105605.120:at.parseLeoSentinel
def parseLeoSentinel (self,s):

    at = self ; c = at.c
    new_df = False ; valid = True ; n = len(s)
    start = '' ; end = '' ; isThinDerivedFile = False
    encoding_tag = "-encoding="
    version_tag = "-ver="
    tag = "@+leo"
    thin_tag = "-thin"
    << set the opening comment delim >>
    << make sure we have @+leo >>
    << read optional version param >>
    << read optional thin param >>
    << read optional encoding param >>
    << set the closing comment delim >>
    if not new_df and not g.unitTesting:
        g.trace('not new_df(!)',repr(s))
    return valid,new_df,start,end,isThinDerivedFile
#@+node:ekr.20041005105605.121:<< set the opening comment delim >>
# s contains the tag
i = j = g.skip_ws(s,0)

# The opening comment delim is the initial non-tag
while i < n and not g.match(s,i,tag) and not g.is_nl(s,i):
    i += 1

if j < i:
    start = s[j:i]
else:
    valid = False

#@-node:ekr.20041005105605.121:<< set the opening comment delim >>
#@+node:ekr.20041005105605.122:<< make sure we have @+leo >>
@ REM hack: leading whitespace is significant before the @+leo.  We do this so that sentinelKind need not skip whitespace following self.startSentinelComment.  This is correct: we want to be as restrictive as possible about what is recognized as a sentinel.  This minimizes false matches.
@c

if 0: # Make leading whitespace significant.
    i = g.skip_ws(s,i)

if g.match(s,i,tag):
    i += len(tag)
else: valid = False
#@-node:ekr.20041005105605.122:<< make sure we have @+leo >>
#@+node:ekr.20041005105605.123:<< read optional version param >>
new_df = g.match(s,i,version_tag)

if new_df:
    # Pre Leo 4.4.1: Skip to the next minus sign or end-of-line.
    # Leo 4.4.1 +:   Skip to next minus sign, end-of-line, or non numeric character.
    # This is required to handle trailing comment delims properly.
    i += len(version_tag)
    j = i
    while i < len(s) and (s[i] == '.' or s[i].isdigit()):
        i += 1

    if j < i:
        pass
    else:
        valid = False
#@-node:ekr.20041005105605.123:<< read optional version param >>
#@+node:ekr.20041005105605.124:<< read optional thin param >>
if g.match(s,i,thin_tag):
    i += len(tag)
    isThinDerivedFile = True
#@-node:ekr.20041005105605.124:<< read optional thin param >>
#@+node:ekr.20041005105605.125:<< read optional encoding param >>
# Set the default encoding
at.encoding = c.config.default_derived_file_encoding

if g.match(s,i,encoding_tag):
    # Read optional encoding param, e.g., -encoding=utf-8,
    i += len(encoding_tag)
    # Skip to the next end of the field.
    j = s.find(",.",i)
    if j > -1:
        # The encoding field was written by 4.2 or after:
        encoding = s[i:j]
        i = j + 2 # 6/8/04, 1/11/05 (was i = j + 1)
    else:
        # The encoding field was written before 4.2.
        j = s.find('.',i)
        if j > -1:
            encoding = s[i:j]
            i = j + 1 # 6/8/04
        else:
            encoding = None
    # g.trace("encoding:",encoding)
    if encoding:
        if g.isValidEncoding(encoding):
            at.encoding = encoding
        else:
            g.es_print("bad encoding in derived file:",encoding)
    else:
        valid = False
#@-node:ekr.20041005105605.125:<< read optional encoding param >>
#@+node:ekr.20041005105605.126:<< set the closing comment delim >>
# The closing comment delim is the trailing non-whitespace.
i = j = g.skip_ws(s,i)
while i < n and not g.is_ws(s[i]) and not g.is_nl(s,i):
    i += 1
end = s[j:i]
#@-node:ekr.20041005105605.126:<< set the closing comment delim >>
#@-node:ekr.20041005105605.120:at.parseLeoSentinel
#@+node:ekr.20041005105605.74:scanText4 & allies
def scanText4 (self,theFile,fileName,p,verbose=False):

    """Scan a 4.x derived file non-recursively."""

    trace = False and not g.unitTesting
    at = self
    << init ivars for scanText4 >>
    if trace: g.trace(fileName)
    try:
        while at.errors == 0 and not at.done:
            s = at.readLine(theFile)
            self.lineNumber += 1
            if len(s) == 0: break
            kind = at.sentinelKind4(s)
            if kind == at.noSentinel:
                i = 0
            else:
                i = at.skipSentinelStart4(s,0)
            func = at.dispatch_dict[kind]
            if trace: g.trace('%15s %16s %s' % (
                at.sentinelName(kind),func.__name__,repr(s)))
            func(s,i)
    except AssertionError:
        junk, message, junk = sys.exc_info()
        at.error('unexpected assertion failure in',fileName,'\n',message)

    if at.errors == 0 and not at.done:
        << report unexpected end of text >>

    return at.lastLines
#@+node:ekr.20041005105605.75:<< init ivars for scanText4 >>
# Unstacked ivars...
at.cloneSibCount = 0
at.done = False
at.inCode = True
at.indent = 0 # Changed only for sentinels.
at.lastLines = [] # The lines after @-leo
at.leadingWs = ""
at.lineNumber = 0
at.root = p.copy() # Bug fix: 12/10/05
at.rootSeen = False
at.updateWarningGiven = False

# Stacked ivars...
at.endSentinelStack = [at.endLeo] # We have already handled the @+leo sentinel.
at.out = [] ; at.outStack = []
at.v = p.v
at.tStack = []
# New code: always identify root @thin node with self.root:
at.lastThinNode = None
at.thinNodeStack = []
#@nonl
#@-node:ekr.20041005105605.75:<< init ivars for scanText4 >>
#@+node:ekr.20041005105605.76:<< report unexpected end of text >>
assert at.endSentinelStack,'empty sentinel stack'

at.readError(
    "Unexpected end of file. Expecting %s sentinel" %
    at.sentinelName(at.endSentinelStack[-1]))
#@-node:ekr.20041005105605.76:<< report unexpected end of text >>
#@+node:ekr.20041005105605.77:readNormalLine
def readNormalLine (self,s,i):

    at = self

    if at.inCode:
        if not at.raw:
            s = g.removeLeadingWhitespace(s,at.indent,at.tab_width)
        at.out.append(s)
    else:
        << Skip the leading stuff >>
        << Append s to docOut >>
#@+node:ekr.20041005105605.78:<< Skip the leading stuff >>
if len(at.endSentinelComment) == 0:
    # Skip the single comment delim and a blank.
    i = g.skip_ws(s,0)
    if g.match(s,i,at.startSentinelComment):
        i += len(at.startSentinelComment)
        if g.match(s,i," "): i += 1
else:
    i = at.skipIndent(s,0,at.indent)
#@-node:ekr.20041005105605.78:<< Skip the leading stuff >>
#@+node:ekr.20041005105605.79:<< Append s to docOut >>
line = s[i:-1] # remove newline for rstrip.

if line == line.rstrip():
    # no trailing whitespace: the newline is real.
    at.docOut.append(line + '\n')
else:
    # trailing whitespace: the newline is fake.
    at.docOut.append(line)
#@-node:ekr.20041005105605.79:<< Append s to docOut >>
#@-node:ekr.20041005105605.77:readNormalLine
#@+node:ekr.20041005105605.80:start sentinels
#@+node:ekr.20041005105605.81:at.readStartAll
def readStartAll (self,s,i):

    """Read an @+all sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert g.match(s,j,"@+all"),'missing @+all'
    else:
        assert g.match(s,j,"+all"),'missing +all'

    # g.trace('root_seen',at.root_seen,at.root.h,repr(s))
    at.atAllFlag = True

    # Make sure that the generated at-all is properly indented.
    at.out.append(leadingWs + "@all\n")

    at.endSentinelStack.append(at.endAll)
#@-node:ekr.20041005105605.81:at.readStartAll
#@+node:ekr.20041005105605.82:readStartAt & readStartDoc
def readStartAt (self,s,i):
    """Read an @+at sentinel."""
    at = self ; assert g.match(s,i,"+at"),'missing +at'
    if 0:# new code: append whatever follows the sentinel.
        i += 3 ; j = at.skipToEndSentinel(s,i) ; follow = s[i:j]
        at.out.append('@' + follow) ; at.docOut = []
    else:
        i += 3 ; j = g.skip_ws(s,i) ; ws = s[i:j]
        at.docOut = ['@' + ws + '\n'] # This newline may be removed by a following @nonl
    at.inCode = False
    at.endSentinelStack.append(at.endAt)

def readStartDoc (self,s,i):
    """Read an @+doc sentinel."""
    at = self ; assert g.match(s,i,"+doc"),'missing +doc'
    if 0: # new code: append whatever follows the sentinel.
        i += 4 ; j = at.skipToEndSentinel(s,i) ; follow = s[i:j]
        at.out.append('@' + follow) ; at.docOut = []
    else:
        i += 4 ; j = g.skip_ws(s,i) ; ws = s[i:j]
        at.docOut = ["@doc" + ws + '\n'] # This newline may be removed by a following @nonl
    at.inCode = False
    at.endSentinelStack.append(at.endDoc)

def skipToEndSentinel(self,s,i):
    at = self
    end = at.endSentinelComment
    if end:
        j = s.find(end,i)
        if j == -1:
            return g.skip_to_end_of_line(s,i)
        else:
            return j
    else:
        return g.skip_to_end_of_line(s,i)
#@-node:ekr.20041005105605.82:readStartAt & readStartDoc
#@+node:ekr.20041005105605.83:readStartLeo
def readStartLeo (self,s,i):

    """Read an unexpected @+leo sentinel."""

    at = self
    assert g.match(s,i,"+leo"),'missing +leo sentinel'
    at.readError("Ignoring unexpected @+leo sentinel")
#@-node:ekr.20041005105605.83:readStartLeo
#@+node:ekr.20041005105605.84:readStartMiddle
def readStartMiddle (self,s,i):

    """Read an @+middle sentinel."""

    at = self

    at.readStartNode(s,i,middle=True)
#@-node:ekr.20041005105605.84:readStartMiddle
#@+node:ekr.20041005105605.85:at.readStartNode
def readStartNode (self,s,i,middle=False):

    """Read an @+node or @+middle sentinel."""

    trace = False and not g.unitTesting
    at = self
    if middle:
        assert g.match(s,i,"+middle:"),'missing +middle'
        i += 8
    else:
        assert g.match(s,i,"+node:"),'missing +node'
        i += 6

    if at.thinFile:
        << set gnx and bump i >>
    << Set headline, undoing the CWEB hack >>
    if not at.root_seen:
        # g.trace(repr(s[0:i+20]))
        at.root_seen = True

    i,newIndent = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    at.indentStack.append(at.indent) ; at.indent = newIndent

    at.outStack.append(at.out) ; at.out = []
    at.tStack.append(at.v)

    if trace: g.trace(at.root)
    if at.importing:
        p = at.createImportedNode(at.root,headline)
        at.v = p.v
    elif at.thinFile:
        if at.thinNodeStack:
            at.thinNodeStack.append(at.lastThinNode)
            v = at.createThinChild4(gnx,headline)
        else:
            v = at.root.v
            at.thinNodeStack.append(v)
        at.lastThinNode = v
        at.v = v
    else:
        at.v = at.findChild4(headline)

    if trace: g.trace('scanning',at.v)

    at.endSentinelStack.append(at.endNode)
#@+node:ekr.20041005105605.86:<< set gnx and bump i >>
# We have skipped past the opening colon of the gnx.
j = s.find(':',i)
if j == -1:
    g.trace("no closing colon",g.get_line(s,i))
    at.readError("Expecting gnx in @+node sentinel")
    return # 5/17/04
else:
    gnx = s[i:j]
    i = j + 1 # Skip the i
#@-node:ekr.20041005105605.86:<< set gnx and bump i >>
#@+node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
# Set headline to the rest of the line.
# Don't strip leading whitespace."

if len(at.endSentinelComment) == 0:
    headline = s[i:-1].rstrip()
else:
    k = s.rfind(at.endSentinelComment,i)
    headline = s[i:k].rstrip() # works if k == -1

# Undo the CWEB hack: undouble @ signs if the opening comment delim ends in '@'.
if at.startSentinelComment[-1:] == '@':
    headline = headline.replace('@@','@')
#@-node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
#@-node:ekr.20041005105605.85:at.readStartNode
#@+node:ekr.20041005105605.89:readStartOthers
def readStartOthers (self,s,i):

    """Read an @+others sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert g.match(s,j,"@+others"),'missing @+others'
    else:
        assert g.match(s,j,"+others"),'missing +others'

    # Make sure that the generated at-others is properly indented.
    at.out.append(leadingWs + "@others\n")

    at.endSentinelStack.append(at.endOthers)
#@-node:ekr.20041005105605.89:readStartOthers
#@-node:ekr.20041005105605.80:start sentinels
#@+node:ekr.20041005105605.90:end sentinels
#@+node:ekr.20041005105605.91:readEndAll (4.2)
def readEndAll (self,unused_s,unused_i):

    """Read an @-all sentinel."""

    at = self
    at.popSentinelStack(at.endAll)
#@-node:ekr.20041005105605.91:readEndAll (4.2)
#@+node:ekr.20041005105605.92:readEndAt & readEndDoc
def readEndAt (self,unused_s,unused_i):

    """Read an @-at sentinel."""

    at = self
    at.readLastDocLine("@")
    at.popSentinelStack(at.endAt)
    at.inCode = True

def readEndDoc (self,unused_s,unused_i):

    """Read an @-doc sentinel."""

    at = self
    at.readLastDocLine("@doc")
    at.popSentinelStack(at.endDoc)
    at.inCode = True
#@-node:ekr.20041005105605.92:readEndAt & readEndDoc
#@+node:ekr.20041005105605.93:readEndLeo
def readEndLeo (self,unused_s,unused_i):

    """Read an @-leo sentinel."""

    at = self

    # Ignore everything after @-leo.
    # Such lines were presumably written by @last.
    while 1:
        s = at.readLine(at.inputFile)
        if len(s) == 0: break
        at.lastLines.append(s) # Capture all trailing lines, even if empty.

    at.done = True
#@-node:ekr.20041005105605.93:readEndLeo
#@+node:ekr.20041005105605.94:readEndMiddle
def readEndMiddle (self,s,i):

    """Read an @-middle sentinel."""

    at = self

    at.readEndNode(s,i,middle=True)
#@-node:ekr.20041005105605.94:readEndMiddle
#@+node:ekr.20041005105605.95:at.readEndNode
def readEndNode (self,unused_s,unused_i,middle=False):

    """Handle end-of-node processing for @-others and @-ref sentinels."""

    trace = False and not g.unitTesting
    at = self ; c = at.c

    # End raw mode.
    at.raw = False

    # Set the temporary body text.
    s = ''.join(at.out)
    s = g.toUnicode(s)

    # g.trace(repr(s))

    if at.importing:
        at.v._bodyString = s # Allowed use of _bodyString.
    elif middle: 
        pass # Middle sentinels never alter text.
    else:
        if hasattr(at.v,"tempBodyString") and s != at.v.tempBodyString:
            old = at.v.tempBodyString
        elif at.v.hasBody() and s != at.v.getBody():
            old = at.v.getBody()
        else:
            old = None
        # 9/4/04: Suppress this warning for the root: @first complicates matters.
        if old and at.v != at.root.v: # and not g.app.unitTesting
            << indicate that the node has been changed >>
        if old and at.atAllFlag:
            # Don't change.
            if trace: g.trace('*** no update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
        else:
            if trace: g.trace('*** update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
            at.v.tempBodyString = s

    # Indicate that the vnode has been set in the derived file.
    at.v.setVisited()
    # g.trace('visit',at.v)

    # End the previous node sentinel.
    at.indent = at.indentStack.pop()
    at.out = at.outStack.pop()
    at.v = at.tStack.pop()
    if at.thinFile and not at.importing:
        at.lastThinNode = at.thinNodeStack.pop()

    at.popSentinelStack(at.endNode)
#@+node:ekr.20041005105605.96:<< indicate that the node has been changed >>
if at.perfectImportRoot:
    << bump at.correctedLines and tell about the correction >>
    at.v._bodyString = s # Allowed use of _bodyString.
        # Just setting at.v.tempBodyString won't work here.
    at.v.setDirty() # Mark the node dirty.  Ancestors will be marked dirty later.
    at.c.setChanged(True)
else:
    # New in Leo 4.4.1 final.  This warning can be very confusing.
    # New in Leo 4.7 b2: We suppress warning for trees containing '@all'
    if at.atAllFlag: # Give the warning if we are not in an '@all' tree.
        pass
    # elif not at.updateWarningGiven:
    else:
        # at.updateWarningGiven = True
        # g.pr("***",at.v,at.root.v)
        g.es_print("uncached read node changed",at.v.h,color="red") # was at.root.h
    # Just set the dirty bit. Ancestors will be marked dirty later.
    at.v.setDirty()
    # Important: the dirty bits won't stick unless we set c.changed here.
    # Do *not* call c.setChanged(True) here: that would be too slow.
    c.changed = True
#@nonl
#@+node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
# Report the number of corrected nodes.
at.correctedLines += 1

found = False
for p in at.perfectImportRoot.self_and_subtree():
    if p.v == at.v:
        found = True ; break

if found:
    if 0: # For debugging.
        g.pr('\n','-' * 40)
        g.pr("old",len(old))
        for line in g.splitLines(old):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
        g.pr("new",len(s))
        for line in g.splitLines(s):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
else:
    # This should never happen.
    g.es("correcting hidden node: v=",repr(at.v),color="red")
#@-node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
#@-node:ekr.20041005105605.96:<< indicate that the node has been changed >>
#@-node:ekr.20041005105605.95:at.readEndNode
#@+node:ekr.20041005105605.98:readEndOthers
def readEndOthers (self,unused_s,unused_i):

    """Read an @-others sentinel."""

    at = self
    at.popSentinelStack(at.endOthers)
#@-node:ekr.20041005105605.98:readEndOthers
#@+node:ekr.20041005105605.99:readLastDocLine
def readLastDocLine (self,tag):

    """Read the @c line that terminates the doc part.
    tag is @doc or @."""

    at = self
    end = at.endSentinelComment
    start = at.startSentinelComment
    s = ''.join(at.docOut)

    # Remove the @doc or @space.  We'll add it back at the end.
    if g.match(s,0,tag):
        s = s[len(tag):]
    else:
        at.readError("Missing start of doc part")
        return

    # Bug fix: Append any whitespace following the tag to tag.
    while s and s[0] in (' ','\t'):
        tag = tag + s[0] ; s = s[1:]

    if end:
        # Remove leading newline.
        if s[0] == '\n': s = s[1:]
        # Remove opening block delim.
        if g.match(s,0,start):
            s = s[len(start):]
        else:
            at.readError("Missing open block comment")
            g.trace('tag',repr(tag),'start',repr(start),'s',repr(s))
            return
        # Remove trailing newline.
        if s[-1] == '\n': s = s[:-1]
        # Remove closing block delim.
        if s[-len(end):] == end:
            s = s[:-len(end)]
        else:
            at.readError("Missing close block comment")
            g.trace(s)
            g.trace(end)
            g.trace(start)
            return

    at.out.append(tag + s)
    at.docOut = []
#@-node:ekr.20041005105605.99:readLastDocLine
#@-node:ekr.20041005105605.90:end sentinels
#@+node:ekr.20041005105605.100:Unpaired sentinels
# Ooops: shadow files are cleared if there is a read error!!
#@nonl
#@+node:ekr.20041005105605.101:ignoreOldSentinel
def  ignoreOldSentinel (self,s,unused_i):

    """Ignore an 3.x sentinel."""

    g.es("ignoring 3.x sentinel:",s.strip(),color="blue")
#@-node:ekr.20041005105605.101:ignoreOldSentinel
#@+node:ekr.20041005105605.102:readAfterRef
def  readAfterRef (self,s,i):

    """Read an @afterref sentinel."""

    at = self
    assert g.match(s,i,"afterref"),'missing afterref'

    # Append the next line to the text.
    s = at.readLine(at.inputFile)
    at.out.append(s)
#@-node:ekr.20041005105605.102:readAfterRef
#@+node:ekr.20041005105605.103:readClone
def readClone (self,s,i):

    at = self ; tag = "clone"

    assert g.match(s,i,tag),'missing clone sentinel'

    # Skip the tag and whitespace.
    i = g.skip_ws(s,i+len(tag))

    # Get the clone count.
    junk,val = g.skip_long(s,i)

    if val == None:
        at.readError("Invalid count in @clone sentinel")
    else:
        at.cloneSibCount = val
#@-node:ekr.20041005105605.103:readClone
#@+node:ekr.20041005105605.104:readComment
def readComment (self,s,i):

    """Read an @comment sentinel."""

    assert g.match(s,i,"comment"),'missing comment sentinel'

    # Just ignore the comment line!
#@-node:ekr.20041005105605.104:readComment
#@+node:ekr.20041005105605.105:readDelims
def readDelims (self,s,i):

    """Read an @delims sentinel."""

    at = self
    assert g.match(s,i-1,"@delims"),'missing @delims'

    # Skip the keyword and whitespace.
    i0 = i-1
    i = g.skip_ws(s,i-1+7)

    # Get the first delim.
    j = i
    while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
        i += 1

    if j < i:
        at.startSentinelComment = s[j:i]
        # g.pr("delim1:", at.startSentinelComment)

        # Get the optional second delim.
        j = i = g.skip_ws(s,i)
        while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
            i += 1
        end = g.choose(j<i,s[j:i],"")
        i2 = g.skip_ws(s,i)
        if end == at.endSentinelComment and (i2 >= len(s) or g.is_nl(s,i2)):
            at.endSentinelComment = "" # Not really two params.
            line = s[i0:j]
            line = line.rstrip()
            at.out.append(line+'\n')
        else:
            at.endSentinelComment = end
            # g.pr("delim2:",end)
            line = s[i0:i]
            line = line.rstrip()
            at.out.append(line+'\n')
    else:
        at.readError("Bad @delims")
        # Append the bad @delims line to the body text.
        at.out.append("@delims")
#@-node:ekr.20041005105605.105:readDelims
#@+node:ekr.20041005105605.106:readDirective (@@)
def readDirective (self,s,i):

    """Read an @@sentinel."""

    trace = False and not g.unitTesting
    at = self
    assert g.match(s,i,"@"),'missing @@ sentinel' # The first '@' has already been eaten.

    if trace: g.trace(repr(s[i:]))
        # g.trace(g.get_line(s,i))

    if g.match_word(s,i,"@raw"):
        at.raw = True
    elif g.match_word(s,i,"@end_raw"):
        at.raw = False

    e = at.endSentinelComment
    s2 = s[i:]
    if len(e) > 0:
        k = s.rfind(e,i)
        if k != -1:
            s2 = s[i:k] + '\n'

    start = at.startSentinelComment
    if start and len(start) > 0 and start[-1] == '@':
        s2 = s2.replace('@@','@')

    if 0: # New in 4.2.1: never change comment delims here...
        if g.match_word(s,i,"@language"):
            << handle @language >>
        elif g.match_word(s,i,"@comment"):
            << handle @comment >>

    at.out.append(s2)
#@+node:ekr.20041005105605.107:<< handle @language >>
# Skip the keyword and whitespace.
i += len("@language")
i = g.skip_ws(s,i)
j = g.skip_c_id(s,i)
language = s[i:j]

delim1,delim2,delim3 = g.set_delims_from_language(language)

if trace:
    g.trace(g.get_line(s,i))
    g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("ignoring bad @language sentinel:",line,color="red")
#@-node:ekr.20041005105605.107:<< handle @language >>
#@+node:ekr.20041005105605.108:<< handle @comment >>
j = g.skip_line(s,i)
line = s[i:j]
delim1,delim2,delim3 = g.set_delims_from_string(line)

#g.trace(g.get_line(s,i))
#g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    self.startSentinelComment = delim1
    self.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    self.startSentinelComment = delim2
    self.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("ignoring bad @comment sentinel:",line,color="red")
#@-node:ekr.20041005105605.108:<< handle @comment >>
#@-node:ekr.20041005105605.106:readDirective (@@)
#@+node:ekr.20041005105605.109:readNl
def readNl (self,s,i):

    """Handle an @nonl sentinel."""

    at = self
    assert g.match(s,i,"nl"),'missing nl sentinel'

    if at.inCode:
        at.out.append('\n')
    else:
        at.docOut.append('\n')
#@-node:ekr.20041005105605.109:readNl
#@+node:ekr.20041005105605.110:readNonl
def readNonl (self,s,i):

    """Handle an @nonl sentinel."""

    at = self
    assert g.match(s,i,"nonl"),'missing nonl sentinel'

    if at.inCode:
        s = ''.join(at.out)
        # 2010/01/07: protect against a mostly-harmless read error.
        if s:
            if s[-1] == '\n':
                at.out = [s[:-1]]
            else:
                g.trace("out:",s)
                at.readError("unexpected @nonl directive in code part")
    else:
        s = ''.join(at.pending)
        if s:
            if s[-1] == '\n':
                at.pending = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in pending doc part")
        else:
            s = ''.join(at.docOut)
            if s and s[-1] == '\n':
                at.docOut = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in doc part")
#@-node:ekr.20041005105605.110:readNonl
#@+node:ekr.20041005105605.111:readRef
@ The sentinel contains an @ followed by a section name in angle brackets.  This code is different from the code for the @@ sentinel: the expansion of the reference does not include a trailing newline.
@c

def readRef (self,s,i):

    """Handle an @<< sentinel."""

    at = self
    j = g.skip_ws(s,i)
    assert g.match(s,j,"<<"),'missing @<< sentinel'

    if len(at.endSentinelComment) == 0:
        line = s[i:-1] # No trailing newline
    else:
        k = s.find(at.endSentinelComment,i)
        line = s[i:k] # No trailing newline, whatever k is.

    # Undo the cweb hack.
    start = at.startSentinelComment
    if start and len(start) > 0 and start[-1] == '@':
        line = line.replace('@@','@')

    at.out.append(line)
#@-node:ekr.20041005105605.111:readRef
#@+node:ekr.20041005105605.112:readVerbatim
def readVerbatim (self,s,i):

    """Read an @verbatim sentinel."""

    at = self
    assert g.match(s,i,"verbatim"),'missing verbatim sentinel'

    # Append the next line to the text.
    s = at.readLine(at.inputFile) 
    i = at.skipIndent(s,0,at.indent)
    # Do **not** insert the verbatim line itself!
        # at.out.append("@verbatim\n")
    at.out.append(s[i:])
#@+node:ekr.20090620101138.6072:@test verbatim sentinel
if g.unitTesting:
    c,p = g.getTestVars()

    # Here is something that should generate a verbtim sentinel::

#@verbatim
    #@+leo-encoding=iso-8859-1.

    # The length of this node should remain constant.

    assert len(p.b) == 235,len(p.b)
#@nonl
#@-node:ekr.20090620101138.6072:@test verbatim sentinel
#@-node:ekr.20041005105605.112:readVerbatim
#@-node:ekr.20041005105605.100:Unpaired sentinels
#@+node:ekr.20041005105605.113:badEndSentinel, popSentinelStack
def badEndSentinel (self,expectedKind):

    """Handle a mismatched ending sentinel."""

    at = self
    assert at.endSentinelStack,'empty sentinel stack'
    s = "Ignoring %s sentinel.  Expecting %s" % (
        at.sentinelName(at.endSentinelStack[-1]),
        at.sentinelName(expectedKind))
    at.readError(s)

def popSentinelStack (self,expectedKind):

    """Pop an entry from endSentinelStack and check it."""

    at = self
    if at.endSentinelStack and at.endSentinelStack[-1] == expectedKind:
        at.endSentinelStack.pop()
    else:
        at.badEndSentinel(expectedKind)
#@-node:ekr.20041005105605.113:badEndSentinel, popSentinelStack
#@-node:ekr.20041005105605.74:scanText4 & allies
#@+node:ekr.20050103163224:scanHeaderForThin (used by import code)
# Note: Import code uses this.

def scanHeaderForThin (self,theFile,fileName):

    '''Scan the header of a derived file and return True if it is a thin file.

    N.B. We are not interested in @first lines, so any encoding will do.'''

    at = self

    # The encoding doesn't matter.  No error messages are given.
    at.encoding = at.c.config.default_derived_file_encoding

    junk,junk,isThin = at.scanHeader(theFile,fileName)

    return isThin
#@-node:ekr.20050103163224:scanHeaderForThin (used by import code)
#@-node:ekr.20100122073254.6165:Don't use tnodeList to separate old/new @file nodes
#@+node:ekr.20100123180019.6314:Eliminated warning re orphan nodes
#@+node:ekr.20041005105605.216:warnAboutOrpanAndIgnoredNodes
# Called from writeOpenFile.

def warnAboutOrphandAndIgnoredNodes (self):

    # Always warn, even when language=="cweb"
    at = self ; root = at.root

    for p in root.self_and_subtree():
        if not p.v.isVisited():
            at.writeError("Orphan node:  " + p.h)
            if p.hasParent():
                g.es("parent node:",p.parent().h,color="blue")
            if not at.thinFile and p.isAtIgnoreNode():
                at.writeError("@ignore node: " + p.h)

    if at.thinFile:
        p = root.copy() ; after = p.nodeAfterTree()
        while p and p != after:
            if p.isAtAllNode():
                p.moveToNodeAfterTree()
            else:
                if p.isAtIgnoreNode():
                    at.writeError("@ignore node: " + p.h)
                p.moveToThreadNext()
#@-node:ekr.20041005105605.216:warnAboutOrpanAndIgnoredNodes
#@+node:ekr.20041005105605.169:putAtAllChild
@
This code puts only the first of two or more cloned siblings, preceding the
clone with an @clone n sentinel.

This is a debatable choice: the cloned tree appears only once in the external
file. This should be benign; the text created by @all is likely to be used only
for recreating the outline in Leo. The representation in the derived file
doesn't matter much.
@c

def putAtAllChild(self,p):

    at = self

    parent_v = p._parentVnode()

    if False: # 2010/01/23: This generates atFile errors about orphan nodes.
        clonedSibs,thisClonedSibIndex = at.scanForClonedSibs(parent_v,p.v)
        if clonedSibs > 1:
            at.putSentinel("@clone %d" % (clonedSibs))
        else:
            g.trace('**** ignoring',p.h)
            p.v.setVisited() # 2010/01/23
            return # Don't write second or greater trees.

    at.putOpenNodeSentinel(p,inAtAll=True) # Suppress warnings about @file nodes.
    at.putAtAllBody(p) 

    for child in p.children():
        at.putAtAllChild(child)

    at.putCloseNodeSentinel(p)
#@-node:ekr.20041005105605.169:putAtAllChild
#@-node:ekr.20100123180019.6314:Eliminated warning re orphan nodes
#@-node:ekr.20100121105450.6175:Bugs
#@+node:ekr.20100121105450.6174:Added --debug switch
#@+node:ekr.20091007103358.6061:scanOptions
def scanOptions():

    '''Handle all options and remove them from sys.argv.'''
    trace = False

    # Note: this automatically implements the --help option.
    parser = optparse.OptionParser()
    parser.add_option('-c', '--config', dest="one_config_path")
    parser.add_option('--debug',        action="store_true",dest="debug")
    parser.add_option('-f', '--file',   dest="fileName")
    parser.add_option('--gui',          dest="gui",help = 'gui to use (qt/tk/qttabs)')
    #parser.add_option('--help',         action="store_true",dest="help_option")
    parser.add_option('--ipython',      action="store_true",dest="use_ipython")
    parser.add_option('--no-cache',     action="store_true",dest='no_cache')
    parser.add_option('--silent',       action="store_true",dest="silent")
    parser.add_option('--script',       dest="script")
    parser.add_option('--script-window',dest="script_window")
    parser.add_option('--version',      action="store_true",dest="version")

    # Parse the options, and remove them from sys.argv.
    options, args = parser.parse_args()
    sys.argv = [sys.argv[0]] ; sys.argv.extend(args)
    if trace: print('scanOptions',sys.argv)

    # Handle the args...

    # -c or --config
    path = options.one_config_path
    if path:
        path = g.os_path_finalize_join(os.getcwd(),path)
        if g.os_path_exists(path):
            g.app.oneConfigFilename = path
        else:
            g.es_print('Invalid -c option: file not found:',path,color='red')

    # --debug
    if options.debug:
        g.debug = True
        g.trace('*** debug mode on')

    # -f or --file
    fileName = options.fileName

    # --gui
    gui = options.gui
    g.app.qt_use_tabs = False
    if gui:
        gui = gui.lower()
        if gui == 'qttabs':
            gui = 'qt'
            g.app.qt_use_tabs = True

        if gui not in ('tk','qt','wx'):
            g.trace('unknown gui: %s' % gui)
            gui = None

    # --ipython
    g.app.useIpython = options.use_ipython

    # --no-cache
    if options.no_cache:
        g.trace('disabling caching')
        g.enableDB = False

    # --script
    script_path = options.script
    script_path_w = options.script_window
    if script_path and script_path_w:
        parser.error("--script and script-window are mutually exclusive")

    script_name = script_path or script_path_w
    if script_name:
        script_name = g.os_path_finalize_join(g.app.loadDir,script_name)
        script,e = g.readFileIntoString(script_name,kind='script:')
    else:
        script = None
        # if trace: print('scanOptions: no script')

    # --silent
    g.app.silentMode = options.silent
    # g.trace('silentMode',g.app.silentMode)

    # --version: print the version and exit.
    versionFlag = options.version

    # Compute the return values.
    windowFlag = script and script_path_w
    if trace:
        print('scanOptions: fileName',fileName)
        print('scanOptions: argv',sys.argv)
    return fileName,gui,script,versionFlag,windowFlag
#@-node:ekr.20091007103358.6061:scanOptions
#@-node:ekr.20100121105450.6174:Added --debug switch
#@+node:ekr.20100122073254.6162:Eliminated node-changed marks
# These marks are just annoying.
#@nonl
#@+node:ekr.20050301105854:copyAllTempBodyStringsToTnodes
def  copyAllTempBodyStringsToTnodes (self,root,thinFile):

    c = self.c
    for p in root.self_and_subtree():
        try: s = p.v.tempBodyString
        except Exception: s = ""
        old_body = p.b
        if s != old_body:
            if False and old_body: # For debugging.
                g.pr("\nchanged: " + p.h)
                g.pr("\nnew:",s)
                g.pr("\nold:",p.b)
            if thinFile:
                p.v.setBodyString(s)
                if p.v.isDirty():
                    p.setAllAncestorAtFileNodesDirty()
            else:
                c.setBodyString(p,s) # Sets c and p dirty.

            if not thinFile or (thinFile and p.v.isDirty()):
                # New in Leo 4.3: support for mod_labels plugin:
                try:
                    c.mod_label_controller.add_label(p,"before change:",old_body)
                except Exception:
                    pass
                g.es("changed:",p.h,color="blue")
                # p.setMarked()
#@-node:ekr.20050301105854:copyAllTempBodyStringsToTnodes
#@+node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
def tabNannyNode (self,p,body):

    import parser,tabnanny,tokenize

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))
    except parser.ParserError:
        junk, msg, junk = sys.exc_info()
        g.es("ParserError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        g.es("TokenError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        badline = nag.get_lineno()
        line    = nag.get_line()
        message = nag.get_msg()
        g.es("indentation error in",p.h,"line",badline,color="red")
        g.es(message)
        line2 = repr(str(line))[1:-1]
        g.es("offending line:\n",line2)
        # p.setMarked()
    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
#@nonl
#@-node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
#@-node:ekr.20100122073254.6162:Eliminated node-changed marks
#@+node:ekr.20100123044506.6237:Eliminated support for @noref
@nocolor-node

Changes:

- putOpenNodeSentinel now *never* sets tnodeList.
#@nonl
#@+node:ekr.20100123044506.6247:changed
#@+node:ekr.20061002095711:c.navHelper
def navHelper (self,p,ch,extend):

    c = self ; h = p.h.lower()

    if extend:
        prefix = c.navPrefix + ch
        return h.startswith(prefix.lower()) and prefix

    if h.startswith(ch):
        return ch

    # New feature: search for first non-blank character after @x for common x.
    if ch != '@' and h.startswith('@'):
        for s in ('button','command','file','thin','asis','nosent',): # 'noref'):
            prefix = '@'+s
            if h.startswith('@'+s):
                while 1:
                    n = len(prefix)
                    ch2 = n < len(h) and h[n] or ''
                    if ch2.isspace():
                        prefix = prefix + ch2
                    else: break
                if len(prefix) < len(h) and h.startswith(prefix + ch.lower()):
                    return prefix + ch
    return ''
#@nonl
#@-node:ekr.20061002095711:c.navHelper
#@+node:ekr.20031218072017.2989:c.setChanged
def setChanged (self,changedFlag):

    trace = False and not g.unitTesting
    c = self
    if not c.frame: return
    c.changed = changedFlag
    if c.loading: return # don't update while loading.

    if trace: g.trace('Commands',changedFlag,c,g.callers(4))

    # Clear all dirty bits _before_ setting the caption.
    if not changedFlag:
        for v in c.all_unique_nodes():
            if v.isDirty():
                v.clearDirty()

    if g.app.qt_use_tabs and hasattr(c.frame,'top'):
        c.frame.top.master.setChanged(c,changedFlag)

    s = c.frame.getTitle()
    if len(s) > 2:
        if changedFlag:
            if s [0] != '*': c.frame.setTitle("* " + s)
        else:
            if s[0:2]=="* ": c.frame.setTitle(s[2:])
#@-node:ekr.20031218072017.2989:c.setChanged
#@-node:ekr.20100123044506.6247:changed
#@+node:ekr.20100123044506.6246:recognition...
#@+node:ekr.20040306211032:p.Comparisons
def anyAtFileNodeName         (self): return self.v.anyAtFileNodeName()
def atAutoNodeName            (self): return self.v.atAutoNodeName()
def atEditNodeName            (self): return self.v.atEditNodeName()
def atFileNodeName            (self): return self.v.atFileNodeName()
def atNoSentinelsFileNodeName (self): return self.v.atNoSentinelsFileNodeName()
# def atRawFileNodeName         (self): return self.v.atRawFileNodeName()
def atShadowFileNodeName      (self): return self.v.atShadowFileNodeName()
def atSilentFileNodeName      (self): return self.v.atSilentFileNodeName()
def atThinFileNodeName        (self): return self.v.atThinFileNodeName()

# New names, less confusing
atNoSentFileNodeName  = atNoSentinelsFileNodeName
#atNorefFileNodeName   = atRawFileNodeName
atAsisFileNodeName    = atSilentFileNodeName

def isAnyAtFileNode         (self): return self.v.isAnyAtFileNode()
def isAtAllNode             (self): return self.v.isAtAllNode()
def isAtAutoNode            (self): return self.v.isAtAutoNode()
def isAtAutoRstNode         (self): return self.v.isAtAutoRstNode()
def isAtEditNode            (self): return self.v.isAtEditNode()
def isAtFileNode            (self): return self.v.isAtFileNode()
def isAtIgnoreNode          (self): return self.v.isAtIgnoreNode()
def isAtNoSentinelsFileNode (self): return self.v.isAtNoSentinelsFileNode()
def isAtOthersNode          (self): return self.v.isAtOthersNode()
# def isAtRawFileNode         (self): return self.v.isAtRawFileNode()
def isAtSilentFileNode      (self): return self.v.isAtSilentFileNode()
def isAtShadowFileNode      (self): return self.v.isAtShadowFileNode()
def isAtThinFileNode        (self): return self.v.isAtThinFileNode()

# New names, less confusing:
isAtNoSentFileNode = isAtNoSentinelsFileNode
# isAtNorefFileNode  = isAtRawFileNode
isAtAsisFileNode   = isAtSilentFileNode

# Utilities.
def matchHeadline (self,pattern): return self.v.matchHeadline(pattern)
#@-node:ekr.20040306211032:p.Comparisons
#@+node:ekr.20031218072017.3350:anyAtFileNodeName
def anyAtFileNodeName (self):

    """Return the file name following an @file node or an empty string."""

    names = (
        "@auto",
        "@auto-rst",
        "@edit",
        "@file",
        "@thin",   "@file-thin",   "@thinfile",
        "@asis",   "@file-asis",   "@silentfile",
        # "@noref",  "@file-noref",  "@rawfile",
        "@nosent", "@file-nosent", "@nosentinelsfile",
        "@shadow",)

    return self.findAtFileName(names)
#@-node:ekr.20031218072017.3350:anyAtFileNodeName
#@+node:ekr.20031218072017.3348:at...FileNodeName & tests
# These return the filename following @xxx, in v.headString.
# Return the the empty string if v is not an @xxx node.

def atAutoNodeName (self,h=None):
    # # Prevent conflicts with autotrees plugin: don't allow @auto-whatever to match.
    # return g.match_word(h,0,tag) and not g.match(h,0,tag+'-') and h[len(tag):].strip()
    names = ("@auto","@auto-rst",)
    return self.findAtFileName(names,h=h)

def atAutoRstNodeName (self,h=None):
    names = ("@auto-rst",)
    return self.findAtFileName(names,h=h)

def atEditNodeName (self):
    names = ("@edit",)
    return self.findAtFileName(names)

def atFileNodeName (self):
    names = ("@file",)
    return self.findAtFileName(names)

def atNoSentinelsFileNodeName (self):
    names = ("@nosent", "@file-nosent", "@nosentinelsfile")
    return self.findAtFileName(names)

# def atRawFileNodeName (self):
    # names = ("@noref", "@file-noref", "@rawfile")
    # return self.findAtFileName(names)

def atShadowFileNodeName (self):
    names = ("@shadow",)
    return self.findAtFileName(names)

def atSilentFileNodeName (self):
    names = ("@asis", "@file-asis", "@silentfile")
    return self.findAtFileName(names)

def atThinFileNodeName (self):
    names = ("@thin", "@file-thin", "@thinfile")
    return self.findAtFileName(names)

# New names, less confusing
atNoSentFileNodeName  = atNoSentinelsFileNodeName
# atNorefFileNodeName   = atRawFileNodeName
atAsisFileNodeName    = atSilentFileNodeName
#@+node:ekr.20090521064955.5905:@test v.atAutoNodeName & v.atAutoRstNodeName
if g.unitTesting:

    c,p = g.getTestVars()

    table = (
        ('@auto-rst rst-file','rst-file','rst-file'),
        ('@auto x','x',''),
        ('xyz','',''),
    )

    for s,expected1,expected2 in table:
        result1 = p.v.atAutoNodeName(h=s)
        result2 = p.v.atAutoRstNodeName(h=s)
        assert result1 == expected1,'fail1: given %s expected %s got %s' % (
            repr(s),repr(expected1),repr(result1))
        assert result2 == expected2,'fail2: given %s expected %s got %s' % (
            repr(s),repr(expected2),repr(result2))
#@-node:ekr.20090521064955.5905:@test v.atAutoNodeName & v.atAutoRstNodeName
#@-node:ekr.20031218072017.3348:at...FileNodeName & tests
#@+node:ekr.20040325073709:isAt...FileNode (vnode)
def isAtAutoNode (self):
    return g.choose(self.atAutoNodeName(),True,False)

def isAtAutoRstNode (self):
    return g.choose(self.atAutoRstNodeName(),True,False)

def isAtEditNode (self):
    return g.choose(self.atEditNodeName(),True,False)

def isAtFileNode (self):
    return g.choose(self.atFileNodeName(),True,False)

def isAtNoSentinelsFileNode (self):
    return g.choose(self.atNoSentinelsFileNodeName(),True,False)

# def isAtRawFileNode (self): # @file-noref
    # return g.choose(self.atRawFileNodeName(),True,False)

def isAtSilentFileNode (self): # @file-asis
    return g.choose(self.atSilentFileNodeName(),True,False)

def isAtShadowFileNode (self):
    return g.choose(self.atShadowFileNodeName(),True,False)

def isAtThinFileNode (self):
    return g.choose(self.atThinFileNodeName(),True,False)

# New names, less confusing:
isAtNoSentFileNode = isAtNoSentinelsFileNode
# isAtNorefFileNode  = isAtRawFileNode
isAtAsisFileNode   = isAtSilentFileNode
#@-node:ekr.20040325073709:isAt...FileNode (vnode)
#@-node:ekr.20100123044506.6246:recognition...
#@+node:ekr.20100123044506.6248:reading...
#@+node:ekr.20041005105605.21:read (atFile) & helpers
# This code no longer reads @noref trees.

def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    # g.trace(root.h,len(root.b))
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    if at.errors:
        return False
    fileName = at.openFileForReading(fromString=fromString)
    if at.inputFile:
        c.setFileTimeStamp(fileName)
    else:
        return False
    root.v.at_read = True # Remember that we have read this file.
    # Get the file from the cache if possible.
    ok,cachefile = self.readFromCache(fileName,force,root)
    if ok:
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    root.clearVisitedInTree()
    d = at.scanAllDirectives(root,importing=at.importing,reading=True)
    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.warnAboutUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        self.copyAllTempBodyStringsToTnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if at.errors == 0:
        self.writeCachedTree(root,cachefile)

    return at.errors == 0
#@+node:ekr.20041005105605.25:deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
#@-node:ekr.20041005105605.25:deleteAllTempBodyStrings
#@+node:ekr.20100122130101.6174:deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@-node:ekr.20100122130101.6174:deleteTnodeList
#@+node:ekr.20041005105605.22:initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName

    # isAtFile = (
        # not thinFile and
        # not importFileName and
        # not atShadow and
        # not fromString and
        # root.h.startswith('@file'))
#@-node:ekr.20041005105605.22:initFileName
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20071105164407:warnAboutUnvisitedNodes
def warnAboutUnvisitedNodes (self,root):

    resurrected = 0

    for p in root.self_and_subtree():
        if not p.v.isVisited():
            g.trace('**** not visited',p.v,p.h)
            g.es('resurrected node:',p.h,color='blue')
            g.es('in file:',root.h,color='blue')
            resurrected += 1

    if resurrected:
        g.es('you may want to delete ressurected nodes')
#@-node:ekr.20071105164407:warnAboutUnvisitedNodes
#@-node:ekr.20041005105605.21:read (atFile) & helpers
#@-node:ekr.20100123044506.6248:reading...
#@+node:ekr.20100123044506.6244:writing...
#@+node:ekr.20041005105605.193:putOpenNodeSentinel
def putOpenNodeSentinel(self,p,inAtAll=False,middle=False):

    """Write @+node sentinel for p."""

    at = self

    if not inAtAll and p.isAtFileNode() and p != at.root:
        at.writeError("@file not valid in: " + p.h)
        return

    # g.trace(at.thinFile,p)

    s = at.nodeSentinelText(p)

    if middle:
        at.putSentinel("@+middle:" + s)
    else:
        at.putSentinel("@+node:" + s)

    # Leo 4.7 b2: we never write tnodeLists.
#@nonl
#@-node:ekr.20041005105605.193:putOpenNodeSentinel
#@+node:ekr.20041005105605.136:norefWrite (deleted)
def norefWrite(self,root,toString=False):

    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    try:
        targetFileName = root.atNorefFileNodeName()
        at.initWriteIvars(root,targetFileName,nosentinels=False,toString=toString)
        if at.errors: return
        if not at.openFileForWriting(root,targetFileName,toString):
            # openFileForWriting calls root.setDirty() if there are errors.
            return
        << write root's tree >>
        at.closeWriteFile()
        at.replaceTargetFileIfDifferent(root) # Sets/clears dirty and orphan bits.
    except Exception:
        at.writeException(root) # Sets dirty and orphan bits.

rawWrite = norefWrite
#@+node:ekr.20041005105605.137:<< write root's tree >>
<< put all @first lines in root >>
at.putOpenLeoSentinel("@+leo-ver=4")
<< put optional @comment sentinel lines >>

for p in root.self_and_subtree():
    << Write p's node >>

at.putSentinel("@-leo")
<< put all @last lines in root >>
#@+node:ekr.20041005105605.138:<< put all @first lines in root >>
# Write any @first lines.  These lines are also converted to @verbatim lines,
# so the read logic simply ignores lines preceding the @+leo sentinel.

s = root.v.b
tag = "@first"
i = 0
while g.match(s,i,tag):
    i += len(tag)
    i = g.skip_ws(s,i)
    j = i
    i = g.skip_to_end_of_line(s,i)
    # Write @first line, whether empty or not
    line = s[j:i]
    at.putBuffered(line) ; at.onl()
    i = g.skip_nl(s,i)
#@-node:ekr.20041005105605.138:<< put all @first lines in root >>
#@+node:ekr.20041005105605.139:<< put optional @comment sentinel lines >>
s2 = c.config.output_initial_comment
if s2:
    lines = s2.split("\\n")
    for line in lines:
        line = line.replace("@date",time.asctime())
        if len(line)> 0:
            at.putSentinel("@comment " + line)
#@-node:ekr.20041005105605.139:<< put optional @comment sentinel lines >>
#@+node:ekr.20041005105605.140:<< Write p's node >>
at.putOpenNodeSentinel(p)

s = p.b
s = self.cleanLines(p,s)

if s:
    s = g.toEncodedString(s,at.encoding,reportErrors=True)
    at.outputStringWithLineEndings(s)

# Put an @nonl sentinel if s does not end in a newline.
if s and s[-1] != '\n':
    at.onl_sent() ; at.putSentinel("@nonl")

at.putCloseNodeSentinel(p)
#@-node:ekr.20041005105605.140:<< Write p's node >>
#@+node:ekr.20041005105605.141:<< put all @last lines in root >>
@ Write any @last lines.  These lines are also converted to @verbatim lines, so the read logic simply ignores lines following the @-leo sentinel.
@c

tag = "@last"
lines = root.v.b.split('\n')
n = len(lines) ; j = k = n - 1
# Don't write an empty last line.
if j >= 0 and len(lines[j])==0:
    j = k = n - 2
# Scan backwards for @last directives.
while j >= 0:
    line = lines[j]
    if g.match(line,0,tag): j -= 1
    else: break
# Write the @last lines.
for line in lines[j+1:k+1]:
    i = len(tag) ; i = g.skip_ws(line,i)
    at.putBuffered(line[i:]) ; at.onl()
#@-node:ekr.20041005105605.141:<< put all @last lines in root >>
#@-node:ekr.20041005105605.137:<< write root's tree >>
#@-node:ekr.20041005105605.136:norefWrite (deleted)
#@+node:ekr.20051104075904.44:at-File test code (leoTest.py)
def runAtFileTest(c,p):

    """Common code for testing output of @file, @thin, etc."""

    at = c.atFileCommands
    child1 = p.firstChild()
    child2 = child1.next()
    h1 = child1.h.lower().strip()
    h2 = child2.h.lower().strip()
    assert(g.match(h1,0,"#@"))
    assert(g.match(h2,0,"output"))
    expected = child2.b

    # Compute the type from child1's headline.
    j = g.skip_c_id(h1,2)
    theType = h1[1:j]
    assert theType in ("@auto","@edit","@file","@thin","@nosent",
        # "@noref",
        "@asis","@root",), "bad type: %s" % type

    thinFile = theType == "@thin"
    nosentinels = theType in ("@asis","edit","@nosent")

    if theType == "@root":
        c.tangleCommands.tangle_output = ''
        c.tangleCommands.tangle(event=None,p=child1)
        at.stringOutput = c.tangleCommands.tangle_output
    elif theType == "@asis":
        at.asisWrite(child1,toString=True)
    elif theType == "@auto":
        at.writeOneAtAutoNode(child1,toString=True,force=True)
    elif theType == "@edit":
        at.writeOneAtEditNode(child1,toString=True)
    # elif theType == "@noref":
        # at.norefWrite(child1,toString=True)
    else:
        at.write(child1,thinFile=thinFile,nosentinels=nosentinels,toString=True)
    try:
        result = g.toUnicode(at.stringOutput)
        assert(result == expected)
    except AssertionError:
        << dump result and expected >>
        raise
#@+node:ekr.20051104075904.45:<< dump result and expected >>
print('\n','-' * 20)
print("result...")
for line in g.splitLines(result):
    print("%3d" % len(line),repr(line))
print('-' * 20)
print("expected...")
for line in g.splitLines(expected):
    print("%3d" % len(line),repr(line))
print('-' * 20)
#@-node:ekr.20051104075904.45:<< dump result and expected >>
#@-node:ekr.20051104075904.44:at-File test code (leoTest.py)
#@+node:ekr.20041005105605.147:writeAll (atFile) & helper
def writeAll(self,
    writeAtFileNodesFlag=False,
    writeDirtyAtFileNodesFlag=False,
    toString=False
):

    """Write @file nodes in all or part of the outline"""

    trace = False and not g.unitTesting
    at = self ; c = at.c
    if trace: scanAtPathDirectivesCount = c.scanAtPathDirectivesCount
    writtenFiles = [] # Files that might be written again.
    force = writeAtFileNodesFlag

    if writeAtFileNodesFlag:
        # The Write @<file> Nodes command.
        # Write all nodes in the selected tree.
        p = c.p
        after = p.nodeAfterTree()
    else:
        # Write dirty nodes in the entire outline.
        p =  c.rootPosition()
        after = c.nullPosition()

    << Clear all orphan bits >>
    while p and p != after:
        if p.isAnyAtFileNode() or p.isAtIgnoreNode():
            self.writeAllHelper(p,force,toString,writeAtFileNodesFlag,writtenFiles)
            p.moveToNodeAfterTree()
        else:
            p.moveToThreadNext()

    << say the command is finished >>
    if trace: g.trace('%s calls to c.scanAtPathDirectives()' % (
        c.scanAtPathDirectivesCount-scanAtPathDirectivesCount))

#@+node:ekr.20041005105605.148:<< Clear all orphan bits >>
@ We must clear these bits because they may have been set on a previous write.
Calls to atFile::write may set the orphan bits in @file nodes.
If so, write_Leo_file will write the entire @file tree.
@c

for v2 in p.self_and_subtree():
    v2.clearOrphan()
#@-node:ekr.20041005105605.148:<< Clear all orphan bits >>
#@+node:ekr.20041005105605.150:<< say the command is finished >>
if writeAtFileNodesFlag or writeDirtyAtFileNodesFlag:
    if len(writtenFiles) > 0:
        g.es("finished")
    elif writeAtFileNodesFlag:
        g.es("no @<file> nodes in the selected tree")
    else:
        g.es("no dirty @<file> nodes")
#@-node:ekr.20041005105605.150:<< say the command is finished >>
#@+node:ekr.20041005105605.149:writeAllHelper (atFile)
def writeAllHelper (self,p,
    force,toString,writeAtFileNodesFlag,writtenFiles
):

    trace = False and not g.unitTesting
    at = self ; c = at.c

    if p.isAtIgnoreNode() and not p.isAtAsisFileNode():
        pathChanged = False
    else:
        oldPath = at.getPathUa(p).lower()
        newPath = at.fullPath(p).lower()
        pathChanged = oldPath and oldPath != newPath
        # 2010/01/27: suppress this message during save-as and save-to commands.
        if pathChanged and not c.ignoreChangedPaths:
            at.setPathUa(p,newPath) # Remember that we have changed paths.
            g.es_print('path changed for',p.h,color='blue')
            if trace: g.trace('p %s\noldPath %s\nnewPath %s' % (
                p.h,repr(oldPath),repr(newPath)))

    if p.v.isDirty() or pathChanged or writeAtFileNodesFlag or p.v in writtenFiles:

        # Tricky: @ignore not recognised in @asis nodes.
        if p.isAtAsisFileNode():
            at.asisWrite(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtIgnoreNode():
            pass
        elif p.isAtAutoNode():
            at.writeOneAtAutoNode(p,toString=toString,force=force)
            writtenFiles.append(p.v)
        elif p.isAtEditNode():
            at.writeOneAtEditNode(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtNoSentFileNode():
            at.write(p,kind='@nosent',nosentinels=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtShadowFileNode():
            at.writeOneAtShadowNode(p,toString=toString,force=force or pathChanged)
            writtenFiles.append(p.v)
        elif p.isAtThinFileNode():
            at.write(p,kind='@thin',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtFileNode():
            # Write old @file nodes using @thin format.
            at.write(p,kind='@file',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
#@-node:ekr.20041005105605.149:writeAllHelper (atFile)
#@-node:ekr.20041005105605.147:writeAll (atFile) & helper
#@+node:ekr.20041005105605.151:writeMissing
def writeMissing(self,p,toString=False):

    at = self ; c = at.c
    writtenFiles = False

    p = p.copy()
    after = p.nodeAfterTree()
    while p and p != after: # Don't use iterator.
        if p.isAtAsisFileNode() or (p.isAnyAtFileNode() and not p.isAtIgnoreNode()):
            at.targetFileName = p.anyAtFileNodeName()
            if at.targetFileName:
                at.targetFileName = c.os_path_finalize_join(
                    self.default_directory,at.targetFileName)
                if not g.os_path_exists(at.targetFileName):
                    ok = at.openFileForWriting(p,at.targetFileName,toString)
                    # openFileForWriting calls p.setDirty() if there are errors.
                    if ok:
                        << write the @file node >>
                        at.closeWriteFile()
            p.moveToNodeAfterTree()
        elif p.isAtIgnoreNode():
            p.moveToNodeAfterTree()
        else:
            p.moveToThreadNext()

    if writtenFiles > 0:
        g.es("finished")
    else:
        g.es("no @file node in the selected tree")
#@+node:ekr.20041005105605.152:<< write the @file node >> (writeMissing)
if p.isAtAsisFileNode():
    at.asisWrite(p)
# elif p.isAtNorefFileNode():
    # at.norefWrite(p)
elif p.isAtNoSentFileNode():
    at.write(p,kind='@nosent',nosentinels=True)
elif p.isAtFileNode():
    at.write(p,kind='@file')
else: assert(0)

writtenFiles = True
#@-node:ekr.20041005105605.152:<< write the @file node >> (writeMissing)
#@-node:ekr.20041005105605.151:writeMissing
#@-node:ekr.20100123044506.6244:writing...
#@-node:ekr.20100123044506.6237:Eliminated support for @noref
#@+node:ekr.20100123044506.6238:Eliminated tnodeLists
#@+node:ekr.20100123044506.6240:Keep
#@+node:ekr.20041005105605.14:<< init ivars for reading >>
self.atAllFlag = False # True if @all seen.
self.cloneSibCount = 0 # n > 1: Make sure n cloned sibs exists at next @+node sentinel
self.correctedLines = 0
self.docOut = [] # The doc part being accumulated.
self.done = False # True when @-leo seen.
self.endSentinelStack = []
self.importing = False
self.importRootSeen = False
self.indentStack = []
self.inputFile = None
self.lastLines = [] # The lines after @-leo
self.lastThinNode = None # Used by createThinChild4.
self.leadingWs = ""
self.lineNumber = 0 # New in Leo 4.4.8.
self.out = None
self.outStack = []
self.rootSeen = False
self.tnodeList = [] # Needed until old-style @file nodes are no longer supported.
self.tnodeListIndex = 0
self.v = None
self.tStack = []
self.thinNodeStack = [] # Used by createThinChild4.
self.updateWarningGiven = False
#@-node:ekr.20041005105605.14:<< init ivars for reading >>
#@+node:ekr.20041005105605.73:findChild4
def findChild4 (self,headline):

    """Return the next vnode in at.root.tnodeLisft.
    This is called only for @file/@noref nodes"""

    # Note: tnodeLists are used _only_ when reading @file (not @thin) nodes.
    # tnodeLists compensate (a hack) for not having gnx's in derived files! 

    trace = False and not g.unitTesting
    at = self ; v = at.root.v

    if not g.unitTesting:
        if v.isAtFileNode():
            g.es_print('Warning: @file logic',v.h)

    if trace: g.trace('%s %s %s' % (
        at.tnodeListIndex,
        v.tnodeList[at.tnodeListIndex],headline))

    if not hasattr(v,"tnodeList"):
        at.readError("no tnodeList for " + repr(v))
        g.es("write the @file node or use the Import Derived File command")
        g.trace("no tnodeList for ",v,g.callers())
        return None

    if at.tnodeListIndex >= len(v.tnodeList):
        at.readError("bad tnodeList index: %d, %s" % (at.tnodeListIndex,repr(v)))
        g.trace("bad tnodeList index",at.tnodeListIndex,len(v.tnodeList),v)
        return None

    v = v.tnodeList[at.tnodeListIndex]
    assert(v)
    at.tnodeListIndex += 1

    # Don't check the headline.  It simply causes problems.
    v.setVisited() # Supress warning/deletion of unvisited nodes.
    return v
#@-node:ekr.20041005105605.73:findChild4
#@+node:ekr.20100122130101.6174:deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@-node:ekr.20100122130101.6174:deleteTnodeList
#@+node:ekr.20031218072017.2072:c.checkOutline
def checkOutline (self,event=None,verbose=True,unittest=False,full=True,root=None):

    """Report any possible clone errors in the outline.

    Remove any tnodeLists."""

    c = self ; count = 1 ; errors = 0
    isTkinter = g.app.gui and g.app.gui.guiName() == "tkinter"

    if full and not unittest:
        g.es("all tests enabled: this may take awhile",color="blue")

    if root: iter = root.self_and_subtree
    else:    iter = c.all_positions

    for p in iter():
        try:
            count += 1
            << remove tnodeList >>
            if full: # Unit tests usually set this false.
                << do full tests >>
        except AssertionError:
            errors += 1
            << give test failed message >>
    if verbose or not unittest:
        << print summary message >>
    return errors
#@+node:ekr.20040313150633:<< remove tnodeList >>
# Empty tnodeLists are not errors.
v = p.v

if hasattr(v,"tnodeList"): # and len(v.tnodeList) > 0 and not v.isAnyAtFileNode():
    if 0:
        s = "deleting tnodeList for " + repr(v)
        g.es_print(s,color="blue")
    delattr(v,"tnodeList")
    v._p_changed = True
#@-node:ekr.20040313150633:<< remove tnodeList >>
#@+node:ekr.20040323155951:<< do full tests >>
if not unittest:
    if count % 1000 == 0:
        g.es('','.',newline=False)
    if count % 8000 == 0:
        g.enl()

@others
#@+node:ekr.20040314035615:assert consistency of threadNext & threadBack links
threadBack = p.threadBack()
threadNext = p.threadNext()

if threadBack:
    assert p == threadBack.threadNext(), "p==threadBack.threadNext"

if threadNext:
    assert p == threadNext.threadBack(), "p==threadNext.threadBack"
#@-node:ekr.20040314035615:assert consistency of threadNext & threadBack links
#@+node:ekr.20040314035615.1:assert consistency of next and back links
back = p.back()
next = p.next()

if back:
    assert p == back.next(), 'p!=back.next(),  back: %s back.next: %s' % (
        back,back.next())

if next:
    assert p == next.back(), 'p!=next.back, next: %s next.back: %s' % (
        next,next.back())
#@-node:ekr.20040314035615.1:assert consistency of next and back links
#@+node:ekr.20040314035615.2:assert consistency of parent and child links
if p.hasParent():
    n = p.childIndex()
    assert p == p.parent().moveToNthChild(n), "p==parent.moveToNthChild"

for child in p.children():
    assert p == child.parent(), "p==child.parent"

if p.hasNext():
    assert p.next().parent() == p.parent(), "next.parent==parent"

if p.hasBack():
    assert p.back().parent() == p.parent(), "back.parent==parent"
#@-node:ekr.20040314035615.2:assert consistency of parent and child links
#@+node:ekr.20080426051658.1:assert consistency of parent and children arrays
@
Every nodes gets visited, so we only check consistency
between p and its parent, not between p and its children.

In other words, this is a strong test.
@c

parent_v = p._parentVnode()
n = p.childIndex()

assert parent_v.children[n] == p.v,'fail 1'
#@-node:ekr.20080426051658.1:assert consistency of parent and children arrays
#@-node:ekr.20040323155951:<< do full tests >>
#@+node:ekr.20040314044652:<< give test failed message >>
junk, value, junk = sys.exc_info()

s = "test failed at position %s\n%s" % (repr(p),value)

g.es_print(s,color="red")
#@-node:ekr.20040314044652:<< give test failed message >>
#@+node:ekr.20040314043900:<<print summary message >>
if full:
    g.enl()

if errors or verbose:
    color = g.choose(errors,'red','blue')
    g.es_print('',count,'nodes checked',errors,'errors',color=color)
#@-node:ekr.20040314043900:<<print summary message >>
#@-node:ekr.20031218072017.2072:c.checkOutline
#@+node:ekr.20060919110638.44:vnodeAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded and descendentTnodeUnknownAttributes.

def vnodeAttributes (self,attrs):

    node = self.node

    for bunch in self.attrsToList(attrs):
        name = bunch.name ; val = bunch.val
        if name == 't':
            aList = self.tnxToListDict.get(val,[])
            aList.append(self.node)
            self.tnxToListDict[val] = aList
            node.tnx = str(val) # nodeIndices.toString returns a string.
        else:
            node.attributes[name] = val
#@nonl
#@-node:ekr.20060919110638.44:vnodeAttributes
#@+node:ekr.20060919110638.16: node.__init__
def __init__ (self):

    self.attributes = {}
    self.bodyString = ''
    self.headString = ''
    self.children = []
    self.tnodeAttributes = {}
    self.tnodeList = []
    self.tnx = None
#@nonl
#@-node:ekr.20060919110638.16: node.__init__
#@+node:ekr.20031218072017.3019:leoFileCommands._init_
def __init__(self,c):

    # g.trace("__init__", "fileCommands.__init__")
    self.c = c
    self.frame = c.frame

    self.nativeTnodeAttributes = ('tx',)
    self.nativeVnodeAttributes = (
        'a',
        'descendentTnodeUnknownAttributes',
        'descendentVnodeUnknownAttributes', # New in Leo 4.5.
        'expanded','marks','t','tnodeList',
        # 'vtag',
    )

    self.checkOutlineBeforeSave = c.config.getBool(
        'check_outline_before_save',default=False)

    self.initIvars()
#@-node:ekr.20031218072017.3019:leoFileCommands._init_
#@+node:ekr.20061004053644:handleVnodeSaxAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded, and descendentTnodeUnknownAttributes.
# New in Leo 4.5: added descendentVnodeUnknownAttributes to native attributes.

def handleVnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.attributes
    # if trace and d: g.trace(d)

    s = d.get('a')
    if s:
        # g.trace('%s a=%s %s' % (id(sax_node),s,v.headString()))
        # 'C' (clone) and 'D' bits are not used.
        if 'M' in s: v.setMarked()
        if 'E' in s: v.expand()
        if 'O' in s: v.setOrphan()
        # if 'T' in s: self.topVnode = v
        if 'V' in s:
            # g.trace('setting currentVnode',v,color='red')
            self.currentVnode = v

    s = d.get('tnodeList','')
    tnodeList = s and s.split(',')
    if tnodeList:
        # This tnodeList will be resolved later.
        if trace: g.trace('found tnodeList',v.headString(),tnodeList)
        v.tempTnodeList = tnodeList

    s = d.get('descendentTnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentTnodeUaDictList',aDict)
            self.descendentTnodeUaDictList.append(aDict)

    s = d.get('descendentVnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentVnodeUaDictList',aDict)
            self.descendentVnodeUaDictList.append((v,aDict),)

    s = d.get('expanded')
    if s:
        aList = self.getDescendentAttributes(s,tag="expanded")
        # g.trace('expanded list',len(aList))
        self.descendentExpandedList.extend(aList)

    s = d.get('marks')
    if s:
        aList = self.getDescendentAttributes(s,tag="marks")
        # g.trace('marks list',len(aList))
        self.descendentMarksList.extend(aList)

    aDict = {}
    for key in d:
        if key in self.nativeVnodeAttributes:
            # This is not a bug.
            if False and trace: g.trace(
                '****ignoring***',key,d.get(key))
        else:
            val = d.get(key)
            val2 = self.getSaxUa(key,val)
            aDict[key] = val2
            # g.trace(key,val,val2)
    if aDict:
        # if trace: g.trace('uA',v,aDict)
        v.unknownAttributes = aDict
#@+node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()
    sax_node = g.bunch(
        attributes={
'a':'M',
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
    })
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleVnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr) is not None,attr
        # The a:M attribute should mark the node.
        assert d.get('a') is None
        assert v.isMarked()
        aList = d.get('icons')
        assert aList
        assert len(aList) == 2
        for d2 in aList:
            for key in ('on','where','yoffset','file'):
                assert d2.get(key) is not None,key
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
#@-node:ekr.20061004053644:handleVnodeSaxAttributes
#@+node:ekr.20060919110638.11:resolveTnodeLists
def resolveTnodeLists (self):

    trace = False and not g.unitTesting
    c = self.c

    for p in c.all_unique_positions():
        if hasattr(p.v,'tempTnodeList'):
            # g.trace(p.v.headString())
            result = []
            for tnx in p.v.tempTnodeList:
                index = self.canonicalTnodeIndex(tnx)
                v = self.gnxDict.get(index)
                if v:
                    if trace: g.trace(tnx,v)
                    result.append(v)
                else:
                    g.trace('*** No vnode for %s' % tnx)
            if result:
                p.v.tnodeList = result
                # g.trace('*** tnodeList for',p.h,result)
            delattr(p.v,'tempTnodeList')
#@nonl
#@-node:ekr.20060919110638.11:resolveTnodeLists
#@-node:ekr.20100123044506.6240:Keep
#@+node:ekr.20100123044506.6243:changed
#@+node:ekr.20031218072017.1863:putVnode
def putVnode (self,p,isIgnore=False):

    """Write a <v> element corresponding to a vnode."""

    fc = self ; c = fc.c ; v = p.v
    isAuto = p.isAtAutoNode() and p.atAutoNodeName().strip()
    isEdit = p.isAtEditNode() and p.atEditNodeName().strip()
    isShadow = p.isAtShadowFileNode()
    isThin = p.isAtThinFileNode()
    isOrphan = p.isOrphan()
    if not isIgnore: isIgnore = p.isAtIgnoreNode()

    if   isIgnore: forceWrite = True      # Always write full @ignore trees.
    elif isAuto:   forceWrite = False     # Never write non-ignored @auto trees.
    elif isEdit:   forceWrite = False     # Never write non-ignored @edit trees.
    elif isShadow: forceWrite = False     # Never write non-ignored @shadow trees.
    elif isThin:   forceWrite = isOrphan  # Only write orphan @thin trees.
    else:          forceWrite = True      # Write all other @<file> trees.

    << Set gnx = vnode index >>
    attrs = []
    << Append attribute bits to attrs >>
    << Append unKnownAttributes to attrs >>
    attrs = ''.join(attrs)
    v_head = '<v t="%s"%s>' % (gnx,attrs)
    if gnx in fc.vnodesDict:
        fc.put(v_head+'</v>\n')
    else:
        fc.vnodesDict[gnx]=True
        v_head += '<vh>%s</vh>' % (xml.sax.saxutils.escape(p.v.headString()or''))
        # The string catentation is faster than repeated calls to fc.put.
        if not self.usingClipboard:
            << issue informational messages >>
        # New in 4.2: don't write child nodes of @file-thin trees (except when writing to clipboard)
        if p.hasChildren() and (forceWrite or self.usingClipboard):
            fc.put('%s\n' % v_head)
            # This optimization eliminates all "recursive" copies.
            p.moveToFirstChild()
            while 1:
                fc.putVnode(p,isIgnore)
                if p.hasNext(): p.moveToNext()
                else:           break
            p.moveToParent() # Restore p in the caller.
            fc.put('</v>\n')
        else:
            fc.put('%s</v>\n' % v_head) # Call put only once.
#@+node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
gnx = g.app.nodeIndices.toString(v.fileIndex)

if forceWrite or self.usingClipboard:
    v.setWriteBit() # 4.2: Indicate we wrote the body text.
#@-node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
# v.unknownAttributes are now put in <t> elements.

if p.hasChildren() and not forceWrite and not self.usingClipboard:
    # We put the entire tree when using the clipboard, so no need for this.
    if not isAuto: # Bug fix: 2008/8/7.
        attrs.append(self.putDescendentVnodeUas(p)) # New in Leo 4.5.
        attrs.append(self.putDescendentAttributes(p))
#@nonl
#@-node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
#@+node:ekr.20040702085529:<< issue informational messages >>
if isOrphan and isThin:
    g.es("writing erroneous:",p.h,color="blue")
    p.clearOrphan()
#@-node:ekr.20040702085529:<< issue informational messages >>
#@-node:ekr.20031218072017.1863:putVnode
#@+node:ekr.20041005105605.193:putOpenNodeSentinel
def putOpenNodeSentinel(self,p,inAtAll=False,middle=False):

    """Write @+node sentinel for p."""

    at = self

    if not inAtAll and p.isAtFileNode() and p != at.root:
        at.writeError("@file not valid in: " + p.h)
        return

    # g.trace(at.thinFile,p)

    s = at.nodeSentinelText(p)

    if middle:
        at.putSentinel("@+middle:" + s)
    else:
        at.putSentinel("@+node:" + s)

    # Leo 4.7 b2: we never write tnodeLists.
#@nonl
#@-node:ekr.20041005105605.193:putOpenNodeSentinel
#@+node:ekr.20031218072017.2012:writeAtFileNodes (fileCommands)
def writeAtFileNodes (self,event=None):

    '''Write all @file nodes in the selected outline.'''

    self.c.atFileCommands.writeAll(writeAtFileNodesFlag=True)
#@-node:ekr.20031218072017.2012:writeAtFileNodes (fileCommands)
#@+node:ekr.20080801071227.5:writeAtShadowNodes (fileCommands)
def writeAtShadowNodes (self,event=None):

    '''Write all @file nodes in the selected outline.'''

    self.c.atFileCommands.writeAll(writeAtFileNodesFlag=True)
#@-node:ekr.20080801071227.5:writeAtShadowNodes (fileCommands)
#@+node:ekr.20031218072017.1666:writeDirtyAtFileNodes (fileCommands)
def writeDirtyAtFileNodes (self,event=None):

    '''Write all changed @file Nodes.'''

    self.c.atFileCommands.writeAll(writeDirtyAtFileNodesFlag=True)
#@-node:ekr.20031218072017.1666:writeDirtyAtFileNodes (fileCommands)
#@+node:ekr.20080801071227.6:writeDirtyAtShadowNodes (fileCommands)
def writeDirtyAtShadowNodes (self,event=None):

    '''Write all changed @shadow Nodes.'''

    self.c.atFileCommands.writeDirtyAtShadowNodes()

#@-node:ekr.20080801071227.6:writeDirtyAtShadowNodes (fileCommands)
#@+node:ekr.20031218072017.2013:writeMissingAtFileNodes
def writeMissingAtFileNodes (self,event=None):

    '''Write all missing @file nodes.'''

    c = self.c

    if c.p:
        c.atFileCommands.writeMissing(c.p)
#@-node:ekr.20031218072017.2013:writeMissingAtFileNodes
#@+node:ekr.20041005105605.15:initWriteIvars
def initWriteIvars(self,root,targetFileName,
    atAuto=False,
    atEdit=False,
    atShadow=False,
    nosentinels=False,
    thinFile=False,
    scriptWrite=False,
    toString=False,
    forcePythonSentinels=None,
):

    self.initCommonIvars()
    << init ivars for writing >>

    if forcePythonSentinels is None:
        forcePythonSentinels = scriptWrite

    if root:
        self.scanAllDirectives(root,
            scripting=scriptWrite,
            forcePythonSentinels=forcePythonSentinels)

    # g.trace(forcePythonSentinels,self.startSentinelComment,self.endSentinelComment)

    if forcePythonSentinels:
        # Force Python comment delims for g.getScript.
        self.startSentinelComment = "#"
        self.endSentinelComment = None

    # Init state from arguments.
    self.targetFileName = targetFileName
    self.sentinels = not nosentinels
    self.thinFile = thinFile
    self.toString = toString
    self.root = root

    # Ignore config settings for unit testing.
    if toString and g.app.unitTesting: self.output_newline = '\n'

    # Init all other ivars even if there is an error.
    if not self.errors and self.root:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        self.root.v._p_changed = True
#@+node:ekr.20041005105605.16:<< init ivars for writing >>>
@
When tangling, we first write to a temporary output file. After tangling is
temporary file. Otherwise we delete the old target file and rename the temporary
file to be the target file.
@c

self.docKind = None
self.explicitLineEnding = False # True: an @lineending directive specifies the ending.
self.fileChangedFlag = False # True: the file has actually been updated.
self.atAuto = atAuto
self.atEdit = atEdit
self.atShadow = atShadow
self.shortFileName = "" # short version of file name used for messages.
self.thinFile = False
self.force_newlines_in_at_nosent_bodies = self.c.config.getBool(
    'force_newlines_in_at_nosent_bodies')

if toString:
    self.outputFile = g.fileLikeObject()
    self.stringOutput = ""
    self.targetFileName = self.outputFileName = "<string-file>"
else:
    self.outputFile = None # The temporary output file.
    self.stringOutput = None
    self.targetFileName = self.outputFileName = g.u('')
#@-node:ekr.20041005105605.16:<< init ivars for writing >>>
#@-node:ekr.20041005105605.15:initWriteIvars
#@+node:ekr.20041005105605.144:write & helper (atFile)
def write (self,root,
    kind = '@unknown', # Should not happen.
    nosentinels = False,
    thinFile = False,
    scriptWrite = False,
    toString = False,
):
    """Write a 4.x derived file.
    root is the position of an @<file> node"""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    << set at.targetFileName >>
    at.initWriteIvars(root,at.targetFileName,
        nosentinels = nosentinels, thinFile = thinFile,
        scriptWrite = scriptWrite, toString = toString)

    # "look ahead" computation of eventual fileName.
    eventualFileName = c.os_path_finalize_join(
        at.default_directory,at.targetFileName)
    exists = g.os_path_exists(eventualFileName)
    # g.trace('eventualFileName',eventualFileName,
        # 'at.targetFileName',at.targetFileName)

    if not scriptWrite and not toString:
        if nosentinels:
            if not self.shouldWriteAtNosentNode(root,exists):
                return
        elif not hasattr(root.v,'at_read') and exists:
            # Prompt if writing a new @file or @thin node would
            # overwrite an existing file.
            ok = self.promptForDangerousWrite(eventualFileName,kind)
            if ok:
                root.v.at_read = True # Create the attribute for all clones.
            else:
                g.es("not written:",eventualFileName)
                return

    if not at.openFileForWriting(root,at.targetFileName,toString):
        # openFileForWriting calls root.setDirty() if there are errors.
        return

    try:
        at.writeOpenFile(root,nosentinels=nosentinels,toString=toString)
        assert root==at.root
        if toString:
            at.closeWriteFile() # sets self.stringOutput
            # Major bug: failure to clear this wipes out headlines!
            # Minor bug: sometimes this causes slight problems...
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
        else:
            at.closeWriteFile()
            if at.errors > 0 or root.isOrphan():
                << set dirty and orphan bits >>
                g.es("not written:",at.outputFileName)
            else:
                at.replaceTargetFileIfDifferent(root)
                    # Sets/clears dirty and orphan bits.

    except Exception:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        if toString:
            at.exception("exception preprocessing script")
            root.v._p_changed = True
        else:
            at.writeException() # Sets dirty and orphan bits.
#@+node:ekr.20041005105605.145:<< set at.targetFileName >>
if toString:
    at.targetFileName = "<string-file>"
elif nosentinels:
    at.targetFileName = root.atNoSentFileNodeName()
elif thinFile:
    at.targetFileName = root.atThinFileNodeName()
    if not at.targetFileName:
        # We have an @file node.
        at.targetFileName = root.atFileNodeName()
else:
    at.targetFileName = root.atFileNodeName()
#@-node:ekr.20041005105605.145:<< set at.targetFileName >>
#@+node:ekr.20041005105605.146:<< set dirty and orphan bits >>
# Setting the orphan and dirty flags tells Leo to write the tree..
root.setOrphan()
root.setDirty()
# Delete the temp file.
self.remove(at.outputFileName) 

#@-node:ekr.20041005105605.146:<< set dirty and orphan bits >>
#@+node:ekr.20080620095343.1:shouldWriteAtNosentNode
@ Much thought went into this decision tree:

- We do not want decisions to depend on past history.That ' s too confusing.
- We must ensure that the file will be written if the user does significant work.
- We must ensure that the user can create an @auto x node at any time
  without risk of of replacing x with empty or insignificant information.
- We want the user to be able to create an @auto node which will be populated the next time the.leo file is opened.
- We don't want minor import imperfections to be written to the @auto file.
- The explicit commands that read and write @auto trees must always be honored.
@c

def shouldWriteAtNosentNode (self,p,exists):

    '''Return True if we should write the @auto node at p.'''

    if not exists: # We can write a non-existent file without danger.
        return True
    elif self.isSignificantTree(p):
        return True # Assume the tree contains what should be written.
    else:
        g.es_print(p.h,'not written:',color='red')
        g.es_print('no children and less than 10 characters (excluding directives)',color='blue')
        return False
#@-node:ekr.20080620095343.1:shouldWriteAtNosentNode
#@-node:ekr.20041005105605.144:write & helper (atFile)
#@+node:ekr.20050506084734:writeFromString
# This is at.write specialized for scripting.

def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):

    """Write a 4.x derived file from a string.

    This is used by the scripting logic."""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline, but don't change the focus!

    at.initWriteIvars(root,"<string-file>",
        nosentinels=not useSentinels,thinFile=False,scriptWrite=True,toString=True,
        forcePythonSentinels=forcePythonSentinels)

    try:
        ok = at.openFileForWriting(root,at.targetFileName,toString=True)
        if g.app.unitTesting: assert ok # string writes never fail.
        # Simulate writing the entire file so error recovery works.
        at.writeOpenFile(root,nosentinels=not useSentinels,toString=True,fromString=s)
        at.closeWriteFile()
        # Major bug: failure to clear this wipes out headlines!
        # Minor bug: sometimes this causes slight problems...
        if root:
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
    except Exception:
        at.exception("exception preprocessing script")

    return at.stringOutput
#@-node:ekr.20050506084734:writeFromString
#@+node:ekr.20041005105605.147:writeAll (atFile) & helper
def writeAll(self,
    writeAtFileNodesFlag=False,
    writeDirtyAtFileNodesFlag=False,
    toString=False
):

    """Write @file nodes in all or part of the outline"""

    trace = False and not g.unitTesting
    at = self ; c = at.c
    if trace: scanAtPathDirectivesCount = c.scanAtPathDirectivesCount
    writtenFiles = [] # Files that might be written again.
    force = writeAtFileNodesFlag

    if writeAtFileNodesFlag:
        # The Write @<file> Nodes command.
        # Write all nodes in the selected tree.
        p = c.p
        after = p.nodeAfterTree()
    else:
        # Write dirty nodes in the entire outline.
        p =  c.rootPosition()
        after = c.nullPosition()

    << Clear all orphan bits >>
    while p and p != after:
        if p.isAnyAtFileNode() or p.isAtIgnoreNode():
            self.writeAllHelper(p,force,toString,writeAtFileNodesFlag,writtenFiles)
            p.moveToNodeAfterTree()
        else:
            p.moveToThreadNext()

    << say the command is finished >>
    if trace: g.trace('%s calls to c.scanAtPathDirectives()' % (
        c.scanAtPathDirectivesCount-scanAtPathDirectivesCount))

#@+node:ekr.20041005105605.148:<< Clear all orphan bits >>
@ We must clear these bits because they may have been set on a previous write.
Calls to atFile::write may set the orphan bits in @file nodes.
If so, write_Leo_file will write the entire @file tree.
@c

for v2 in p.self_and_subtree():
    v2.clearOrphan()
#@-node:ekr.20041005105605.148:<< Clear all orphan bits >>
#@+node:ekr.20041005105605.150:<< say the command is finished >>
if writeAtFileNodesFlag or writeDirtyAtFileNodesFlag:
    if len(writtenFiles) > 0:
        g.es("finished")
    elif writeAtFileNodesFlag:
        g.es("no @<file> nodes in the selected tree")
    else:
        g.es("no dirty @<file> nodes")
#@-node:ekr.20041005105605.150:<< say the command is finished >>
#@+node:ekr.20041005105605.149:writeAllHelper (atFile)
def writeAllHelper (self,p,
    force,toString,writeAtFileNodesFlag,writtenFiles
):

    trace = False and not g.unitTesting
    at = self ; c = at.c

    if p.isAtIgnoreNode() and not p.isAtAsisFileNode():
        pathChanged = False
    else:
        oldPath = at.getPathUa(p).lower()
        newPath = at.fullPath(p).lower()
        pathChanged = oldPath and oldPath != newPath
        # 2010/01/27: suppress this message during save-as and save-to commands.
        if pathChanged and not c.ignoreChangedPaths:
            at.setPathUa(p,newPath) # Remember that we have changed paths.
            g.es_print('path changed for',p.h,color='blue')
            if trace: g.trace('p %s\noldPath %s\nnewPath %s' % (
                p.h,repr(oldPath),repr(newPath)))

    if p.v.isDirty() or pathChanged or writeAtFileNodesFlag or p.v in writtenFiles:

        # Tricky: @ignore not recognised in @asis nodes.
        if p.isAtAsisFileNode():
            at.asisWrite(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtIgnoreNode():
            pass
        elif p.isAtAutoNode():
            at.writeOneAtAutoNode(p,toString=toString,force=force)
            writtenFiles.append(p.v)
        elif p.isAtEditNode():
            at.writeOneAtEditNode(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtNoSentFileNode():
            at.write(p,kind='@nosent',nosentinels=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtShadowFileNode():
            at.writeOneAtShadowNode(p,toString=toString,force=force or pathChanged)
            writtenFiles.append(p.v)
        elif p.isAtThinFileNode():
            at.write(p,kind='@thin',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtFileNode():
            # Write old @file nodes using @thin format.
            at.write(p,kind='@file',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
#@-node:ekr.20041005105605.149:writeAllHelper (atFile)
#@-node:ekr.20041005105605.147:writeAll (atFile) & helper
#@-node:ekr.20100123044506.6243:changed
#@-node:ekr.20100123044506.6238:Eliminated tnodeLists
#@+node:ekr.20100124092134.6247:checked for p.setDirty
@
This is surprising. It should be the same as p.v.setDirty, but it calls
c.setDirty instead! However, in Leo's code p.setDirty is used by commands, so it
can't be changed. We must make *sure* not to call p.setDirty when reading files.
#@+node:ekr.20040303163330:p.setDirty
def setDirty (self,setDescendentsDirty=True):

    '''Mark a node and all ancestor @file nodes dirty.'''

    p = self ; dirtyVnodeList = []

    # g.trace(p.h,g.callers(4))

    if not p.v.isDirty():
        p.v.setDirty()
        dirtyVnodeList.append(p.v)

    # Important: this must be called even if p.v is already dirty.
    # Typing can change the @ignore state!
    dirtyVnodeList2 = p.setAllAncestorAtFileNodesDirty(setDescendentsDirty)
    dirtyVnodeList.extend(dirtyVnodeList2)

    return dirtyVnodeList
#@-node:ekr.20040303163330:p.setDirty
#@+node:ekr.20040315034158:p.setBodyString & setHeadString
def setBodyString (self,s):

    p = self
    return p.v.setBodyString(s)

initBodyString = setBodyString
setTnodeText = setBodyString
scriptSetBodyString = setBodyString

def initHeadString (self,s):

    p = self
    p.v.initHeadString(s)

def setHeadString (self,s):

    p = self
    p.v.initHeadString(s)
    # Note: p.setDirty is expensive.
    # We can't change this because Leo's core uses
    # p.setDirty and c.setDirty interchangeably.
    p.setDirty()
#@nonl
#@-node:ekr.20040315034158:p.setBodyString & setHeadString
#@+node:ekr.20041005105605.72:at.createThinChild4
def createThinChild4 (self,gnxString,headline):

    """Find or create a new *vnode* whose parent (also a vnode) is at.lastThinNode.
    This is called only for @thin trees."""

    trace = False and not g.unitTesting
    verbose = False
    at = self ; c = at.c ; indices = g.app.nodeIndices
    last = at.lastThinNode
    lastIndex = last.fileIndex
    gnx = indices.scanGnx(gnxString,0)

    if trace and verbose: g.trace("last %s, gnx %s %s" % (
        last,gnxString,headline))

    parent = at.lastThinNode # A vnode.
    children = parent.children
    for child in children:
        if gnx == child.fileIndex:
            break
    else:
        child = None

    if at.cloneSibCount > 1:
        n = at.cloneSibCount ; at.cloneSibCount = 0
        if child: clonedSibs,junk = at.scanForClonedSibs(parent,child)
        else: clonedSibs = 0
        copies = n - clonedSibs
        if trace: g.trace(copies,headline)
    else:
        if gnx == lastIndex:
            last.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace:g.trace('found last',last)
            return last
        if child:
            child.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace: g.trace('found child',child)
            return child
        copies = 1 # Create exactly one copy.

    while copies > 0:
        copies -= 1
        # Create the vnode only if it does not already exist.
        gnxDict = c.fileCommands.gnxDict
        v = gnxDict.get(gnxString)
        if v:
            if gnx != v.fileIndex:
                g.trace('can not happen: v.fileIndex: %s gnx: %s' % (v.fileIndex,gnx))
        else:
            v = leoNodes.vnode(context=c)
            v._headString = headline # Allowed use of v._headString.
            v.fileIndex = gnx
            gnxDict[gnxString] = v

        child = v
        child._linkAsNthChild(parent,parent.numberOfChildren())

    if trace and verbose: g.trace('new node: %s' % child)
    child.setVisited() # Supress warning/deletion of unvisited nodes.
    return child
#@-node:ekr.20041005105605.72:at.createThinChild4
#@-node:ekr.20100124092134.6247:checked for p.setDirty
#@+node:ekr.20100122162421.6240:Clones in @all files now have low priority
To do: create cloneTest.leo and related files.
#@nonl
#@+node:ekr.20100124110832.6214:unchanged...
# These may have changed, but not for this particular project.
#@nonl
#@+node:ekr.20041005105605.72:at.createThinChild4
def createThinChild4 (self,gnxString,headline):

    """Find or create a new *vnode* whose parent (also a vnode) is at.lastThinNode.
    This is called only for @thin trees."""

    trace = False and not g.unitTesting
    verbose = False
    at = self ; c = at.c ; indices = g.app.nodeIndices
    last = at.lastThinNode
    lastIndex = last.fileIndex
    gnx = indices.scanGnx(gnxString,0)

    if trace and verbose: g.trace("last %s, gnx %s %s" % (
        last,gnxString,headline))

    parent = at.lastThinNode # A vnode.
    children = parent.children
    for child in children:
        if gnx == child.fileIndex:
            break
    else:
        child = None

    if at.cloneSibCount > 1:
        n = at.cloneSibCount ; at.cloneSibCount = 0
        if child: clonedSibs,junk = at.scanForClonedSibs(parent,child)
        else: clonedSibs = 0
        copies = n - clonedSibs
        if trace: g.trace(copies,headline)
    else:
        if gnx == lastIndex:
            last.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace:g.trace('found last',last)
            return last
        if child:
            child.setVisited() # Supress warning/deletion of unvisited nodes.
            if trace: g.trace('found child',child)
            return child
        copies = 1 # Create exactly one copy.

    while copies > 0:
        copies -= 1
        # Create the vnode only if it does not already exist.
        gnxDict = c.fileCommands.gnxDict
        v = gnxDict.get(gnxString)
        if v:
            if gnx != v.fileIndex:
                g.trace('can not happen: v.fileIndex: %s gnx: %s' % (v.fileIndex,gnx))
        else:
            v = leoNodes.vnode(context=c)
            v._headString = headline # Allowed use of v._headString.
            v.fileIndex = gnx
            gnxDict[gnxString] = v

        child = v
        child._linkAsNthChild(parent,parent.numberOfChildren())

    if trace and verbose: g.trace('new node: %s' % child)
    child.setVisited() # Supress warning/deletion of unvisited nodes.
    return child
#@-node:ekr.20041005105605.72:at.createThinChild4
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20041005105605.85:at.readStartNode
def readStartNode (self,s,i,middle=False):

    """Read an @+node or @+middle sentinel."""

    trace = False and not g.unitTesting
    at = self
    if middle:
        assert g.match(s,i,"+middle:"),'missing +middle'
        i += 8
    else:
        assert g.match(s,i,"+node:"),'missing +node'
        i += 6

    if at.thinFile:
        << set gnx and bump i >>
    << Set headline, undoing the CWEB hack >>
    if not at.root_seen:
        # g.trace(repr(s[0:i+20]))
        at.root_seen = True

    i,newIndent = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    at.indentStack.append(at.indent) ; at.indent = newIndent

    at.outStack.append(at.out) ; at.out = []
    at.tStack.append(at.v)

    if trace: g.trace(at.root)
    if at.importing:
        p = at.createImportedNode(at.root,headline)
        at.v = p.v
    elif at.thinFile:
        if at.thinNodeStack:
            at.thinNodeStack.append(at.lastThinNode)
            v = at.createThinChild4(gnx,headline)
        else:
            v = at.root.v
            at.thinNodeStack.append(v)
        at.lastThinNode = v
        at.v = v
    else:
        at.v = at.findChild4(headline)

    if trace: g.trace('scanning',at.v)

    at.endSentinelStack.append(at.endNode)
#@+node:ekr.20041005105605.86:<< set gnx and bump i >>
# We have skipped past the opening colon of the gnx.
j = s.find(':',i)
if j == -1:
    g.trace("no closing colon",g.get_line(s,i))
    at.readError("Expecting gnx in @+node sentinel")
    return # 5/17/04
else:
    gnx = s[i:j]
    i = j + 1 # Skip the i
#@-node:ekr.20041005105605.86:<< set gnx and bump i >>
#@+node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
# Set headline to the rest of the line.
# Don't strip leading whitespace."

if len(at.endSentinelComment) == 0:
    headline = s[i:-1].rstrip()
else:
    k = s.rfind(at.endSentinelComment,i)
    headline = s[i:k].rstrip() # works if k == -1

# Undo the CWEB hack: undouble @ signs if the opening comment delim ends in '@'.
if at.startSentinelComment[-1:] == '@':
    headline = headline.replace('@@','@')
#@-node:ekr.20041005105605.87:<< Set headline, undoing the CWEB hack >>
#@-node:ekr.20041005105605.85:at.readStartNode
#@+node:ekr.20031218072017.2989:c.setChanged
def setChanged (self,changedFlag):

    trace = False and not g.unitTesting
    c = self
    if not c.frame: return
    c.changed = changedFlag
    if c.loading: return # don't update while loading.

    if trace: g.trace('Commands',changedFlag,c,g.callers(4))

    # Clear all dirty bits _before_ setting the caption.
    if not changedFlag:
        for v in c.all_unique_nodes():
            if v.isDirty():
                v.clearDirty()

    if g.app.qt_use_tabs and hasattr(c.frame,'top'):
        c.frame.top.master.setChanged(c,changedFlag)

    s = c.frame.getTitle()
    if len(s) > 2:
        if changedFlag:
            if s [0] != '*': c.frame.setTitle("* " + s)
        else:
            if s[0:2]=="* ": c.frame.setTitle(s[2:])
#@-node:ekr.20031218072017.2989:c.setChanged
#@+node:ekr.20060919110638.5:fc.createSaxChildren & helpers
def createSaxChildren (self, sax_node, parent_v):

    c = self.c
    trace = False and not g.unitTesting # and c.shortFileName().find('small') > -1
    children = []

    for sax_child in sax_node.children:
        tnx = sax_child.tnx
        v = self.gnxDict.get(tnx)

        if v: # A clone.
            if trace: g.trace('**clone',v)
            v = self.createSaxVnode(sax_child,parent_v,v=v)   
        else:
            v = self.createSaxVnode(sax_child,parent_v)
            self.createSaxChildren(sax_child,v)

        children.append(v)

    parent_v.children = children
    for child in children:
        child.parents.append(parent_v)
        if trace: g.trace(
            '*** added parent',parent_v,'to',child,
            'len(child.parents)',len(child.parents))

    return children
#@+node:ekr.20060919110638.7:fc.createSaxVnode & helpers
def createSaxVnode (self,sax_node,parent_v,v=None):

    c = self.c
    trace = False and not g.unitTesting and c.shortFileName().find('test') > -1
    verbose = False
    h = sax_node.headString
    b = sax_node.bodyString

    if v:
        # The body of the later node overrides the earlier.
        # Don't set t.h: h is always empty.
        # This may be an internal error.
        if v.b == b:
            if trace and verbose: g.trace(
                '***no update\nold: %s\nnew: %s' % (v.b,b))
        else:
            if trace: g.trace(
                '***update\nold: %s\nnew: %s' % (v.b,b))
            v.b = b 
    else:
        v = leoNodes.vnode(context=c)
        v.setBodyString(b)
        v.setHeadString(h)

        if sax_node.tnx:
            v.fileIndex = g.app.nodeIndices.scanGnx(sax_node.tnx,0)

    index = self.canonicalTnodeIndex(sax_node.tnx)
    self.gnxDict [index] = v

    if trace and verbose: g.trace(
        'tnx','%-22s' % (index),'v',id(v),
        'len(body)','%-4d' % (len(b)),h)

    self.handleVnodeSaxAttributes(sax_node,v)
    self.handleTnodeSaxAttributes(sax_node,v)

    return v
#@+node:ekr.20060919110638.8:handleTnodeSaxAttributes
def handleTnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.tnodeAttributes
    if trace and d: g.trace(sax_node,list(d.keys()))

    aDict = {}
    for key in d:
        val = d.get(key)
        val2 = self.getSaxUa(key,val)
        # g.trace(key,val,val2)
        aDict[key] = val2

    if aDict:
        if trace: g.trace('uA',v,list(aDict.keys()))
        v.unknownAttributes = aDict
#@+node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()

    sax_node = g.bunch(
        tnodeAttributes={
# The 'tx' attribute is handled by contentHandler.tnodeAttributes.
# 'tx':"ekr.20090701133940.1767",
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
})
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleTnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr),attr
        for attr in ('tx','a'):
            assert d.get(attr) is None,attr # A known attribute.
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
#@-node:ekr.20060919110638.8:handleTnodeSaxAttributes
#@+node:ekr.20061004053644:handleVnodeSaxAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded, and descendentTnodeUnknownAttributes.
# New in Leo 4.5: added descendentVnodeUnknownAttributes to native attributes.

def handleVnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.attributes
    # if trace and d: g.trace(d)

    s = d.get('a')
    if s:
        # g.trace('%s a=%s %s' % (id(sax_node),s,v.headString()))
        # 'C' (clone) and 'D' bits are not used.
        if 'M' in s: v.setMarked()
        if 'E' in s: v.expand()
        if 'O' in s: v.setOrphan()
        # if 'T' in s: self.topVnode = v
        if 'V' in s:
            # g.trace('setting currentVnode',v,color='red')
            self.currentVnode = v

    s = d.get('tnodeList','')
    tnodeList = s and s.split(',')
    if tnodeList:
        # This tnodeList will be resolved later.
        if trace: g.trace('found tnodeList',v.headString(),tnodeList)
        v.tempTnodeList = tnodeList

    s = d.get('descendentTnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentTnodeUaDictList',aDict)
            self.descendentTnodeUaDictList.append(aDict)

    s = d.get('descendentVnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentVnodeUaDictList',aDict)
            self.descendentVnodeUaDictList.append((v,aDict),)

    s = d.get('expanded')
    if s:
        aList = self.getDescendentAttributes(s,tag="expanded")
        # g.trace('expanded list',len(aList))
        self.descendentExpandedList.extend(aList)

    s = d.get('marks')
    if s:
        aList = self.getDescendentAttributes(s,tag="marks")
        # g.trace('marks list',len(aList))
        self.descendentMarksList.extend(aList)

    aDict = {}
    for key in d:
        if key in self.nativeVnodeAttributes:
            # This is not a bug.
            if False and trace: g.trace(
                '****ignoring***',key,d.get(key))
        else:
            val = d.get(key)
            val2 = self.getSaxUa(key,val)
            aDict[key] = val2
            # g.trace(key,val,val2)
    if aDict:
        # if trace: g.trace('uA',v,aDict)
        v.unknownAttributes = aDict
#@+node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()
    sax_node = g.bunch(
        attributes={
'a':'M',
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
    })
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleVnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr) is not None,attr
        # The a:M attribute should mark the node.
        assert d.get('a') is None
        assert v.isMarked()
        aList = d.get('icons')
        assert aList
        assert len(aList) == 2
        for d2 in aList:
            for key in ('on','where','yoffset','file'):
                assert d2.get(key) is not None,key
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
#@-node:ekr.20061004053644:handleVnodeSaxAttributes
#@-node:ekr.20060919110638.7:fc.createSaxVnode & helpers
#@-node:ekr.20060919110638.5:fc.createSaxChildren & helpers
#@-node:ekr.20100124110832.6214:unchanged...
#@+node:ekr.20100124110832.6213:changed...
#@+node:ekr.20041005105605.95:at.readEndNode
def readEndNode (self,unused_s,unused_i,middle=False):

    """Handle end-of-node processing for @-others and @-ref sentinels."""

    trace = False and not g.unitTesting
    at = self ; c = at.c

    # End raw mode.
    at.raw = False

    # Set the temporary body text.
    s = ''.join(at.out)
    s = g.toUnicode(s)

    # g.trace(repr(s))

    if at.importing:
        at.v._bodyString = s # Allowed use of _bodyString.
    elif middle: 
        pass # Middle sentinels never alter text.
    else:
        if hasattr(at.v,"tempBodyString") and s != at.v.tempBodyString:
            old = at.v.tempBodyString
        elif at.v.hasBody() and s != at.v.getBody():
            old = at.v.getBody()
        else:
            old = None
        # 9/4/04: Suppress this warning for the root: @first complicates matters.
        if old and at.v != at.root.v: # and not g.app.unitTesting
            << indicate that the node has been changed >>
        if old and at.atAllFlag:
            # Don't change.
            if trace: g.trace('*** no update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
        else:
            if trace: g.trace('*** update\nold: %s\nnew: %s' % (
                repr(old),repr(s)))
            at.v.tempBodyString = s

    # Indicate that the vnode has been set in the derived file.
    at.v.setVisited()
    # g.trace('visit',at.v)

    # End the previous node sentinel.
    at.indent = at.indentStack.pop()
    at.out = at.outStack.pop()
    at.v = at.tStack.pop()
    if at.thinFile and not at.importing:
        at.lastThinNode = at.thinNodeStack.pop()

    at.popSentinelStack(at.endNode)
#@+node:ekr.20041005105605.96:<< indicate that the node has been changed >>
if at.perfectImportRoot:
    << bump at.correctedLines and tell about the correction >>
    at.v._bodyString = s # Allowed use of _bodyString.
        # Just setting at.v.tempBodyString won't work here.
    at.v.setDirty() # Mark the node dirty.  Ancestors will be marked dirty later.
    at.c.setChanged(True)
else:
    # New in Leo 4.4.1 final.  This warning can be very confusing.
    # New in Leo 4.7 b2: We suppress warning for trees containing '@all'
    if at.atAllFlag: # Give the warning if we are not in an '@all' tree.
        pass
    # elif not at.updateWarningGiven:
    else:
        # at.updateWarningGiven = True
        # g.pr("***",at.v,at.root.v)
        g.es_print("uncached read node changed",at.v.h,color="red") # was at.root.h
    # Just set the dirty bit. Ancestors will be marked dirty later.
    at.v.setDirty()
    # Important: the dirty bits won't stick unless we set c.changed here.
    # Do *not* call c.setChanged(True) here: that would be too slow.
    c.changed = True
#@nonl
#@+node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
# Report the number of corrected nodes.
at.correctedLines += 1

found = False
for p in at.perfectImportRoot.self_and_subtree():
    if p.v == at.v:
        found = True ; break

if found:
    if 0: # For debugging.
        g.pr('\n','-' * 40)
        g.pr("old",len(old))
        for line in g.splitLines(old):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
        g.pr("new",len(s))
        for line in g.splitLines(s):
            #line = line.replace(' ','< >').replace('\t','<TAB>')
            g.pr(repr(str(line)))
        g.pr('\n','-' * 40)
else:
    # This should never happen.
    g.es("correcting hidden node: v=",repr(at.v),color="red")
#@-node:ekr.20041005105605.97:<< bump at.correctedLines and tell about the correction >>
#@-node:ekr.20041005105605.96:<< indicate that the node has been changed >>
#@-node:ekr.20041005105605.95:at.readEndNode
#@+node:ekr.20041005105605.81:at.readStartAll
def readStartAll (self,s,i):

    """Read an @+all sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert g.match(s,j,"@+all"),'missing @+all'
    else:
        assert g.match(s,j,"+all"),'missing +all'

    # g.trace('root_seen',at.root_seen,at.root.h,repr(s))
    at.atAllFlag = True

    # Make sure that the generated at-all is properly indented.
    at.out.append(leadingWs + "@all\n")

    at.endSentinelStack.append(at.endAll)
#@-node:ekr.20041005105605.81:at.readStartAll
#@+node:ekr.20060919110638.7:fc.createSaxVnode & helpers
def createSaxVnode (self,sax_node,parent_v,v=None):

    c = self.c
    trace = False and not g.unitTesting and c.shortFileName().find('test') > -1
    verbose = False
    h = sax_node.headString
    b = sax_node.bodyString

    if v:
        # The body of the later node overrides the earlier.
        # Don't set t.h: h is always empty.
        # This may be an internal error.
        if v.b == b:
            if trace and verbose: g.trace(
                '***no update\nold: %s\nnew: %s' % (v.b,b))
        else:
            if trace: g.trace(
                '***update\nold: %s\nnew: %s' % (v.b,b))
            v.b = b 
    else:
        v = leoNodes.vnode(context=c)
        v.setBodyString(b)
        v.setHeadString(h)

        if sax_node.tnx:
            v.fileIndex = g.app.nodeIndices.scanGnx(sax_node.tnx,0)

    index = self.canonicalTnodeIndex(sax_node.tnx)
    self.gnxDict [index] = v

    if trace and verbose: g.trace(
        'tnx','%-22s' % (index),'v',id(v),
        'len(body)','%-4d' % (len(b)),h)

    self.handleVnodeSaxAttributes(sax_node,v)
    self.handleTnodeSaxAttributes(sax_node,v)

    return v
#@+node:ekr.20060919110638.8:handleTnodeSaxAttributes
def handleTnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.tnodeAttributes
    if trace and d: g.trace(sax_node,list(d.keys()))

    aDict = {}
    for key in d:
        val = d.get(key)
        val2 = self.getSaxUa(key,val)
        # g.trace(key,val,val2)
        aDict[key] = val2

    if aDict:
        if trace: g.trace('uA',v,list(aDict.keys()))
        v.unknownAttributes = aDict
#@+node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()

    sax_node = g.bunch(
        tnodeAttributes={
# The 'tx' attribute is handled by contentHandler.tnodeAttributes.
# 'tx':"ekr.20090701133940.1767",
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
})
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleTnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr),attr
        for attr in ('tx','a'):
            assert d.get(attr) is None,attr # A known attribute.
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702070510.6028:@test handleTnodeSaxAttributes
#@-node:ekr.20060919110638.8:handleTnodeSaxAttributes
#@+node:ekr.20061004053644:handleVnodeSaxAttributes
# The native attributes of <v> elements are a, t, vtag, tnodeList,
# marks, expanded, and descendentTnodeUnknownAttributes.
# New in Leo 4.5: added descendentVnodeUnknownAttributes to native attributes.

def handleVnodeSaxAttributes (self,sax_node,v):

    trace = False and not g.unitTesting
    d = sax_node.attributes
    # if trace and d: g.trace(d)

    s = d.get('a')
    if s:
        # g.trace('%s a=%s %s' % (id(sax_node),s,v.headString()))
        # 'C' (clone) and 'D' bits are not used.
        if 'M' in s: v.setMarked()
        if 'E' in s: v.expand()
        if 'O' in s: v.setOrphan()
        # if 'T' in s: self.topVnode = v
        if 'V' in s:
            # g.trace('setting currentVnode',v,color='red')
            self.currentVnode = v

    s = d.get('tnodeList','')
    tnodeList = s and s.split(',')
    if tnodeList:
        # This tnodeList will be resolved later.
        if trace: g.trace('found tnodeList',v.headString(),tnodeList)
        v.tempTnodeList = tnodeList

    s = d.get('descendentTnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentTnodeUaDictList',aDict)
            self.descendentTnodeUaDictList.append(aDict)

    s = d.get('descendentVnodeUnknownAttributes')
    if s: 
        aDict = self.getDescendentUnknownAttributes(s)
        if aDict:
            # g.trace('descendentVnodeUaDictList',aDict)
            self.descendentVnodeUaDictList.append((v,aDict),)

    s = d.get('expanded')
    if s:
        aList = self.getDescendentAttributes(s,tag="expanded")
        # g.trace('expanded list',len(aList))
        self.descendentExpandedList.extend(aList)

    s = d.get('marks')
    if s:
        aList = self.getDescendentAttributes(s,tag="marks")
        # g.trace('marks list',len(aList))
        self.descendentMarksList.extend(aList)

    aDict = {}
    for key in d:
        if key in self.nativeVnodeAttributes:
            # This is not a bug.
            if False and trace: g.trace(
                '****ignoring***',key,d.get(key))
        else:
            val = d.get(key)
            val2 = self.getSaxUa(key,val)
            aDict[key] = val2
            # g.trace(key,val,val2)
    if aDict:
        # if trace: g.trace('uA',v,aDict)
        v.unknownAttributes = aDict
#@+node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
if g.unitTesting:

    c,p = g.getTestVars()
    sax_node = g.bunch(
        attributes={
'a':'M',
'lineYOffset':"4b032e",
# A real icon attribute, see the tests below for what we expect
'icons':"5d7100287d71012855026f6e71025505746e6f6465710355047479\
70657104550466696c6571055507796f666673657471064b006805583700000\
0433a5c6c656f2e7265706f5c7472756e6b5c6c656f5c49636f6e735c54616e\
676f5c31367831365c616374696f6e735c6164642e706e67710755047870616\
471084b01550577686572657109550e6265666f7265486561646c696e65710a\
5507786f6666736574710b4b02550772656c50617468710c581b00000054616\
e676f5c31367831365c616374696f6e735c6164642e706e67710d757d710e28\
55026f6e710f68035504747970657110550466696c6571115507796f6666736\
57471124b006811583a000000433a5c6c656f2e7265706f5c7472756e6b5c6c\
656f5c49636f6e735c54616e676f5c31367831365c616374696f6e735c626f7\
4746f6d2e706e67711355047870616471144b01550577686572657115550e62\
65666f7265486561646c696e6571165507786f666673657471174b025507726\
56c506174687118581e00000054616e676f5c31367831365c616374696f6e73\
5c626f74746f6d2e706e67711975652e"
    })
    try:
        p2 = p.insertAsLastChild()
        v = p2.v
        c.fileCommands.handleVnodeSaxAttributes(sax_node,v)
        # print v,v.u
        d = v.u
        for attr in ('lineYOffset','icons'):
            assert d.get(attr) is not None,attr
        # The a:M attribute should mark the node.
        assert d.get('a') is None
        assert v.isMarked()
        aList = d.get('icons')
        assert aList
        assert len(aList) == 2
        for d2 in aList:
            for key in ('on','where','yoffset','file'):
                assert d2.get(key) is not None,key
    finally:
        if 1:
            while p.hasChildren():
                # print('deleting',p.firstChild())
                p.firstChild().doDelete()
#@-node:ekr.20090702072557.6420:@test handleVnodeSaxAttributes
#@-node:ekr.20061004053644:handleVnodeSaxAttributes
#@-node:ekr.20060919110638.7:fc.createSaxVnode & helpers
#@+node:ekr.20031218072017.1553:fc.getLeoFile & helpers
# The caller should follow this with a call to c.redraw().

def getLeoFile (self,theFile,fileName,readAtFileNodesFlag=True,silent=False):

    c = self.c
    c.setChanged(False) # May be set when reading @file nodes.
    self.warnOnReadOnlyFiles(fileName)
    self.checking = False
    self.mFileName = c.mFileName
    self.initReadIvars()

    try:
        c.loading = True # disable c.changed
        ok = self.getLeoFileHelper(theFile,fileName,silent)

        # Do this before reading derived files.
        self.resolveTnodeLists()

        if ok and readAtFileNodesFlag:
            # Redraw before reading the @file nodes so the screen isn't blank.
            # This is important for big files like LeoPy.leo.
            c.redraw()
            c.setFileTimeStamp(fileName)
            c.atFileCommands.readAll(c.rootVnode(),partialFlag=False)

        # Do this after reading derived files.
        if readAtFileNodesFlag:
            # The descendent nodes won't exist unless we have read the @thin nodes!
            self.restoreDescendentAttributes()

        self.setPositionsFromVnodes()
        c.selectVnode(c.p) # load body pane
        if c.config.getBool('check_outline_after_read'):
            c.checkOutline(event=None,verbose=True,unittest=False,full=True)
    finally:
        c.loading = False # reenable c.changed

    if c.changed:
        self.propegateDirtyNodes()
    c.setChanged(c.changed) # Refresh the changed marker.
    self.initReadIvars()
    return ok, c.frame.ratio
#@+node:ekr.20090526081836.5841:getLeoFileHelper
def getLeoFileHelper(self,theFile,fileName,silent):

    '''Read the .leo file and create the outline.'''

    c = self.c

    try:
        ok = True
        v = self.readSaxFile(theFile,fileName,silent,inClipboard=False,reassignIndices=False)
        if v: # v is None for minimal .leo files.
            c.setRootVnode(v)
            self.rootVnode = v
        else:
            v = leoNodes.vnode(context=c)
            v.setHeadString('created root node')
            p = leoNodes.position(v)
            p._linkAsRoot(oldRoot=None)
            self.rootVnode = v
            c.setRootPosition(p)
            c.changed = False
    except BadLeoFile:
        junk, message, junk = sys.exc_info()
        if not silent:
            g.es_exception()
            g.alert(self.mFileName + " is not a valid Leo file: " + str(message))
        ok = False

    return ok
#@-node:ekr.20090526081836.5841:getLeoFileHelper
#@+node:ekr.20100124110832.6212:propegateDirtyNodes
def propegateDirtyNodes (self):

    fc = self ; c = fc.c

    aList = [z.copy() for z in c.all_positions() if z.isDirty()]
    for p in aList:
        p.setAllAncestorAtFileNodesDirty()
#@-node:ekr.20100124110832.6212:propegateDirtyNodes
#@+node:ekr.20031218072017.1554:warnOnReadOnlyFiles
def warnOnReadOnlyFiles (self,fileName):

    # os.access may not exist on all platforms.

    try:
        self.read_only = not os.access(fileName,os.W_OK)
    except AttributeError:
        self.read_only = False
    except UnicodeError:
        self.read_only = False

    if self.read_only and not g.unitTesting:
        g.es("read only:",fileName,color="red")
#@+node:ekr.20090526102407.10049:@test g.warnOnReadOnlyFile
if g.unitTesting:

    import os,stat
    c,p = g.getTestVars()
    fc = c.fileCommands

    path = g.os_path_finalize_join(g.app.loadDir,'..','test','test-read-only.txt')
    if os.path.exists(path):
        os.chmod(path, stat.S_IREAD)
        fc.warnOnReadOnlyFiles(path)
        assert fc.read_only
    else:
        fc.warnOnReadOnlyFiles(path)
#@-node:ekr.20090526102407.10049:@test g.warnOnReadOnlyFile
#@-node:ekr.20031218072017.1554:warnOnReadOnlyFiles
#@-node:ekr.20031218072017.1553:fc.getLeoFile & helpers
#@+node:ekr.20090829064400.6040:v.createOutlineFromCacheList & helpers
def createOutlineFromCacheList(self,c,aList,top=True,atAll=None):
    """ Create outline structure from recursive aList
    built by p.makeCacheList.

    Clones will be automatically created by gnx,
    but *not* for the top-level node.
    """

    trace = False and not g.unitTesting
    parent_v = self

    #import pprint ; pprint.pprint(tree)
    parent_v = self
    h,b,gnx,children = aList
    if h is not None:
        v = parent_v
        v._headString = h    
        v._bodyString = b

    if top:
        # Scan the body for @all directives.
        for line in g.splitLines(b):
            if line.startswith('@all'):
                atAll = True ; break
        else:
            atAll = False
    else:
        assert atAll in (True,False,)

    for z in children:
        h,b,gnx,grandChildren = z
        isClone,child_v = parent_v.fastAddLastChild(c,gnx)
        if isClone:
            # The cached file can not have changed,
            # otherwise the file would not be in the cache!?
            if child_v.b != b: # or child_v.h
                if atAll: # Bug fix: the last seen clone rules.
                    if trace: g.trace('***not changed\nold: %s\nnew: %s' % (
                        child_v.b,b))
                else:
                    g.es_print("cached read node changed:",child_v.h,color="red")
                    # g.trace(g.callers(5))
                    child_v.h = h
                    child_v.b = b
                    child_v.setDirty()
                        # 2010/01/24: just mark chid_v dirty.
                        # getLeoFile will call setAllAncestorAtFileNodesDirty.
                    c.changed = True
                        # Tell getLeoFile that it must scan for dirty nodes.
        else:
            child_v.createOutlineFromCacheList(c,z,top=False,atAll=atAll)
#@+node:ekr.20090829064400.6042:v.fastAddLastChild
# Similar to createThinChild4
def fastAddLastChild(self,c,gnxString):
    '''Create new vnode as last child of the receiver.

    If the gnx exists already, create a clone instead of new vnode.
    '''

    trace = False and not g.unitTesting
    verbose = False
    parent_v = self
    indices = g.app.nodeIndices
    gnxDict = c.fileCommands.gnxDict

    if gnxString is None: v = None
    else:                 v = gnxDict.get(gnxString)
    is_clone = v is not None

    if trace: g.trace(
        'clone','%-5s' % (is_clone),
        'parent_v',parent_v,'gnx',gnxString,'v',repr(v))

    if is_clone:
        pass
    else:
        v = vnode(context=c)
        if gnxString:
            gnx = indices.scanGnx(gnxString,0)
            v.fileIndex = gnx
        gnxDict[gnxString] = v

    child_v = v
    child_v._linkAsNthChild(parent_v,parent_v.numberOfChildren())
    child_v.setVisited() # Supress warning/deletion of unvisited nodes.

    return is_clone,child_v
#@-node:ekr.20090829064400.6042:v.fastAddLastChild
#@-node:ekr.20090829064400.6040:v.createOutlineFromCacheList & helpers
#@-node:ekr.20100124110832.6213:changed...
#@-node:ekr.20100122162421.6240:Clones in @all files now have low priority
#@+node:ekr.20100125073206.8711:use g.readFileIntoString

    try:
        s = open(fn,'rb').read()
    except IOError:
        g.es("can not open %s" % (fn),color='red')
#@+node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
def readFileIntoString (fn,encoding='utf-8',kind=None,mode='rb',raw=False):

    '''Return the contents of the file whose full path is fn.

    Return (s,e)
    s is the string, converted to unicode, or None if there was an error.
    e the encoding line for Python files: it is usually None.
    '''

    try:
        e = None
        f = open(fn,mode)
        s = f.read()
        f.close()
        if raw:
            return s,None
        else:
            # Python's encoding comments override everything else.
            if s:
                junk,ext = g.os_path_splitext(fn)
                if ext == '.py':
                    e = g.getPythonEncodingFromString(s)
            s = g.toUnicode(s,encoding=e or encoding)
            return s,e
    except IOError:
        # Translate 'can not open' and kind, but not fn.
        if kind:
            g.es('can not open','',kind,fn,color='red')
        else:
            g.es('can not open',fn,color='red')
    except Exception:
        g.trace('unexpected exception reading %s' % (fn),color='red')
        g.es_exception()

    import leo.core.leoTest as leoTest
    leoTest.fail()
    return None,None
#@-node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
#@+node:ekr.20100125073206.8720:Changed...
#@+node:ekr.20031218072017.3300:removeSentinelsCommand
def removeSentinelsCommand (self,paths,toString=False):

    c = self.c

    self.setEncoding()

    for fileName in paths:
        g.setGlobalOpenDir(fileName)
        path, self.fileName = g.os_path_split(fileName)
        s,e = g.readFileIntoString(fileName,self.encoding)
        if s is None: return
        if e: self.encoding = e
        << set delims from the header line >>
        # g.trace("line: '%s', start: '%s', end: '%s'" % (line_delim,start_delim,end_delim))
        s = self.removeSentinelLines(s,line_delim,start_delim,end_delim)
        ext = c.config.remove_sentinels_extension
        if not ext:
            ext = ".txt"
        if ext[0] == '.':
            newFileName = c.os_path_finalize_join(path,fileName+ext)
        else:
            head,ext2 = g.os_path_splitext(fileName) 
            newFileName = c.os_path_finalize_join(path,head+ext+ext2)
        if toString:
            return s
        else:
            << Write s into newFileName >>
            return None
#@+node:ekr.20031218072017.3302:<< set delims from the header line >>
# Skip any non @+leo lines.
i = 0
while i < len(s) and g.find_on_line(s,i,"@+leo") == -1:
    i = g.skip_line(s,i)

# Get the comment delims from the @+leo sentinel line.
at = self.c.atFileCommands
j = g.skip_line(s,i) ; line = s[i:j]

valid,junk,start_delim,end_delim,junk = at.parseLeoSentinel(line)
if not valid:
    if not toString: g.es("invalid @+leo sentinel in",fileName)
    return

if end_delim:
    line_delim = None
else:
    line_delim,start_delim = start_delim,None
#@-node:ekr.20031218072017.3302:<< set delims from the header line >>
#@+node:ekr.20031218072017.1149:<< Write s into newFileName >>
try:
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    theFile = open(newFileName,mode)
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    theFile.write(s)
    theFile.close()
    if not g.unitTesting:
        g.es("created:",newFileName)
except Exception:
    g.es("exception creating:",newFileName)
    g.es_exception()
#@-node:ekr.20031218072017.1149:<< Write s into newFileName >>
#@-node:ekr.20031218072017.3300:removeSentinelsCommand
#@+node:ekr.20031218072017.3210:createOutline (leoImport)
def createOutline (self,fileName,parent,
    atAuto=False,atShadow=False,s=None,ext=None):

    c = self.c ; u = c.undoer ; s1 = s
    w = c.frame.body
    # New in Leo 4.4.7: honor @path directives.
    self.scanDefaultDirectory(parent) # sets .defaultDirectory.
    fileName = c.os_path_finalize_join(self.default_directory,fileName)
    junk,self.fileName = g.os_path_split(fileName)
    self.methodName,self.fileType = g.os_path_splitext(self.fileName)
    self.setEncoding(p=parent,atAuto=atAuto)
    if not ext: ext = self.fileType
    ext = ext.lower()
    if not s:
        if atShadow: kind = '@shadow '
        elif atAuto: kind = '@auto '
        else: kind = ''
        s,e = g.readFileIntoString(fileName,encoding=self.encoding,kind=kind)
        if s is None: return None
        if e: self.encoding = e

    # Create the top-level headline.
    if atAuto:
        p = parent.copy()
        p.setBodyString('')
    else:
        undoData = u.beforeInsertNode(parent)
        p = parent.insertAsLastChild()

        if self.treeType == "@file":
            p.initHeadString("@file " + fileName)
        else:
            # @root nodes don't have @root in the headline.
            p.initHeadString(fileName)
        u.afterInsertNode(p,'Import',undoData)

    self.rootLine = g.choose(self.treeType=="@file","","@root-code "+self.fileName+'\n')

    if p.isAtAutoRstNode(): # @auto-rst is independent of file extension.
        func = self.scanRstText
    else:
        func = self.importDispatchDict.get(ext)

    if func and not c.config.getBool('suppress_import_parsing',default=False):
        func(s,p,atAuto=atAuto)
    else:
        # Just copy the file to the parent node.
        self.scanUnknownFileType(s,p,ext,atAuto=atAuto)

    if atAuto:
        # Remember that we have read this file.
        # Fixes bug 488894: unsettling dialog when saving Leo file
        # after creating and populating an @auto node.
        # Important: this often sets the bit in the wrong node:
        # The caller may have to set the bit in the "real" root node.
        p.v.at_read = True # Create the attribute

    p.contract()
    w.setInsertPoint(0)
    w.seeInsertPoint()
    return p
#@-node:ekr.20031218072017.3210:createOutline (leoImport)
#@+node:ekr.20091007103358.6061:scanOptions
def scanOptions():

    '''Handle all options and remove them from sys.argv.'''
    trace = False

    # Note: this automatically implements the --help option.
    parser = optparse.OptionParser()
    parser.add_option('-c', '--config', dest="one_config_path")
    parser.add_option('--debug',        action="store_true",dest="debug")
    parser.add_option('-f', '--file',   dest="fileName")
    parser.add_option('--gui',          dest="gui",help = 'gui to use (qt/tk/qttabs)')
    #parser.add_option('--help',         action="store_true",dest="help_option")
    parser.add_option('--ipython',      action="store_true",dest="use_ipython")
    parser.add_option('--no-cache',     action="store_true",dest='no_cache')
    parser.add_option('--silent',       action="store_true",dest="silent")
    parser.add_option('--script',       dest="script")
    parser.add_option('--script-window',dest="script_window")
    parser.add_option('--version',      action="store_true",dest="version")

    # Parse the options, and remove them from sys.argv.
    options, args = parser.parse_args()
    sys.argv = [sys.argv[0]] ; sys.argv.extend(args)
    if trace: print('scanOptions',sys.argv)

    # Handle the args...

    # -c or --config
    path = options.one_config_path
    if path:
        path = g.os_path_finalize_join(os.getcwd(),path)
        if g.os_path_exists(path):
            g.app.oneConfigFilename = path
        else:
            g.es_print('Invalid -c option: file not found:',path,color='red')

    # --debug
    if options.debug:
        g.debug = True
        g.trace('*** debug mode on')

    # -f or --file
    fileName = options.fileName

    # --gui
    gui = options.gui
    g.app.qt_use_tabs = False
    if gui:
        gui = gui.lower()
        if gui == 'qttabs':
            gui = 'qt'
            g.app.qt_use_tabs = True

        if gui not in ('tk','qt','wx'):
            g.trace('unknown gui: %s' % gui)
            gui = None

    # --ipython
    g.app.useIpython = options.use_ipython

    # --no-cache
    if options.no_cache:
        g.trace('disabling caching')
        g.enableDB = False

    # --script
    script_path = options.script
    script_path_w = options.script_window
    if script_path and script_path_w:
        parser.error("--script and script-window are mutually exclusive")

    script_name = script_path or script_path_w
    if script_name:
        script_name = g.os_path_finalize_join(g.app.loadDir,script_name)
        script,e = g.readFileIntoString(script_name,kind='script:')
    else:
        script = None
        # if trace: print('scanOptions: no script')

    # --silent
    g.app.silentMode = options.silent
    # g.trace('silentMode',g.app.silentMode)

    # --version: print the version and exit.
    versionFlag = options.version

    # Compute the return values.
    windowFlag = script and script_path_w
    if trace:
        print('scanOptions: fileName',fileName)
        print('scanOptions: argv',sys.argv)
    return fileName,gui,script,versionFlag,windowFlag
#@-node:ekr.20091007103358.6061:scanOptions
#@+node:ekr.20090212054250.9:c.createNodeFromExternalFile
def createNodeFromExternalFile(self,fn):

    '''Read the file into a node.
    Return None, indicating that c.open should set focus.'''

    c = self

    s,e = g.readFileIntoString(fn)
    if s is None: return
    head,ext = g.os_path_splitext(fn)
    if ext.startswith('.'): ext = ext[1:]
    language = g.app.extension_dict.get(ext)
    if language:
        prefix = '@color\n@language %s\n\n' % language
    else:
        prefix = '@killcolor\n\n'
    p2 = c.insertHeadline(op_name='Open File', as_child=False)
    p2.h = '@edit %s' % fn # g.shortFileName(fn)
    p2.b = prefix + s
    w = c.frame.body.bodyCtrl
    if w: w.setInsertPoint(0)
    c.redraw()
    c.recolor()
#@nonl
#@-node:ekr.20090212054250.9:c.createNodeFromExternalFile
#@+node:ekr.20070915134101:readFileIntoNode
def readFileIntoNode (self,event=None):

    '''Read a file into a single node.'''

    c = self ; undoType = 'Read File Into Node'
    c.endEditing()

    filetypes = [("All files", "*"),("Python files","*.py"),("Leo files", "*.leo"),]
    fileName = g.app.gui.runOpenFileDialog(
        title="Read File Into Node",filetypes=filetypes,defaultextension=None)
    if not fileName:return
    s,e = g.readFileIntoString(fileName)
    if s is None: return

    g.chdir(fileName)
    s = '@nocolor\n' + s
    w = c.frame.body.bodyCtrl
    p = c.insertHeadline(op_name=undoType)
    p.setHeadString('@read-file-into-node ' + fileName)
    p.setBodyString(s)
    w.setAllText(s)
    c.redraw(p)
#@-node:ekr.20070915134101:readFileIntoNode
#@+node:ekr.20050920084036.166:getReadableTextFile
def getReadableTextFile (self):

    fn = g.app.gui.runOpenFileDialog(
        title = 'Open Text File',
        filetypes = [("Text","*.txt"), ("All files","*")],
        defaultextension = ".txt")

    return fn
#@-node:ekr.20050920084036.166:getReadableTextFile
#@+node:ekr.20050920084036.167:insertFile
def insertFile (self,event):

    '''Prompt for the name of a file and put the selected text into it.'''

    k = self.k ; c = k.c ; w = self.editWidget(event)
    if not w: return

    fn = self.getReadableTextFile()
    if not fn: return

    s,e = g.readFileIntoString(fn)
    if s is None: return

    self.beginCommand(undoType='insert-file')
    i = w.getInsertPoint()
    w.insert(i,s)
    w.seeInsertPoint()
    self.endCommand(changed=True,setLabel=True)
#@-node:ekr.20050920084036.167:insertFile
#@+node:ekr.20050920084036.165:diff (revise)
def diff (self,event):

    '''Creates a node and puts the diff between 2 files into it.'''

    k = self.k
    w = self.editWidget(event)
    if not w: return
    fn = self.getReadableTextFile()
    if not fn: return
    fn2 = self.getReadableTextFile()
    if not fn2: return
    s1,e = g.readFileIntoString(fn)
    if s1 is None: return
    s2,e = g.readFileIntoString(fn2)
    if s2 is None: return

    ### self.switchToBuffer(event,"*diff* of ( %s , %s )" % (name,name2))
    data = difflib.ndiff(s1,s2)
    idata = []
    for z in data:
        idata.append(z)
    w.delete(0,'end')
    w.insert(0,''.join(idata))
#@-node:ekr.20050920084036.165:diff (revise)
#@+node:ekr.20080921154026.1:g.openWrapperLeoFile
def openWrapperLeoFile (old_c,fileName,gui):

    '''Open a wrapper .leo file for the given file,
    and import the file into .leo file.'''

    # This code is similar to c.new, but different enough to be separate.
    if not g.os_path_exists(fileName):
        if not g.unitTesting:
            g.es_print("can not open:",fileName,color="blue")
        return None

    c,frame = g.app.newLeoCommanderAndFrame(
        fileName=None,relativeFileName=None,gui=gui)

    # Needed for plugins.
    if 0: # This causes duplicate common buttons.
        g.doHook("new",old_c=old_c,c=c,new_c=c)

    # Use the config params to set the size and location of the window.
    frame.setInitialWindowGeometry()
    frame.deiconify()
    frame.lift()
    frame.resizePanesToRatio(frame.ratio,frame.secondary_ratio) # Resize the _new_ frame.

    if True: # Just read the file into the node.
        fileName = g.os_path_finalize(fileName)
        s,e = g.readFileIntoString(fileName)
        if s is None: return None
        p = c.rootPosition()
        if p:
            p.setHeadString('@edit %s' % fileName)
            p.setBodyString(s)
            c.selectPosition(p)
    else:  # Import the file into the new outline.
        junk,ext = g.os_path_splitext(fileName)
        p = c.p
        p = c.importCommands.createOutline(fileName,parent=p,atAuto=False,ext=ext)
        c.setCurrentPosition(p)
        c.moveOutlineLeft()
        p = c.p
        c.setCurrentPosition(p.back())
        c.deleteOutline(op_name=None)
        p = c.p
        p.expand()

    # chapterController.finishCreate must be called after the first real redraw
    # because it requires a valid value for c.rootPosition().
    if c.config.getBool('use_chapters') and c.chapterController:
        c.chapterController.finishCreate()

    frame.c.setChanged(True) # Mark the outline dirty.
    return c
#@-node:ekr.20080921154026.1:g.openWrapperLeoFile
#@+node:ekr.20080713091247.1:x.replaceFileWithString & test
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    trace = False and not g.unitTesting
    x = self
    exists = g.os_path_exists(fn)

    if exists:
        # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s2 is None:
            return False
        if s == s2:
            if not g.unitTesting: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            x.error('not written: %s directory not found' % fn)
        return False

    # Replace the file.
    try:
        f = open(fn,'wb')
        f.write(g.toEncodedString(s,encoding='utf-8'))
        if trace: g.trace('fn',fn,
            '\nlines...\n%s' %(g.listToString(g.splitLines(s))),
            '\ncallers',g.callers(4))
        f.close()
        if not g.unitTesting:
            # g.trace('created:',fn,g.callers())
            if exists:  g.es('wrote:',fn)
            else:       g.es('created:',fn)
        return True
    except IOError:
        x.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20090530055015.6862:@test x.replaceFileWithString
if g.unitTesting:

    c,p = g.getTestVars()
    x = c.shadowController

    fn = 'does/not/exist'
    assert not g.os_path_exists(fn)
    assert not x.replaceFileWithString (fn,'abc')
#@-node:ekr.20090530055015.6862:@test x.replaceFileWithString
#@-node:ekr.20080713091247.1:x.replaceFileWithString & test
#@+node:ekr.20031218072017.3481:untangleRoot (calls cleanup)
@ This method untangles the derived files in a vnode known to contain at least one @root directive. The work is done in two passes. The first pass creates the UST by scanning the derived file. The second pass updates the outline using the UST and a TST that is created during the pass.

We assume that all sections from root to end are contained in the derived file, and we attempt to update all such sections. The begin/end params indicate the range of nodes to be scanned when building the TST.
@c

def untangleRoot(self,root,begin,end):

    # g.trace("root,begin,end:",root,begin,end)
    c = self.c
    << Set path & root_name to the file specified in the @root directive >>
    << return if @silent or unknown language >>
    path = c.os_path_finalize_join(self.tangle_directory,path)
    file_buf,e = g.readFileIntoString(path)
    if file_buf is None:
        self.cleanup()
        return
    else:
        file_buf = file_buf.replace('\r','')

    g.es('','@root ' + path)
    # Pass 1: Scan the C file, creating the UST
    self.scan_derived_file(file_buf)
    # g.trace(self.ust_dump())
    if self.errors + g.app.scanErrors == 0:
        << Pass 2: Untangle the outline using the UST and a newly-created TST >>
    self.cleanup()
#@+node:ekr.20031218072017.3483:<< Set path & root_name to the file specified in the @root directive >>
s = root.b
i = 0
while i < len(s):
    code, junk = self.token_type(s,i,report_errors=True)
    if code == at_root:
        # token_type sets root_name unless there is a syntax error.
        if self.root_name: path = self.root_name
        break
    else: i = g.skip_line(s,i)

if not self.root_name:
    # A bad @root command.  token_type has already given an error.
    self.cleanup()
    return
#@-node:ekr.20031218072017.3483:<< Set path & root_name to the file specified in the @root directive >>
#@+node:ekr.20031218072017.3482:<< return if @silent or unknown language >>
if self.language == "unknown":
    g.es("@comment disables untangle for",path, color="blue")
    return

if self.print_mode in ("quiet","silent"):
    g.es('','@%s' % (self.print_mode),"inhibits untangle for",path, color="blue")
    return
#@-node:ekr.20031218072017.3482:<< return if @silent or unknown language >>
#@+node:ekr.20031218072017.3485:<< Pass 2:  Untangle the outline using the UST and a newly-created TST >>
@
This code untangles the root and all its siblings. We don't call tangleTree here
because we must handle all siblings. tanglePass1 handles an entire tree. It also
handles @ignore.
@c

p = begin
while p and p != end: # Don't use iterator.
    self.tanglePass1(p)
    if self.errors + g.app.scanErrors != 0:
        break
    p.moveToNodeAfterTree()

self.ust_warn_about_orphans()
#@-node:ekr.20031218072017.3485:<< Pass 2:  Untangle the outline using the UST and a newly-created TST >>
#@-node:ekr.20031218072017.3481:untangleRoot (calls cleanup)
#@+node:ekr.20031218072017.3220:importFlattenedOutline
def importFlattenedOutline (self,files): # Not a command, so no event arg.

    c = self.c ; u = c.undoer ; current = c.p
    if current == None: return
    if len(files) < 1: return

    self.setEncoding()
    fileName = files[0] # files contains at most one file.
    g.setGlobalOpenDir(fileName)
    s,e = g.readFileIntoString(fileName)
    if s is None: return
    array = s.split("\n")

    # Convert the string to an outline and insert it after the current node.
    undoData = u.beforeInsertNode(current)
    p = self.convertMoreStringsToOutlineAfter(array,current)
    if p:
        c.endEditing()
        c.validateOutline()
        c.redrawAndEdit(p)
        p.setDirty()
        c.setChanged(True)
        u.afterInsertNode(p,'Import',undoData)
    else:
        g.es("not a valid MORE file",fileName)
#@-node:ekr.20031218072017.3220:importFlattenedOutline
#@+node:ekr.20031218072017.3231:scanWebFile (handles limbo)
def scanWebFile (self,fileName,parent):

    theType = self.webType
    lb = g.choose(theType=="cweb","@<","<<")
    rb = g.choose(theType=="cweb","@>",">>")

    s,e = g.readFileIntoString(fileName)
    if s is None: return

    << Create a symbol table of all section names >>
    << Create nodes for limbo text and the root section >>
    while i < len(s):
        outer_progress = i
        << Create a node for the next module >>
        assert(i > outer_progress)
#@+node:ekr.20031218072017.3232:<< Create a symbol table of all section names >>
i = 0 ; self.web_st = []

while i < len(s):
    progress = i
    i = g.skip_ws_and_nl(s,i)
    # line = g.get_line(s,i) ; g.trace(line)
    if self.isDocStart(s,i):
        if theType == "cweb": i += 2
        else: i = g.skip_line(s,i)
    elif theType == "cweb" and g.match(s,i,"@@"):
        i += 2
    elif g.match(s,i,lb):
        i += 2 ; j = i ; k = g.find_on_line(s,j,rb)
        if k > -1: self.cstEnter(s[j:k])
    else: i += 1
    assert (i > progress)

# g.trace(self.cstDump())
#@-node:ekr.20031218072017.3232:<< Create a symbol table of all section names >>
#@+node:ekr.20031218072017.3233:<< Create nodes for limbo text and the root section >>
i = 0
while i < len(s):
    progress = i
    i = g.skip_ws_and_nl(s,i)
    if self.isModuleStart(s,i) or g.match(s,i,lb):
        break
    else: i = g.skip_line(s,i)
    assert(i > progress)

j = g.skip_ws(s,0)
if j < i:
    self.createHeadline(parent,"@ " + s[j:i],"Limbo")

j = i
if g.match(s,i,lb):
    while i < len(s):
        progress = i
        i = g.skip_ws_and_nl(s,i)
        if self.isModuleStart(s,i):
            break
        else: i = g.skip_line(s,i)
        assert(i > progress)
    self.createHeadline(parent,s[j:i],g.angleBrackets(" @ "))

# g.trace(g.get_line(s,i))
#@-node:ekr.20031218072017.3233:<< Create nodes for limbo text and the root section >>
#@+node:ekr.20031218072017.3234:<< Create a node for the next module >>
if theType=="cweb":
    assert(self.isModuleStart(s,i))
    start = i
    if self.isDocStart(s,i):
        i += 2
        while i < len(s):
            progress = i
            i = g.skip_ws_and_nl(s,i)
            if self.isModuleStart(s,i): break
            else: i = g.skip_line(s,i)
            assert (i > progress)
    << Handle cweb @d, @f, @c and @p directives >>
else:
    assert(self.isDocStart(s,i)) # isModuleStart == isDocStart for noweb.
    start = i ; i = g.skip_line(s,i)
    while i < len(s):
        progress = i
        i = g.skip_ws_and_nl(s,i)
        if self.isDocStart(s,i): break
        else: i = g.skip_line(s,i)
        assert (i > progress)

body = s[start:i]
body = self.massageWebBody(body)
headline = self.scanBodyForHeadline(body)
self.createHeadline(parent,body,headline)
#@+node:ekr.20031218072017.3235:<< Handle cweb @d, @f, @c and @p directives >>
if g.match(s,i,"@d") or g.match(s,i,"@f"):
    i += 2 ; i = g.skip_line(s,i)
    # Place all @d and @f directives in the same node.
    while i < len(s):
        progress = i
        i = g.skip_ws_and_nl(s,i)
        if g.match(s,i,"@d") or g.match(s,i,"@f"): i = g.skip_line(s,i)
        else: break
        assert (i > progress)
    i = g.skip_ws_and_nl(s,i)

while i < len(s) and not self.isModuleStart(s,i):
    progress = i
    i = g.skip_line(s,i)
    i = g.skip_ws_and_nl(s,i)
    assert (i > progress)

if g.match(s,i,"@c") or g.match(s,i,"@p"):
    i += 2
    while i < len(s):
        progress = i
        i = g.skip_line(s,i)
        i = g.skip_ws_and_nl(s,i)
        if self.isModuleStart(s,i):
            break
        assert (i > progress)
#@-node:ekr.20031218072017.3235:<< Handle cweb @d, @f, @c and @p directives >>
#@-node:ekr.20031218072017.3234:<< Create a node for the next module >>
#@-node:ekr.20031218072017.3231:scanWebFile (handles limbo)
#@+node:ekr.20070919133659:checkDerivedFile (atFile)
def checkDerivedFile (self, event=None):

    at = self ; c = at.c ; p = c.p

    if not p.isAtFileNode() and not p.isAtThinFileNode():
        return g.es('Please select an @thin or @file node',color='red')

    fn = p.anyAtFileNodeName()
    path = g.os_path_dirname(c.mFileName)
    fn = g.os_path_finalize_join(g.app.loadDir,path,fn)
    if not g.os_path_exists(fn):
        return g.es_print('file not found: %s' % (fn),color='red')

    s,e = g.readFileIntoString(fn)
    if s is None: return

    # Create a dummy, unconnected, vnode as the root.
    root_v = leoNodes.vnode(context=c)
    root = leoNodes.position(root_v)
    theFile = g.fileLikeObject(fromString=s)
    # 2010/01/22: readOpenFiles now determines whether a file is thin or not.
    at.initReadIvars(root,fn)
    if at.errors: return
    at.openFileForReading(fromString=s)
    if not at.inputFile: return
    at.readOpenFile(root,at.inputFile,fn)
    at.inputFile.close()
    if at.errors == 0:
        g.es_print('check-derived-file passed',color='blue')
#@-node:ekr.20070919133659:checkDerivedFile (atFile)
#@+node:ekr.20100122130101.6176:at.readFromCache
def readFromCache (self,fileName,force,root):

    at = self ; c = at.c
    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None: return False,None

    cachefile = self._contentHashFile(root.h,s)

    # 2010/01/22: uncache *any* file provided 'force' is False.
    doCache = g.enableDB and not force
    ok = doCache and cachefile in c.db
    if ok:
        # Delete the previous tree, regardless of the @<file> type.
        while root.hasChildren():
            root.firstChild().doDelete()
        # Recreate the file from the cache.
        aList = c.db[cachefile]
        root.v.createOutlineFromCacheList(c,aList)
        at.inputFile.close()
        root.clearDirty()

    return ok,cachefile
#@-node:ekr.20100122130101.6176:at.readFromCache
#@+node:ekr.20070909100252:readOneAtAutoNode (atFile)
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    s,e = g.readFileIntoString(fileName,raw=True)
    if s is None:
        cachefile = None
    else:
        cachefile = self._contentHashFile(p.h,s)

    # Remember that we have read this file.
    p.v.at_read = True # Create the attribute

    # Disable caching for test.leo.
    if c.shortFileName() != 'test.leo':
        if cachefile is not None and cachefile in c.db:        
            # g.es('uncache:',p.h)
            aList = c.db[cachefile]
            p.v.createOutlineFromCacheList(c,aList)
            return

    if not g.unitTesting:
        g.es("reading:",p.h)

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        # Note: the file contains an @ignore,
        # so no unintended write can happen.
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        self.writeCachedTree(p, cachefile)
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@-node:ekr.20070909100252:readOneAtAutoNode (atFile)
#@+node:ekr.20090225080846.3:readOneAtEditNode (atFile)
def readOneAtEditNode (self,fn,p):

    at = self ; c = at.c ; ic = c.importCommands
    oldChanged = c.isChanged()
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    fn = c.os_path_finalize_join(at.default_directory,fn)
    junk,ext = g.os_path_splitext(fn)

    if not g.unitTesting:
        g.es("reading @edit:", g.shortFileName(fn))

    s,e = g.readFileIntoString(fn,kind='@edit')
    if s is None: return
    encoding = g.choose(e is None,'utf-8',e)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    changed = c.isChanged()
    head = ''
    ext = ext.lower()
    if ext in ('.html','.htm'):   head = '@language html\n'
    elif ext in ('.txt','.text'): head = '@nocolor\n'
    else:
        language = ic.languageForExtension(ext)
        if language and language != 'unknown_language':
            head = '@language %s\n' % language
        else:
            head = '@nocolor\n'

    p.b = g.u(head) + g.toUnicode(s,encoding=encoding,reportErrors='True')

    if not changed: c.setChanged(False)
    g.doHook('after-edit',p=p)
#@-node:ekr.20090225080846.3:readOneAtEditNode (atFile)
#@+node:ekr.20090514111518.5661:checkPythonCode (leoAtFile) & helpers
def checkPythonCode (self,root,s=None,targetFn=None):

    c = self.c

    if not targetFn: targetFn = self.targetFileName

    if targetFn and targetFn.endswith('.py') and self.checkPythonCodeOnWrite:

        if not s:
            s,e = g.readFileIntoString(self.outputFileName)
            if s is None: return

        # It's too slow to check each node separately.
        ok = self.checkPythonSyntax(root,s)

        # Syntax checking catches most indentation problems.
        if False and ok: self.tabNannyNode(root,s)
#@+node:ekr.20090514111518.5663:checkPythonSyntax (leoAtFile)
def checkPythonSyntax (self,p,body):

    try:
        ok = True
        if g.isPython3:
            code.compile_command(body + '\n')
        else:
            compiler.parse(body + '\n')
    except (parser.ParserError,SyntaxError):
        self.syntaxError(p,body)
        ok = False
    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
        ok = False

    return ok
#@+node:ekr.20090514111518.5666:syntaxError & test
def syntaxError(self,p,body):

    g.es_print("Syntax error in: %s" % (p.h),color="red")
    typ,val,tb = sys.exc_info()
    message = hasattr(val,'message') and val.message
    if message: g.es_print(message)
    lines = g.splitLines(body)
    n = val.lineno
    if n is None:
        # for z in dir(val): print z,repr(getattr(val,z))
        return
    i = val.lineno-1
    for j in range(max(0,i-3),min(i+3,len(lines)-1)):
        g.es_print('%5s:%s %s' % (
            j,g.choose(j==i,'*',' '),lines[j].rstrip()))
        if j == i:
            g.es_print(' '*(7+val.offset)+'^')
#@nonl
#@+node:ekr.20090620121836.6073:syntaxErrorTest
def syntaxErrorTest():

    '''Used to test Leo's handling of the following syntax error'''

    # xxx(c=None,'whatever')
#@nonl
#@-node:ekr.20090620121836.6073:syntaxErrorTest
#@-node:ekr.20090514111518.5666:syntaxError & test
#@-node:ekr.20090514111518.5663:checkPythonSyntax (leoAtFile)
#@+node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
def tabNannyNode (self,p,body):

    import parser,tabnanny,tokenize

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))
    except parser.ParserError:
        junk, msg, junk = sys.exc_info()
        g.es("ParserError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        g.es("TokenError in",p.h,color="red")
        g.es('',str(msg))
        # p.setMarked()
    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        badline = nag.get_lineno()
        line    = nag.get_line()
        message = nag.get_msg()
        g.es("indentation error in",p.h,"line",badline,color="red")
        g.es(message)
        line2 = repr(str(line))[1:-1]
        g.es("offending line:\n",line2)
        # p.setMarked()
    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
#@nonl
#@-node:ekr.20090514111518.5665:tabNannyNode (leoAtFile)
#@-node:ekr.20090514111518.5661:checkPythonCode (leoAtFile) & helpers
#@+node:ekr.20080712150045.1:replaceFileWithString (atFile)
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    at = self ; testing = g.app.unitTesting

    # g.trace('fn',fn,'s','\n',s)
    # g.trace(g.callers())

    exists = g.os_path_exists(fn)

    if exists: # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s is None:
            return False
        if s == s2:
            if not testing: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            g.es('not written: %s directory not found' % fn,color='red')
        return False

    # Replace
    try:
        f = open(fn,'wb')
        if g.isPython3:
            s = g.toEncodedString(s,encoding=self.encoding)
        f.write(s)
        f.close()
        if not testing:
            if exists:
                g.es('wrote:    ',fn)
            else:
                # g.trace('created:',fn,g.callers())
                g.es('created:',fn)
        return True
    except IOError:
        at.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20090530055015.6873:@test at.replaceFileWithString
if g.unitTesting:

    c,p = g.getTestVars()
    at = c.atFileCommands

    fn = 'does/not/exist'
    assert not g.os_path_exists(fn)
    assert not at.replaceFileWithString (fn,'abc')
#@-node:ekr.20090530055015.6873:@test at.replaceFileWithString
#@-node:ekr.20080712150045.1:replaceFileWithString (atFile)
#@-node:ekr.20100125073206.8720:Changed...
#@-node:ekr.20100125073206.8711:use g.readFileIntoString
#@+node:ekr.20100125143136.6235:Fixed unicode failures without sys.setdefaultencoding('utf-8')
#@+node:ekr.20031218072017.1498:Unicode utils...
#@+node:ekr.20090517020744.5859: Unicode tests
#@+node:ekr.20090517020744.5860:@test open non-existent non-ascii directory
@first

if g.unitTesting:

    c,p = g.getTestVars()
    # file = u'Ỗ'
    path = g.os_path_join('Ỗ','Ỗ')
    # print(g.toEncodedString(file,'utf-8'))

    ok,frame = g.openWithFileName(path,c)

    assert not ok and not frame
#@-node:ekr.20090517020744.5860:@test open non-existent non-ascii directory
#@+node:ekr.20090517020744.5861:@test can't open message in g.openWithFileName
@first

if g.unitTesting:

    c,p = g.getTestVars()
    old_c = c
    filename = "testᾹ(U+1FB9: Greek Capital Letter Alpha With Macron)"
    ok,frame = g.openWithFileName(filename,old_c)
    assert(not ok)
#@-node:ekr.20090517020744.5861:@test can't open message in g.openWithFileName
#@+node:ekr.20090517020744.5862:@test atFile.printError
@first

if g.unitTesting:

    c,p = g.getTestVars()
    at = c.atFileCommands
    at.errors = 0
    s = 'La Peña'
    at.printError('test of at.printError:',s)
#@-node:ekr.20090517020744.5862:@test atFile.printError
#@+node:ekr.20090517020744.5863:@test % operator with unicode
@first

if g.unitTesting:

    s = "testᾹ(U+1FB9: Greek Capital Letter Alpha With Macron)"

    s2 = 'test: %s' % s
#@-node:ekr.20090517020744.5863:@test % operator with unicode
#@+node:ekr.20090517020744.5864:@test failure to convert unicode characters to ascii
@first

if g.unitTesting:

    if not g.isPython3:
        encoding = 'ascii'
        s = '炰'
        s2,ok = g.toUnicodeWithErrorCode(s,encoding)
        assert not ok, 'toUnicodeWithErrorCode returns True for %s with ascii encoding' % s
#@-node:ekr.20090517020744.5864:@test failure to convert unicode characters to ascii
#@+node:ekr.20090517020744.5865:@test of round-tripping toUnicode & toEncodedString
@first

if g.unitTesting:

    if not g.isPython3:

        for s,encoding in (
            ('a',    'utf-8'),
            ('a',    'ascii'),
            ('äöü',  'utf-8'),
            ('äöü',  'mbcs'),
            ('炰',    'utf-8'),
            ('炰',    'mbcs'),
        ):
            if g.isValidEncoding(encoding):
                s2,ok = g.toUnicodeWithErrorCode(s,encoding)
                assert ok, 'toUnicodeWithErrorCode fails for %s' %s
                s3,ok = g.toEncodedStringWithErrorCode(s2,encoding)
                assert ok, 'toEncodedStringWithErrorCode fails for %s' % s2
                assert s3 == s, 'Round-trip one fails for %s' %s

                s2 = g.toUnicode(s,encoding)
                s3 = g.toEncodedString(s2,encoding)
                assert s3 == s, 'Round-trip two fails for %s' %s
#@-node:ekr.20090517020744.5865:@test of round-tripping toUnicode & toEncodedString
#@+node:ekr.20090517020744.5867:@test round trip toUnicode toEncodedString
@first

if g.unitTesting:

    if not g.isPython3:
        table = [
            ('a',    'utf-8'),
            ('a',    'ascii'),
            ('äöü',  'utf-8'),
            ('äöü',  'mbcs'),
            ('炰',   'utf-8'),
        ]
        import sys
        if sys.platform.startswith('win'):
            data = '炰','mbcs'
            table.append(data)

        for s,encoding in table:
            if g.isValidEncoding(encoding):
                s2,ok = g.toUnicodeWithErrorCode(s,encoding)
                assert ok, 'toUnicodeWithErrorCode fails for %s' %s
                s3,ok = g.toEncodedStringWithErrorCode(s2,encoding)
                assert ok, 'toEncodedStringWithErrorCode fails for %s' % s2
                assert s3 == s, 'Round-trip one failed for %s' %s

                s2 = g.toUnicode(s,encoding)
                s3 = g.toEncodedString(s2,encoding)
                assert s3 == s, 'Round-trip two failed for %s' %s
#@-node:ekr.20090517020744.5867:@test round trip toUnicode toEncodedString
#@-node:ekr.20090517020744.5859: Unicode tests
#@+node:ekr.20100125073206.8709:g.getPythonEncodingFromString
def getPythonEncodingFromString(s):

    '''Return the encoding given by Python's encoding line.
    s is the entire file.
    '''

    encoding = None
    tag,tag2 = '# -*- coding:','-*-'
    n1,n2 = len(tag),len(tag2)

    if s:
        # For Python 3.x we must convert to unicode before calling startswith.
        # The encoding doesn't matter: we only look at the first line, and if
        # the first line is an encoding line, it will contain only ascii characters.
        s = g.toUnicode(s,encoding='ascii',reportErrors=False)
        lines = g.splitLines(s)
        line1 = lines[0].strip()
        if line1.startswith(tag) and line1.endswith(tag2):
            e = line1[n1:-n2].strip()
            if e and g.isValidEncoding(e):
                encoding = e

    return encoding
#@-node:ekr.20100125073206.8709:g.getPythonEncodingFromString
#@+node:ekr.20080816125725.2:g.isBytes, isChar, isString & isUnicode
# The syntax of these functions must be valid on Python2K and Python3K.

def isBytes(s):
    '''Return True if s is Python3k bytes type.'''
    if g.isPython3:
        # Generates a pylint warning, but that can't be helped.
        return type(s) == type(bytes('a','utf-8'))
    else:
        return False

def isChar(s):
    '''Return True if s is a Python2K character type.'''
    if g.isPython3:
        return False
    else:
        return type(s) == types.StringType

def isString(s):
    '''Return True if s is any string, but not bytes.'''
    if g.isPython3:
        return type(s) == type('a')
    else:
        return type(s) in types.StringTypes

def isUnicode(s):
    '''Return True if s is a unicode string.'''
    if g.isPython3:
        return type(s) == type('a')
    else:
        return type(s) == types.UnicodeType
#@-node:ekr.20080816125725.2:g.isBytes, isChar, isString & isUnicode
#@+node:ekr.20031218072017.1500:g.isValidEncoding
def isValidEncoding (encoding):

    if not encoding:
        return False

    if sys.platform == 'cli':
        return True

    import codecs

    try:
        codecs.lookup(encoding)
        return True
    except LookupError: # Windows.
        return False
    except AttributeError: # Linux.
        return False
#@nonl
#@-node:ekr.20031218072017.1500:g.isValidEncoding
#@+node:ekr.20061006152327:g.isWordChar & g.isWordChar1
def isWordChar (ch):

    '''Return True if ch should be considered a letter.'''

    return ch and (ch.isalnum() or ch == '_')

def isWordChar1 (ch):

    return ch and (ch.isalpha() or ch == '_')
#@nonl
#@-node:ekr.20061006152327:g.isWordChar & g.isWordChar1
#@+node:ekr.20031218072017.1501:g.reportBadChars & test
def reportBadChars (s,encoding):

    if g.isPython3:
        errors = 0
        if g.isUnicode(s):
            for ch in s:
                try: ch.encode(encoding,"strict")
                except UnicodeEncodeError:
                    errors += 1
            if errors:
                s2 = "%d errors converting %s to %s" % (
                    errors, s.encode(encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
        elif g.isChar(s):
            for ch in s:
                try: unicode(ch,encoding,"strict")
                except Exception: errors += 1
            if errors:
                s2 = "%d errors converting %s (%s encoding) to unicode" % (
                    errors, unicode(s,encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
    else:
        errors = 0
        if g.isUnicode(s):
            for ch in s:
                try: ch.encode(encoding,"strict")
                except UnicodeEncodeError:
                    errors += 1
            if errors:
                s2 = "%d errors converting %s to %s" % (
                    errors, s.encode(encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
        elif g.isChar(s):
            for ch in s:
                try: unicode(ch,encoding,"strict")
                except Exception: errors += 1
            if errors:
                s2 = "%d errors converting %s (%s encoding) to unicode" % (
                    errors, unicode(s,encoding,'replace'),
                    encoding.encode('ascii','replace'))
                if not g.unitTesting:
                    g.es(s2,color='red')
#@+node:ekr.20090517020744.5882:@test g.reportBadChars
@first

if g.unitTesting:

    for s,encoding in (
        ('aĂbĂ',  'ascii'),
        #(u'aĂbĂ', 'ascii'),
        ('炰',    'ascii'),
        #(u'炰',   'ascii'),

        ('aĂbĂ',  'utf-8'),
        #(u'aĂbĂ', 'utf-8'),
        ('炰',    'utf-8'),
        #(u'炰',   'utf-8'),
    ):

        g.reportBadChars(s,encoding)
#@-node:ekr.20090517020744.5882:@test g.reportBadChars
#@-node:ekr.20031218072017.1501:g.reportBadChars & test
#@+node:ekr.20050208093800:g.toEncodedString
def toEncodedString (s,encoding,reportErrors=False):

    if g.isUnicode(s):
        try:
            s = s.encode(encoding,"strict")
        except UnicodeError:
            if reportErrors: g.reportBadChars(s,encoding)
            s = s.encode(encoding,"replace")
    return s
#@-node:ekr.20050208093800:g.toEncodedString
#@+node:ekr.20050208093800.1:g.toUnicode
def toUnicode (s,encoding=None,reportErrors=False):

    # The encoding is usually g.app.defaultEncoding,
    # but is may be different while importing or reading files.
    if encoding is None:
        encoding = g.app.defaultEncoding

    if isPython3:
        f,mustConvert = str,g.isBytes
    else:
        f = unicode
        def mustConvert (s):
            return type(s) != types.UnicodeType

    if not s:
        s = g.u('')
    elif mustConvert(s):
        try:
            s = f(s,encoding,'strict')
        except (UnicodeError,Exception):
            s = f(s,encoding,'replace')
            if reportErrors: g.reportBadChars(s,encoding)
    else:
        pass

    return s
#@-node:ekr.20050208093800.1:g.toUnicode
#@+node:ekr.20091206161352.6232:g.u & g.ue
if isPython3: # g.not defined yet.
    def u(s):
        return s
    def ue(s,encoding):
        return str(s,encoding)
else:
    def u(s):
        return unicode(s)
    def ue(s,encoding):
        return unicode(s,encoding)
#@-node:ekr.20091206161352.6232:g.u & g.ue
#@+node:ekr.20080919065433.2:toEncodedStringWithErrorCode (for unit testing)
def toEncodedStringWithErrorCode (s,encoding,reportErrors=False):

    ok = True

    if g.isUnicode(s):
        try:
            s = s.encode(encoding,"strict")
        except Exception:
            if reportErrors: g.reportBadChars(s,encoding)
            s = s.encode(encoding,"replace")
            ok = False
    return s, ok
#@-node:ekr.20080919065433.2:toEncodedStringWithErrorCode (for unit testing)
#@+node:ekr.20080919065433.1:toUnicodeWithErrorCode (for unit testing)
def toUnicodeWithErrorCode (s,encoding,reportErrors=False):

    ok = True
    if g.isPython3: f = str
    else: f = unicode
    if s is None:
        s = g.u('')
    if not g.isUnicode(s):
        try:
            s = f(s,encoding,'strict')
        except Exception:
            if reportErrors:
                g.reportBadChars(s,encoding)
            s = f(s,encoding,'replace')
            ok = False
    return s,ok
#@-node:ekr.20080919065433.1:toUnicodeWithErrorCode (for unit testing)
#@-node:ekr.20031218072017.1498:Unicode utils...
#@+node:ville.20090606150238.6351:_contentHashFile (atFile)
def _contentHashFile(self,s,content):

    '''Compute the hash of s (usually a headline) and content.
    s may be unicode, content must be bytes (or plain string in Python 2.x'''

    m = hashlib.md5()

    if g.isUnicode(s):
        s = g.toEncodedString(s,encoding='utf-8')

    if g.isUnicode(content):
        g.internalError('content arg must be str/bytes')
        content = g.toEncodedString(content,encoding='utf-8')

    m.update(s)
    m.update(content)
    return "fcache/" + m.hexdigest()

#@-node:ville.20090606150238.6351:_contentHashFile (atFile)
#@-node:ekr.20100125143136.6235:Fixed unicode failures without sys.setdefaultencoding('utf-8')
#@+node:ekr.20100125190708.6259:Fixed Leo3k problem with g.getPythonEncodingFromString
- g.getPythonEncodingFromString fails with Python 3.x on both Windows and ubuntu.
#@nonl
#@+node:ekr.20100125073206.8709:g.getPythonEncodingFromString
def getPythonEncodingFromString(s):

    '''Return the encoding given by Python's encoding line.
    s is the entire file.
    '''

    encoding = None
    tag,tag2 = '# -*- coding:','-*-'
    n1,n2 = len(tag),len(tag2)

    if s:
        # For Python 3.x we must convert to unicode before calling startswith.
        # The encoding doesn't matter: we only look at the first line, and if
        # the first line is an encoding line, it will contain only ascii characters.
        s = g.toUnicode(s,encoding='ascii',reportErrors=False)
        lines = g.splitLines(s)
        line1 = lines[0].strip()
        if line1.startswith(tag) and line1.endswith(tag2):
            e = line1[n1:-n2].strip()
            if e and g.isValidEncoding(e):
                encoding = e

    return encoding
#@-node:ekr.20100125073206.8709:g.getPythonEncodingFromString
#@-node:ekr.20100125190708.6259:Fixed Leo3k problem with g.getPythonEncodingFromString
#@+node:ekr.20100126062623.6237:Ensure the contents arg to _contentHashFile is bytes
#@+node:ekr.20100126062623.6240:g.internalError
def internalError (*args):

    callers = g.callers(5).split(',')
    caller = callers[-1]
    g.es_print('Internal Leo error in',caller,color='red')
    g.es_print(*args)
    g.es_print('Called from',','.join(callers[:-1]))
#@-node:ekr.20100126062623.6240:g.internalError
#@+node:ville.20090606150238.6351:_contentHashFile (atFile)
def _contentHashFile(self,s,content):

    '''Compute the hash of s (usually a headline) and content.
    s may be unicode, content must be bytes (or plain string in Python 2.x'''

    m = hashlib.md5()

    if g.isUnicode(s):
        s = g.toEncodedString(s,encoding='utf-8')

    if g.isUnicode(content):
        g.internalError('content arg must be str/bytes')
        content = g.toEncodedString(content,encoding='utf-8')

    m.update(s)
    m.update(content)
    return "fcache/" + m.hexdigest()

#@-node:ville.20090606150238.6351:_contentHashFile (atFile)
#@-node:ekr.20100126062623.6237:Ensure the contents arg to _contentHashFile is bytes
#@+node:ekr.20100126110826.6254:Removed unit test message
Check your configuration of script_file_path.
#@nonl
#@+node:ekr.20070115135502:writeScriptFile
def writeScriptFile (self,script):

    # Get the path to the file.
    c = self
    path = c.config.getString('script_file_path')
    if path:
        isAbsPath = os.path.isabs(path)
        driveSpec, path = os.path.splitdrive(path)
        parts = path.split('/')
        # xxx bad idea, loadDir is often read only!
        path = g.app.loadDir
        if isAbsPath:
            # make the first element absolute
            parts[0] = driveSpec + os.sep + parts[0]
        allParts = [path] + parts
        path = c.os_path_finalize_join(*allParts)
    else:
        path = c.os_path_finalize_join(
            g.app.homeLeoDir,'scriptFile.py')                    

    # Write the file.
    try:
        if g.isPython3:
            # Use the default encoding.
            # script = g.toUnicode(script,'utf-8'reportErrors=False)
            f = open(path,encoding='utf-8',mode='w')
        else:
            f = open(path,'w')
        f.write(script)
        f.close()
    except Exception:
        g.es_exception()
        g.es("Failed to write script to %s" % path)
        # g.es("Check your configuration of script_file_path, currently %s" %
            # c.config.getString('script_file_path'))
        path = None

    return path
#@nonl
#@-node:ekr.20070115135502:writeScriptFile
#@-node:ekr.20100126110826.6254:Removed unit test message
#@+node:ekr.20100124142131.6222:Preserve expansion state of present node on startup
@nocolor-node

After much tracing, we see the bug was in selectChapterByNameHelper.
We must compare the vnodes, not the positions!
#@nonl
#@+node:ekr.20090306060344.2:selectChapterHelper
def selectChapterByNameHelper (self,chapter,collapse=True):

    cc = self ; c = cc.c

    if chapter != cc.selectedChapter:
        if cc.selectedChapter:
            cc.selectedChapter.unselect()
        chapter.select()
        c.setCurrentPosition(chapter.p)
        cc.selectedChapter = chapter

        # New in Leo 4.6 b2: clean up, but not initially.
        if collapse and chapter.name == 'main':
            for p in c.all_unique_positions():
                # 2010/01/26: compare vnodes, not positions.
                if p.v != c.p.v:
                    p.contract()

        # New in Leo 4.6 b2: *do* call c.redraw.
        c.redraw()
#@-node:ekr.20090306060344.2:selectChapterHelper
#@-node:ekr.20100124142131.6222:Preserve expansion state of present node on startup
#@+node:ekr.20100122104234.6167:cache current position
@nocolor-node

We write the archived position to the cache instead of root.v.uA.

This reduces false bzr diffs.
#@nonl
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20060919110638.13:setPositionsFromVnodes & helper
def setPositionsFromVnodes (self):

    trace = False and not g.unitTesting
    c = self.c ; p = c.rootPosition()
    current,str_pos = None,None
    use_db = g.enableDB and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        str_pos = c.db.get('current_position_%s' % key)
        if trace: g.trace('from c.db',str_pos,key)

    if not str_pos:
        d = hasattr(p.v,'unknownAttributes') and p.v.unknownAttributes
        if d: str_pos = d.get('str_leo_pos')
        if trace: g.trace('from p.v.u',str_pos)

    if str_pos:
        current = self.archivedPositionToPosition(str_pos)

    c.setCurrentPosition(current or c.rootPosition())
#@+node:ekr.20061006104837.1:archivedPositionToPosition
def archivedPositionToPosition (self,s):

    c = self.c
    aList = s.split(',')
    try:
        aList = [int(z) for z in aList]
    except Exception:
        # g.trace('oops: bad archived position. not an int:',aList,c)
        aList = None
    if not aList: return None
    p = c.rootPosition() ; level = 0
    while level < len(aList):
        i = aList[level]
        while i > 0:
            if p.hasNext():
                p.moveToNext()
                i -= 1
            else:
                # g.trace('oops: bad archived position. no sibling:',aList,p.h,c)
                return None
        level += 1
        if level < len(aList):
            p.moveToFirstChild()
            # g.trace('level',level,'index',aList[level],p.h)
    return p
#@nonl
#@-node:ekr.20061006104837.1:archivedPositionToPosition
#@-node:ekr.20060919110638.13:setPositionsFromVnodes & helper
#@-node:ekr.20100122104234.6167:cache current position
#@+node:ekr.20100126215837.15931:Suppress path changed message in save-as and save-to
#@+node:ekr.20031218072017.2813:<< initialize ivars >> (commands)
self._currentPosition = self.nullPosition()
self._rootPosition    = self.nullPosition()
self._topPosition     = self.nullPosition()

# Delayed focus.
self.doubleClickFlag = False
self.hasFocusWidget = None
self.requestedFocusWidget = None

# Official ivars.
self.gui = g.app.gui
self.ipythonController = None # Set only by the ipython plugin.

# Interlock to prevent setting c.changed when switching chapters.
c.suppressHeadChanged = False

# Interlocks to prevent premature closing of a window.
self.inCommand = False
self.requestCloseWindow = False

# For emacs/vim key handling.
self.commandsDict = None
self.keyHandler = self.k = None
self.miniBufferWidget = None

# per-document info...
self.disableCommandsMessage = ''
    # The presence of this message disables all commands.
self.hookFunction = None
self.openDirectory = None
self.timeStampDict = {} # New in Leo 4.6.

self.expansionLevel = 0  # The expansion level of this outline.
self.expansionNode = None # The last node we expanded or contracted.
self.changed = False # True if any data has been changed since the last save.
self.loading = False # True if we are loading a file: disables c.setChanged()
self.outlineToNowebDefaultFileName = "noweb.nw" # For Outline To Noweb dialog.
self.promptingForClose = False # To lock out additional closing dialogs.
self.ignoreChangedPaths = False # True: disable path changed message in at.WriteAllHelper.

# For tangle/untangle
self.tangle_errors = 0

# Global options
self.fixed = False
self.page_width = 132
self.tab_width = -4
self.tangle_batch_flag = False
self.untangle_batch_flag = False

# Default Tangle options
self.use_header_flag = False
self.output_doc_flag = False

# Default Target Language
self.target_language = "python" # Required if leoConfig.txt does not exist.

# For hoist/dehoist commands.
self.hoistStack = []
    # Stack of nodes to be root of drawn tree.
    # Affects drawing routines and find commands.
self.recentFiles = [] # List of recent files

# For outline navigation.
self.navPrefix = g.u('') # Must always be a string.
self.navTime = None

pth, bname = os.path.split(self.mFileName)
if pth and bname and g.enableDB:
    fn = self.mFileName.lower()
    fn = g.toEncodedString(fn,'utf-8') # Required for Python 3.x.
    dbdirname = '%s/db/%s_%s' % (
        g.app.homeLeoDir,bname,hashlib.md5(fn).hexdigest())
    # Use compressed pickles (handy for @thin caches)
    self.db = leo.external.pickleshare.PickleShareDB(dbdirname,protocol='picklez')
else:
    self.db = {}
#@nonl
#@-node:ekr.20031218072017.2813:<< initialize ivars >> (commands)
#@+node:ekr.20031218072017.3043:saveAs (leoFileCommands)
def saveAs(self,fileName):

    c = self.c ; v = c.currentVnode()

    if not g.doHook("save1",c=c,p=v,v=v,fileName=fileName):
        c.endEditing() # Set the current headline text.
        self.setDefaultDirectoryForNewFiles(fileName)
        # Disable path-changed messages in writeAllHelper.
        c.ignoreChangedPaths = True
        try:
            if self.write_Leo_file(fileName,outlineOnlyFlag=False):
                c.setChanged(False) # Clears all dirty bits.
                self.putSavedMessage(fileName)
        finally:
            c.ignoreChangedPaths = True

        c.redraw_after_icons_changed()

    g.doHook("save2",c=c,p=v,v=v,fileName=fileName)
#@-node:ekr.20031218072017.3043:saveAs (leoFileCommands)
#@+node:ekr.20031218072017.3044:saveTo (leoFileCommands)
def saveTo (self,fileName):

    c = self.c ; v = c.currentVnode()

    if not g.doHook("save1",c=c,p=v,v=v,fileName=fileName):
        c.endEditing()# Set the current headline text.
        self.setDefaultDirectoryForNewFiles(fileName)
        # Disable path-changed messages in writeAllHelper.
        c.ignoreChangedPaths = True
        try:
            self.write_Leo_file(fileName,outlineOnlyFlag=False)
        finally:
            c.ignoreChangedPaths = False
        self.putSavedMessage(fileName)

        c.redraw_after_icons_changed()

    g.doHook("save2",c=c,p=v,v=v,fileName=fileName)
#@-node:ekr.20031218072017.3044:saveTo (leoFileCommands)
#@+node:ekr.20041005105605.149:writeAllHelper (atFile)
def writeAllHelper (self,p,
    force,toString,writeAtFileNodesFlag,writtenFiles
):

    trace = False and not g.unitTesting
    at = self ; c = at.c

    if p.isAtIgnoreNode() and not p.isAtAsisFileNode():
        pathChanged = False
    else:
        oldPath = at.getPathUa(p).lower()
        newPath = at.fullPath(p).lower()
        pathChanged = oldPath and oldPath != newPath
        # 2010/01/27: suppress this message during save-as and save-to commands.
        if pathChanged and not c.ignoreChangedPaths:
            at.setPathUa(p,newPath) # Remember that we have changed paths.
            g.es_print('path changed for',p.h,color='blue')
            if trace: g.trace('p %s\noldPath %s\nnewPath %s' % (
                p.h,repr(oldPath),repr(newPath)))

    if p.v.isDirty() or pathChanged or writeAtFileNodesFlag or p.v in writtenFiles:

        # Tricky: @ignore not recognised in @asis nodes.
        if p.isAtAsisFileNode():
            at.asisWrite(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtIgnoreNode():
            pass
        elif p.isAtAutoNode():
            at.writeOneAtAutoNode(p,toString=toString,force=force)
            writtenFiles.append(p.v)
        elif p.isAtEditNode():
            at.writeOneAtEditNode(p,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtNoSentFileNode():
            at.write(p,kind='@nosent',nosentinels=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtShadowFileNode():
            at.writeOneAtShadowNode(p,toString=toString,force=force or pathChanged)
            writtenFiles.append(p.v)
        elif p.isAtThinFileNode():
            at.write(p,kind='@thin',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
        elif p.isAtFileNode():
            # Write old @file nodes using @thin format.
            at.write(p,kind='@file',thinFile=True,toString=toString)
            writtenFiles.append(p.v)
#@-node:ekr.20041005105605.149:writeAllHelper (atFile)
#@-node:ekr.20100126215837.15931:Suppress path changed message in save-as and save-to
#@+node:ekr.20100127045907.6221:Fixed 3.x crash when replacing files
@nocolor-node

exception writing: C:\Users\edreamleo\Desktop\thin-unicode-test.txt
Traceback (most recent call last):
  File "c:\leo.repo\trunk\leo\core\leoAtFile.py", line 2424, in write
    at.replaceTargetFileIfDifferent(root)
  File "c:\leo.repo\trunk\leo\core\leoAtFile.py", line 4541, in replaceTargetFileIfDifferent
    ignoreBlankLines=ignoreBlankLines):
  File "c:\leo.repo\trunk\leo\core\leoAtFile.py", line 4035, in compareFiles
    s1,s2 = f1.read(), f2.read()
  File "c:\python31\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 326: character maps to <undefined>
exception removing: C:\Users\edreamleo\Desktop\thin-unicode-test.txt.tmp
#@+node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
def readFileIntoString (fn,encoding='utf-8',kind=None,mode='rb',raw=False):

    '''Return the contents of the file whose full path is fn.

    Return (s,e)
    s is the string, converted to unicode, or None if there was an error.
    e the encoding line for Python files: it is usually None.
    '''

    try:
        e = None
        f = open(fn,mode)
        s = f.read()
        f.close()
        if raw:
            return s,None
        else:
            # Python's encoding comments override everything else.
            if s:
                junk,ext = g.os_path_splitext(fn)
                if ext == '.py':
                    e = g.getPythonEncodingFromString(s)
            s = g.toUnicode(s,encoding=e or encoding)
            return s,e
    except IOError:
        # Translate 'can not open' and kind, but not fn.
        if kind:
            g.es('can not open','',kind,fn,color='red')
        else:
            g.es('can not open',fn,color='red')
    except Exception:
        g.trace('unexpected exception reading %s' % (fn),color='red')
        g.es_exception()

    import leo.core.leoTest as leoTest
    leoTest.fail()
    return None,None
#@-node:ekr.20100125073206.8710:g.readFileIntoString (Leo 4.7)
#@+node:ekr.20041005105605.197:compareFiles
def compareFiles (self,path1,path2,ignoreLineEndings,ignoreBlankLines=False):

    """Compare two text files."""
    at = self

    # We can't use 'U' mode because of encoding issues (Python 2.x only).
    s1,e = g.readFileIntoString(path1,mode='rb',raw=True)
    if s1 is None: return False # Should never happen.
    s2,e = g.readFileIntoString(path2,mode='rb',raw=True)
    if s2 is None: return False # Should never happen.
    equal = s1 == s2
    if ignoreBlankLines and not equal:
        s1 = g.removeBlankLines(s1)
        s2 = g.removeBlankLines(s2)
        equal = s1 == s2
    if ignoreLineEndings and not equal:
        s1 = g.toUnicode(s1,encoding=at.encoding)
        s2 = g.toUnicode(s2,encoding=at.encoding)
        s1 = s1.replace('\n','').replace('\r','')
        s2 = s2.replace('\n','').replace('\r','')
        equal = s1 == s2
    # g.trace('equal',equal,'ignoreLineEndings',ignoreLineEndings,'encoding',at.encoding)
    return equal
#@nonl
#@-node:ekr.20041005105605.197:compareFiles
#@-node:ekr.20100127045907.6221:Fixed 3.x crash when replacing files
#@+node:ekr.20100127074338.6249:Fixed Tangle problem with latext files
tangle.scanAllDirectives now properly updates the delim ivars.
#@nonl
#@+node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
def scanAtWrapDirectives(aList,issue_error_flag=False):

    '''Scan aList for @wrap and @nowrap directives.'''

    for d in aList:
        if d.get('wrap') is not None:
            return True
        elif d.get('nowrap') is not None:
            return False

    return None

def scanAllAtWrapDirectives(c,p):

    '''Scan p and all ancestors looking for @wrap/@nowrap directives.'''

    if c and p:
        default = c and c.config.getBool("body_pane_wraps")
        aList = g.get_directives_dict_list(p)

        val = g.scanAtWrapDirectives(aList)
        ret = g.choose(val is None,default,val)
    else:
        ret = None
    # g.trace(ret,p.h)
    return ret
#@-node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
#@+node:ekr.20080923124254.16:tangle.scanAllDirectives
def scanAllDirectives(self,p):

    """Scan vnode p and p's ancestors looking for directives,
    setting corresponding tangle ivars and globals.
    """

    c = self.c
    self.init_directive_ivars()
    if p:
        s = p.b
        << Collect @first attributes >>

    # delims = (self.single_comment_string,self.start_comment_string,self.end_comment_string)
    lang_dict = {'language':self.language,'delims':None,} # Delims not used

    table = (
        ('encoding',    self.encoding,  g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives), 
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process.
    lang_dict       = d.get('lang-dict')
    lineending      = d.get('lineending')
    if lineending:
        self.output_newline = lineending
    self.encoding             = d.get('encoding')
    self.language             = lang_dict.get('language')
    self.page_width           = d.get('pagewidth')
    self.tangle_directory     = d.get('path')
    self.tab_width            = d.get('tabwidth')

    # Handle the print-mode directives.
    self.print_mode = None
    for d in aList:
        for key in ('verbose','terse','quiet','silent'):
            if d.get(key) is not None:
                self.print_mode = key ; break
        if self.print_mode: break
    if not self.print_mode: self.print_mode = 'verbose'

    # 2010/01/27: bug fix: make sure to set the ivars.
    delim1,delim2,delim3 = g.set_delims_from_language(self.language)
    self.single_comment_string = delim1
    self.start_comment_string = delim2
    self.end_comment_string = delim3

    # g.trace(self.tangle_directory)

    # For unit testing.
    return {
        "encoding"  : self.encoding,
        "language"  : self.language,
        "lineending": self.output_newline,
        "pagewidth" : self.page_width,
        "path"      : self.tangle_directory,
        "tabwidth"  : self.tab_width,
    }
#@+node:ekr.20080923124254.17:<< Collect @first attributes >>
@ Stephen P. Schaefer 9/13/2002: Add support for @first.
Unlike other root attributes, does *NOT* inherit from parent nodes.
@c
tag = "@first"
sizeString = len(s) # DTHEIN 13-OCT-2002: use to detect end-of-string
i = 0
while 1:
    # DTHEIN 13-OCT-2002: directives must start at beginning of a line
    if not g.match_word(s,i,tag):
        i = g.skip_line(s,i)
    else:
        i = i + len(tag)
        j = i = g.skip_ws(s,i)
        i = g.skip_to_end_of_line(s,i)
        if i>j:
            self.first_lines += s[j:i] + '\n'
        i = g.skip_nl(s,i)
    if i >= sizeString:  # DTHEIN 13-OCT-2002: get out when end of string reached
        break
#@-node:ekr.20080923124254.17:<< Collect @first attributes >>
#@-node:ekr.20080923124254.16:tangle.scanAllDirectives
#@-node:ekr.20100127074338.6249:Fixed Tangle problem with latext files
#@+node:ekr.20100127113901.6244:created g.scanAllAtTabWidthDirectives
#@+node:ekr.20080827175609.39:c.scanAllDirectives
def scanAllDirectives(self,p=None):

    '''Scan p and ancestors for directives.

    Returns a dict containing the results, including defaults.'''

    c = self ; p = p or c.p

    # Set defaults
    language = c.target_language and c.target_language.lower()
    lang_dict = {
        'language':language,
        'delims':g.set_delims_from_language(language),
    }
    wrap = c.config.getBool("body_pane_wraps")

    table = (
        ('encoding',    None,           g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
        ('wrap',        wrap,           g.scanAtWrapDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process: do *not* set commander ivars.
    lang_dict = d.get('lang-dict')

    return {
        "delims"        : lang_dict.get('delims'),
        "encoding"      : d.get('encoding'),
        "language"      : lang_dict.get('language'),
        "lineending"    : d.get('lineending'),
        "pagewidth"     : d.get('pagewidth'),
        "path"          : d.get('path') or g.getBaseDirectory(c),
        "tabwidth"      : d.get('tabwidth'),
        "pluginsList"   : [], # No longer used.
        "wrap"          : d.get('wrap'),
    }
#@nonl
#@-node:ekr.20080827175609.39:c.scanAllDirectives
#@+node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
def scanAtWrapDirectives(aList,issue_error_flag=False):

    '''Scan aList for @wrap and @nowrap directives.'''

    for d in aList:
        if d.get('wrap') is not None:
            return True
        elif d.get('nowrap') is not None:
            return False

    return None

def scanAllAtWrapDirectives(c,p):

    '''Scan p and all ancestors looking for @wrap/@nowrap directives.'''

    if c and p:
        default = c and c.config.getBool("body_pane_wraps")
        aList = g.get_directives_dict_list(p)

        val = g.scanAtWrapDirectives(aList)
        ret = g.choose(val is None,default,val)
    else:
        ret = None
    # g.trace(ret,p.h)
    return ret
#@-node:ekr.20080831084419.4:g.scanAtWrapDirectives & scanAllAtWrapDirectives
#@+node:ekr.20080827175609.37:g.scanAtTabwidthDirectives & scanAllTabWidthDirectives
def scanAtTabwidthDirectives(aList,issue_error_flag=False):

    '''Scan aList for @tabwidth directives.'''

    for d in aList:
        s = d.get('tabwidth')
        if s is not None:
            junk,val = g.skip_long(s,0)
            if val not in (None,0):
                return val
            else:
                if issue_error_flag and not g.app.unitTesting:
                    g.es("ignoring @tabwidth",s,color="red")
    return None

def scanAllAtTabWidthDirectives(c,p):

    '''Scan p and all ancestors looking for @tabwidth directives.'''

    if c and p:
        aList = g.get_directives_dict_list(p)
        val = g.scanAtTabwidthDirectives(aList)
        ret = g.choose(val is None,c.tab_width,val)
    else:
        ret = None
    # g.trace(ret,p and p.h,ret)
    return ret
#@-node:ekr.20080827175609.37:g.scanAtTabwidthDirectives & scanAllTabWidthDirectives
#@+node:ekr.20041126042730:getTabWidth
def getTabWidth (self,p=None):

    c = self.c
    if 1:
        # Faster, more self-contained.
        val = g.scanAllAtTabWidthDirectives(c,p)
        return val
    else:
        d = c.scanAllDirectives(p)
        w = d.get("tabwidth")
        if w not in (0,None):
            return w
        else:
            return self.c.tab_width
#@-node:ekr.20041126042730:getTabWidth
#@-node:ekr.20100127113901.6244:created g.scanAllAtTabWidthDirectives
#@+node:ekr.20100124142131.6223:Fixed Terry's unicode problem
@nocolor-node

Deleting a range of line containing unicode characters deletes too much.

Happens on both @edit and @thin files.
#@+node:ekr.20051125080855:selfInsertCommand, helpers
def selfInsertCommand(self,event,action='insert'):

    '''Insert a character in the body pane.
    This is the default binding for all keys in the body pane.'''

    trace = False and not g.unitTesting # or c.config.getBool('trace_masterCommand')
    verbose = True
    w = self.editWidget(event)
    if not w: return 'break'
    << set local vars >>
    if trace: g.trace('ch',repr(ch),'keysym',repr(keysym)) # ,'stroke',repr(stroke))
    if g.doHook("bodykey1",c=c,p=p,v=p,ch=ch,oldSel=oldSel,undoType=undoType):
        return "break" # The hook claims to have handled the event.
    if ch == '\t':
        self.updateTab(p,w)
    elif ch == '\b':
        # This is correct: we only come here if there no bindngs for this key. 
        self.backwardDeleteCharacter(event)
    elif ch in ('\r','\n'):
        ch = '\n'
        self.insertNewlineHelper(w,oldSel,undoType)
    elif inBrackets and self.autocompleteBrackets:
        self.updateAutomatchBracket(p,w,ch,oldSel)
    elif ch: # Null chars must not delete the selection.
        i,j = oldSel
        if i > j: i,j = j,i
        # Use raw insert/delete to retain the coloring.
        if i != j:                  w.delete(i,j)
        elif action == 'overwrite': w.delete(i)
        w.insert(i,ch)
        w.setInsertPoint(i+1)
        if inBrackets and self.flashMatchingBrackets:
            self.flashMatchingBracketsHelper(w,i,ch)               
    else:
        return 'break' # This method *always* returns 'break'

    # Set the column for up and down keys.
    spot = w.getInsertPoint()
    c.editCommands.setMoveCol(w,spot)

    # Update the text and handle undo.
    newText = w.getAllText()
    changed = newText != oldText
    if trace and verbose:
        g.trace('ch',repr(ch),'changed',changed,'newText',repr(newText[-10:]))
    if changed:
        # g.trace('ins',w.getInsertPoint())
        c.frame.body.onBodyChanged(undoType=undoType,
            oldSel=oldSel,oldText=oldText,oldYview=None)

    g.doHook("bodykey2",c=c,p=p,v=p,ch=ch,oldSel=oldSel,undoType=undoType)
    return 'break'
#@+node:ekr.20061103114242:<< set local vars >>
c = self.c
p = c.p
gui = g.app.gui
ch = gui.eventChar(event)
keysym = gui.eventKeysym(event)
# stroke = gui.eventStroke(event)
if keysym == 'Return':
    ch = '\n' # This fixes the MacOS return bug.
if keysym == 'Tab': # Support for wx_alt_gui plugin.
    ch = '\t'
name = c.widget_name(w)
oldSel =  name.startswith('body') and w.getSelectionRange() or (None,None)
oldText = name.startswith('body') and p.b or ''
undoType = 'Typing'
brackets = self.openBracketsList + self.closeBracketsList
inBrackets = ch and g.toUnicode(ch) in brackets
# if trace: g.trace(name,repr(ch),ch and ch in brackets)
#@nonl
#@-node:ekr.20061103114242:<< set local vars >>
#@+node:ekr.20090213065933.14:doPlainTab
def doPlainTab(self,s,i,tab_width,w):

    '''Insert spaces equivalent to one tab.'''

    start,end = g.getLine(s,i)
    s2 = s[start:i]
    width = g.computeWidth(s2,tab_width)

    if tab_width > 0:
        w.insert(i,'\t')
        ins = i+1
    else:
        n = abs(tab_width) - (width % abs(tab_width))
        w.insert(i,' ' * n)
        ins = i+n

    w.setSelectionRange(ins,ins,insert=ins)
#@-node:ekr.20090213065933.14:doPlainTab
#@+node:ekr.20060627091557:flashCharacter
def flashCharacter(self,w,i):

    bg      = self.bracketsFlashBg or 'DodgerBlue1'
    fg      = self.bracketsFlashFg or 'white'
    flashes = self.bracketsFlashCount or 3
    delay   = self.bracketsFlashDelay or 75

    w.flashCharacter(i,bg,fg,flashes,delay)
#@-node:ekr.20060627091557:flashCharacter
#@+node:ekr.20060627083506:flashMatchingBracketsHelper
def flashMatchingBracketsHelper (self,w,i,ch):

    d = {}
    if ch in self.openBracketsList:
        for z in range(len(self.openBracketsList)):
            d [self.openBracketsList[z]] = self.closeBracketsList[z]
        reverse = False # Search forward
    else:
        for z in range(len(self.openBracketsList)):
            d [self.closeBracketsList[z]] = self.openBracketsList[z]
        reverse = True # Search backward

    delim2 = d.get(ch)

    s = w.getAllText()
    j = g.skip_matching_python_delims(s,i,ch,delim2,reverse=reverse)
    if j != -1:
        self.flashCharacter(w,j)
#@-node:ekr.20060627083506:flashMatchingBracketsHelper
#@+node:ekr.20060804095512:initBracketMatcher
def initBracketMatcher (self,c):

    if len(self.openBracketsList) != len(self.closeBracketsList):

        g.es_print('bad open/close_flash_brackets setting: using defaults')
        self.openBracketsList  = '([{'
        self.closeBracketsList = ')]}'

    # g.trace('self.openBrackets',openBrackets)
    # g.trace('self.closeBrackets',closeBrackets)
#@-node:ekr.20060804095512:initBracketMatcher
#@+node:ekr.20051026171121:insertNewlineHelper
def insertNewlineHelper (self,w,oldSel,undoType):

    trace = False and not g.unitTesting
    c = self.c ; p = c.p
    i,j = oldSel ; ch = '\n'
    if trace:
        s = w.widget.toPlainText()
        g.trace(i,j,len(s),w)

    if i != j:
        # No auto-indent if there is selected text.
        w.delete(i,j)
        w.insert(i,ch)
        w.setInsertPoint(i+1)
    else:
        w.insert(i,ch)
        w.setInsertPoint(i+1)

        if (c.autoindent_in_nocolor or 
            (c.frame.body.colorizer.useSyntaxColoring(p) and
            undoType != "Change")
        ):
            # No auto-indent if in @nocolor mode or after a Change command.
            self.updateAutoIndent(p,w)

    w.seeInsertPoint()
#@-node:ekr.20051026171121:insertNewlineHelper
#@+node:ekr.20051026171121.1:updateAutoIndent (leoEditCommands)
def updateAutoIndent (self,p,w):

    c = self.c ; d = c.scanAllDirectives(p)
    tab_width = d.get("tabwidth",c.tab_width)
    # Get the previous line.
    s = w.getAllText()
    ins = w.getInsertPoint()
    i = g.skip_to_start_of_line(s,ins)
    i,j = g.getLine(s,i-1)
    s = s[i:j-1]
    # g.trace(i,j,repr(s))

    # Add the leading whitespace to the present line.
    junk, width = g.skip_leading_ws_with_indent(s,0,tab_width)
    # g.trace('width',width,'tab_width',tab_width)

    if s and s [-1] == ':':
        # For Python: increase auto-indent after colons.
        if g.findLanguageDirectives(c,p) == 'python':
            width += abs(tab_width)
    if self.smartAutoIndent:
        # Determine if prev line has unclosed parens/brackets/braces
        bracketWidths = [width] ; tabex = 0
        for i in range(0,len(s)):
            if s [i] == '\t':
                tabex += tab_width-1
            if s [i] in '([{':
                bracketWidths.append(i+tabex+1)
            elif s [i] in '}])' and len(bracketWidths) > 1:
                bracketWidths.pop()
        width = bracketWidths.pop()
    ws = g.computeLeadingWhitespace(width,tab_width)
    if ws:
        i = w.getInsertPoint()
        w.insert(i,ws)
        w.setInsertPoint(i+len(ws))
#@-node:ekr.20051026171121.1:updateAutoIndent (leoEditCommands)
#@+node:ekr.20051027172949:updateAutomatchBracket
def updateAutomatchBracket (self,p,w,ch,oldSel):

    # assert ch in ('(',')','[',']','{','}')

    c = self.c ; d = c.scanAllDirectives(p)
    i,j = oldSel
    language = d.get('language')
    s = w.getAllText()

    if ch in ('(','[','{',):
        automatch = language not in ('plain',)
        if automatch:
            ch = ch + {'(':')','[':']','{':'}'}.get(ch)
        if i != j: w.delete(i,j)
        w.insert(i,ch)
        if automatch:
            ins = w.getInsertPoint()
            w.setInsertPoint(ins-1)
    else:
        ins = w.getInsertPoint()
        ch2 = ins<len(s) and s[ins] or ''
        if ch2 in (')',']','}'):
            ins = w.getInsertPoint()
            w.setInsertPoint(ins+1)
        else:
            if i != j: w.delete(i,j)
            w.insert(i,ch)
            w.setInsertPoint(i+1)
#@-node:ekr.20051027172949:updateAutomatchBracket
#@+node:ekr.20051026092433:updateTab
def updateTab (self,p,w,smartTab=True):

    c = self.c

    # g.trace('tab_width',tab_width)
    i,j = w.getSelectionRange()
        # Returns insert point if no selection, with i <= j.

    if i != j:
        # w.delete(i,j)
        c.indentBody()
    else:
        d = c.scanAllDirectives(p)
        tab_width = d.get("tabwidth",c.tab_width)
        # Get the preceeding characters.
        s = w.getAllText()
        # start = g.skip_to_start_of_line(s,i)
        start,end = g.getLine(s,i)
        before = s[start:i]
        after = s[i:end]
        if after.endswith('\n'): after = after[:-1]
        ws = g.get_leading_ws(before)
        s2 = s[start:i] # The characters before the insert point.

        # Only do smart tab at the start of a blank line.
        doSmartTab = (smartTab and c.smart_tab and i == start)
            # Truly at the start of the line.
            # and not after # Nothing *at all* after the cursor.
        # g.trace(doSmartTab,'i %s start %s after %s' % (i,start,repr(after)))

        if doSmartTab:
            self.updateAutoIndent(p,w)
            # Add a tab if otherwise nothing would happen.
            if s == w.getAllText():
                self.doPlainTab(s,i,tab_width,w)
        else:
            self.doPlainTab(s,i,tab_width,w)
#@-node:ekr.20051026092433:updateTab
#@-node:ekr.20051125080855:selfInsertCommand, helpers
#@+node:ekr.20050920084036.138:insertNewLine
def insertNewLine (self,event):

    '''Insert a newline at the cursor.'''

    c = self.c ; k = c.k ; w = self.editWidget(event)
    if not w: return

    assert g.app.gui.isTextWidget(w)
    name = c.widget_name(w)
    if name.startswith('head'): return

    oldSel = w.getSelectionRange()
    # g.trace('oldSel',oldSel)

    self.beginCommand(undoType='newline')

    # New in Leo 4.5: use the same logic as in selfInsertCommand.
    self.insertNewlineHelper(w=w,oldSel=oldSel,undoType=None)
    k.setInputState('insert')
    k.showStateAndMode()

    self.endCommand()

insertNewline = insertNewLine
#@-node:ekr.20050920084036.138:insertNewLine
#@+node:ekr.20051026171121:insertNewlineHelper
def insertNewlineHelper (self,w,oldSel,undoType):

    trace = False and not g.unitTesting
    c = self.c ; p = c.p
    i,j = oldSel ; ch = '\n'
    if trace:
        s = w.widget.toPlainText()
        g.trace(i,j,len(s),w)

    if i != j:
        # No auto-indent if there is selected text.
        w.delete(i,j)
        w.insert(i,ch)
        w.setInsertPoint(i+1)
    else:
        w.insert(i,ch)
        w.setInsertPoint(i+1)

        if (c.autoindent_in_nocolor or 
            (c.frame.body.colorizer.useSyntaxColoring(p) and
            undoType != "Change")
        ):
            # No auto-indent if in @nocolor mode or after a Change command.
            self.updateAutoIndent(p,w)

    w.seeInsertPoint()
#@-node:ekr.20051026171121:insertNewlineHelper
#@-node:ekr.20100124142131.6223:Fixed Terry's unicode problem
#@+node:ekr.20100129054823.17686:Fix crasher in rst3 command
TypeError: string argument expected, got 'bytes'
--------------------
  line 1364: 
* line 1365:         self.outputFile.write(s)
  line 1366:     #@-node:ekr.20090502071837.94:write (leoRst)
  line 1367:     #@+node:ekr.20090502071837.71:writeBody
saved: LeoDocs.leo
#@nonl
#@+node:ekr.20090502071837.94:write (leoRst)
def write (self,s):

    if self.trialWrite:
        pass
    elif g.isPython3:
        pass
    else:
        s = self.encode(s)

    # g.trace(repr(s),g.callers(2))

    self.outputFile.write(s)
#@-node:ekr.20090502071837.94:write (leoRst)
#@+node:ekr.20090502071837.65:writeToDocutils (sets argv) & helper
def writeToDocutils (self,s):

    '''Send s to docutils using the writer implied by self.ext and return the result.'''

    trace = False and not g.unitTesting

    if not docutils:
        g.es('docutils not present',color='red')
        return

    openDirectory = self.c.frame.openDirectory
    overrides = {'output_encoding': self.encoding }

    # Compute the args list if the stylesheet path does not exist.
    styleSheetArgsDict = self.handleMissingStyleSheetArgs()

    for ext,writer in (
        ('.html','html'),
        ('.htm','html'),
        ('.tex','latex'),
        ('.pdf','leo_pdf'),
    ):
        if self.ext == ext:
            break
    else:
        g.es_print('unknown docutils extension: %s' % (self.ext),color='red')
        return ''

    # Make the stylesheet path relative to the directory containing the output file.
    rel_stylesheet_path = self.getOption('stylesheet_path') or ''

    # New in Leo 4.5: The rel_stylesheet_path is relative to the open directory.
    stylesheet_path = g.os_path_finalize_join(
        self.c.frame.openDirectory,rel_stylesheet_path)

    path = g.os_path_finalize_join(
        stylesheet_path,self.getOption('stylesheet_name'))

    res = ""
    if self.getOption('stylesheet_embed') == False:
        rel_path = g.os_path_join(
            rel_stylesheet_path,self.getOption('stylesheet_name'))
        rel_path = rel_path.replace('\\','/') # 2010/01/28
        overrides['stylesheet'] = rel_path
        overrides['stylesheet_path'] = None
        overrides['embed_stylesheet'] = None
    elif g.os_path_exists(path):
        if self.ext != '.pdf':
            overrides['stylesheet'] = path
            overrides['stylesheet_path'] = None
    elif styleSheetArgsDict:
        g.es_print('using publish_argv_for_missing_stylesheets',
            styleSheetArgsDict)
        overrides.update(styleSheetArgsDict)
            # MWC add args to settings
    elif rel_stylesheet_path == stylesheet_path:
        g.es_print('stylesheet not found: %s' % (path),color='red')
    else:
        g.es_print('stylesheet not found\n',path,color='red')
        if self.path:g.es_print('@path:', self.path)
        g.es_print('open path:',self.c.frame.openDirectory)
        if rel_stylesheet_path:
            g.es_print('relative path:', rel_stylesheet_path)
    try:
        # All paths now come through here.
        if trace: g.trace('overrides',overrides)
        result = None # Ensure that result is defined.
        result = docutils.core.publish_string(source=s,
                reader_name='standalone',
                parser_name='restructuredtext',
                writer_name=writer,
                settings_overrides=overrides)
    except docutils.ApplicationError as error:
        # g.es_print('Docutils error (%s):' % (
            # error.__class__.__name__),color='red')
        g.es_print('Docutils error:',color='red')
        g.es_print(error,color='blue')
    except Exception:
        g.es_print('Unexpected docutils exception')
        g.es_exception()
    return result
#@+node:ekr.20090502071837.66:handleMissingStyleSheetArgs
def handleMissingStyleSheetArgs (self,s=None):

    '''Parse the publish_argv_for_missing_stylesheets option,
    returning a dict containing the parsed args.'''

    force = False
    if force:
        # See http://docutils.sourceforge.net/docs/user/config.html#documentclass
        return {'documentclass':'report', 'documentoptions':'english,12pt,lettersize'}

    if not s:
        s = self.getOption('publish_argv_for_missing_stylesheets')
    if not s: return {}

    # Handle argument lists such as this:
    # --language=en,--documentclass=report,--documentoptions=[english,12pt,lettersize]
    d = {}
    while s:
        s = s.strip()
        if not s.startswith('--'): break
        s = s[2:].strip()
        eq = s.find('=')
        cm = s.find(',')
        if eq == -1 or (-1 < cm < eq): # key[nl] or key,
            val = ''
            cm = s.find(',')
            if cm == -1:
                key = s.strip()
                s = ''
            else:
                key = s[:cm].strip()
                s = s[cm+1:].strip()
        else: # key = val
            key = s[:eq].strip()
            s = s[eq+1:].strip()
            if s.startswith('['): # [...]
                rb = s.find(']')
                if rb == -1: break # Bad argument.
                val = s[:rb+1]
                s = s[rb+1:].strip()
                if s.startswith(','):
                    s = s[1:].strip()
            else: # val[nl] or val,
                cm = s.find(',')
                if cm == -1:
                    val = s
                    s = ''
                else:
                    val = s[:cm].strip()
                    s = s[cm+1:].strip()

        # g.trace('key',repr(key),'val',repr(val),'s',repr(s))
        if not key: break
        if not val.strip(): val = '1'
        d[str(key)] = str(val)

    return d
#@nonl
#@-node:ekr.20090502071837.66:handleMissingStyleSheetArgs
#@-node:ekr.20090502071837.65:writeToDocutils (sets argv) & helper
#@-node:ekr.20100129054823.17686:Fix crasher in rst3 command
#@-node:ekr.20100118163110.6256:Leo 4.7 b2 projects
#@+node:ekr.20100129131524.6188:Leo 4.7 rc1 projects
#@+node:ekr.20100129131524.6187:Disable caching during unit tests
#@+node:ekr.20031218072017.3037:putGlobals
# Changed for Leo 4.0.

def putGlobals (self):

    trace = False and not g.unitTesting
    c = self.c

    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName

    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        if trace: g.trace(len(list(c.db.keys())),c.mFileName,key)
        << put all data to c.db >>

    # Always put positions, to trigger sax methods.
    self.put("<globals")
    << put the body/outline ratios >>
    self.put(">") ; self.put_nl()
    << put the position of this frame >>
    << put the position of the log window >>
    self.put("</globals>") ; self.put_nl()
#@+node:ekr.20100112095623.6267:<< put all data to c.db >>
c.db['body_outline_ratio_%s' % key] = str(c.frame.ratio)
c.db['body_secondary_ratio_%s' % key] = str(c.frame.secondary_ratio)

if trace: g.trace('ratios: %1.2f %1.2f' % (
    c.frame.ratio,c.frame.secondary_ratio))

width,height,left,top = c.frame.get_window_info()

c.db['window_position_%s' % key] = (
    str(top),str(left),str(height),str(width))

if trace: g.trace('top',top,'left',left,'height',height,'width',width)
#@-node:ekr.20100112095623.6267:<< put all data to c.db >>
#@+node:ekr.20031218072017.3038:<< put the body/outline ratios >>
self.put(" body_outline_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.ratio)))

self.put(" body_secondary_ratio=")
self.put_in_dquotes(g.choose(c.fixed or use_db,"0.5","%1.2f" % (
    c.frame.secondary_ratio)))

if trace: g.trace('fixed or use_db',c.fixed or use_db,
    '%1.2f %1.2f' % (c.frame.ratio,c.frame.secondary_ratio))
#@-node:ekr.20031218072017.3038:<< put the body/outline ratios >>
#@+node:ekr.20031218072017.3039:<< put the position of this frame >>
# New in Leo 4.5: support fixed .leo files.

if c.fixed or use_db:
    width,height,left,top = 700,500,50,50
        # Put fixed, immutable, reasonable defaults.
        # Leo 4.5 and later will ignore these when reading.
        # These should be reasonable defaults so that the
        # file will be opened properly by older versions
        # of Leo that do not support fixed .leo files.
else:
    width,height,left,top = c.frame.get_window_info()

# g.trace(width,height,left,top)

self.put_tab()
self.put("<global_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3039:<< put the position of this frame >>
#@+node:ekr.20031218072017.3040:<< put the position of the log window >>
top = left = height = width = 0 # no longer used

self.put_tab()
self.put("<global_log_window_position")
self.put(" top=") ; self.put_in_dquotes(str(top))
self.put(" left=") ; self.put_in_dquotes(str(left))
self.put(" height=") ; self.put_in_dquotes(str(height))
self.put(" width=") ; self.put_in_dquotes(str(width))
self.put("/>") ; self.put_nl()
#@-node:ekr.20031218072017.3040:<< put the position of the log window >>
#@-node:ekr.20031218072017.3037:putGlobals
#@+node:ekr.20031218072017.1863:putVnode
def putVnode (self,p,isIgnore=False):

    """Write a <v> element corresponding to a vnode."""

    fc = self ; c = fc.c ; v = p.v
    isAuto = p.isAtAutoNode() and p.atAutoNodeName().strip()
    isEdit = p.isAtEditNode() and p.atEditNodeName().strip()
    isShadow = p.isAtShadowFileNode()
    isThin = p.isAtThinFileNode()
    isOrphan = p.isOrphan()
    if not isIgnore: isIgnore = p.isAtIgnoreNode()

    if   isIgnore: forceWrite = True      # Always write full @ignore trees.
    elif isAuto:   forceWrite = False     # Never write non-ignored @auto trees.
    elif isEdit:   forceWrite = False     # Never write non-ignored @edit trees.
    elif isShadow: forceWrite = False     # Never write non-ignored @shadow trees.
    elif isThin:   forceWrite = isOrphan  # Only write orphan @thin trees.
    else:          forceWrite = True      # Write all other @<file> trees.

    << Set gnx = vnode index >>
    attrs = []
    << Append attribute bits to attrs >>
    << Append unKnownAttributes to attrs >>
    attrs = ''.join(attrs)
    v_head = '<v t="%s"%s>' % (gnx,attrs)
    if gnx in fc.vnodesDict:
        fc.put(v_head+'</v>\n')
    else:
        fc.vnodesDict[gnx]=True
        v_head += '<vh>%s</vh>' % (xml.sax.saxutils.escape(p.v.headString()or''))
        # The string catentation is faster than repeated calls to fc.put.
        if not self.usingClipboard:
            << issue informational messages >>
        # New in 4.2: don't write child nodes of @file-thin trees (except when writing to clipboard)
        if p.hasChildren() and (forceWrite or self.usingClipboard):
            fc.put('%s\n' % v_head)
            # This optimization eliminates all "recursive" copies.
            p.moveToFirstChild()
            while 1:
                fc.putVnode(p,isIgnore)
                if p.hasNext(): p.moveToNext()
                else:           break
            p.moveToParent() # Restore p in the caller.
            fc.put('</v>\n')
        else:
            fc.put('%s</v>\n' % v_head) # Call put only once.
#@+node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
gnx = g.app.nodeIndices.toString(v.fileIndex)

if forceWrite or self.usingClipboard:
    v.setWriteBit() # 4.2: Indicate we wrote the body text.
#@-node:ekr.20031218072017.1864:<< Set gnx = vnode index >>
#@+node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
# These string catenations are benign because they rarely happen.
attr = ""
# New in Leo 4.5: support fixed .leo files.
if not c.fixed:
    if v.isExpanded() and v.hasChildren(): attr += "E"
    if v.isMarked():   attr += "M"
    if v.isOrphan():   attr += "O"
    if attr:
        attrs.append(' a="%s"' % attr)

# Put the archived *current* position in the *root* positions <v> element.
if p == self.rootPosition:
    aList = [str(z) for z in self.currentPosition.archivedPosition()]
    d = hasattr(v,'unKnownAttributes') and v.unknownAttributes or {}
    str_pos = ','.join(aList)
    # 2010/01/26: don't write the current position if we can cache it.
    use_db = g.enableDB and not g.unitTesting and c.db and c.mFileName
    if use_db:
        globals_tag = g.choose(g.isPython3,'leo3k.globals','leo2k.globals')
        globals_tag = g.toEncodedString(globals_tag,'ascii')
        key = c.atFileCommands._contentHashFile(c.mFileName,globals_tag)
        c.db['current_position_%s' % key] = str_pos
        if d.get('str_leo_pos'): del d['str_leo_pos']
        # g.trace('to c.db',str_pos,key)
    elif c.fixed:
        if d.get('str_leo_pos'): del d['str_leo_pos']
    else:
        d['str_leo_pos'] = str_pos
    # g.trace(aList,d)
    v.unknownAttributes = d
elif hasattr(v,"unknownAttributes"):
    d = v.unknownAttributes
    if d and not c.fixed and d.get('str_leo_pos'):
        # g.trace("clearing str_leo_pos",v)
        del d['str_leo_pos']
        v.unknownAttributes = d
#@-node:ekr.20031218072017.1865:<< Append attribute bits to attrs >> putVnode
#@+node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
# v.unknownAttributes are now put in <t> elements.

if p.hasChildren() and not forceWrite and not self.usingClipboard:
    # We put the entire tree when using the clipboard, so no need for this.
    if not isAuto: # Bug fix: 2008/8/7.
        attrs.append(self.putDescendentVnodeUas(p)) # New in Leo 4.5.
        attrs.append(self.putDescendentAttributes(p))
#@nonl
#@-node:ekr.20040324082713:<< Append unKnownAttributes to attrs>> putVnode
#@+node:ekr.20040702085529:<< issue informational messages >>
if isOrphan and isThin:
    g.es("writing erroneous:",p.h,color="blue")
    p.clearOrphan()
#@-node:ekr.20040702085529:<< issue informational messages >>
#@-node:ekr.20031218072017.1863:putVnode
#@-node:ekr.20100129131524.6187:Disable caching during unit tests
#@+node:ekr.20100128124511.6236:Eliminate most imports from leo/extensions
@nocolor-node

Eliminated cruft in leo/extensions
- sets folder
- subprocess folder
- optparse.py
- aspell23/24.pyd files can also go.

Eliminated calls to g.importExtenion for zlib,optparse,subprocess.

Don't know about Gato.
#@nonl
#@-node:ekr.20100128124511.6236:Eliminate most imports from leo/extensions
#@+node:ekr.20100130042842.9007:better traces for ctors
#@+node:ekr.20051023083258:callers & _callerName
def callers (n=8,count=0,excludeCaller=True,files=False):

    '''Return a list containing the callers of the function that called g.callerList.

    If the excludeCaller keyword is True (the default), g.callers is not on the list.

    If the files keyword argument is True, filenames are included in the list.
    '''

    # sys._getframe throws ValueError in both cpython and jython if there are less than i entries.
    # The jython stack often has less than 8 entries,
    # so we must be careful to call g._callerName with smaller values of i first.
    result = []
    i = g.choose(excludeCaller,3,2)
    while 1:
        s = g._callerName(i,files=files)
        if s:
            result.append(s)
        if not s or len(result) >= n: break
        i += 1

    result.reverse()
    if count > 0: result = result[:count]
    sep = g.choose(files,'\n',',')
    return sep.join(result)
#@+node:ekr.20031218072017.3107:_callerName
def _callerName (n=1,files=False):

    try: # get the function name from the call stack.
        f1 = sys._getframe(n) # The stack frame, n levels up.
        code1 = f1.f_code # The code object
        name = code1.co_name
        if name == '__init__':
            name = '__init__(%s,line %s)' % (
                g.shortFileName(code1.co_filename),code1.co_firstlineno)
        if files:
            return '%s:%s' % (g.shortFilename(code1.co_filename),name)
        else:
            return name # The code name
    except ValueError:
        return '' # The stack is not deep enough.
    except Exception:
        g.es_exception()
        return '' # "<no caller name>"
#@-node:ekr.20031218072017.3107:_callerName
#@-node:ekr.20051023083258:callers & _callerName
#@-node:ekr.20100130042842.9007:better traces for ctors
#@-node:ekr.20100129131524.6188:Leo 4.7 rc1 projects
#@-all
#@-node:ekr.20100120072650.6089:@thin leoProjects.txt
#@-leo
