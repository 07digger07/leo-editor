#@+leo-ver=4-thin
#@+node:ekr.20100119205347.6015:@thin ../doc/leoToDo.txt
#@+all
#@+node:ekr.20071211093011:4.7 One-node world, Leo3K
@nocolor-node

- Support for Python 3.x.
- autocompleter
- Code completion.
- Refactoring: rope, etc.
- Flexitble file format.
#@nonl
#@+node:ekr.20100126110826.6253:Before rc1
@nocolor-node
#@nonl
#@+node:ekr.20100204052559.5792:Make goto-global-line work with @auto files
@nocolor-node

Fix bug 363406: goto global line doesn't seem to be working in @auto files
#@+node:ekr.20100205180205.5845:Report
@nocolor-node

363406: goto global line doesn't seem to be working in @auto files

Still seeing this at revno 2254

running my program in a shell I get:

Traceback (most recent call last):
  File "dualentry.py", line 228, in <module>
    SQLComp()
  File "dualentry.py", line 86, in __init__
    self.runWith(state, chain, [])
  File "dualentry.py", line 148, in runWith
    othStates = self.lookFor(chain, state, otherChains, i)
  File "dualentry.py", line 191, in lookFor
    assert cur.rowcount in (0,1)
AssertionError

but when I use Alt-G goto global line 191 it takes me to the bottom of the toplevel @auto node:

@language python
@tabwidth -4
@others
SQLComp()

|<-- cursor ends up here

cat -n dualentry.py | grep 191 confirms that the assert is on line 191 of the file.
tbnorth wrote on 2009-07-23: 	#3

p.s. I just noticed leo's logging "only 15 lines" in blue, but this is a lie.
#@-node:ekr.20100205180205.5845:Report
#@+node:ekr.20080710082231.10:c.gotoLineNumber and helpers
def goToLineNumber (self,n,p=None,scriptData=None):

    '''Place the cursor on the n'th line of a derived file or script.
    When present scriptData is a dict with 'root' and 'lines' keys.'''

    c = self
    if n < 0: return

    if scriptData:
        fileName,lines,p,root = c.goto_setup_script(scriptData)
    else:
        if not p: p = c.p
        fileName,lines,n,root = c.goto_setup_file(n,p)

    isRaw = not root or (
        root.isAtEditNode() or root.isAtAsisFileNode() or
        root.isAtAutoNode() or root.isAtNoSentFileNode())
    ignoreSentinels = root and root.isAtNoSentFileNode()
    if not root:
        if scriptData:  root = p.copy()
        else:           root = c.p

    if isRaw:
        p,n2,found = c.goto_countLines(root,n)
        n2 += 1
    # elif n<=1
        # p,n2,found = root,1,True
    # elif n > len(lines):
        # p,n2,found = root,root.b.count('\n'),False
    else:
        # if n == 0: n = 1
        vnodeName,gnx,n2,delim = c.goto_findVnode(root,lines,n,ignoreSentinels)
        p,found = c.goto_findGnx(delim,root,gnx,vnodeName)

    c.goto_showResults(found,p or root,n,n2,lines)
#@+node:ekr.20080904071003.12:goto_countLines & helper
def goto_countLines (self,root,n):

    '''Scan through root's outline, looking for line n.
    Return (p,i,found)
    p is the found node.
    i is the offset of the line within the node.
    found is True if the line was found.'''

    trace = False and not g.unitTesting
    c = self

    if trace: g.trace('=' * 10,n,root.h)

    # Start the recursion.
    p,i,n,found = c.goto_countLinesHelper(root,n,trace)
    return p,i,found
#@+node:ekr.20100206173123.5805:goto_countLinesHelper
def goto_countLinesHelper (self,p,n,trace):

    '''Scan root's body text, looking for line n,
    ao is the index of the line containing @others or None.

    Return (p,i,n,found) where:
    p is the found node if found, or the original p if not.
    i is the offset of the line within the node.
    found is True if the line was found.'''

    verbose = True
    if trace: g.trace('-' * 5,n,p.h)
    c = self ; ao = None
    lines = g.splitLines(p.b)
    i = 0
    while i < len(lines):
        progress = i
        line = lines[i]
        if trace and verbose: g.trace('i %s n %s %s' % (i,n,line.rstrip()))
        if line.strip().startswith('@'):
            # Increase number of the line we are looking for.
            n += 1
            i += 1
            if line.strip().startswith('@others'):
                # Start looking in inner nodes.
                if trace: 
                    g.trace('@others offset: %3s n: %3s %s' % (i,n,p.h))
                if ao is None:
                    ao = i
                    if p.hasChildren():
                        n2 = n-i
                        for child in p.children():
                            # Recursively scan the children.
                            p2,i2,n2,found = c.goto_countLinesHelper(
                                child,n2,trace)
                            if found:
                                return p2,i2,n2,found
                            else:
                                if trace: g.trace('return i2',i2,'n2',n2,'-->',n2-i2)
                                # Don't change i here!
                                n2 -= i2
                        n = n2
                        assert n > 0 # otherwise we would have suceeded.
                    # else: silently ignore @others without children.
                # else: silently ignore duplicate @others.
            # else: nothing more to do.
        elif i == n: # Found the line.
            if trace: g.trace('Found!  offset: %3s n: %3s %s' % (n,i,p.h))
            return p,i,n,True
        else: # A plain line.
            i += 1
        assert i > progress
    assert i == len(lines)
    return p,i-1,n,False
#@-node:ekr.20100206173123.5805:goto_countLinesHelper
#@-node:ekr.20080904071003.12:goto_countLines & helper
#@+node:ekr.20080904071003.18:goto_findGnx
def goto_findGnx (self,delim,root,gnx,vnodeName):

    '''Scan root's tree for a node with the given gnx and vnodeName.

    return (p,found)'''

    if delim and gnx:
        gnx = g.app.nodeIndices.scanGnx(gnx,0)
        for p in root.self_and_subtree():
            if p.matchHeadline(vnodeName):
                if p.v.fileIndex == gnx:
                    return p.copy(),True
        return None,False
    else:
        return root,False
#@-node:ekr.20080904071003.18:goto_findGnx
#@+node:ekr.20080904071003.25:goto_findRoot
def goto_findRoot (self,p):

    '''Find the closest ancestor @<file> node, except @all nodes.

    return root, fileName.'''

    c = self ; p1 = p.copy()

    # First look for ancestor @file node.
    for p in p.self_and_parents():
        fileName = not p.isAtAllNode() and p.anyAtFileNodeName()
        if fileName:
            return p.copy(),fileName

    # Search the entire tree for joined nodes.
    # Bug fix: Leo 4.5.1: *must* search *all* positions.
    for p in c.all_positions():
        if p.v == p1.v and p != p1:
            # Found a joined position.
            for p2 in p.self_and_parents():
                fileName = not p2.isAtAllNode() and p2.anyAtFileNodeName()
                if fileName:
                    return p2.copy(),fileName

    return None,None
#@-node:ekr.20080904071003.25:goto_findRoot
#@+node:ekr.20031218072017.2877:goto_findVnode & helpers
def goto_findVnode (self,root,lines,n,ignoreSentinels):

    '''Search the lines of a derived file containing sentinels for a vnode.
    return (vnodeName,gnx,offset,delim):

    vnodeName:  the name found in the previous @+body sentinel.
    gnx:        the gnx of the found node.
    offset:     the offset within the node of the desired line.
    delim:      the comment delim from the @+leo sentinel.
    '''

    c = self
    # g.trace('lines...\n',g.listToString(lines))
    gnx = None
    delim,thinFile = c.goto_setDelimFromLines(lines)
    if not delim:
        g.es('no sentinels in:',root.h)
        return None,None,None,None

    nodeLine,offset = c.goto_findNodeSentinel(delim,lines,n)
    if nodeLine == -1:
        # The line precedes the first @+node sentinel
        g.trace('no @+node!!')
        return root.h,gnx,1,delim

    s = lines[nodeLine]
    gnx,vnodeName = c.goto_getNodeLineInfo(s,thinFile)
    if delim and vnodeName:
        # g.trace('offset',offset)
        return vnodeName,gnx,offset,delim
    else:
        g.es("bad @+node sentinel")
        return None,None,None,None
#@+node:ekr.20100124164700.12156:goto_findNodeSentinel & helper
def goto_findNodeSentinel(self,delim,lines,n):

    '''
    Scan backwards from the line n, looking for an @-body line. When found,
    get the vnode's name from that line and set p to the indicated vnode. This
    will fail if vnode names have been changed, and that can't be helped.

    We compute the offset of the requested line **within the found node**.
    '''

    c = self
    offset = 0 # This is essentially the Tk line number.
    nodeSentinelLine = -1
    line = n - 1 # Start with the requested line.
    while line >= 0 and nodeSentinelLine == -1:
        progress = line
        s = lines[line]
        i = g.skip_ws(s,0)
        if g.match(s,i,delim):
            line,nodeSentinelLine,offset = c.goto_handleDelim(
                delim,s,i,line,lines,n,offset)
        else:
            # offset += 1
                # Assume the line is real.
                # A dubious assumption.
            line -= 1
        assert nodeSentinelLine > -1 or line < progress
    return nodeSentinelLine,offset
#@+node:ekr.20031218072017.2880:goto_handleDelim
def goto_handleDelim (self,delim,s,i,line,lines,n,offset):

    '''Handle the delim while scanning backward.'''

    c = self
    if line == n:
        g.es("line",str(n),"is a sentinel line")
    i += len(delim)
    nodeSentinelLine = -1

    if g.match(s,i,"-node"):
        # The end of a nested section.
        old_line = line
        line = c.goto_skipToMatchingNodeSentinel(lines,line,delim)
        assert line < old_line
        # g.trace('found',repr(lines[line]))
        nodeSentinelLine = line
        offset = n-line
    elif g.match(s,i,"+node"):
        # g.trace('found',repr(lines[line]))
        nodeSentinelLine = line
        offset = n-line
    elif g.match(s,i,"<<") or g.match(s,i,"@first"):
        # if not ignoreSentinels:
            # offset += 1 # Count these as a "real" lines.
        line -= 1
    else:
        line -= 1
        nodeSentinelLine = -1
    return line,nodeSentinelLine,offset
#@-node:ekr.20031218072017.2880:goto_handleDelim
#@-node:ekr.20100124164700.12156:goto_findNodeSentinel & helper
#@+node:ekr.20031218072017.2881:goto_getNodeLineInfo
def goto_getNodeLineInfo (self,s,thinFile):

    i = 0 ; gnx = None ; vnodeName = None

    if thinFile:
        # gnx is lies between the first and second ':':
        i = s.find(':',i)
        if i > 0:
            i += 1
            j = s.find(':',i)
            if j > 0:   gnx = s[i:j]
            else:       i = len(s) # Force an error.
        else:
            i = len(s) # Force an error.

    # vnode name is everything following the first or second':'
    i = s.find(':',i)
    if i > -1:
        vnodeName = s[i+1:].strip()
    else:
        vnodeName = None
        g.es_print("bad @+node sentinel",color='red')

    return gnx,vnodeName
#@-node:ekr.20031218072017.2881:goto_getNodeLineInfo
#@+node:ekr.20031218072017.2878:goto_setDelimFromLines
def goto_setDelimFromLines (self,lines):

    # Find the @+leo line.
    c = self ; at = c.atFileCommands
    i = 0 
    while i < len(lines) and lines[i].find("@+leo")==-1:
        i += 1
    leoLine = i # Index of the line containing the leo sentinel

    # Set delim and thinFile from the @+leo line.
    delim,thinFile = None,False

    if leoLine < len(lines):
        s = lines[leoLine]
        valid,newDerivedFile,start,end,thinFile = at.parseLeoSentinel(s)
        # New in Leo 4.5.1: only support 4.x files.
        if valid and newDerivedFile:
            delim = start + '@'

    return delim,thinFile
#@-node:ekr.20031218072017.2878:goto_setDelimFromLines
#@+node:ekr.20031218072017.2882:goto_skipToMatchingNodeSentinel
def goto_skipToMatchingNodeSentinel (self,lines,n,delim):

    s = lines[n]
    i = g.skip_ws(s,0)
    assert(g.match(s,i,delim))
    i += len(delim)
    if g.match(s,i,"+node"):
        start="+node" ; end="-node" ; delta=1
    else:
        assert(g.match(s,i,"-node"))
        start="-node" ; end="+node" ; delta=-1
    # Scan to matching @+-node delim.
    n += delta ; level = 0
    while 0 <= n < len(lines):
        s = lines[n] ; i = g.skip_ws(s,0)
        if g.match(s,i,delim):
            i += len(delim)
            if g.match(s,i,start):
                level += 1
            elif g.match(s,i,end):
                if level == 0: break
                else: level -= 1
        n += delta

    # g.trace(n)
    return n
#@-node:ekr.20031218072017.2882:goto_skipToMatchingNodeSentinel
#@-node:ekr.20031218072017.2877:goto_findVnode & helpers
#@+node:ekr.20080904071003.26:goto_getFileLines
def goto_getFileLines (self,root,fileName):

    '''Read the file into lines.'''

    c = self
    isAtEdit = root.isAtEditNode()
    isAtNoSent = root.isAtNoSentFileNode()

    if isAtNoSent or isAtEdit:
        # Write a virtual file containing sentinels.
        at = c.atFileCommands
        kind = g.choose(isAtNoSent,'@nosent','@edit')
        at.write(root,kind=kind,nosentinels=False,toString=True)
        lines = g.splitLines(at.stringOutput)
    else:
        # Calculate the full path.
        d = g.scanDirectives(c,p=root)
        path = d.get("path")
        # g.trace('path',path,'fileName',fileName)
        fileName = c.os_path_finalize_join(path,fileName)
        lines    = c.goto_open(fileName)

    return lines
#@-node:ekr.20080904071003.26:goto_getFileLines
#@+node:ekr.20080708094444.63:goto_open
def goto_open (self,filename):
    """
    Open a file for "goto linenumber" command and check if a shadow file exists.
    Construct a line mapping. This ivar is empty if no shadow file exists.
    Otherwise it contains a mapping, shadow file number -> real file number.
    """

    c = self ; x = c.shadowController

    try:
        shadow_filename = x.shadowPathName(filename)
        if os.path.exists(shadow_filename):
            fn = shadow_filename
            lines = open(shadow_filename).readlines()
            x.line_mapping = x.push_filter_mapping(
                lines,
                x.markerFromFileLines(lines,shadow_filename))
        else:
            # Just open the original file.  This is not an error!
            fn = filename
            c.line_mapping = []
            lines = open(filename).readlines()
    except Exception:
        # Make sure failures to open a file generate clear messages.
        g.es_print('can not open',fn,color='blue')
        # g.es_exception()
        lines = []

    return lines
#@-node:ekr.20080708094444.63:goto_open
#@+node:ekr.20080904071003.28:goto_setup_file
def goto_setup_file (self,n,p):

    '''Return (lines,n) where:

    lines are the lines to be scanned.
    n is the effective line number (munged for @shadow nodes).
    '''

    c = self ; x = c.shadowController

    root,fileName = c.goto_findRoot(p)

    if root and fileName:
        c.shadowController.line_mapping = [] # Set by goto_open.
        lines = c.goto_getFileLines(root,fileName)
            # This will set x.line_mapping for @shadow files.
        if len(x.line_mapping) > n:
            n = x.line_mapping[n]
    else:
        if not g.unitTesting:
            g.es("no ancestor @<file node>: using script line numbers",
                color="blue")
        lines = g.getScript(c,p,useSelectedText=False)
        lines = g.splitLines(lines)

    return fileName,lines,n,root
#@-node:ekr.20080904071003.28:goto_setup_file
#@+node:ekr.20100205193439.5844:goto_setup_script
def goto_setup_script (self,scriptData):

    c = self

    p = scriptData.get('p')
    root,fileName = c.goto_findRoot(p)
    lines = scriptData.get('lines')

    return fileName,lines,p,root
#@-node:ekr.20100205193439.5844:goto_setup_script
#@+node:ekr.20080904071003.14:goto_showResults
def goto_showResults(self,found,p,n,n2,lines):

    c = self ; w = c.frame.body.bodyCtrl

    # Select p and make it visible.
    c.redraw(p)

    # Put the cursor on line n2 of the body text.
    s = w.getAllText()
    if found:
        ins = g.convertRowColToPythonIndex(s,n2-1,0)    
    else:
        ins = len(s)
        if len(lines) < n and not g.unitTesting:
            g.es('only',len(lines),'lines',color="blue")

    w.setInsertPoint(ins)
    c.bodyWantsFocusNow()
    w.seeInsertPoint()
#@-node:ekr.20080904071003.14:goto_showResults
#@-node:ekr.20080710082231.10:c.gotoLineNumber and helpers
#@+node:ekr.20080904071003.12:goto_countLines & helper
def goto_countLines (self,root,n):

    '''Scan through root's outline, looking for line n.
    Return (p,i,found)
    p is the found node.
    i is the offset of the line within the node.
    found is True if the line was found.'''

    trace = False and not g.unitTesting
    c = self

    if trace: g.trace('=' * 10,n,root.h)

    # Start the recursion.
    p,i,n,found = c.goto_countLinesHelper(root,n,trace)
    return p,i,found
#@+node:ekr.20100206173123.5805:goto_countLinesHelper
def goto_countLinesHelper (self,p,n,trace):

    '''Scan root's body text, looking for line n,
    ao is the index of the line containing @others or None.

    Return (p,i,n,found) where:
    p is the found node if found, or the original p if not.
    i is the offset of the line within the node.
    found is True if the line was found.'''

    verbose = True
    if trace: g.trace('-' * 5,n,p.h)
    c = self ; ao = None
    lines = g.splitLines(p.b)
    i = 0
    while i < len(lines):
        progress = i
        line = lines[i]
        if trace and verbose: g.trace('i %s n %s %s' % (i,n,line.rstrip()))
        if line.strip().startswith('@'):
            # Increase number of the line we are looking for.
            n += 1
            i += 1
            if line.strip().startswith('@others'):
                # Start looking in inner nodes.
                if trace: 
                    g.trace('@others offset: %3s n: %3s %s' % (i,n,p.h))
                if ao is None:
                    ao = i
                    if p.hasChildren():
                        n2 = n-i
                        for child in p.children():
                            # Recursively scan the children.
                            p2,i2,n2,found = c.goto_countLinesHelper(
                                child,n2,trace)
                            if found:
                                return p2,i2,n2,found
                            else:
                                if trace: g.trace('return i2',i2,'n2',n2,'-->',n2-i2)
                                # Don't change i here!
                                n2 -= i2
                        n = n2
                        assert n > 0 # otherwise we would have suceeded.
                    # else: silently ignore @others without children.
                # else: silently ignore duplicate @others.
            # else: nothing more to do.
        elif i == n: # Found the line.
            if trace: g.trace('Found!  offset: %3s n: %3s %s' % (n,i,p.h))
            return p,i,n,True
        else: # A plain line.
            i += 1
        assert i > progress
    assert i == len(lines)
    return p,i-1,n,False
#@-node:ekr.20100206173123.5805:goto_countLinesHelper
#@-node:ekr.20080904071003.12:goto_countLines & helper
#@-node:ekr.20100204052559.5792:Make goto-global-line work with @auto files
#@+node:ekr.20100210102224.5744:Notes for key bindings
@nocolor-node

Requirements:
    - Existing bindings must still be valid.
    - But @mode does not have to remain.

Think data:
    - Drive binding by tables.
    *** Design these tables first.
    - Table design should be flixible.
      It can change without affecting user.

keySequence class?
    - Represents a sequence of keystrokes.

bufferMode class?
    - Might encapsulate directives, etc.

bindHelper class?
    - Would mediate various aspects of binding.
    - c.bindHelper or k.bindHelper?
#@nonl
#@-node:ekr.20100210102224.5744:Notes for key bindings
#@-node:ekr.20100126110826.6253:Before rc1
#@-node:ekr.20071211093011:4.7 One-node world, Leo3K
#@+node:ekr.20100209160132.5771:until-4-7-final branch
#@+node:ekr.20100209160132.5770:cache notes
@nocolor-node

Top-level folder are direct subfolders of .leo/db.
Top-level folders represent file *locations* not file contents.
Exception: the top-level "globals" folder represents minor data.

Only two files are ever needed in a top-level folder:

contents_<key>: the contents of the file.
data_<key>: a dict representing the "minor data" of the file:
    <globals> element stuff, expansion bits, etc.

We write contents_<key> only once.
By definition, its contents never changes, since the contents generates the key.
We can write data_<key> as many times as we like.

To do:
- Simplify or even eliminate the path-manipulation code in PickleShareDB.
- Use g.makeAllNonExistentDirectories to make top-level directories.
- Clear cache should clear all top-level directories.
#@nonl
#@+node:ekr.20100209114432.5751:Cache expansion bits
# Simplify the structure of the cache: put more into the "minor" files.
#@nonl
#@-node:ekr.20100209114432.5751:Cache expansion bits
#@-node:ekr.20100209160132.5770:cache notes
#@+node:ekr.20100210163813.5748:Caching buglets?
@nocolor-node

This is a recent bug, but imo it has uncovered some other caching buglets. These
buglets are not big enough to delay Leo 4.7, but the new caching scheme would
ensure they never bite.

1. The code that computes what I have been calling the top-level directory is dubious::

    dbdirname = join(g.app.homeLeoDir,'db',
            '%s_%s' % (bname,hashlib.md5(fn).hexdigest()))

The problem is that bname is only the base name of the cached file, not a name
(or key) that depends on the full path. Thus, two copies of the same file in the
same place will be cached in the same directory. Is this ominous?

2. It's not clear what caching to do with the save-to command.
#@-node:ekr.20100210163813.5748:Caching buglets?
#@+node:ekr.20100209114432.5750:Work on docs
- Better scren shots.
#@nonl
#@+node:ekr.20100204052559.5791:Mac TOC sidebar collapsible
http://groups.google.com/group/leo-editor/browse_thread/thread/abe236a45b0511c7

Python uses Sphinx for its doc, they have a discussion about making
the TOC on the left hand side collapsible/non-scrolling here:

http://www.google.com/url?sa=t&source=web&ct=res&cd=4&ved=0CBYQFjAD&url=http%3A%2F%2Fbugs.python.org%2Fissue3143&ei=bW5oS-eQIJDalAfqlYyGCA&usg=AFQjCNGyhpE3wZ2jvfwA0dwjCfoAxleDRQ&sig2=2CRD7hNMmx1NzFHMyOq_cQ

that includes code for the CSS stylesheet to do this.

Although this does not appear in the python docs (yet), it might be
valuable for Leo's Doc's



I downloaded the example files from the above link, the collapsible
sidebar works well with the python documentation.  As the Leo
documentation is just a variant of python's, I downloaded a HTML
chapter and the support files kept in .../static, then I placed the
"sidebar.js" in with those files on my local copy.  To make the
sidebar collapsing work, all I had to do was add it to the list of
javascript files in the chapter .html file, i.e., I added the second
line below

    <script type="text/javascript" src="IPythonBridge_files/
doctools.js"></script>
    <script type="text/javascript" src="IPythonBridge_files/
sidebar.js"></script>

in the 'head' section, (the above takes into account that I was doing
this on my local, differently arranged, copy).

That is all that it takes to give us a collapsible TOC
#@nonl
#@-node:ekr.20100204052559.5791:Mac TOC sidebar collapsible
#@-node:ekr.20100209114432.5750:Work on docs
#@+node:ekr.20100118143729.6256:Wish-list bug 508108: No methods sub-nodes in PHP class import
@nocolor-node

EKR: this is a wish-list item

https://bugs.launchpad.net/leo-editor/+bug/508108

When importing a PHP class file, I get two nodes: the first is just some Leo
definitions (@language, @tab, @others), while the second is the whole class. I
expect Leo to create a node for each method in the class as it does for
"classless" file of functions (not sure how it is done in other languages). This
kind of change would also make @auto a lot more useful for PHP.
#@nonl
#@-node:ekr.20100118143729.6256:Wish-list bug 508108: No methods sub-nodes in PHP class import
#@+node:ekr.20100206173123.5801:Fix or eliminate check python syntax commands
@nocolor-node

Directives and section references are not the problem. Rather, the problems are
thinks like 'return' in a node that doesn't look it is in a function.

The solution would likely be to check the entire file at once in checkPython
code. But this won't work for the check-all-python-code command.

Do we really need these checks? I think not, because the automatic checks work
so well.
#@nonl
#@+node:ekr.20100206142026.5967:To do: use g.checkPythonNode as the base of all syntax checking
#@+node:ekr.20040723094220.5:c.checkPythonNode
def checkPythonNode (self,p,unittest=False,suppressErrors=False):

    c = self ; h = p.h

    # Call getScript to ignore directives and section references.
    body = g.getScript(c,p.copy())
    if not body: return

    try:
        fn = '<node: %s>' % p.h
        if not g.isPython3:
            body = g.toEncodedString(body)
        compile(body+'\n',fn,'exec')
        c.tabNannyNode(p,h,body,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=False,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise

#@-node:ekr.20040723094220.5:c.checkPythonNode
#@+node:EKR.20040614071102.1:g.getScript
def getScript (c,p,useSelectedText=True,forcePythonSentinels=True,useSentinels=True):

    '''Return the expansion of the selected text of node p.
    Return the expansion of all of node p's body text if there
    is p is not the current node or if there is no text selection.'''

    # New in Leo 4.6 b2: use a pristine atFile handler
    # so there can be no conflict with c.atFileCommands.
    # at = c.atFileCommands
    import leo.core.leoAtFile as leoAtFile
    at = leoAtFile.atFile(c)

    w = c.frame.body.bodyCtrl
    p1 = p and p.copy()
    if not p:
        p = c.p
    try:
        if g.app.inBridge:
            s = p.b
        elif p1:
            s = p.b # Bug fix: Leo 8.8.4.
        elif p == c.p:
            if useSelectedText and w.hasSelection():
                s = w.getSelectedText()
            else:
                s = w.getAllText()
        else:
            s = p.b
        # Remove extra leading whitespace so the user may execute indented code.
        s = g.removeExtraLws(s,c.tab_width)
        if s.strip():
            g.app.scriptDict["script1"]=s
            # Important: converts unicode to utf-8 encoded strings.
            script = at.writeFromString(p.copy(),s,
                forcePythonSentinels=forcePythonSentinels,
                useSentinels=useSentinels)
            script = script.replace("\r\n","\n") # Use brute force.
            # Important, the script is an **encoded string**, not a unicode string.
            g.app.scriptDict["script2"]=script
        else: script = ''
    except Exception:
        g.es_print("unexpected exception in g.getScript")
        g.es_exception()
        script = ''

    # g.trace(type(script),repr(script))
    return script
#@-node:EKR.20040614071102.1:g.getScript
#@+node:ekr.20050506084734:writeFromString (atFile)
# This is at.write specialized for scripting.

def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):

    """Write a 4.x derived file from a string.

    This is used by the scripting logic."""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline, but don't change the focus!

    at.initWriteIvars(root,"<string-file>",
        nosentinels=not useSentinels,thinFile=False,scriptWrite=True,toString=True,
        forcePythonSentinels=forcePythonSentinels)

    try:
        ok = at.openFileForWriting(root,at.targetFileName,toString=True)
        if g.app.unitTesting: assert ok # string writes never fail.
        # Simulate writing the entire file so error recovery works.
        at.writeOpenFile(root,nosentinels=not useSentinels,toString=True,fromString=s)
        at.closeWriteFile()
        # Major bug: failure to clear this wipes out headlines!
        # Minor bug: sometimes this causes slight problems...
        if root:
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
    except Exception:
        at.exception("exception preprocessing script")

    return at.stringOutput
#@-node:ekr.20050506084734:writeFromString (atFile)
#@+node:ekr.20100206142026.5839:g.checkPythonNode & helper (NEW)
def checkPythonNode (c,s,fn=None,p=None,
    munge=False,suppressErrors=False,
    tabNanny=False,unittest=False,
    suppressErrors=False,
):

    '''The future base of all syntax checking'''

    if not s.strip():
        return
    if munge:
        at = c.atFileCommands
        s = g.toUnicode(s)
        at.writeFromString(p=None,s=s,
            forcePythonSentinels=True,useSentinels=True)
    if not s.strip():
        return
    if fn:
        pass
    elif p:
        fn = '<node: %s>' % p.h
    else:
        fn = '<string'>
    try:
        if not g.isPython3:
            s = g.toEncodedString(s)
        s = s.replace('\r','')
        compile(s+'\n',fn,'exec')
        if tabNanny:
            c.tabNannyNode(p,h,s,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=True,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise
#@+node:ekr.20100206142026.5840:checkPythonNodeHelper
def checkPythonNodeHelper (c,s):




    return g.toUnicode(
        .writeFromString(p = None,s=s,
        forcePythonSentinels=True,useSentinels=True)
#@-node:ekr.20100206142026.5840:checkPythonNodeHelper
#@-node:ekr.20100206142026.5839:g.checkPythonNode & helper (NEW)
#@+node:ekr.20060624085200:g.handleScriptException
def handleScriptException (c,p,script,script1):

    g.es("exception executing script",color='blue')

    full = c.config.getBool('show_full_tracebacks_in_scripts')

    fileName, n = g.es_exception(full=full)

    if p and not script1 and fileName == "<string>":
        c.goToScriptLineNumber(p,script,n)

    << dump the lines near the error >>
#@+node:EKR.20040612215018:<< dump the lines near the error >>
if g.os_path_exists(fileName):
    f = open(fileName)
    lines = f.readlines()
    f.close()
else:
    lines = g.splitLines(script)

s = '-' * 20
g.es_print('',s)

# Print surrounding lines.
i = max(0,n-2)
j = min(n+2,len(lines))
while i < j:
    ch = g.choose(i==n-1,'*',' ')
    s = "%s line %d: %s" % (ch,i+1,lines[i])
    g.es('',s,newline=False)
    i += 1
#@-node:EKR.20040612215018:<< dump the lines near the error >>
#@-node:ekr.20060624085200:g.handleScriptException
#@-node:ekr.20100206142026.5967:To do: use g.checkPythonNode as the base of all syntax checking
#@+node:ekr.20040723094220:Check Outline commands & allies
#@+node:ekr.20040723094220.1:c.checkAllPythonCode
def checkAllPythonCode(self,event=None,unittest=False,ignoreAtIgnore=True):

    '''Check all nodes in the selected tree for syntax and tab errors.'''

    c = self ; count = 0 ; result = "ok"

    for p in c.all_unique_positions():
        count += 1
        if not unittest:
            << print dots >>

        if g.scanForAtLanguage(c,p) == "python":
            if not g.scanForAtSettings(p) and (
                not ignoreAtIgnore or not g.scanForAtIgnore(c,p)
            ):
                try:
                    c.checkPythonNode(p,unittest)
                except (SyntaxError,tokenize.TokenError,tabnanny.NannyNag):
                    result = "error" # Continue to check.
                except Exception:
                    return "surprise" # abort
                if unittest and result != "ok":
                    g.pr("Syntax error in %s" % p.cleanHeadString())
                    return result # End the unit test: it has failed.

    if not unittest:
        g.es("check complete",color="blue")

    return result
#@+node:ekr.20040723094220.2:<< print dots >>
if count % 100 == 0:
    g.es('','.',newline=False)

if count % 2000 == 0:
    g.enl()
#@-node:ekr.20040723094220.2:<< print dots >>
#@-node:ekr.20040723094220.1:c.checkAllPythonCode
#@+node:ekr.20040723094220.3:c.checkPythonCode
def checkPythonCode (self,event=None,
    unittest=False,ignoreAtIgnore=True,
    suppressErrors=False,checkOnSave=False):

    '''Check the selected tree for syntax and tab errors.'''

    c = self ; count = 0 ; result = "ok"

    if not unittest:
        g.es("checking Python code   ")

    for p in c.p.self_and_subtree():

        count += 1
        if not unittest and not checkOnSave:
            << print dots >>

        if g.scanForAtLanguage(c,p) == "python":
            if not ignoreAtIgnore or not g.scanForAtIgnore(c,p):
                try:
                    c.checkPythonNode(p,unittest,suppressErrors)
                except (SyntaxError,tokenize.TokenError,tabnanny.NannyNag):
                    result = "error" # Continue to check.
                except Exception:
                    return "surprise" # abort

    if not unittest:
        g.es("check complete",color="blue")

    # We _can_ return a result for unit tests because we aren't using doCommand.
    return result
#@+node:ekr.20040723094220.4:<< print dots >>
if count % 100 == 0:
    g.es('','.',newline=False)

if count % 2000 == 0:
    g.enl()
#@-node:ekr.20040723094220.4:<< print dots >>
#@-node:ekr.20040723094220.3:c.checkPythonCode
#@+node:ekr.20040723094220.5:c.checkPythonNode
def checkPythonNode (self,p,unittest=False,suppressErrors=False):

    c = self ; h = p.h

    # Call getScript to ignore directives and section references.
    body = g.getScript(c,p.copy())
    if not body: return

    try:
        fn = '<node: %s>' % p.h
        if not g.isPython3:
            body = g.toEncodedString(body)
        compile(body+'\n',fn,'exec')
        c.tabNannyNode(p,h,body,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=False,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise

#@-node:ekr.20040723094220.5:c.checkPythonNode
#@+node:ekr.20040723094220.6:c.tabNannyNode
# This code is based on tabnanny.check.

def tabNannyNode (self,p,headline,body,unittest=False,suppressErrors=False):

    """Check indentation using tabnanny."""

    c = self

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))

    except IndentationError:
        junk,msg,junk = sys.exc_info()
        if not suppressErrors:
            g.es("IndentationError in",headline,color="blue")
            g.es('',msg)
        if unittest: raise

    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        if not suppressErrors:
            g.es("TokenError in",headline,color="blue")
            g.es('',msg)
        if unittest: raise

    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        if not suppressErrors:
            badline = nag.get_lineno()
            line    = nag.get_line()
            message = nag.get_msg()
            g.es("indentation error in",headline,"line",badline,color="blue")
            g.es(message)
            line2 = repr(str(line))[1:-1]
            g.es("offending line:\n",line2)
        if unittest: raise

    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
        if unittest: raise
#@-node:ekr.20040723094220.6:c.tabNannyNode
#@-node:ekr.20040723094220:Check Outline commands & allies
#@-node:ekr.20100206173123.5801:Fix or eliminate check python syntax commands
#@+node:ekr.20100127064113.6206:fix pylint
#  unbound recursion...

def unbound():
    unbound()

unbound()
#@nonl
#@-node:ekr.20100127064113.6206:fix pylint
#@+node:ekr.20100209224508.5744:Calls to .write
All these could be considered potential Python 3.x bugs.  Most are not.
#@nonl
#@+node:ekr.20031218072017.1470:put
def put (self,s):

    '''Put string s to self.outputFile. All output eventually comes here.'''

    # Improved code: self.outputFile (a cStringIO object) always exists.
    # g.trace(g.callers(1),repr(s))
    if s:
        self.putCount += 1
        if not g.isPython3:
            s = g.toEncodedString(s,self.leo_file_encoding,reportErrors=True)
        self.outputFile.write(s)

def put_dquote (self):
    self.put('"')

def put_dquoted_bool (self,b):
    if b: self.put('"1"')
    else: self.put('"0"')

def put_flag (self,a,b):
    if a:
        self.put(" ") ; self.put(b) ; self.put('="1"')

def put_in_dquotes (self,a):
    self.put('"')
    if a: self.put(a) # will always be True if we use backquotes.
    else: self.put('0')
    self.put('"')

def put_nl (self):
    self.put("\n")

def put_tab (self):
    self.put("\t")

def put_tabs (self,n):
    while n > 0:
        self.put("\t")
        n -= 1
#@nonl
#@-node:ekr.20031218072017.1470:put
#@+node:ekr.20100119145629.6111:writeToFileHelper & helpers
def writeToFileHelper (self,fileName,toOPML):

    c = self.c ; toZip = c.isZipped
    ok,backupName = self.createBackupFile(fileName)
    if not ok: return False
    fileName,theActualFile = self.createActualFile(fileName,toOPML,toZip)
    self.mFileName = fileName
    self.outputFile = StringIO() # Always write to a string.

    try:
        if toOPML:
            self.putToOPML()
        else:
            self.putLeoFile()
        s = self.outputFile.getvalue()
        g.app.write_Leo_file_string = s # 2010/01/19: always set this.
        if toZip:
            self.writeZipFile(s)
        else:
            if g.isPython3:
                s = bytes(s,self.leo_file_encoding,'replace')
            theActualFile.write(s)
            theActualFile.close()
            c.setFileTimeStamp(fileName)
            # raise AttributeError # To test handleWriteLeoFileException.
            # Delete backup file.
            if backupName and g.os_path_exists(backupName):
                self.deleteFileWithMessage(backupName,'backup')
        return True
    except Exception:
        self.handleWriteLeoFileException(
            fileName,backupName,theActualFile)
        return False
#@+node:ekr.20100119145629.6106:createActualFile
def createActualFile (self,fileName,toOPML,toZip):

    c = self.c

    if toOPML and not self.mFileName.endswith('opml'):
        fileName = self.mFileName + '.opml'

    if toZip:
        self.toString = True
        theActualFile = None
    else:
        try:
            # 2010/01/21: always write in binary mode.
            theActualFile = open(fileName,'wb')
        except IOError:
            theActualFile = None

    return fileName,theActualFile
#@-node:ekr.20100119145629.6106:createActualFile
#@+node:ekr.20031218072017.3047:createBackupFile (fileCommands)
def createBackupFile (self,fileName):

    '''
        Create a closed backup file and copy the file to it,
        but only if the original file exists.
    '''

    c = self.c

    if g.os_path_exists(fileName):
        # backupName = g.os_path_join(g.app.loadDir,fileName+'.bak')

        fd,backupName = tempfile.mkstemp(text=False)
        f = open(fileName,'rb') # rb is essential.
        s = f.read()
        f.close()

        try:
            try:
                os.write(fd,s)
            finally:
                os.close(fd)
            ok = True
        except Exception:
            g.es('exception creating backup file',color='red')
            g.es_exception()
            ok,backupName = False,None

        if not ok and self.read_only:
            g.es("read only",color="red")
    else:
        ok,backupName = True,None

    return ok,backupName
#@-node:ekr.20031218072017.3047:createBackupFile (fileCommands)
#@+node:ekr.20100119145629.6108:handleWriteLeoFileException
def handleWriteLeoFileException(self,fileName,backupName,theActualFile):

    c = self.c

    g.es("exception writing:",fileName)
    g.es_exception(full=True)

    if theActualFile:
        theActualFile.close()

    # Delete fileName.
    if fileName and g.os_path_exists(fileName):
        self.deleteFileWithMessage(fileName,'')

    # Rename backupName to fileName.
    if backupName and g.os_path_exists(backupName):
        g.es("restoring",fileName,"from",backupName)

        # No need to create directories when restoring.
        g.utils_rename(c,backupName,fileName)
    else:
        g.trace('backup file does not exist!',
            repr(backupName),color='red')
#@-node:ekr.20100119145629.6108:handleWriteLeoFileException
#@-node:ekr.20100119145629.6111:writeToFileHelper & helpers
#@+node:ekr.20031218072017.1149:<< Write s into newFileName >>
try:
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    theFile = open(newFileName,mode)
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    theFile.write(s)
    theFile.close()
    if not g.unitTesting:
        g.es("created:",newFileName)
except Exception:
    g.es("exception creating:",newFileName)
    g.es_exception()
#@-node:ekr.20031218072017.1149:<< Write s into newFileName >>
#@+node:ekr.20080713091247.1:x.replaceFileWithString
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    trace = False and not g.unitTesting
    x = self
    exists = g.os_path_exists(fn)

    if exists:
        # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s2 is None:
            return False
        if s == s2:
            if not g.unitTesting: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            x.error('not written: %s directory not found' % fn)
        return False

    # Replace the file.
    try:
        f = open(fn,'wb')
        f.write(g.toEncodedString(s))
        if trace: g.trace('fn',fn,
            '\nlines...\n%s' %(g.listToString(g.splitLines(s))),
            '\ncallers',g.callers(4))
        f.close()
        if not g.unitTesting:
            # g.trace('created:',fn,g.callers())
            if exists:  g.es('wrote:',fn)
            else:       g.es('created:',fn)
        return True
    except IOError:
        x.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@-node:ekr.20080713091247.1:x.replaceFileWithString
#@+node:ekr.20080712150045.1:replaceFileWithString (atFile)
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    at = self ; testing = g.app.unitTesting

    # g.trace('fn',fn,'s','\n',s)
    # g.trace(g.callers())

    exists = g.os_path_exists(fn)

    if exists: # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s is None:
            return False
        if s == s2:
            if not testing: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            g.es('not written: %s directory not found' % fn,color='red')
        return False

    # Replace
    try:
        f = open(fn,'wb')
        if g.isPython3:
            s = g.toEncodedString(s,encoding=self.encoding)
        f.write(s)
        f.close()
        if not testing:
            if exists:
                g.es('wrote:    ',fn)
            else:
                # g.trace('created:',fn,g.callers())
                g.es('created:',fn)
        return True
    except IOError:
        at.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@-node:ekr.20080712150045.1:replaceFileWithString (atFile)
#@+node:ekr.20070115135502:writeScriptFile
def writeScriptFile (self,script):

    # Get the path to the file.
    c = self
    path = c.config.getString('script_file_path')
    if path:
        isAbsPath = os.path.isabs(path)
        driveSpec, path = os.path.splitdrive(path)
        parts = path.split('/')
        # xxx bad idea, loadDir is often read only!
        path = g.app.loadDir
        if isAbsPath:
            # make the first element absolute
            parts[0] = driveSpec + os.sep + parts[0]
        allParts = [path] + parts
        path = c.os_path_finalize_join(*allParts)
    else:
        path = c.os_path_finalize_join(
            g.app.homeLeoDir,'scriptFile.py')                    

    # Write the file.
    try:
        if g.isPython3:
            # Use the default encoding.
            f = open(path,encoding='utf-8',mode='w')
        else:
            f = open(path,'w')
        f.write(script)
        f.close()
    except Exception:
        g.es_exception()
        g.es("Failed to write script to %s" % path)
        # g.es("Check your configuration of script_file_path, currently %s" %
            # c.config.getString('script_file_path'))
        path = None

    return path
#@nonl
#@-node:ekr.20070115135502:writeScriptFile
#@+node:ekr.20090502071837.94:write (leoRst)
def write (self,s):

    if self.trialWrite:
        pass
    elif g.isPython3:
        pass
    else:
        s = self.encode(s)

    # g.trace(repr(s),g.callers(2))

    self.outputFile.write(s)
#@-node:ekr.20090502071837.94:write (leoRst)
#@+node:ekr.20090502071837.64:writeSpecialTree
def writeSpecialTree (self,p,toString,justOneFile):

    c = self.c
    isHtml = self.ext in ('.html','.htm')
    if isHtml and not SilverCity:
        if not self.silverCityWarningGiven:
            self.silverCityWarningGiven = True
            g.es('SilverCity not present so no syntax highlighting')

    self.initWrite(p)
        # was encoding=g.choose(isHtml,'utf-8','iso-8859-1'))
    self.outputFile = StringIO()
    self.writeTree(p)
    self.source = self.outputFile.getvalue()
    self.outputFile = None

    if not toString:
        # Compute this here for use by intermediate file.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)

        # Create the directory if it doesn't exist.
        theDir, junk = g.os_path_split(self.outputFileName)
        theDir = c.os_path_finalize(theDir)
        if not g.os_path_exists(theDir):
            ok = g.makeAllNonExistentDirectories(theDir,c=c,force=False)
            if not ok:
                g.es_print('did not create:',theDir,color='red')
                return False

        # if not os.access(theDir,os.F_OK):
            # os.mkdir(theDir)

        if self.getOption('write_intermediate_file'):
            name = self.outputFileName + '.txt'
            f = open(name,'w')
            f.write(self.source)
            f.close()
            self.report(name)

    try:
        output = self.writeToDocutils(self.source)
        ok = output is not None
    except Exception:
        g.pr('Exception in docutils')
        g.es_exception()
        ok = False

    if ok:
        if isHtml:
            import re
            idxTitle = output.find('<title></title>')
            if idxTitle > -1:
                m = re.search('<h1>([^<]*)</h1>', output)
                if not m:
                    m = re.search('<h1><[^>]+>([^<]*)</a></h1>', output)
                if m:
                    output = output.replace(
                        '<title></title>',
                        '<title>%s</title>' % m.group(1)
                    )


        if toString:
            self.stringOutput = output
        else:
            # Write the file to the directory containing the .leo file.
            f = open(self.outputFileName,'w')
            f.write(output)
            f.close()
            self.http_endTree(self.outputFileName, p, justOneFile=justOneFile)

    return ok
#@-node:ekr.20090502071837.64:writeSpecialTree
#@+node:ekr.20100203050306.5937:c.createOpenWithTempFile
def createOpenWithTempFile (self,p,ext):

    trace = False and not g.unitTesting
    c = self ; f = None

    # May be over-ridden by mod_tempfname plugin.
    fn = c.openWithTempFilePath(p,ext)

    try:
        if g.os_path_exists(fn):
            g.es('recreating:  ',g.shortFileName(fn),color='red')
        else:
            g.es('creating:  ',g.shortFileName(fn),color='blue')
        f = open(fn,'w')
        # Convert s to whatever encoding is in effect.
        d = c.scanAllDirectives(p)
        encoding = d.get('encoding',None)
        if encoding == None:
            encoding = c.config.default_derived_file_encoding
        if g.isPython3: # 2010/02/09
            s = p.b
        else:
            s = g.toEncodedString(p.b,encoding,reportErrors=True) 
        f.write(s)
        f.flush()
        f.close()
        try:
            time = g.os_path_getmtime(fn)
            if time: g.es('time: ',time)
        except:
            time = None

        # Remove previous entry from app.openWithFiles if it exists.
        for d in g.app.openWithFiles[:]:
            if p.v == d.get('v'):
                if trace: g.trace('removing',d.get('path'))
                g.app.openWithFiles.remove(d)

        d = {
            # Used by app.destroyOpenWithFilesForFrame.
            'c':c,
            # Used here and by app.destroyOpenWithFileWithDict.
            'path':fn,
            # Used by c.testForConflicts.
            'body':s,
            'encoding':encoding,
            'time':time,
            # Used by the open_with plugin.
            'p':p.copy(),
            # Used by c.openWithHelper, and below.
            'v':p.v,
        }
        g.app.openWithFiles.append(d)
        return fn
    except:
        if f: f.close()
        g.es('exception creating temp file',color='red')
        g.es_exception()
        return None
#@-node:ekr.20100203050306.5937:c.createOpenWithTempFile
#@+node:ekr.20031218072017.1982:<< attempt to create leoID.txt >>
for theDir in (homeLeoDir,globalConfigDir,loadDir):
    # N.B. We would use the _working_ directory if theDir is None!
    if theDir:
        try:
            fn = g.os_path_join(theDir,tag)
            f = open(fn,'w')
            f.write(g.app.leoID)
            f.close()
            if g.os_path_exists(fn):
                g.es_print('',tag,'created in',theDir,color='red')
                return
        except IOError:
            pass

        g.es('can not create',tag,'in',theDir,color='red')
#@-node:ekr.20031218072017.1982:<< attempt to create leoID.txt >>
#@+node:ekr.20041005105605.155:<< Write p's headline if it starts with @@ >>
s = p.h

if g.match(s,0,"@@"):
    s = s[2:]
    if s and len(s) > 0:
        s = g.toEncodedString(s,at.encoding,reportErrors=True) # 3/7/03
        at.outputFile.write(s)
#@-node:ekr.20041005105605.155:<< Write p's headline if it starts with @@ >>
#@+node:ekr.20041005105605.204:os
def os (self,s):

    """Write a string to the output stream.

    All output produced by leoAtFile module goes here."""

    trace = False and not g.unitTesting
    at = self ; tag = self.underindentEscapeString
    f = at.outputFile

    if s and f:
        try:
            if s.startswith(tag):
                junk,s = self.parseUnderindentTag(s)
            # Bug fix: this must be done last.
            s = g.toEncodedString(s,at.encoding,reportErrors=True)
            if trace: g.trace(repr(s),g.callers(5))
            f.write(s)
        except Exception:
            at.exception("exception writing:" + s)
#@-node:ekr.20041005105605.204:os
#@+node:ekr.20070915142635:writeFileFromNode
def writeFileFromNode (self,event=None):

    # If node starts with @read-file-into-node, use the full path name in the headline.
    # Otherwise, prompt for a file name.

    c = self ; p = c.p
    c.endEditing()

    h = p.h.rstrip()
    s = p.b
    tag = '@read-file-into-node'

    if h.startswith(tag):
        fileName = h[len(tag):].strip()
    else:
        fileName = None

    if not fileName:
        filetypes = [("All files", "*"),("Python files","*.py"),("Leo files", "*.leo"),]
        fileName = g.app.gui.runSaveFileDialog(
            initialfile=None,
            title='Write File From Node',
            filetypes=filetypes,
            defaultextension=None)
    if fileName:
        try:
            theFile = open(fileName,'w')
            g.chdir(fileName)
        except IOError:
            theFile = None
        if theFile:
            if s.startswith('@nocolor\n'):
                s = s[len('@nocolor\n'):]
            theFile.write(s)
            theFile.flush()
            g.es_print('wrote:',fileName,color='blue')
            theFile.close()
        else:
            g.es('can not write %s',fileName,color='red')
#@nonl
#@-node:ekr.20070915142635:writeFileFromNode
#@+node:ekr.20050424131051:writeRecentFilesFileHelper
def writeRecentFilesFileHelper (self,fileName):
    # g.trace(fileName)

    # Don't update the file if it begins with read-only.
    theFile = None
    try:
        theFile = open(fileName)
        lines = theFile.readlines()
        if lines and self.munge(lines[0])=='readonly':
            # g.trace('read-only: %s' %fileName)
            return
    except IOError:
        # The user may have erased a file.  Not an error.
        if theFile: theFile.close()

    theFile = None
    try:
        theFile = open(fileName,'w')
        if self.recentFiles:
            s = '\n'.join(self.recentFiles)
            theFile.write(s)
        else:
            theFile.write(g.toEncodedString('\n'))

    except IOError:
        # The user may have erased a file.  Not an error.
        pass

    except Exception:
        g.es('unexpected exception writing',fileName,color='red')
        g.es_exception()

    if theFile:
        theFile.close()
#@-node:ekr.20050424131051:writeRecentFilesFileHelper
#@+node:ekr.20050920084036.24:writeAbbreviations
def writeAbbreviations (self,event):

    '''Write abbreviations to a file.'''

    fileName = g.app.gui.runSaveFileDialog(
        initialfile = None,
        title='Write Abbreviations',
        filetypes = [("Text","*.txt"), ("All files","*")],
        defaultextension = ".txt")

    if not fileName: return

    try:
        f = open(fileName,'w')
        for x in self.abbrevs:
            f.write('%s=%s\n' % (x,self.abbrevs[x]))
        f.close()
    except IOError:
        g.es('can not create',fileName)
#@-node:ekr.20050920084036.24:writeAbbreviations
#@+node:ekr.20050920084036.170:saveFile
def saveFile (self,event):

    '''Prompt for the name of a file and put the body text of the selected node into it..'''

    w = self.editWidget(event)
    if not w: return

    fileName = g.app.gui.runSaveFileDialog(
        initialfile = None,
        title='save-file',
        filetypes = [("Text","*.txt"), ("All files","*")],
        defaultextension = ".txt")

    if not fileName: return

    try:
        s = w.getAllText()
        f = open(fileName,'w')
        f.write(s)
        f.close()
    except IOError:
        g.es('can not create',fileName)
#@-node:ekr.20050920084036.170:saveFile
#@+node:ekr.20051025071455.37:add (spellTab)
def add(self,event=None):
    """Add the selected suggestion to the dictionary."""

    if not self.currentWord: return

    # g.trace(self.currentWord)

    try:
        f = None
        try:
            # Rewrite the dictionary in alphabetical order.
            f = open(self.dictionaryFileName, "r")
            words = f.readlines()
            f.close()
            words = [word.strip() for word in words]
            words.append(self.currentWord)
            words.sort()
            f = open(self.dictionaryFileName, "w")
            for word in words:
                f.write("%s\n" % g.toEncodedString(word,reportErrors=True))
            f.flush()
            f.close()
            if 1:
                s = 'Spell: added %s' % self.currentWord
                self.messages.append(s)
            else: # Too distracting.
                g.es("adding ", color= "blue", newline= False) 
                g.es('','%s' % self.currentWord)
        except IOError:
            g.es("can not add",self.currentWord,"to dictionary",color="red")
    finally:
        if f: f.close()

    self.dictionary[self.currentWord.lower()] = 0
    self.tab.onFindButton()
#@-node:ekr.20051025071455.37:add (spellTab)
#@+node:ekr.20041012091252:rawPrint
def rawPrint (self,s):

    if self.old:
        self.old.write(s+'\n')
    else:
        g.pr(s)
#@-node:ekr.20041012091252:rawPrint
#@+node:ekr.20031218072017.1462:exportHeadlines
def exportHeadlines (self,fileName):

    c = self.c ; nl = g.u(self.output_newline)
    p = c.p
    if not p: return
    self.setEncoding()
    firstLevel = p.level()
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    try:
        theFile = open(fileName,mode)
    except IOError:
        g.es("can not open",fileName,color="blue")
        leoTest.fail()
        return
    for p in p.self_and_subtree():
        head = p.moreHead(firstLevel,useVerticalBar=True)
        s = g.toEncodedString(head + nl,self.encoding,reportErrors=True)
        theFile.write(s)
    theFile.close()
#@-node:ekr.20031218072017.1462:exportHeadlines
#@+node:ekr.20031218072017.1147:flattenOutline
def flattenOutline (self,fileName):

    c = self.c ; nl = g.u(self.output_newline)
    p = c.currentVnode()
    if not p: return
    self.setEncoding()
    firstLevel = p.level()

    # 10/14/02: support for output_newline setting.
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    try:
        theFile = open(fileName,mode)
    except IOError:
        g.es("can not open",fileName,color="blue")
        leoTest.fail()
        return

    for p in p.self_and_subtree():
        head = p.moreHead(firstLevel)
        s = g.toEncodedString(head + nl,encoding=self.encoding,reportErrors=True)
        theFile.write(s)
        body = p.moreBody() # Inserts escapes.
        if len(body) > 0:
            s = g.toEncodedString(body + nl,self.encoding,reportErrors=True)
            theFile.write(s)
    theFile.close()
#@-node:ekr.20031218072017.1147:flattenOutline
#@+node:ekr.20031218072017.1148:outlineToWeb
def outlineToWeb (self,fileName,webType):

    c = self.c ; nl = self.output_newline
    current = c.p
    if not current: return
    self.setEncoding()
    self.webType = webType
    # 10/14/02: support for output_newline setting.
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    try:
        theFile = open(fileName,mode)
    except IOError:
        g.es("can not open",fileName,color="blue")
        leoTest.fail()
        return

    self.treeType = "@file"
    # Set self.treeType to @root if p or an ancestor is an @root node.
    for p in current.parents():
        flag,junk = g.is_special(p.b,0,"@root")
        if flag:
            self.treeType = "@root"
            break
    for p in current.self_and_subtree():
        s = self.convertVnodeToWeb(p)
        if len(s) > 0:
            s = g.toEncodedString(s,self.encoding,reportErrors=True)
            theFile.write(s)
            if s[-1] != '\n': theFile.write(nl)
    theFile.close()
#@-node:ekr.20031218072017.1148:outlineToWeb
#@+node:ekr.20031218072017.1464:weave
def weave (self,filename):

    c = self.c ; nl = self.output_newline
    p = c.p
    if not p: return
    self.setEncoding()
    << open filename to f, or return >>
    for p in p.self_and_subtree():
        s = p.b
        s2 = s.strip()
        if s2 and len(s2) > 0:
            f.write("-" * 60) ; f.write(nl)
            << write the context of p to f >>
            f.write("-" * 60) ; f.write(nl)
            s = g.toEncodedString(s,self.encoding,reportErrors=True)
            f.write(s.rstrip() + nl)
    f.flush()
    f.close()
#@+node:ekr.20031218072017.1150:<< open filename to f, or return >>
try:
    # 10/14/02: support for output_newline setting.
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    f = open(filename,mode)
    if not f: return
except Exception:
    g.es("exception opening:",filename)
    g.es_exception()
    return
#@-node:ekr.20031218072017.1150:<< open filename to f, or return >>
#@+node:ekr.20031218072017.1465:<< write the context of p to f >>
# write the headlines of p, p's parent and p's grandparent.
context = [] ; p2 = p.copy() ; i = 0
while i < 3:
    i += 1
    if not p2: break
    context.append(p2.h)
    p2.moveToParent()

context.reverse()
indent = ""
for line in context:
    f.write(indent)
    indent += '\t'
    line = g.toEncodedString(line,self.encoding,reportErrors=True)
    f.write(line)
    f.write(nl)
#@-node:ekr.20031218072017.1465:<< write the context of p to f >>
#@-node:ekr.20031218072017.1464:weave
#@+node:ekr.20031218072017.1465:<< write the context of p to f >>
# write the headlines of p, p's parent and p's grandparent.
context = [] ; p2 = p.copy() ; i = 0
while i < 3:
    i += 1
    if not p2: break
    context.append(p2.h)
    p2.moveToParent()

context.reverse()
indent = ""
for line in context:
    f.write(indent)
    indent += '\t'
    line = g.toEncodedString(line,self.encoding,reportErrors=True)
    f.write(line)
    f.write(nl)
#@-node:ekr.20031218072017.1465:<< write the context of p to f >>
#@+node:ekr.20090502071837.61:writeNormalTree
def writeNormalTree (self,p,toString=False):

    self.initWrite(p)

    # Always write to a string first.
    self.outputFile = StringIO()
    self.writeTree(p)
    self.source = self.stringOutput = self.outputFile.getvalue()

    # Copy to a file if requested.
    if not toString:
        # Comput the output file name *after* calling writeTree.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)
        self.outputFile = open(self.outputFileName,'w')
        self.outputFile.write(self.stringOutput)
        self.outputFile.close()

    return True
#@-node:ekr.20090502071837.61:writeNormalTree
#@+node:ekr.20080822065427.4:show_error_lines
def show_error_lines (self,lines,fileName):

    for line in lines:
        g.es_print(line)

    if False: # Only for major debugging.
        try:
            f1 = open(fileName, "w")
            for line in lines:
                f1.write(g.toEncodedString(line))
            f1.close()
        except IOError:
            g.es_exception()
            g.es_print('can not open',fileName)
#@-node:ekr.20080822065427.4:show_error_lines
#@+node:ekr.20031218072017.1488:oblank, oblanks, os, otab, otabs (Tangle)
def oblank (self):
    self.oblanks(1)

def oblanks (self,n):
    if abs(n) > 0:
        s = g.toEncodedString(' ' * abs(n),encoding=self.encoding)
        self.output_file.write(s)

def onl(self):
    s = self.output_newline
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    self.output_file.write(s)

def os (self,s):
    s = s.replace('\r','\n')
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    self.output_file.write(s)

def otab (self):
    self.otabs(1)

def otabs (self,n):
    if abs(n) > 0:
        s = g.toEncodedString('\t' * abs(n),self.encoding,reportErrors=True)
        self.output_file.write(s)
#@-node:ekr.20031218072017.1488:oblank, oblanks, os, otab, otabs (Tangle)
#@+node:ekr.20031218072017.3650:show
def show (self,s):

    # g.pr(s)
    if self.outputFile:
        s = g.toEncodedString(s + '\n')
        self.outputFile.write(s)
    elif self.c:
        g.es(s)
    else:
        g.pr(s)
        g.pr('')
#@-node:ekr.20031218072017.3650:show
#@-node:ekr.20100209224508.5744:Calls to .write
#@-node:ekr.20100209160132.5771:until-4-7-final branch
#@+node:ekr.20100109214940.6225:4.8 vim, cleanups, your mission...
#@+node:ekr.20100206074650.5852:Posting re "your mission, should you choose to accept it"
#@+node:ekr.20090202064534.4:Your mission, should you choose to accept it
@nocolor-node

Here are the emacs features that I use very often that any editor would
need to have in order for me to switch.  I've seen some editors with
some of these, but none with all unless it is an emacs clone.  I'll
leave out the obvious things like platform independence, good syntax
highlighting, calltips or auto-completion.  Also, these features are
just dealing with the code editor portion of the app, if it is more than
that (like a full IDE) then some of these things may or may not apply to
the non code editor parts:

* (done) Python should be just one of the languages that this editor supports,
not the primary target.  I spend as much time in C/C++ as I do Python,
and my editor of choice needs to help me with C/C++ coding just as much
as it does with Python.  So some sort of support for calltips and
auto-completion would be marvelous, and also being able to act as a
front-end for gdb since I currently use emacs for that most of the time.

* (done) Absolutely every feature or action must be able to be done with just
the keyboard.  Moving the hand back and forth to the mouse wastes time,
breaks concentration and contributes to RSI.  Multi-key sequences are
fine as long as they are grouped in a logical fashion.  For example in
emacs all of the version control features are accessible via the
Ctrl-x,v sequence plus one more letter.

* (to be improved) Incremental search, both forward and reverse, and wrapping around
after you've reached the end or the beginning of the document.  I like
to have the same key to start the search and also do a search-next after
you've typed all the characters you are searching for, and also to have
backspace go back one search position and/or remove one character from
the search text.

* (done) Multiple top level windows, and able to show any buffer in any TLW,
including those that are already displayed in another TLW.  Of course
there should be key-bindings available for opening a new TLW, cycling
forward and backward through the buffer list, and a way to select a
buffer from a popup list of buffer/file names.

* (to be improved) The Kill-Ring.  For those of you that have never used an emacs-like
editor it works like this:  There is a collection of the N previous
blocks of text that have been cut or copied (in emacs 'cut' == 'kill'
more or less)  When I do a yank (paste) it uses the last thing put in
the kill-ring.  If I then immediately use another key-binding then it
replaces that pasted text with the next item in the kill ring, and so on
until I eventually wrap around get back to the first one in the ring, or
I do some other command or move the cursor somewhere else.

* (done) Registers.  A text snippet can be copied into a register, which is
like the kill ring except you refer to each one by name, where the names
are 'a' through 'z'.  You can also append to a register that already has
text in it, and you can paste the contents of a register into the
document at the current cursor location.

* (done) Able to have selections be either a stream of characters or a
rectangle.  A stream selection is like what you have in all text
editors, it starts from position a on line N and continues forward or
back to position b on line M and includes all the characters in between.
  A rectangle selection is all the characters between position a and b
on lines N to M.  In other words, it has width and height and it might
be something like positions 5 through 10 on lines 20 to 25.  Cutting or
deleting a rectangle removes the text in the rectangle and shifts any
text to the right of the rectangle over.  It does not remove any lines
although they may end up being empty.  Pasting a rectangle inserts the
new text with the upper-left of the rectangle at the current cursor
position, shifts existing text to the right if needed, and fills with
spaces on the left if a line affected by the paste is not long enough.
New lines are not added unless the file needs to be extended to
accommodate the rectangle paste.  Rectangles can also be put into registers.

* (to be improved) Good keystroke macro recording and the ability to save and load
keystroke macros, and the ability to assign a key-binding to a saved
recorded macro. Any time I need to make the same edits to a bunch of
lines or groups of lines I'll record doing it on the first one including
the keystrokes needed to reposition for the next line, and then stop
recording and then it's just one keystroke to replay the keystrokes for
every other line that needs it done.  I record, use and throw away up to
a dozen or so macros per day.

* (done, and better than asserted) If you must have a toolbar make it optional
and keep it simple. Toolbars require the mouse and the goal is to keep the hand
off the mouse as much as possible.

* (done) Similarly, avoid using popup dialogs whenever possible.  This includes
things like the file dialog.  I don't mind seeing the file dialog if I
select a menu item, because most likely my hand is already on the mouse,
but the rest of the time I just want to hit a key, type a path name
(with tab-completion to help find stuff, up/down keys to cycle through
past selections) and press enter.  So I would prefer this editor to have
something like emacs' minibuffer, or the QuickFind panel in Firefox.  In
other words, when there is something you would normally use a dialog for
just create a small panel that rolls up from the bottom of the frame,
put the keyboard focus there, perhaps do stuff in the main buffer as
they are typing if appropriate, and then when the user is done the panel
rolls out of sight again and keyboard focus is restored to their active
buffer.  This can be done for file open/saves, search & replace,
specifying build or grep commands (see next item) choosing to execute
some editor function by name that may not have some key-binding yet (see
item after next) etc.

* (done, with user @commands)
Flexible build/grep commands.  Emacs handles both of these in almost
the same way so I'll list them together here.  I hit a key and am
presented with either the default, or the most recently used compile or
grep command.  I can edit the command or use the up/down arrows to
select previous commands that I've used.  I then hit enter and emacs
runs the command putting the output in an editor buffer.  There is a key
I can hit to kill the compile if needed.  It then parses the output and
there is a key I can use to find the file listed in the compile or grep
output, load it, and position the cursor on the reported line.  (This
can even be done while the compile/grep is still running.)

* (done) For access to editor commands/functionality that may not be bound to a
keystroke it's real nice to have the ability to hit a key, type the
command name, press enter and then it's done.  This can also allow for
commands that might need to prompt for parameters, be interactive, etc.
  All editor commands should be named and can be bound to keys by name
or executed by name in this way.

* (done) Regex search.  Emacs has support for regular expression search modes
for all of the search types, incremental search, search/replace,
although I don't use it that much.

* (done, or not needed, depending on your point of view)
Multi-file search and replace.  Be able to select files interactively,
or by wildcard, or both.  Enter search string, or regex, and replace
text.  The editor loads each file and does the search, allowing you to
choose for each one whether to do the replacement, or replace all.

* If it is a full IDE it would be nice to have a way to start just the
code editor portion for quick edits.

Things that would be nice to have, but that I could live without:
(All of these things can be done easily with @command)

* Interactive diffs, merges and applying of patches.

* Able to be a front-end for gdb.

* Able to be a front-end for CVS, SVN, etc.

* Be able to run shell commands, or the shell itself in an editor buffer.

* have a built-in psychotherapist or be able to play towers of hanoi.  ;-) 
#@nonl
#@+node:ekr.20100206074650.5848:Done
* Python should be just one of the languages that this editor supports, not the
primary target.

* Absolutely every feature or action must be able to be done with just the
keyboard.

* Multiple top level windows, and able to show any buffer in any TLW, including
those that are already displayed in another TLW.

* Registers.

* A rectangle selection and paste.

* Regex search.

* Good keystroke macro recording and the ability to save and load keystroke
macros, and the ability to assign a key-binding to a saved recorded macro.

* If you must have a toolbar make it optional and keep it simple.

Aside: Leo shows that Robin's assertion that "Toolbars require the mouse" is
incorrect.

* Avoid using popup dialogs whenever possible.

* So I would prefer this editor to have something like emacs' minibuffer.

* For access to editor commands/functionality that may not be bound to a
keystroke it's real nice to have the ability to hit a key, type the command
name, press enter and then it's done. This can also allow for commands that
might need to prompt for parameters, be interactive, etc. All editor commands
should be named and can be bound to keys by name or executed by name in this
way.

* If it is a full IDE it would be nice to have a way to start just the code
editor portion for quick edits.

* Able to be a front-end for gdb. (With a Leo plugin)

* Be able to run shell commands, or the shell itself in an editor buffer.

* have a built-in psychotherapist or be able to play towers of hanoi. ;-)
#@nonl
#@-node:ekr.20100206074650.5848:Done
#@+node:ekr.20100206074650.5851:Not needed
Not done, but could be done in @command easily enough

* Flexible build/grep commands.

* Multi-file search and replace.

* Interactive diffs, merges and applying of patches.

* Able to be a front-end for CVS, SVN, etc.

* Typing completion for file dialogs.
#@nonl
#@-node:ekr.20100206074650.5851:Not needed
#@+node:ekr.20100206074650.5850:To be improved
* The Kill-Ring.

* Incremental search, both forward and reverse, and wrapping around after you've
reached the end or the beginning of the document.
#@-node:ekr.20100206074650.5850:To be improved
#@-node:ekr.20090202064534.4:Your mission, should you choose to accept it
#@-node:ekr.20100206074650.5852:Posting re "your mission, should you choose to accept it"
#@+node:ekr.20100206074650.5844:Cleanups & features: first
#@+node:ekr.20100202145902.6106:Init all settings in c.initConfigSettings
@nocolor-node

To do:

- remove most of the logic in configSettings.__init__.
- Move config ivars to the commander.
#@nonl
#@+node:ekr.20100130042842.6404:Reading settings (do not delete)
Here are the calls to g.app.getxxx

# runLeo.createFrame
fileName = g.app.config.getString(c=None,setting='default_leo_file')

# c.configSettings.initIvar
# Why not init these settings by hand???
val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

# g.es and g.es_print
keys['color'] = g.app.config.getColor(None,"log_error_color") or 'red'

# leoPlugins.loadHandlers
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')
s = g.app.config.getEnabledPlugins()

# leoPlugins.loadOnePlugin
verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

#@+node:ekr.20041120064303:readSettingsFiles & helpers (g.app.config)
def readSettingsFiles (self,fileName,verbose=True):

    trace = False and not g.unitTesting
    seen = []
    self.write_recent_files_as_needed = False # Will be set later.
    << define localDirectory, localConfigFile & myLocalConfigFile >>

    if trace: g.trace(g.callers(5))
    table = (
        (self.globalConfigFile,False),
        (self.homeFile,False),
        (localConfigFile,False),
        (self.myGlobalConfigFile,False),
        (self.myHomeConfigFile,False),
        (self.machineConfigFile,False),
        (myLocalConfigFile,False),
        # New in Leo 4.6: the -c file is in *addition* to other config files.
        (g.app.oneConfigFilename,False),
        (fileName,True),
    )

    # Init settings from leoSettings.leo and myLeoSettings.leo files.
    for path,localFlag in table:
        if path:
            path = g.os_path_realpath(g.os_path_finalize(path))
            # Bug fix: 6/3/08: make sure we mark files seen no matter how they are specified.
        isZipped = path and zipfile.is_zipfile(path)
        isLeo = isZipped or (path and path.endswith('.leo'))
        if isLeo and path and path.lower() not in seen and g.os_path_exists(path):
            seen.append(path.lower())
            if verbose and not g.app.unitTesting and not self.silent and not g.app.batchMode:
                s = 'reading settings in %s' % path
                # This occurs early in startup, so use the following instead of g.es_print.
                if not g.isPython3:
                    s = g.toEncodedString(s,'ascii')
                g.es_print(s,color='blue')
            c = self.openSettingsFile(path)
            if c:
                self.updateSettings(c,localFlag)
                g.app.destroyWindow(c.frame)
                self.write_recent_files_as_needed = c.config.getBool(
                    'write_recent_files_as_needed')
                if 0:
                    # This is useless. setIvarsFromSettings does nothing
                    # until the self.inited flag is True.
                    g.trace('?' * 20,c)
                    self.setIvarsFromSettings(c)
    self.readRecentFiles(localConfigFile)
    # self.createMyLeoSettingsFile(myLocalConfigFile)
    self.inited = True
    self.setIvarsFromSettings(None)
#@+node:ekr.20061028082834:<< define localDirectory, localConfigFile & myLocalConfigFile >>
# This can't be done in initSettingsFiles because
# the local directory does not yet exist.
localDirectory = g.os_path_dirname(fileName)

#  Set the local leoSettings.leo file.
localConfigFile = g.os_path_join(localDirectory,'leoSettings.leo')
if not g.os_path_exists(localConfigFile):
    localConfigFile = None

# Set the local myLeoSetting.leo file.
myLocalConfigFile = g.os_path_join(localDirectory,'myLeoSettings.leo')
if not g.os_path_exists(myLocalConfigFile):
    myLocalConfigFile = None
#@nonl
#@-node:ekr.20061028082834:<< define localDirectory, localConfigFile & myLocalConfigFile >>
#@+node:ekr.20041117085625:openSettingsFile
def openSettingsFile (self,path):

    theFile,isZipped = g.openLeoOrZipFile(path)
    if not theFile: return None

    # Similar to g.openWithFileName except it uses a null gui.
    # Changing g.app.gui here is a major hack.
    oldGui = g.app.gui
    g.app.gui = leoGui.nullGui("nullGui")
    c,frame = g.app.newLeoCommanderAndFrame(
        fileName=path,relativeFileName=None,
        initEditCommanders=False,updateRecentFiles=False)
    frame.log.enable(False)
    c.setLog()
    g.app.lockLog()
    ok = frame.c.fileCommands.open(
        theFile,path,readAtFileNodesFlag=False,silent=True) # closes theFile.
    g.app.unlockLog()
    c.openDirectory = frame.openDirectory = g.os_path_dirname(path)
    g.app.gui = oldGui
    return ok and c
#@-node:ekr.20041117085625:openSettingsFile
#@+node:ekr.20051013161232:updateSettings
def updateSettings (self,c,localFlag):

    d = self.readSettings(c,localFlag)

    if d:
        d['_hash'] = theHash = c.hash()
        if localFlag:
            self.localOptionsDict[theHash] = d
        else:
            self.localOptionsList.insert(0,d)

    if 0: # Good trace.
        if localFlag:
            g.trace(c.fileName())
            g.trace(d and list(d.keys()))
#@-node:ekr.20051013161232:updateSettings
#@-node:ekr.20041120064303:readSettingsFiles & helpers (g.app.config)
#@+node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@-node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
#@+node:ekr.20041118084146.1:set (g.app.config) To be deleted??
def set (self,c,setting,kind,val):

    '''Set the setting.  Not called during initialization.'''

    trace = False and not g.unitTesting
    found = False ;  key = self.munge(setting)
    if trace: g.trace(setting,kind,val)

    if c:
        d = self.localOptionsDict.get(c.hash())
        if d: found = True

    if not found:
        theHash = c.hash()
        for d in self.localOptionsList:
            hash2 = d.get('_hash')
            if theHash == hash2:
                found = True ; break

    if not found:
        d = self.dictList [0]

    d[key] = g.Bunch(setting=setting,kind=kind,val=val,tag='setting')

    if 0:
        dkind = d.get('_hash','<no hash: %s>' % c.hash())
        g.trace(dkind,setting,kind,val)
#@-node:ekr.20041118084146.1:set (g.app.config) To be deleted??
#@+node:ekr.20041118104240:initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@-node:ekr.20041118104240:initIvar (c.configSettings)
#@+node:ekr.20041228042224:setIvarsFromSettings (g.app.config)
def setIvarsFromSettings (self,c):

    '''Init g.app.config ivars or c's ivars from settings.

    - Called from readSettingsFiles with c = None to init g.app.config ivars.
    - Called from c.__init__ to init corresponding commmander ivars.'''

    trace = False and not g.unitTesting
    verbose = True

    # Ingore temporary commanders created by readSettingsFiles.
    if self.inited:
        if trace:
            if c:
                g.trace('=' * 10, 'inited',c.shortFileName(),g.callers(4))
            else:
                tag = '<no c: called at end of readSettingsFiles>'
                g.trace('=' * 10, 'inited',tag,g.callers(1))
    else:
        if trace and verbose: g.trace('*' * 10,'not inited.  do nothing')
        return

    d = self.ivarsDict
    keys = list(d.keys())
    keys.sort()
    for key in keys:
        if key != '_hash':
            bunch = d.get(key)
            if bunch:
                ivar = bunch.ivar # The actual name of the ivar.
                kind = bunch.kind
                val = self.get(c,key,kind) # Don't use bunch.val!
                if c:
                    if trace: g.trace("%20s %s = %s" % (
                        g.shortFileName(c.mFileName),ivar,val))
                    setattr(c,ivar,val)
                else:
                    if trace: g.trace("%20s %s = %s" % (
                        'g.app.config',ivar,val))
                    setattr(self,ivar,val)
#@-node:ekr.20041228042224:setIvarsFromSettings (g.app.config)
#@-node:ekr.20100130042842.6404:Reading settings (do not delete)
#@+node:ekr.20100130042842.9008: Notes
@nocolor-node

colorizeAnyLanguage.
    g.app.config.defaultFontFamily

c.scanAtPathDirectives:
    relative_path_base_directory:

** Methods that write recent files:
    recentFileMessageWritten (Probabaly ok)

c.configSettings.__init__:

** copies these ivars by hand.
    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize
** calls initIvar and initEncoding to copy other ivars.

g.makeAllNonExistentDirectories:
    # Uses one or the other, depending on the c arg.
    c.create_nonexistent_directories
    g.app.config.create_nonexistent_directories

g.getOutputNewline:
    # Uses one or the other, depending on the c arg.
    c.config.output_newline
    g.app.config.output_newline

g.doHook:
    g.app.config.use_plugins

loadOnePlugin:
    g.app.config.enabledPluginsFileName

leoGui.getFontFromParams:
    g.app.config.defaultFont

k.addModeCommands and several other methods use:
    g.app.config.modeCommandsDict
#@nonl
#@+node:ekr.20100130042842.9010:at_root_bodies_start_in_doc_mode
@nocolor-node

at_root_bodies_start_in_doc_mode

c.scanAtRootDirectives
    should use c.config.getBool instead of the weird code.

g.scanAtRootOptions
    Why doesn't this use c.config ivars??
    Actually, this should be tangle.scanAtRootOptions.  We know c!

leoImport.convertVnodeToWeb:
    Uses c.config.at_root_bodies_start_in_doc_mode
#@nonl
#@+node:ekr.20080828103146.12:c.scanAtRootDirectives
# Called only by scanColorDirectives.

def scanAtRootDirectives(self,aList):

    '''Scan aList for @root-code and @root-doc directives.'''

    c = self

    # To keep pylint happy.
    tag = 'at_root_bodies_start_in_doc_mode'
    start_in_doc = hasattr(c.config,tag) and getattr(c.config,tag)

    # New in Leo 4.6: dashes are valid in directive names.
    for d in aList:
        if 'root-code' in d:
            return 'code'
        elif 'root-doc' in d:
            return 'doc'
        elif 'root' in d:
            return g.choose(start_in_doc,'doc','code')

    return None
#@-node:ekr.20080828103146.12:c.scanAtRootDirectives
#@+node:ekr.20031218072017.3154:g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    return i,mode
#@+node:ekr.20031218072017.3155:<< scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@-node:ekr.20031218072017.3155:<< scan another @root option >>
#@-node:ekr.20031218072017.3154:g.scanAtRootOptions
#@-node:ekr.20100130042842.9010:at_root_bodies_start_in_doc_mode
#@+node:ekr.20100131161507.6302:Replace all of these by config.get methods
c.config.default_at_auto_file_encoding
c.config.default_derived_file_encoding
#@nonl
#@-node:ekr.20100131161507.6302:Replace all of these by config.get methods
#@+node:ekr.20100202145902.6108:code
#@+node:ekr.20031218072017.1880:colorizeAnyLanguage & allies
def colorizeAnyLanguage (self,p,leading=None,trailing=None):

    """Color the body pane either incrementally or non-incrementally"""

    c = self.c ; w = c.frame.body.bodyCtrl

    if not c.config.getBool('use_syntax_coloring'):
        # There have been reports of this trace causing crashes.
        # Certainly it is not necessary.
        # g.trace('no coloring')
        return

    if self.killFlag:
        self.removeAllTags()
        return
    try:
        # g.trace('incremental',self.incremental)
        << initialize ivars & tags >>
        g.doHook("init-color-markup",colorer=self,p=self.p,v=self.p)
        if self.incremental and (
            << all state ivars match >> ):
            << incrementally color the text >>
        else:
            << non-incrementally color the text >>
        << update state ivars >>
        return "ok" # for testing.
    except:
        << set state ivars to "unknown" >>
        if self.c:
            g.es_exception()
        else:
            import traceback ; traceback.print_exc()
        return "error" # for unit testing.
#@+node:ekr.20031218072017.1602:<< initialize ivars & tags >> colorizeAnyLanguage
# Copy the arguments.
self.p = p

# Get the body text, converted to unicode.
self.allBodyText = w.getAllText()
sel = w.getInsertPoint()
start,end = g.convertPythonIndexToRowCol(self.allBodyText,sel)
start += 1 # Simulate the old 1-based Tk scheme.  self.index undoes this hack.
# g.trace('new',start,end)

if self.language: self.language = self.language.lower()
# g.trace(self.count,self.p)
# g.trace(body.tag_names())

if not self.incremental:
    self.removeAllTags()
    # self.removeAllImages()

<< configure fonts >>
<< configure tags >>
<< configure language-specific settings >>

self.hyperCount = 0 # Number of hypertext tags
self.count += 1
lines = self.allBodyText.split('\n')
#@nonl
#@+node:ekr.20060829084924:<< configure fonts >> (revise,maybe)
# Get the default body font.
defaultBodyfont = self.fonts.get('default_body_font')
if not defaultBodyfont:
    defaultBodyfont = c.config.getFontFromParams(
        "body_text_font_family", "body_text_font_size",
        "body_text_font_slant",  "body_text_font_weight",
        c.config.defaultBodyFontSize)
    self.fonts['default_body_font'] = defaultBodyfont

# Configure fonts.
w = c.frame.body.bodyCtrl
keys = sorted(default_font_dict)
for key in keys:
    option_name = default_font_dict[key]
    # First, look for the language-specific setting, then the general setting.
    for name in ('%s_%s' % (self.language,option_name),(option_name)):
        font = self.fonts.get(name)
        if font:
            # g.trace('found',name,id(font))
            w.tag_config(key,font=font)
            break
        else:
            family = c.config.get(name + '_family','family')
            size   = c.config.get(name + '_size',  'size')   
            slant  = c.config.get(name + '_slant', 'slant')
            weight = c.config.get(name + '_weight','weight')
            if family or slant or weight or size:
                family = family or g.app.config.defaultFontFamily
                size   = size or str(c.config.defaultBodyFontSize)
                slant  = slant or 'roman'
                weight = weight or 'normal'
                font = c.config.getFontFromParams(family,size,slant,weight)
                # Save a reference to the font so it 'sticks'.
                self.fonts[name] = font 
                # g.trace(key,name,family,size,slant,weight,id(font))
                w.tag_config(key,font=font)
                break
    else: # Neither the general setting nor the language-specific setting exists.
        if len(list(self.fonts.keys())) > 1: # Restore the default font.
            # g.trace('default',key)
            w.tag_config(key,font=defaultBodyfont)
#@nonl
#@-node:ekr.20060829084924:<< configure fonts >> (revise,maybe)
#@+node:ekr.20031218072017.1603:<< configure tags >>
# g.trace('configure tags',self.c.frame.body.bodyCtrl)

for name in default_colors_dict:
    option_name,default_color = default_colors_dict[name]
    option_color = c.config.getColor(option_name)
    color = g.choose(option_color,option_color,default_color)
    # g.trace(name,color)
    # Must use foreground, not fg.
    try:
        c.frame.body.tag_configure(name, foreground=color)
    except: # Recover after a user error.
        c.frame.body.tag_configure(name, foreground=default_color)

underline_undefined = c.config.getBool("underline_undefined_section_names")
use_hyperlinks      = c.config.getBool("use_hyperlinks")
self.use_hyperlinks = use_hyperlinks

# underline=var doesn't seem to work.
if 0: # use_hyperlinks: # Use the same coloring, even when hyperlinks are in effect.
    c.frame.body.tag_configure("link",underline=1) # defined
    c.frame.body.tag_configure("name",underline=0) # undefined
else:
    c.frame.body.tag_configure("link",underline=0)
    if underline_undefined:
        c.frame.body.tag_configure("name",underline=1)
    else:
        c.frame.body.tag_configure("name",underline=0)

# 8/4/02: we only create tags for whitespace when showing invisibles.
if self.showInvisibles:
    for name,option_name,default_color in (
        ("blank","show_invisibles_space_background_color","Gray90"),
        ("tab",  "show_invisibles_tab_background_color",  "Gray80")):
        option_color = c.config.getColor(option_name)
        color = g.choose(option_color,option_color,default_color)
        try:
            c.frame.body.tag_configure(name,background=color)
        except: # Recover after a user error.
            c.frame.body.tag_configure(name,background=default_color)

# 11/15/02: Colors for latex characters.  Should be user options...

if 1: # Alas, the selection doesn't show if a background color is specified.
    c.frame.body.tag_configure("latexModeBackground",foreground="black")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue")
    c.frame.body.tag_configure("latexBackground",foreground="black")
    c.frame.body.tag_configure("latexKeyword",foreground="blue")
else: # Looks cool, and good for debugging.
    c.frame.body.tag_configure("latexModeBackground",foreground="black",background="seashell1")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue",background="seashell1")
    c.frame.body.tag_configure("latexBackground",foreground="black",background="white")
    c.frame.body.tag_configure("latexKeyword",foreground="blue",background="white")

# Tags for wiki coloring.
if self.showInvisibles:
    c.frame.body.tag_configure("elide",background="yellow")
else:
    c.frame.body.tag_configure("elide",elide="1")
c.frame.body.tag_configure("bold",font=self.bold_font)
c.frame.body.tag_configure("italic",font=self.italic_font)
c.frame.body.tag_configure("bolditalic",font=self.bolditalic_font)
for name in self.color_tags_list:
    c.frame.body.tag_configure(name,foreground=name)
#@-node:ekr.20031218072017.1603:<< configure tags >>
#@+node:ekr.20031218072017.370:<< configure language-specific settings >> colorizer
# Define has_string, keywords, single_comment_start, block_comment_start, block_comment_end.

if self.language == "cweb": # Use C comments, not cweb sentinel comments.
    delim1,delim2,delim3 = g.set_delims_from_language("c")
elif self.comment_string:
    delim1,delim2,delim3 = g.set_delims_from_string(self.comment_string)
elif self.language == "plain": # 1/30/03
    delim1,delim2,delim3 = None,None,None
else:
    delim1,delim2,delim3 = g.set_delims_from_language(self.language)

self.single_comment_start = delim1
self.block_comment_start = delim2
self.block_comment_end = delim3

# A strong case can be made for making this code as fast as possible.
# Whether this is compatible with general language descriptions remains to be seen.
self.case_sensitiveLanguage = self.language not in case_insensitiveLanguages
self.has_string = self.language != "plain"
if self.language == "plain":
    self.string_delims = ()
elif self.language in ("elisp","html"):
    self.string_delims = ('"')
else:
    self.string_delims = ("'",'"')
self.has_pp_directives = self.language in ("c","csharp","cweb","latex")

# The list of languages for which keywords exist.
# Eventually we might just use language_delims_dict.keys()
languages = [
    "actionscript","ada","c","csharp","css","cweb","elisp","html","java","latex","lua",
    "pascal","perl","perlpod","php","plsql","python","rapidq","rebol","ruby","shell","tcltk"]

self.keywords = []
if self.language == "cweb":
    for i in self.c_keywords:
        self.keywords.append(i)
    for i in self.cweb_keywords:
        self.keywords.append(i)
else:
    for name in languages:
        if self.language==name: 
            # g.trace("setting keywords for",name)
            self.keywords = getattr(self, name + "_keywords")

# Color plain text unless we are under the control of @nocolor.
# state = g.choose(self.flag,"normal","nocolor")
state = self.setFirstLineState()

if 1: # 10/25/02: we color both kinds of references in cweb mode.
    self.lb = "<<"
    self.rb = ">>"
else:
    self.lb = g.choose(self.language == "cweb","@<","<<")
    self.rb = g.choose(self.language == "cweb","@>",">>")
#@-node:ekr.20031218072017.370:<< configure language-specific settings >> colorizer
#@-node:ekr.20031218072017.1602:<< initialize ivars & tags >> colorizeAnyLanguage
#@+node:ekr.20031218072017.1881:<< all state ivars match >>
self.flag == self.last_flag and
self.last_language == self.language
#@-node:ekr.20031218072017.1881:<< all state ivars match >>
#@+node:ekr.20031218072017.1882:<< incrementally color the text >>
@  Each line has a starting state.  The starting state for the first line is always "normal".

We need remember only self.lines and self.states between colorizing.  It is not necessary to know where the text comes from, only what the previous text was!  We must always colorize everything when changing nodes, even if all lines match, because the context may be different.

We compute the range of lines to be recolored by comparing leading lines and trailing lines of old and new text.  All other lines (the middle lines) must be colorized, as well as any trailing lines whose states may have changed as the result of changes to the middle lines.
@c

if self.trace: g.trace("incremental",self.language)

# 6/30/03: make a copies of everything
old_lines = self.lines[:]
old_states = self.states[:]
new_lines = lines[:]
new_states = []

new_len = len(new_lines)
old_len = len(old_lines)

if new_len == 0:
    self.states = []
    self.lines = []
    return

# Bug fix: 11/21/02: must test against None.
if leading != None and trailing != None:
    # g.pr("leading,trailing:",leading,trailing)
    leading_lines = leading
    trailing_lines = trailing
else:
    << compute leading, middle & trailing lines >>

middle_lines = new_len - leading_lines - trailing_lines
# g.pr("middle lines", middle_lines)

<< clear leading_lines if middle lines involve @color or @recolor  >>
<< initialize new states >>
<< colorize until the states match >>
#@+node:ekr.20031218072017.1883:<< compute leading, middle & trailing  lines >>
@ The leading lines are the leading matching lines.  The trailing lines are the trailing matching lines.  The middle lines are all other new lines.  We will color at least all the middle lines.  There may be no middle lines if we delete lines.
@c

min_len = min(old_len,new_len)

i = 0
while i < min_len:
    if old_lines[i] != new_lines[i]:
        break
    i += 1
leading_lines = i

if leading_lines == new_len:
    # All lines match, and we must color _everything_.
    # (several routine delete, then insert the text again,
    # deleting all tags in the process).
    # g.pr("recolor all")
    leading_lines = trailing_lines = 0
else:
    i = 0
    while i < min_len - leading_lines:
        if old_lines[old_len-i-1] != new_lines[new_len-i-1]:
            break
        i += 1
    trailing_lines = i
#@-node:ekr.20031218072017.1883:<< compute leading, middle & trailing  lines >>
#@+node:ekr.20031218072017.1884:<< clear leading_lines if middle lines involve @color or @recolor  >>
@ 11/19/02: Changing @color or @nocolor directives requires we recolor all leading states as well.
@c

if trailing_lines == 0:
    m1 = new_lines[leading_lines:]
    m2 = old_lines[leading_lines:]
else:
    m1 = new_lines[leading_lines:-trailing_lines]
    m2 = old_lines[leading_lines:-trailing_lines]
m1.extend(m2) # m1 now contains all old and new middle lines.
if m1:
    for s in m1:
        ### s = g.toUnicode(s)
        i = g.skip_ws(s,0)
        if g.match_word(s,i,"@color") or g.match_word(s,i,"@nocolor"):
            leading_lines = 0
            break
#@-node:ekr.20031218072017.1884:<< clear leading_lines if middle lines involve @color or @recolor  >>
#@+node:ekr.20031218072017.1885:<< initialize new states >>
# Copy the leading states from the old to the new lines.
i = 0
while i < leading_lines and i < old_len: # 12/8/02
    new_states.append(old_states[i])
    i += 1

# We know the starting state of the first middle line!
if middle_lines > 0 and i < old_len:
    new_states.append(old_states[i])
    i += 1

# Set the state of all other middle lines to "unknown".
first_trailing_line = max(0,new_len - trailing_lines)
while i < first_trailing_line:
    new_states.append("unknown")
    i += 1

# Copy the trailing states from the old to the new lines.
i = max(0,old_len - trailing_lines)
while i < old_len and i < len(old_states):
    new_states.append(old_states[i])
    i += 1

# 1/8/03: complete new_states by brute force.
while len(new_states) < new_len:
    new_states.append("unknown")
#@-node:ekr.20031218072017.1885:<< initialize new states >>
#@+node:ekr.20031218072017.1886:<< colorize until the states match >>
# Colorize until the states match.
# All middle lines have "unknown" state, so they will all be colored.

# Start in the state _after_ the last leading line, which may be unknown.
i = leading_lines
while i > 0:
    if i < old_len and i < new_len:
        state = new_states[i]
        # assert(state!="unknown") # This can fail.
        break
    else:
        i -= 1

if i == 0:
    # Color plain text unless we are under the control of @nocolor.
    # state = g.choose(self.flag,"normal","nocolor")
    state = self.setFirstLineState()
    new_states[0] = state

# The new_states[] will be "unknown" unless the lines match,
# so we do not need to compare lines here.
while i < new_len:
    self.line_index = i + 1
    state = self.colorizeLine(new_lines[i],state)
    i += 1
    # Set the state of the _next_ line.
    if i < new_len and state != new_states[i]:
        new_states[i] = state
    else: break

# Update the ivars
self.states = new_states
self.lines = new_lines
#@-node:ekr.20031218072017.1886:<< colorize until the states match >>
#@-node:ekr.20031218072017.1882:<< incrementally color the text >>
#@+node:ekr.20031218072017.1887:<< non-incrementally color the text >>
if self.trace: g.trace("non-incremental",self.language)

self.line_index = 1 # The Tk line number for indices, as in n.i
for s in lines:
    state = self.colorizeLine(s,state)
    self.line_index += 1
#@-node:ekr.20031218072017.1887:<< non-incrementally color the text >>
#@+node:ekr.20031218072017.1888:<< update state ivars >>
self.last_flag = self.flag
self.last_language = self.language
#@nonl
#@-node:ekr.20031218072017.1888:<< update state ivars >>
#@+node:ekr.20031218072017.1889:<< set state ivars to "unknown" >>
self.last_flag = "unknown"
self.last_language = "unknown"
#@-node:ekr.20031218072017.1889:<< set state ivars to "unknown" >>
#@-node:ekr.20031218072017.1880:colorizeAnyLanguage & allies
#@+node:ekr.20080828103146.15:c.scanAtPathDirectives
def scanAtPathDirectives(self,aList,force=False,createPath=True):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and not g.unitTesting
    verbose = True

    c = self
    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        warning = d.get('@path_in_body')
        if trace and path:
            g.trace('**** d',d)
            g.trace('**** @path path',path)
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and path not in paths and not warning:
                paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose:
        g.printList(paths,tag='c.scanAtPathDirectives: raw paths')
    path = c.os_path_finalize_join(*paths)
    if trace and verbose: g.trace('joined path:',path)

    # Step 4: Make the path if necessary.
    if path and createPath and not g.os_path_exists(path):
        ok = g.makeAllNonExistentDirectories(path,c=c,force=force)
        if not ok:
            if force:
                g.es_print('c.scanAtPathDirectives: invalid @path: %s' % (path),color='red')
            path = absbase # Bug fix: 2008/9/18

    if trace: g.trace('returns',path)

    return path
#@-node:ekr.20080828103146.15:c.scanAtPathDirectives
#@+node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@-node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
#@+node:ekr.20031218072017.3119:g.makeAllNonExistentDirectories
# This is a generalization of os.makedir.

def makeAllNonExistentDirectories (theDir,c=None,force=False,verbose=True):

    """Attempt to make all non-existent directories"""

    trace = False and not g.unitTesting
    testing = False # True: don't actually make the directories.

    if force:
        create = True # Bug fix: g.app.config will not exist during startup.
    elif c:
        create = c.config and c.config.create_nonexistent_directories
    else:
        create = (g.app and g.app.config and
            g.app.config.create_nonexistent_directories)

    if not force and not create:
        if trace: g.trace('did not create: force and create are both false')
        return None

    if trace:
        g.trace('\n',theDir,'\n',g.callers(4))
        # g.trace('c exists: %s force: %s create: %s dir: %s' % (
            # c is not None,force,create,theDir))

    if c: theDir = g.os_path_expandExpression(theDir,c=c)

    dir1 = theDir = g.os_path_normpath(theDir)

    # Split theDir into all its component parts.
    paths = []
    while len(theDir) > 0:
        head,tail=g.os_path_split(theDir)
        if len(tail) == 0:
            paths.append(head)
            break
        else:
            paths.append(tail)
            theDir = head
    path = ""
    paths.reverse()
    if trace: g.trace('paths:',paths)
    for s in paths:
        path = g.os_path_join(path,s)
        if not g.os_path_exists(path):
            try:
                if testing:
                    g.trace('***making',path)
                else:
                    os.mkdir(path)
                if verbose and not testing and not g.app.unitTesting:
                    # g.trace('***callers***',g.callers(5))
                    g.es_print("created directory:",path,color='red')
            except Exception:
                # g.trace(g.callers())
                if verbose: g.es_print("exception creating directory:",path,color='red')
                g.es_exception()
                return None
    return dir1 # All have been created.
#@-node:ekr.20031218072017.3119:g.makeAllNonExistentDirectories
#@+node:ekr.20031218072017.1386:g.getOutputNewline
def getOutputNewline (c=None,name=None):

    '''Convert the name of a line ending to the line ending itself.

    Priority:
    - Use name if name given
    - Use c.config.output_newline if c given,
    - Otherwise use g.app.config.output_newline.'''

    if name: s = name
    elif c:  s = c.config.output_newline
    else:    s = app.config.output_newline

    if not s: s = ''
    s = s.lower()
    if s in ( "nl","lf"): s = '\n'
    elif s == "cr": s = '\r'
    elif s == "platform": s = os.linesep  # 12/2/03: emakital
    elif s == "crlf": s = "\r\n"
    else: s = '\n' # Default for erroneous values.
    # g.trace(c,name,c.config.output_newline,'returns',repr(s))

    if g.isPython3:
        s = str(s)
    return s
#@-node:ekr.20031218072017.1386:g.getOutputNewline
#@+node:ekr.20031218072017.1596:g.doHook
@ This global function calls a hook routine.  Hooks are identified by the tag param.
Returns the value returned by the hook routine, or None if the there is an exception.

We look for a hook routine in three places:
1. c.hookFunction
2. app.hookFunction
3. leoPlugins.doPlugins()
We set app.hookError on all exceptions.  Scripts may reset app.hookError to try again.
@c

def doHook(tag,*args,**keywords):

    trace = False ; verbose = False

    if g.app.killed or g.app.hookError: # or (g.app.gui and g.app.gui.isNullGui):
        return None

    if args:
        # A minor error in Leo's core.
        g.pr("***ignoring args param.  tag = %s" % tag)

    if not g.app.config.use_plugins:
        if tag in ('open0','start1'):
            s = "Plugins disabled: use_plugins is 0 in a leoSettings.leo file."
            g.es_print(s,color="blue")
        return None

    # Get the hook handler function.  Usually this is doPlugins.
    c = keywords.get("c")
    f = (c and c.hookFunction) or g.app.hookFunction

    if trace and (verbose or tag != 'idle'):
        g.trace('tag',tag,'f',f and f.__name__)

    if not f:
        import leo.core.leoPlugins as leoPlugins
        g.app.hookFunction = f = leoPlugins.doPlugins

    try:
        # Pass the hook to the hook handler.
        # g.pr('doHook',f.__name__,keywords.get('c'))
        return f(tag,keywords)
    except Exception:
        g.es_exception()
        g.app.hookError = True # Supress this function.
        g.app.idleTimeHook = False # Supress idle-time hook
        return None # No return value
#@-node:ekr.20031218072017.1596:g.doHook
#@+node:ekr.20041113113140:loadOnePlugin
def loadOnePlugin (moduleOrFileName,tag='open0',verbose=False):

    trace = False # and not g.unitTesting

    global loadedModules,loadingModuleNameStack

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
        print ('No g.app.config, making stub...')
        class StubConfig(g.nullObject):
            pass
        g.app.config = StubConfig()

    # Fixed reversion: do this after possibly creating stub config class.
    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.endswith('.py'):
        moduleName = moduleOrFileName [:-3]
    else:
        moduleName = moduleOrFileName
    moduleName = g.shortFileName(moduleName)

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if trace or verbose:
            g.trace('plugin',moduleName,'already loaded',color="blue")
        return module

    assert g.app.loadDir

    plugins_path = g.os_path_finalize_join(g.app.loadDir,"..","plugins")
    moduleName = g.toUnicode(moduleName)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)
    result = g.importFromPath(moduleName,plugins_path,pluginName=moduleName,verbose=True)
    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)

        if tag == 'unit-test-load':
            pass # Keep the result, but do no more.
        elif hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es_print('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.

            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                g.trace('no init()',moduleName)
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.app.batchMode or g.app.inBridge: # or g.unitTesting
        pass
    elif result:
        if trace or verbose:
            g.trace('loaded plugin:',moduleName,color="blue")
    else:
        if trace or warn_on_failure or (verbose and not g.app.initing):
            if trace or tag == 'open0':
                g.trace('can not load enabled plugin:',moduleName,color="red")

    return result
#@-node:ekr.20041113113140:loadOnePlugin
#@+node:ekr.20061031131434.100:addModeCommands (enterModeCallback)
def addModeCommands (self):

    '''Add commands created by @mode settings to c.commandsDict and k.inverseCommandsDict.'''

    k = self ; c = k.c
    d = g.app.config.modeCommandsDict # Keys are command names: enter-x-mode.

    # Create the callback functions and update c.commandsDict and k.inverseCommandsDict.
    for key in d:

        def enterModeCallback (event=None,name=key):
            k.enterNamedMode(event,name)

        c.commandsDict[key] = f = enterModeCallback
        k.inverseCommandsDict [f.__name__] = key
        # g.trace('leoCommands %24s = %s' % (f.__name__,key))
#@-node:ekr.20061031131434.100:addModeCommands (enterModeCallback)
#@-node:ekr.20100202145902.6108:code
#@-node:ekr.20100130042842.9008: Notes
#@+node:ekr.20041118104831.1:class configSettings (leoCommands)
class configSettings:

    """A class to hold config settings for commanders."""

    @others
#@+node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@-node:ekr.20041118104831.2:configSettings.__init__ (c.configSettings)
#@+node:ekr.20041118104240:initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@-node:ekr.20041118104240:initIvar (c.configSettings)
#@+node:ekr.20041118104414:initEncoding
def initEncoding (self,key):

    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.encodingIvarsDict.get(key)
    encodingName = bunch.ivar
    encoding = g.app.config.get(c,encodingName,kind='string')

    # New in 4.4b3: use the global setting as a last resort.
    if encoding:
        # g.trace('c.configSettings',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)
    else:
        encoding = getattr(g.app.config,encodingName)
        # g.trace('g.app.config',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)

    if encoding and not g.isValidEncoding(encoding):
        g.es("bad", "%s: %s" % (encodingName,encoding))
#@-node:ekr.20041118104414:initEncoding
#@+node:ekr.20041118053731:Getters (c.configSettings)
def get (self,setting,theType):
    '''A helper function: return the commander's setting, checking the type.'''
    return g.app.config.get(self.c,setting,theType)

def getAbbrevDict (self):
    '''return the commander's abbreviation dictionary.'''
    return g.app.config.getAbbrevDict(self.c)

def getBool (self,setting,default=None):
    '''Return the value of @bool setting, or the default if the setting is not found.'''
    return g.app.config.getBool(self.c,setting,default=default)

def getButtons (self):
    '''Return a list of tuples (x,y) for common @button nodes.'''
    return g.app.config.atCommonButtonsList # unusual.

def getColor (self,setting):
    '''Return the value of @color setting.'''
    return g.app.config.getColor(self.c,setting)

def getCommands (self):
    '''Return the list of tuples (headline,script) for common @command nodes.'''
    return g.app.config.atCommonCommandsList # unusual.

def getData (self,setting):
    '''Return a list of non-comment strings in the body text of @data setting.'''
    return g.app.config.getData(self.c,setting)

def getDirectory (self,setting):
    '''Return the value of @directory setting, or None if the directory does not exist.'''
    return g.app.config.getDirectory(self.c,setting)

def getFloat (self,setting):
    '''Return the value of @float setting.'''
    return g.app.config.getFloat(self.c,setting)

def getFontFromParams (self,family,size,slant,weight,defaultSize=12):

    '''Compute a font from font parameters.

    Arguments are the names of settings to be use.
    Default to size=12, slant="roman", weight="normal".

    Return None if there is no family setting so we can use system default fonts.'''

    return g.app.config.getFontFromParams(self.c,
        family, size, slant, weight, defaultSize = defaultSize)

def getInt (self,setting):
    '''Return the value of @int setting.'''
    return g.app.config.getInt(self.c,setting)

def getLanguage (self,setting):
    '''Return the value of @string setting.

    The value of this setting should be a language known to Leo.'''
    return g.app.config.getLanguage(self.c,setting)

def getMenusList (self):
    '''Return the list of entries for the @menus tree.'''
    return g.app.config.getMenusList(self.c) # Changed in Leo 4.5.

def getOpenWith (self):
    '''Return a list of dictionaries corresponding to @openwith nodes.'''
    return g.app.config.getOpenWith(self.c)

def getRatio (self,setting):
    '''Return the value of @float setting.
    Warn if the value is less than 0.0 or greater than 1.0.'''
    return g.app.config.getRatio(self.c,setting)

def getRecentFiles (self):
    '''Return the list of recently opened files.'''
    return g.app.config.getRecentFiles()

def getShortcut (self,shortcutName):
    '''Return the tuple (rawKey,accel) for shortcutName in @shortcuts tree.'''
    return g.app.config.getShortcut(self.c,shortcutName)

def getSettingSource(self,setting):
    '''return the name of the file responsible for setting.'''
    return g.app.config.getSettingSource(self.c,setting)

def getString (self,setting):
    '''Return the value of @string setting.'''
    return g.app.config.getString(self.c,setting)
#@-node:ekr.20041118053731:Getters (c.configSettings)
#@+node:ekr.20041118195812:Setters... (c.configSettings)
def setRecentFiles (self,files):
    '''Update the recent files list.'''
    # Append the files to the global list.
    g.app.config.appendToRecentFiles(files)
#@-node:ekr.20041118195812:Setters... (c.configSettings)
#@-node:ekr.20041118104831.1:class configSettings (leoCommands)
#@-node:ekr.20100202145902.6106:Init all settings in c.initConfigSettings
#@+node:ekr.20090131200406.11:Remove remaining tk-isms from Leo's core
@nocolor-node

Eliminate all tk-indices from leoEditCommands.py

These are marked with ###

(found) wordend, wordstart
(found) lineend, linestart
(found) sel.first, sel.last
(found) w.insert, w.delete
#@-node:ekr.20090131200406.11:Remove remaining tk-isms from Leo's core
#@+node:ekr.20100108101415.6196:Create insert-tab commands
insert-tab-or-indent-region, insert-hard-tab, insert-soft-tab.
#@nonl
#@-node:ekr.20100108101415.6196:Create insert-tab commands
#@+node:ekr.20100122104234.6168:Keystroke for add-nocolor-node ?
Generalize?
#@nonl
#@+node:ekr.20070624135822:Templates for common code fragments
@
Use completion to show fragments.
Allow settings to create fragments:
    - @fragments
        - @fragment name
            body contains actual fragment.

@c

# Invent a way for simple keystrokes to insert fragments, such as:

Fragment 1:

c.beginUpdate()
try:
    pass
finally:
    endUpdate()

Fragment 2:

for p in c.all_positions():
    pass
#@-node:ekr.20070624135822:Templates for common code fragments
#@-node:ekr.20100122104234.6168:Keystroke for add-nocolor-node ?
#@+node:ekr.20060927173836.6:Don't abort mode if there are problems with bindings
# Or give a better message.
#@nonl
#@-node:ekr.20060927173836.6:Don't abort mode if there are problems with bindings
#@+node:ekr.20090201122309.5:Improve macro commands: and really use them!
@nocolor-node

- The recording logic now returns the entire event.
- The leoKeyEvent ctor now gets the stroke from self.actualEvent.
- Recording ends with ctrl-g: a small changed to k.masterKeyHandler.
- Playing back the macro just calls k.masterKeyHandler.
- Pickle the minimal representation of a key event, namely the stroke.

#@-node:ekr.20090201122309.5:Improve macro commands: and really use them!
#@+node:ekr.20100205152016.5837:do @view nodes
#@-node:ekr.20100205152016.5837:do @view nodes
#@-node:ekr.20100206074650.5844:Cleanups & features: first
#@+node:ekr.20080603052650.466:Fix vim problems
@nocolor

All problems appear to be easy.

http://groups.google.com/group/leo-editor/browse_thread/thread/141690c553bfde55

Vim mode users: your top 3 complaints, please
#@nonl
#@+node:ekr.20100113075303.6270:Easiest vim problems
#@+node:ekr.20100112051224.6229:(vim) Binding Arrow keys (fixed?)
Binding arrow keys, with or without Shift, Ctrl, Alt, and their combinations, to
commands or @mode nodes have no effect.
#@nonl
#@-node:ekr.20100112051224.6229:(vim) Binding Arrow keys (fixed?)
#@+node:ekr.20100112051224.6239:Displaying mode help
@nocolor-node

The "--> mode-help" command has the following issues related to the
display of the "Help" tab:

1. Key label always capitalized.

Vim commands are mapped to both lower-case and upper-case keys but always appear
mapped to upper-case keys within the "Help" tab.

2. Layout of tab's contents.

To improve readability and better support narrow tab cards, display the mode's
label without the "enter-" and "-mode" text and place the key label before the
mode label.

For example, the following entries would change from::
    enter-vi-delete-line-mode d
    enter-vi-delete-to-begin-of-word-mode b
to::
    d : vi-delete-line
    b : vi-delete-to-begin-of-word
#@nonl
#@-node:ekr.20100112051224.6239:Displaying mode help
#@+node:ekr.20100112051224.6225:Repeat last cursor movement command
Support the ';' key: repeat the last "To character" or "Find character" command.
#@nonl
#@-node:ekr.20100112051224.6225:Repeat last cursor movement command
#@+node:ekr.20090629183608.8445:Cursors (easiest)
Vi normally uses two different "current character" designators depending on the
current state.

Insert state:

In the Insert state, a vertical bar is placed between two characters to indicate
where the next key will be inserted. Leo's cursor is of this type.

Command state: 

In the Command state, vi expects that the cursor is highlighting a current
character and provides commands to enter the insert state or paste text either
before or after that current character. Leo's vi emulation currently does not
support a "current character" cursor. As a result, inserting and pasting before
or after is replaced by inserting or pasting "at" the current cursor location.
For example, the 'i' and 'a' command are both mapped to enter the insert state
at the current cursor location.
#@nonl
#@-node:ekr.20090629183608.8445:Cursors (easiest)
#@+node:ekr.20100112051224.6231:Undo command (fixed?)
Using the "undo" command (key 'u') to undo a change to a node's headline text
only works correctly after another node has been selected. It appears that
changes made to a node's headline text are not recorded in Leo's change history
until the edited node has lost focus.
#@nonl
#@-node:ekr.20100112051224.6231:Undo command (fixed?)
#@-node:ekr.20100113075303.6270:Easiest vim problems
#@+node:ekr.20100113075303.6271:Mode-oriented bindings
#@+node:ekr.20100112051224.6228:Binding numeric keys (modes-oriented bindings)
Mapping a number to a command or an @mode node works but can not be used as it
prevents the number from being entered as text while in Vi's insert state.
#@nonl
#@-node:ekr.20100112051224.6228:Binding numeric keys (modes-oriented bindings)
#@+node:ekr.20100112051224.6230:Binding 'bksp' key (mode-oriented bindings)
Binding 'bksp' key to back-char to move back a character in command mode
prevents 'bksp' from deleting characters in text edit mode.
#@nonl
#@-node:ekr.20100112051224.6230:Binding 'bksp' key (mode-oriented bindings)
#@-node:ekr.20100113075303.6271:Mode-oriented bindings
#@+node:ekr.20080616110054.2:Support vim dot command
The ability to repeat the last editing related command by pressing the period
key is not supported and there is no workaround in place.

Binding keys within nodes:

Some commands can be "easily" repeated by having the command's mode
bind itself to the period key.  This is not currently working.

Support commands requesting input:

Add companion commands that reuse input.  For example, a zap-to-
character-again command could exist which will reuse the key entered
in the last zap-to-character command.  With this support, the mode
that performs the initial command would assign the period key to a
companion mode that is identical to the initial mode but with the zap-
to-character command replaced by the zap-to-character-again command.

Commands requiring companion commands are:
  zap-to-character
  find-character
  backward-find-character
  (Any others?)

Notes:

- The copy of the character should be saved somewhere that does NOT affect the
  contents of the clipboard.

- The same or a separate storage location can be used for all commands to retain
  a copy of the character entered by the user. It doesn't matter since only the
  last command is assigned to the period key to be re-executed.
#@nonl
#@-node:ekr.20080616110054.2:Support vim dot command
#@+node:ekr.20100113075303.6272:Argument handling
#@+node:ekr.20100112051224.6222:Commands requesting user input (hard?)
Commands requesting user input must be the last command executed within an @mode
node. This prevents the implementation of commands such as "yank to <character>"
that requires a "copy to clipboard" operation after the "find-character"
command.
#@nonl
#@-node:ekr.20100112051224.6222:Commands requesting user input (hard?)
#@+node:ekr.20100112051224.6226:Range prefix to commands (k.getArgs)
The ability to specify a numeric range prefix is not supported. For example,
entering "3dd" will not delete the next three lines and "20G" will not move the
cursor to the 20th line in the file.

#@-node:ekr.20100112051224.6226:Range prefix to commands (k.getArgs)
#@+node:ekr.20100112051224.6227:Range prefix to objects (k.getArgs)
The ability to specify a numeric range prefix to an object is not supported. For
example, the "d2fx" command should Delete up to and including the 2nd Found "x"
character.
#@nonl
#@-node:ekr.20100112051224.6227:Range prefix to objects (k.getArgs)
#@-node:ekr.20100113075303.6272:Argument handling
#@+node:ekr.20100112051224.6223:Editing node headlines using @mode nodes
Commands modifying or selecting headline text do not work correctly within a
@mode node.

This eliminates accurate implementation of vi's delete/change/substitute/yank
object commands. As a workaround, the commands are currently written to only
select the text. The user must perform the subsequent delete, change,
substitute, and yank.
#@nonl
#@-node:ekr.20100112051224.6223:Editing node headlines using @mode nodes
#@+node:ekr.20100112051224.6246:Missing commands
#@+node:ekr.20100112051224.6232:Toggle case command
Leo provides support for switching to upper or lower case but no method exists
to toggle between cases (used by Vi's "~" command).

#@-node:ekr.20100112051224.6232:Toggle case command
#@+node:ekr.20100112051224.6233:Replace current character command
Vi's "r" command allows user to replace the current character with the next
entered character.
#@nonl
#@-node:ekr.20100112051224.6233:Replace current character command
#@+node:ekr.20100112051224.6234:Move current line
Vi has a collection of "z<movement>" commands that will move the
current line to the top, middle, and bottom of the screen.  They are
not supported in Leo.
#@nonl
#@-node:ekr.20100112051224.6234:Move current line
#@+node:ekr.20100112051224.6235:Move buffer up/down
Vi maps keys to scroll the text up/down one line and by half the
number of visible lines.  Leo does not support this.

#@-node:ekr.20100112051224.6235:Move buffer up/down
#@+node:ekr.20100112051224.6236:Word-related commands
Vi supports two types of words in its commands:

1. Words that consist of only a subset of the character set and
2. words that consist of all characters except the space and tab characters.

Leo's always considers a word to consist of a subset of characters
although some word related commands include different characters
than others.
#@nonl
#@-node:ekr.20100112051224.6236:Word-related commands
#@+node:ekr.20100112051224.6237:Forward and backward by sentences
Leo's sentence related functions:

- do not stop at empty lines.
- do not skip periods within words.
- do not stop at sentences ending in non-periods.
- do not stop at the end or beginning of the buffer.

Note: see forwardSentenceHelper and backSentenceHelper functions.
#@nonl
#@-node:ekr.20100112051224.6237:Forward and backward by sentences
#@+node:ekr.20100112051224.6238:Focus to body pane
Leo functions exist which unconditionally set focus to the body pane
regardless of the active pane.

For example, bracket matching commands ("%" key) do not work within
a node's headline text.  Instead, the command is performed on the
node's body text.
#@nonl
#@-node:ekr.20100112051224.6238:Focus to body pane
#@+node:ekr.20090629183608.8446:Notes about commands
Yank vs. Yank:
Vi's "yank" commands copy the selected text TO the clipboard.
Leo's "yank" commands insert text FROM the clipboard.

copy-text in modes:
Leo's copy-text command does not work within a mode.  As a result,
all "copy to clipboard" capability is being implemented using the
kill-<object> command followed by Leo's "yank" command to put the
text back.

paste-text in modes:
The paste-text command does not work within an @mode node.  Leo's
"yank" command is used instead.

delete-node does not copy node to clipboard:
A copy-node command is issued to copy the node to the clipboard
followed by the delete-node command.
#@-node:ekr.20090629183608.8446:Notes about commands
#@-node:ekr.20100112051224.6246:Missing commands
#@-node:ekr.20080603052650.466:Fix vim problems
#@+node:ekr.20090811141250.5955:Most important features
@ Important: There is another features list for 4.9.
#@nonl
#@+node:ekr.20100128094926.6222: port pmw to py3k
- Check web site first!
- Create new branch for pmw work.
#@nonl
#@-node:ekr.20100128094926.6222: port pmw to py3k
#@+node:ekr.20100131155919.6298:Add debugging rst-arg
#@-node:ekr.20100131155919.6298:Add debugging rst-arg
#@+node:ekr.20090714085914.5991:Add drag and drop to qt gui
#@-node:ekr.20090714085914.5991:Add drag and drop to qt gui
#@+node:ekr.20090801103907.6018:Add entries to global dicts for more languages
http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780

Especially languages in leo/modes.
#@nonl
#@+node:ekr.20090816125009.5993:@url http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780
#@-node:ekr.20090816125009.5993:@url http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780
#@+node:ekr.20090814190307.5983:print all modes/*.py files
import glob

theDir = g.os_path_finalize_join(g.app.loadDir,'..','modes','*.py')

aList = glob.glob(theDir)

for z in aList:
    print g.os_path_basename(z)

@
Exist:

    "ada"   : "ada",
    "adb"   : "ada",
    "ahk"   : "autohotkey",  # EKR: 2009-01-30.
    "as"    : "actionscript",
    "bas"   : "rapidq",
    "bat"   : "batch",
    "c"     : "c",
    "cfg"   : "config",
    "cpp"   : "cpp",
    "css"   : "css",
    "el"    : "elisp",
    "forth" : "forth",
    "f"     : "fortran",
    "f90"   : "fortran90",
    "h"     : "c",
    "html"  : "html",
    "ini"   : "ini",
    "java"  : "java",
    "ksh"   : "kshell", # Leo 4.5.1.
    "lua"   : "lua",  # ddm 13/02/06
    "nw"    : "noweb",
    "otl"   : "vimoutline",  #TL 8/25/08 Vim's outline plugin
    "p"     : "pascal",
    "pl"    : "perl",   # 11/7/05
    "pod"   : "perlpod", # 11/7/05
    "php"   : "php",
    "py"    : "python",
    "sql"   : "plsql", # qt02537 2005-05-27
    "r"     : "rebol",
    "rb"    : "ruby", # thyrsus 2008-11-05
    "rest"  : "rst",
    "rst"   : "rst",
    "sh"    : "shell",
    "tex"   : "tex",
    "txt"   : "plain",
    "tcl"   : "tcltk",
    "vim"   : "vim",
"w"     : "cweb",
"xml"   : "xml",
"xsl"   : "xslt",

Add first:


ada95.py
antlr.py
apacheconf.py
apdl.py
applescript.py
asp.py
aspect_j.py
assembly_macro32.py
assembly_mcs51.py
assembly_parrot.py
assembly_r2000.py
assembly_x86.py
awk.py
b.py
batch.py
bbj.py
bcel.py
bibtex.py
c.py
chill.py
cobol.py
coldfusion.py
cplusplus.py
csharp.py
css.py
cvs_commit.py
d.py
doxygen.py
dsssl.py
eiffel.py
embperl.py
erlang.py
factor.py
forth.py
fortran.py
fortran90.py
foxpro.py
freemarker.py
gettext.py
groovy.py
haskell.py
hex.py
html.py
i4gl.py
icon.py
idl.py
inform.py
ini.py
inno_setup.py
interlis.py
io.py
java.py
javascript.py
jcl.py
jhtml.py
jmk.py
jsp.py
latex.py
lilypond.py
lisp.py
lotos.py
lua.py
mail.py
makefile.py
maple.py
matlab.py
ml.py
modula3.py
moin.py
mqsc.py
netrexx.py
nqc.py
nsis2.py
objective_c.py
objectrexx.py
occam.py
omnimark.py
pascal.py
patch.py
perl.py
php.py
phpsection.py
pike.py
pl1.py
plain.py
plsql.py
pop11.py
postscript.py
povray.py
powerdynamo.py
progress.py
prolog.py
props.py
psp.py
ptl.py
pvwave.py
pyrex.py
python.py
r.py
rebol.py
redcode.py
relax_ng_compact.py
rest.py
rhtml.py
rib.py
rpmspec.py
rtf.py
ruby.py
rview.py
sas.py
scheme.py
sdl_pr.py
sgml.py
shell.py
shellscript.py
shtml.py
smalltalk.py
smi_mib.py
splus.py
sqr.py
squidconf.py
ssharp.py
svn_commit.py
swig.py
tcl.py
tex.py
texinfo.py
text.py
tpl.py
tsql.py
uscript.py
vbscript.py
velocity.py
verilog.py
vhdl.py
xml.py
xsl.py
zpt.py
__init__.py
#@-node:ekr.20090814190307.5983:print all modes/*.py files
#@-node:ekr.20090801103907.6018:Add entries to global dicts for more languages
#@+node:ekr.20090601083544.6051:Add expand_noweb_references for rst3 plugin
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/3cd5cb06d32264d

> What would work for me is if named sections in a @rst subtree
> would work exactly as they work for other derived files: they
> get inserted at the place where they are referenced.

- Add support for the following options:
    - expand_noweb_references: default False for compatibility.
    - ignore_noweb definitions: default False for compatibility.

- When expand_noweb_references is True, definitions (typically clones)
  must be descendants of the referencing node (in the @rst tree)
#@+node:ekr.20090601083544.6052:post
@nocolor-node

I want to write the documentation for the source program in a @rst3 subtree. In
this @rst3 subtree I want to refer to fragments of the program, like:

In the following code fragment::

  <<code fragment>>

Unfortunately, <<code fragment>> will not be expanded. Furthermore, in order to
get to this work, I should have <<code fragment>> under the @rst3 subtree as
well, but this is then also treated as @rst3 input (which in this case, is not
what I want).
#@nonl
#@-node:ekr.20090601083544.6052:post
#@-node:ekr.20090601083544.6051:Add expand_noweb_references for rst3 plugin
#@+node:ekr.20080918164844.12:Improve headline navigation
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/bce1065d9a332fcd

Now that the leo is more "modeless" (I'm speaking of switching between
outline navigation and body editing modes), which btw is a clear improvement
to how leo used to behave, here are some things that still feel a bit
un-intuitive:

- ctrl+H (edit-headline) "locks" the user into the mode way too much.

   * The headline editing mode should be cancelled when the user does:
      - cursor up/down
      - ESC

   * Even better alternative: I find myself constantly thinking that "ok,
now I need to edit a headline (typically not the current headline), so now
I'll press ctrl+H". I think perhaps pressing up/down should cancel the
current headline editing, and select the next/previous headline for editing.
That is, I wouldn't need to navigate to the headline I want to edit before I
start editing it.

  - cut-node (ctrl+shift+x) selects the wrong node after the cut. The
intuitive assumption is that cut will select the node that "took the place
of the
    current node", instead of starting to travel upwards the set of nodes.

   * Typical use case is the way you usually start deleting a set of items.
You move to the first item and start cutting repeatedly. This wont work with
the current behaviour. 
#@nonl
#@-node:ekr.20080918164844.12:Improve headline navigation
#@+node:ekr.20080730212711.7:Improve plugins handling
@nocolor-node

- Don't repeat "can not load <plugin>" messages.

- Unify print-plugins and print-plugins-info commands, and make them more informative.

- Fix the plugin mess.

    - Create a way to unload a plugin.  This should be relatively easy.
#@+node:ekr.20090804105939.5993:Possibly redo how plugins are loaded
#@-node:ekr.20090804105939.5993:Possibly redo how plugins are loaded
#@+node:ekr.20080313032655.2:Once a plugin is enabled, it is always enabled
#@-node:ekr.20080313032655.2:Once a plugin is enabled, it is always enabled
#@+node:ekr.20080923200153.1:Support scan-directives hook again?
# This affects the add_directives plugin.
# Also, the color_markup plugin doesn't work with the threading colorizer.
#@nonl
#@-node:ekr.20080923200153.1:Support scan-directives hook again?
#@+node:ekr.20080421140032.1:Fix multiple controllers problem in all plugins
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/663e1f9d8e2d1c24

@color
#@nonl
#@-node:ekr.20080421140032.1:Fix multiple controllers problem in all plugins
#@-node:ekr.20080730212711.7:Improve plugins handling
#@+node:ekr.20090724081340.5987:Improve recursive import script and @auto
@nocolor-node

Instead of adding an @ignore directive, it might be better
to change @auto to @@auto.

Should @auto be more lenient with C files?

Improve the recursive import script.
    - Minimize the path names
    - Option to include/exclude the @auto itself

#@-node:ekr.20090724081340.5987:Improve recursive import script and @auto
#@+node:ekr.20090907080624.6081:Spell checker should check headlines
#@-node:ekr.20090907080624.6081:Spell checker should check headlines
#@+node:ekr.20081208102356.1:Threading colorizer doesn't handle multiple body editors
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/5be7a099b299327e

> Tk only colorizes one body editor, and if you delete that editor it
> colorizes no editor.

Thanks for this report.  This is a problem, never noticed until now,
with the threading colorizer.  A workaround is to disable the
threading colorizer plugin. 
#@nonl
#@-node:ekr.20081208102356.1:Threading colorizer doesn't handle multiple body editors
#@+node:ekr.20100131161507.6303:Unit tests that all commands have docstrings
Just make the test.  It doesn't have to pass.
#@nonl
#@-node:ekr.20100131161507.6303:Unit tests that all commands have docstrings
#@+node:ekr.20071001052501:Versioning for nodes
@nocolor

One feature I have not seen in SCS system is something which might be called
"history compression": I might be interested in having both version 5 and 6
in my source tree, when the current version is 7, but I am not really interested
in the 2000 steps which transformed 5 into 6 (just suggested this feature to
the bazaar people). This happens actually quite often to me, since I use the
SCS as a back-up system, saving many (uninteresting) intermediate steps while
implementing a new feature.
#@nonl
#@-node:ekr.20071001052501:Versioning for nodes
#@-node:ekr.20090811141250.5955:Most important features
#@-node:ekr.20100109214940.6225:4.8 vim, cleanups, your mission...
#@+node:ekr.20100206074650.5843:4.9 Autocompletion
#@+node:ekr.20090131200406.14:autocompletion
#@+node:ekr.20081005065934.12:Links from Ville re Scintilla
@nocolor-node

It seems Scintilla relies on externally generated api description
files to provide autocompletion. Links that may be of interest:

http://www.riverbankcomputing.co.uk/static/Docs/QScintilla2/classQsciAPIs.html#b0f824492bb0f3ca54edb4d46945a3de

http://www.burgaud.com/scite-java-api/

http://scintilla.sourceforge.net/tags2api.py

http://www.koders.com/python/fid7000B9C96CF2C6FB5BCE9DF700365C5B2A1F36A7.aspx?s=gtk#L53
#@-node:ekr.20081005065934.12:Links from Ville re Scintilla
#@+node:ekr.20080113165010:About auto completion
@nocolor

Summary: inspect when possible, ask for types otherwise.

    os.? gives a list of all instances of os module.
    x.? gives a list of all known classes.
    x.# gives list of all known functions.
    self.? gives all known methods and ivars of the enclosing class.
    The user will be able to specify type conventsions, like Leo's c,g,p,t,v vars.

Completed (mostly): user interface stuff.

Performance isn't too hard:
    - Do all scanning in separate threads.
    - Associate node info with tnodes.
    - Update node info when deselecting a node (in tree base class)

Parsing:
    - Forgiving parser is essentially complete.
    - It's easy to parse python def lines.
#@nonl
#@-node:ekr.20080113165010:About auto completion
#@+node:ekr.20080110082845:pyxides: code completion
@nocolor

Python code completion module


From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 20:57:18 +0300

I've been developing IDLE over the past 2 years or so. Even before
that, I helped a friend of mine, Noam Raphael, write IDLE's
auto-completion, which is included in recent versions of IDLE.

Noam wrote the original completion code from scratch, and AFAIK every
Python IDE which features code completion has done the same. Surely
there is -some- functionality which could be useful cross-IDE?
Retrieving possible completions from the namespace, for example. And
we should be learning from each-others' ideas and experiences.

So how about we design a generic Python completion module, that
each IDE could extend, and use for the completion logic?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:06:01 +0100

I am very keen for this. I will help where it is required. PIDA
currently has no code completion (outside what vim/emacs provide),



From: "phil jones" <inters...@gmail.com>
Date: Wed, 6 Jun 2007 11:07:33 -0700

What functions would we ask for a code completion module?

Presumably recognition of the beginnings of
- a) python keywords
- b) classes and functions defined earlier in this file?
- c) in scope variables?

As python is dynamically typed, I guess we can't expect to know the
names of methods of objects?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:13:10 +0100

> Presumably recognition of the beginnings of
> - a) python keywords
> - b) classes and functions defined earlier in this file?
> - c) in scope variables?

does c) include: d) imported modules



From: Nicolas Chauvat <nicolas.chau...@logilab.fr>
Date: Wed, 6 Jun 2007 20:17:30 +0200

> >Presumably recognition of the beginnings of
> >- a) python keywords
> >- b) classes and functions defined earlier in this file?
> >- c) in scope variables?

> does c) include: d) imported modules

For code-completion, I suppose astng[1] could be useful.

1: http://www.logilab.org/project/eid/856



From: Stani's Python Editor <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 20:48:41 +0200

A good point. I think we all have been thinking about this. Important
issues for the design is the extraction method and the sources.

*the method*
Importing is a lazy, but accurate way of importing, but is security wise
not such a good idea. Parsing throught an AST compiler is better,
however more difficult. Here are two options.

From version 2.5 the standard Python compiler converts internally the
source code to an abstract syntax tree (AST) before producing the
bytecode. So probably that is a good way to go as every python
distribution has this battery included.

As Nicolas suggested earlier on this mailing list, there is another
option: the AST compiler in python or PyPy:

On Mar 14 2006, 12:16 am, Nicolas Chauvat <nicolas.chau...@logilab.fr>
wrote:

> > WingIDE use anASTgenerator written in C (but cross-platform),
> > lightningly quick, and open sourced. This could be a potential
> > starting point.

> > Additionally isn't Python2.5 planned to have a C-written compiler?

> PyPy also produced an improved parser/compiler.

> http://codespeak.net/pypy/dist/pypy/doc/index.html
> http://codespeak.net/pypy/dist/pypy/module/recparser/

But if it could be done with the standard one it is one dependency less.

*the sources*
In the design we could define first the sources:
1 external imported modules from the pythonpath
2 local modules relative to the current file or context dependent
(Blender, Gimp, ...)
3 inner code

For 1:
It might be a good idea to have a function which scans all the modules
from the pythonpath or one specific module to cache all autocompletion
and calltip information of all classes, methods and doc strings. Why?
Modules in the pythonpath don't change so often. With some criteria
(file name, time stamp, size, ...) you could check if updates are
necessary at startup. Having a readymade 'database' (could be python
dictionary or sqlite database) for autocompletion/call tips would speed
up things (and is also more secure if you are importing rather than
parsing. For example trying to provide gtk autocompletion in a wxPython
by importing is problematic).

For 2:
Here you load the parser on demand. Autocompletion/calltip information
can be added to the database.

For 3:
A different kind of parser needs to be used here as per definition code
you edit contains errors while typing. External modules are retrieved
from 1 and 2, for internal code you can scan all the words and add them
to the autocomplete database. As a refinement you can give special
attention to 'self'. Also for calltips you can inherit when there are
assignments, eg
frame = Frame()
than frame inherits autocomplete & calltip information from Frame.

So autocompletion & calltips deals with two steps: extraction and
'database'. If someone has a good parser already, we could use it.
Otherwise we can define an API for the extraction and maybe lazily
implement it first with importing and concentrate first on the
'database'. When the database is ready we can implement the parsing. You
could also implement the parsing first, but than it takes longer before
you have results. Of course the library is GUI independent, it only
works with strings or lists.

What concerns SPE, it uses importing for autocompletion (1+2) and does
internal code analysis for local code (however without the inheriting).

Tal, how does IDLE's autocompletion works?

Stani



From: Stani's Python Editor <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 20:53:10 +0200

Nicolas Chauvat wrote:
> On Wed, Jun 06, 2007 at 07:13:10PM +0100, Ali Afshar wrote:
>>> Presumably recognition of the beginnings of
>>> - a) python keywords
>>> - b) classes and functions defined earlier in this file?
>>> - c) in scope variables?
>> does c) include: d) imported modules

> For code-completion, I suppose astng[1] could be useful.

> 1: http://www.logilab.org/project/eid/856

How dependent/independent is this from the standard AST compiler or
PyPy? Is it more IDE friendly? Is it based on it or a total independent
implementation?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:59:13 +0100

> A good point. I think we all have been thinking about this. Important
> issues for the design is the extraction method and the sources.

> *the method*
> Importing is a lazy, but accurate way of importing, but is security wise
> not such a good idea. Parsing throught an AST compiler is better,
> however more difficult. Here are two options.

> From version 2.5 the standard Python compiler converts internally the
> source code to an abstract syntax tree (AST) before producing the
> bytecode. So probably that is a good way to go as every python
> distribution has this battery included.

> As Nicolas suggested earlier on this mailing list, there is another
> option: the AST compiler in python or PyPy:

What concerns me about these is whether they would work in a module
which has a syntax error.

I believe Wing's compiler bit of their code completion is open source.
I remember having seen the code.



From: Stani <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 12:08:00 -0700

> What concerns me about these is whether they would work in a module
> which has a syntax error.

> I believe Wing's compiler bit of their code completion is open source.
> I remember having seen the code.

It is indeed, but is implemented in C, which means an extra dependency
and not a 100% python solution. Normally modules (especially in the
pythonpath) which you import don't have syntax errors. Maybe logilabs
implementation handles syntax errors well as it is developed for
PyLint. Nicolas?



From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 22:34:41 +0300

> As python is dynamically typed, I guess we can't expect to know the
> names of methods of objects?

Well, the dir() builtin does just that, though there can be attributes
which won't be included therein. However, the builtin dir() can be
overridden... and ignoring it can break libraries like RPyC which
define a custom dir() function just for this purpose.

This issue has already been run in to by RPyC (an Python RPC lib). The
main developr went ahead and suggested adding a __dir__ method which
will return a list of attributes, and IIRC he has already implemented
a patch for this, and it will likely enter Python2.6.

Until then, I guess we're going to have to rely on dir for this.



From: "Josiah Carlson" <josiah.carl...@gmail.com>
Date: Wed, 6 Jun 2007 12:42:01 -0700

For reference, PyPE auto-parses source code in the background, generating
(among other things) a function/class/method hierarchy.  Its autocomplete
generally sticks to global functions and keywords, but when doing
self.method lookups, it checks the current source code line, looks up in its
index of classes/methods, and trims the results based on known methods in
the current class in the current source file.

It certainly isn't complete (it should try to check base classes of the
class in the same file, it could certainly pay attention to names assigned
in the current scope, the global scope, imports, types of objects as per
WingIDE's assert isinstance(obj, type), etc.), but it also makes the
computation fairly straightforward, fast, and only in reference to the
current document.



From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 22:52:08 +0300

> Tal, how does IDLE's autocompletion works?

Much like Stani said, since Python is interpreted, collection of
possible completions splits into two methods:
1) source code analysis
2) dynamic introspection

Of course, we could do either or a combination of both.

IDLE just uses introspection: since IDLE always has a python shell
running, it just completes according to the shell's state (plus
built-in keywords and modules). This is a very simple method,
obviously lacking. It does allow the user some control of the
completion, though - just import whatever you want to be completable
in the shell. However, introspection is all that is needed in a Python
shell, which is the major reason this is the method used in IDLE.



From: Nicolas Chauvat <nicolas.chau...@logilab.fr>
Date: Wed, 6 Jun 2007 23:59:32 +0200


> How dependent/independent is this from the standard AST compiler or
> PyPy? Is it more IDE friendly? Is it based on it or a total independent
> implementation?

It is independent from PyPy.

The above web page says:

"""
Python Abstract Syntax Tree New Generation

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentialy
governed by pylint's needs.

It extends class defined in the compiler.ast [1] module with some
additional methods and attributes. Instance attributes are added by a
builder object, which can either generate extended ast (let's call
them astng ;) by visiting an existant ast tree or by inspecting living
object. Methods are added by monkey patching ast classes.Python
Abstract Syntax Tree New Generation

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentialy
governed by pylint's needs.

It extends class defined in the compiler.ast [1] module with some
additional methods and attributes. Instance attributes are added by a
builder object, which can either generate extended ast (let's call
them astng ;) by visiting an existant ast tree or by inspecting living
object. Methods are added by monkey patching ast classes.
"""

From: "Sylvain Thénault" <thena...@gmail.com>
Date: Wed, 13 Jun 2007 10:51:04 +0200

> Please let me involve Sylvain in the discussion. As the main author of
> pylint and astng, he will provide better answers.

well logilab-astng is basically a big monkey patching of the compiler
package from the stdlib, so you can't get an astng representation from a
module with syntax errors in. However inference and most others
navigation methods (which are basically the value added by astng) are
"syntax error resilient" : if a dependency module (direct or indirect)
contains a syntax error, you don't get any exception, though since some
information is missing you can miss some results you'ld get if the
faulting module were parseable.



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 10:33:33 +0300

Since astng already does some inference (which we definitely want!)
and is based on the standard Python AST compiler, it sounds like our
#1 candidate. I think we should give the code a serious once-over and
see how well it fits our requirements, and if it can be adapted to
better handle errors. Any volunteers?

Also, has anyone used astng for completion, calltips, or something
similar? Or the standard AST compiler, for that matter?



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 10:40:11 +0300

How does PyPE parse code? Home-rolled, standard AST compiler, something else?

It seems to me we should try to come up with an algorithm for parsing,
before getting to the code. All of the details you mentioned -
noticing assignments, using base-class methods, etc. - could be better
defined and organized this way. Perhaps we could brainstorm on this in
a wiki?



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 11:38:40 +0300

Sorry for being away for such a long time. I hope we can get this
conversation rolling again, and get started with the actual work.

I'll try to sum up what has been said so far, and how I see things.

== Top Priorities ==
* Can we implement a parser based on the standard Python AST compiler
(or astng)? For example, can syntax errors be handled well?
* Is importing reasonable security-wise? If not, can it be made secure?

== General issues ==
* Do we aim for just completion, or also calltips? Perhaps also other
meta-data, e.g. place defined, source code, ... (see IPython's '??')
* Dependencies - do we want to allow C-extensions, or are we going for
a Python-only solution? (IDLE would only use such a Python-only tool.)
It seems that we want to pre-process most of the data in the
background, so I don't see why we would want to do this in C for
efficiency reasons.

== Completion sources ==
1) Importing "external" modules
2) Importing/Parsing "local" modules
3) Parsing the current file
4) Using objects/modules from the shell (e.g. IDLE has both editor
windows and a Python shell)

== Importing ==
* Stani mentioned that importing is problematic from a security point
of view. What are the security issues? Are they really an issue for an
IDE? If so, perhaps we could overcome this by importing in some kind
of "sandbox"?
* What are the pros and cons of Importing vs. Parsing?
* If importing is always preferable to parsing unless there's a syntax
error, perhaps try to import and parse on failure?

== Parsing ==
* This is going to be the most complex method - I think we should have
a general idea of how this should work before starting an
implementation. I suggest hashing ideas out on a wiki, since there a
lot of details to consider.
* Can a parser based on the standard AST compiler (or astng) work? Is
there a way to deal with errors? (HIGH PRIORITY!)
* There are other existing, open-source implementations out there -
WingIDE, PyPE have been mentioned. Any others? We should collect these
so we can use the code for learning, and perhaps direct use (if
possible license-wise).

== Shell ==
This is relatively straight-forward - just use dir(). This should be
optional, for use by IDEs which have a shell (support multiple
shells?).

Some known issues from IDLE and PyCrust:
* Handle object proxies such as RPC proxies (e.g. RPyC)
* Handle ZODB "ghost" objects
* Watch out for circular references
* Watch out for objects with special __getattr__/__hasattr__
implementations (for example xmlrpc, soap)

== Persistence ==
* Stani mentioned a 'database'. I feel Sqlite should be at most
optional, to reduce dependencies.
* Do we really want to have the data persistent (between IDE
sessiosns)? If so, we need to support simultaneous instances of the
IDE so they don't corrupt the data. Any other issues? (I have a
feeling this would better be left for later stages of development.)



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 12:22:59 +0300

One more note: We should distinguish between completion in an editor
and completion in a shell. The conversation up until now has focused
on editors, which is reasonable since that is the problematic scene. I
think a generic Python completion library should support completion in
both contexts, especially if it uses can use a shell's namespace for
completion in the editor.



From: "Ali Afshar" <aafs...@gmail.com>
Date: Tue, 31 Jul 2007 11:20:19 +0100

I have just implemented a completion mockup using Rope (which is a
refactoring library). It works quite nicely, and definitely worth a
look.

http://rope.sourceforge.net/

It even achieves this kind of completion:

class Banana(object):
    def do_something(self):
         return

def foo():
    return [Banana(), Banana()]

foo()[0].<complete> includes do_something

Which seems pretty impressive to me.



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 20:12:50 +0300

Wow, Rope does look very impressive! A quick look at the code tells me
that a lot of work has been invested in it.

So we have one existing Python-only solution. We should evaluate it -
see what it can and can't do, and perhaps take a look at the overall
design.

I'm CC-ing Rope's developer, Ali. Hopefully Ali can help us quickly
understand Rope's code analysis capabilities.

Ali, could you elaborate a bit on what kinds of completion Rope can
do, and the methods it uses? We would especially like to know how your
static and dynamic inference work, what they can accomplish, and what
their limitations are.



From: "Ali Afshar" <aafs...@gmail.com>
Date: Tue, 31 Jul 2007 19:45:15 +0100

> Ali, could you elaborate a bit on what kinds of completion Rope can
> do, and the methods it uses? We would especially like to know how your
> static and dynamic inference work, what they can accomplish, and what
> their limitations are.

Well, I haven't really looked at the code. But I can tell you this:

from rope.ide.codeassist import PythonCodeAssist
from rope.base.project import Project
for compl in PythonCodeAssist(Project(package_root)).assist(buffer,
offset).completions:
    print compl

And that is as far as I really got. I expect to get a better look at
it later in the week though...


From: "Josiah Carlson" <josiah.carl...@gmail.com>
Date: Wed, 1 Aug 2007 00:26:14 -0700

> How does PyPE parse code? Home-rolled, standard AST compiler, something else?

The compiler for syntactically correct Python, a line-based compiler
for broken Python.  TO generate a method list for self.methods, using
the current line number, I discover the enclosing class, check the
listing of methods for that class (generated by the compiler or
line-based parsers), and return a valid list for the specified prefix.
 It doesn't walk the inheritance tree, it doesn't do imports, etc.

> It seems to me we should try to come up with an algorithm for parsing,
> before getting to the code. All of the details you mentioned -
> noticing assignments, using base-class methods, etc. - could be better
> defined and organized this way. Perhaps we could brainstorm on this in
> a wiki?

A wiki would be fine, the one for this mailing list would likely be
best (if it is still up and working).  Then again, Rope looks quite
nifty.  I may have to borrow some of that source ;)


Discussion subject changed to "Fwd: Python code completion module" by Tal Einat

From: Ali Gholami Rudi <aligr...@gmail.com>
Date: Aug 1, 2007 5:50 PM

First of all I should note that rope's main goal was being a
refactoring tool and a refactoring tool needs to know a lot about
python modules.  `rope.base` package provides information about python
modules.

Actually what ropeide provides as auto-completion is defined in
`rope.ide.codeassist` module.  This module almost does nothing but use
`rope.base`.  Since `rope.ide` package is not included in the rope
library (which has been separated from ropeide since 0.6m4) it lacks
good documentation and the API might not be easy to use (most of it is
written in the first months of rope's birth).

> ..., could you elaborate a bit on what kinds of completion Rope can
> do, ...

I don't know what to say here.  Well, actually it tries to use the
source code as much as possible and infer things from it.  So I can
say that it can complete any obvious thing that can be inferred by a
human.  Like this is the first parameter of a method and after dots
its attributes can appear or these modules are imported so their names
and contents are available or this is an instance of some known type
and we know its attributes and ... .  Try ropeide (it uses emacs-like
keybinding, C-/ for completion; see ~/.rope if you want to change
that); it completes common cases (and sometimes completes things you
don't expect it to!).

> ..., and the methods it uses?

Rope analyzes python source code and AST.  Rope used to use the
`compiler` module till 0.5 and now it uses `_ast` module.

> We would especially like to know how your
> static and dynamic inference work, what they can accomplish

There are a few examples in docs/overview.txt.  Unit-test modules like
`ropetest.base.objectinfertest` and `advanced_oi_test` might help,
too.  Also have a look at `rope.base.oi.__init__` pydoc for an
overview of how they work; (I'm afraid it is a bit out of date and
carelessly written.)  The idea behind rope's object inference is to
guess what references (names in source-code) hold.  They collect
information about code when they can and use them later.

>..., and what their limitations are.

Many things in rope are approximations that might be exact if some
conditions hold.  For instance rope might assume that every normal
reference in module scope holds only one kind of object.  Apart from
these assumptions both SOI and DOI have their own disadvantages; For
instance SOI fails when dynamic code is evaluated while DOI does not.
Or DOI is slower than SOI.  (Well, after recent enhancements to rope's
SOI I rarely use DOI).

I tried to answer as short as possible.  If there are questions on
specific parts of rope, I'll be happy to answer.

By the way, I tried to reply this mail to the group, but it seems that
your group requires subscription for posting, so I've sent it to you,
instead.
#@nonl
#@-node:ekr.20080110082845:pyxides: code completion
#@+node:ekr.20060927173836.1:Make calltips and autocompleter 'stateless'
@nocolor

Disabled these binding:

auto-complete-force = None # This command needs work before it is useful. Ctrl-period
show-calltips-force = None # This command needs work before it is useful. Alt-parenleft

The problem is that autocompletion depends on state: self.leadinWord,
prevObjects, etc. Thus, it's not presently possible to start the proces
anywhere. Similar remarks apply to calltips, which relies on autocompleter
state.

This is a complex problem, and not very serious now that there is an easy way of
toggling autocompleter and calltips on and off.

@color
#@nonl
#@-node:ekr.20060927173836.1:Make calltips and autocompleter 'stateless'
#@+node:ekr.20071106083149:Recent post
@killcolor

In general, autocompletion is a tricky problem. Consider:

- There may be no 'clean' version of the source code that you want to
auto-complete: you may be creating a new node, or a new file, and the source
code, being incomplete, will not parse correctly.

- Except in special circumstances, there is no 'real' object corresponding to s,
so there is no way to use Python's inspect module on s. Modules are an
exception: the autocompleter can handle existing modules fairly well. Try "os."
or "os.path." for example.


It might be possible to generalize c.k.defineObjectDict so that the user
could specify autocompleter conventions, say in an @autocompleter node in an
@settings tree.
#@nonl
#@-node:ekr.20071106083149:Recent post
#@-node:ekr.20090131200406.14:autocompletion
#@+node:ekr.20091005145253.6058:Features
#@+node:ekr.20090131200406.15:Optional file features
#@+node:ekr.20090622020908.6058:Add lite sentinels
http://groups.google.com/group/leo-editor/browse_thread/thread/c4f2cf250600e4a9
#@nonl
#@-node:ekr.20090622020908.6058:Add lite sentinels
#@+node:ekr.20080311135649.2:Allow different .leo formats
@nocolor

On Tue, Mar 11, 2008 at 7:03 AM, Kent Tenney <kten...@gmail.com> wrote:

> On 3/11/08, derwisch <johannes.hues...@med.uni-heidelberg.de> wrote:

> >  On 11 Mrz., 08:03, "Ville M. Vainio" <vivai...@gmail.com> wrote:
> >  > It could also be argued that

> >  > - Referring to previous cloned vnodes explicitly in XML does not
> >  > necessarily obscure DAG - it follows the "do not repeat yourself"
> rule
> >  > - It will speed up reading
> >  > - Wouldn't it be better for preserving the integrity of the XML file?

> > I would lean towards this line of argumentation. A couple of days I
> >  had my Leo extension destroy the Leo ODM file (which was still valid
> >  according to Leo, but unreadable wrt the extension and broken uAs). I
> >  resorted to editing the Leo file with Emacs, and was quite surprised
> >  to see that the headStrings were attributes of vnodes.

> I'll chime in with my pet peeve re: .leo file structure::

> I think that putting the headstrings on vnodes and body strings on tnodes
> obscures the informational content of the .leo file, and makes the .leo
> file
> format less attractive as a generalized solution to the problem of how to
> manage head/body pairs which live in a hierarchal structure.

> Thanks,
> Kent

> >  I think that
> >  editing the file might have been a bit easier if there had been no
> >  such redundancy. But this is more a feeling rather than a qualified
> >  opinion.

Thanks for all these comments.  I'll respond to them all here.

Clearly, we should be using a standard xml parser to read .leo files.

My present thoughts:

- I personally like human-readable headlines in <v> elements.

- I am open to putting headlines in <t> elements, as an indication that
tnodes do indeed contain headlines and body text.

- I am willing to consider only writing shared subtrees once.

Oh! (An Aha)  All these are preferences.  We can allow any combination of
these provided that headlines appear somewhere.

So that's clean.  This will happen in Leo 4.5. 
#@nonl
#@-node:ekr.20080311135649.2:Allow different .leo formats
#@+node:ekr.20061002093442:Add opml support to new,open, save commands
#@-node:ekr.20061002093442:Add opml support to new,open, save commands
#@+node:ekr.20071003104917:Make http://edreamleo.org/namespaces/leo-python-editor/1.1 Leo's official namespace
xmlns:leo="http://edreamleo.org/namespaces/leo-python-editor/1.1"
#@nonl
#@-node:ekr.20071003104917:Make http://edreamleo.org/namespaces/leo-python-editor/1.1 Leo's official namespace
#@+node:ekr.20090218115025.3:Why are attributes pickled by default?
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/326a221f4c698f7a

> On Wed, Feb 18, 2009 at 12:12 PM, Kent Tenney <ktenney@gmail.com> wrote:
>>
>> Currently, Leo pickles the value of unknown attributes unless
>> the name starts with 'str_'
>>
>> Running the following code in node 'UA'
>>
>> p = c.currentPosition()
>> p.v.u = {'hello':'world', 'str_hello':'world'}
>>
>> results in the following in the .leo file:
>>
>> <v t="ktenney.20090218114928.367" str_hello="world"
>> hello="5505776f726c6471002e"><vh>UA</vh></v>
>>
>> I think this is surprising, Python-centric and contrary to the
>> spirit of Leo as a flexible data management platform.
>
> I suppose your point is that you can't create an arbitrarily named attribute
> with a string value. Does that create a real problem?

It requires a translation layer, either to (un)munge the name or
(un)pickle. Real problem?

Let's say each time I think 'I can use UAs to store that' I change
my mind when I realize my values will be in a pickle. (I really don't
want to name all my attributes str_xxx)

> As far as being Python-centric, can you suggest any other way of converting
> arbitrary data to a text string?

How is it done in any other XML file?
I've not used XML for arbitrary data, but it probably can be done.

> Why would that way be better than pickle?

My suspicion is that UAs would be used more for
storing text and numbers (as seems common for XML files)
than Python data objects.

Does Leo use UAs to store pickles?

I'm sure pickling capability is great, but I'm not convinced
it should be the _default._

No big deal.
#@nonl
#@-node:ekr.20090218115025.3:Why are attributes pickled by default?
#@+node:ekr.20080626081829.2:Allow headline comments for @nosent files
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/eb718b4c6d478ac0

I'm just getting started learning how to use Leo. Now, I'd like to use
it for some of my projects, but there's no chance that I can convert
everyone at work to using it, so putting sentinel-filled files in our
repository is out of the question. At the same time, my code looks
awfully bare without sentinels because the documentation ends up in
the section names, not the comments!

So, I was wondering if there's a convenient way to pull the section
names into a comment at the start of each section?

===============

Interesting question.  Am I correct in assuming you are using @nosent trees
to generate your files?  If so, it would be easy to add support for the
following options:

@bool write_section_comments_in_at_nosent_trees
@bool write_node_name_comments_in_at_nosent_trees

The first would write a sentinel consisting of only the section name;
the second would write a sentinel consisting only of the node's headline
(for nodes whose headline is not a section name).

These seem like they would be useful additions.  One can even imagine
corresponding Leo directives so that the comments could be turned on or off
within an @nosent tree.

What do you think?

=====================

> Interesting question.  Am I correct in assuming you are using @nosent trees
> to generate your files?  If so, it would be easy to add support for the
> following options:

> @bool write_section_comments_in_at_nosent_trees
> @bool write_node_name_comments_in_at_nosent_trees

> The first would write a sentinel consisting of only the section name;
> the second would write a sentinel consisting only of the node's headline
> (for nodes whose headline is not a section name).

> These seem like they would be useful additions.  One can even imagine
> corresponding Leo directives so that the comments could be turned on or off
> within an @nosent tree.

That sounds like an excellent solution. Particularly the last bit --
if you could turn section-comments on and off as required, it would
become very convenient to use Leo to produce source that is intended
to also be read by non Leo users. 
#@nonl
#@-node:ekr.20080626081829.2:Allow headline comments for @nosent files
#@+node:ekr.20080919085541.3:Use sqlite data base as an alternative representation for .leo files
http://groups.google.com/group/leo-editor/browse_thread/thread/dff0c165e2211691
#@nonl
#@-node:ekr.20080919085541.3:Use sqlite data base as an alternative representation for .leo files
#@-node:ekr.20090131200406.15:Optional file features
#@+node:ekr.20090210093316.1:Optional features
#@+node:ekr.20080922115725.1:Minor @shadow stuff
#@+node:ekr.20081004102201.2:Create a log file for @shadow?
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/5e7bd3af2d1fbf51

How about a shadow.log file which Leo told what it thought of the relationship
between the node, file and shadow? It might provide useful clues.
#@-node:ekr.20081004102201.2:Create a log file for @shadow?
#@+node:ekr.20081001062423.1:Can @shadow mark externally changed nodes?
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/c46eabe8a9fe6e8

@color
#@nonl
#@-node:ekr.20081001062423.1:Can @shadow mark externally changed nodes?
#@+node:ekr.20090402072059.13:Create a general mechanism for aux (shadow, _db) files
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/4ec30df3f1db8db3

On Sat, Mar 28, 2009 at 3:24 AM, VR <viktor.ransmayr@gmail.com> wrote:


    When I tried to de-install Leo-4.6b1 I succeeded, but the program
    reported that 5 directories
    were not removed.

    Three of the directories where

    1) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\config
    2) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\doc
    3) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\plugins

    [containing]


    a) .leoSettings.leo_db
    b) .leoDocs.leo_db
    c) .leo_shadow
    d) .leoPluginsRef.leo_db


Thanks for this report. I think it is important, and needs a good solution.

I dislike all these files being sprayed around the file system. I'd like to see
these files placed somewhere the ~/.leo directory. Is there a reason why this
would be a bad idea?

Similarly, we might also prefer to have shadow files place in, say,
~/.leo/shadow_files.

In both cases, I think we want to create files that indicate their location.
Either that, or mirror their location in (subdirectories) ~/.leo. In other
words, this is a general problem, and it would be good to have a robust, general
solution.
#@nonl
#@-node:ekr.20090402072059.13:Create a general mechanism for aux (shadow, _db) files
#@-node:ekr.20080922115725.1:Minor @shadow stuff
#@+node:ekr.20090601083544.6067:Make all commands available to all commanders
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/a83082cec5ad3df8

QQQ (Ville)
So to create command you would do

import leoPlugins

def mycmd(c,p, event):
  print c,p

leoPlugins.expose_command('my-command', mycmd)
leoPlugins.expose_button('press-this',mycmd)

[EKR: I would rather use g.app.exposeCommand, g.app.exposeButton].

These would be available on *all* new commanders, and the current
commander as well (for easy testing). Plugins would not have to
contain more code than what is presented above.

The idea is to have a global command dict, [EKR: g.app.commandsDict]
and global button dict.
There is one after-create-frame handler that introduces all the
entries in this dict to the commander command dict.
QQQ

============


QQQ
g.app.global_commands_dict, which gets copied to c on commander
creation. it's rev 1889, you'll note that it's a simple
implementation. I didn't add g.button yet. An example:

@g.command('bookmark')
def bookmark(event):
    c = event.get('c')
    p = c.currentPosition()
    bookmarks.append(p.gnx)
    g.es('bookmarked') 
QQQ
#@nonl
#@-node:ekr.20090601083544.6067:Make all commands available to all commanders
#@+node:ekr.20081119132758.2:Support @ifgui in settings trees
#@-node:ekr.20081119132758.2:Support @ifgui in settings trees
#@+node:ekr.20080803063553.4:Allow translation/abbreviation for any Leo directive, including headline directives
#@-node:ekr.20080803063553.4:Allow translation/abbreviation for any Leo directive, including headline directives
#@+node:ekr.20080727122007.1:Allow user to set background colors of nodes
What uA should be used to specify node colors?

if the foreground / background color API uses uAs,
would/should the uAs use the reserved "leo_&lt;something&gt;" namespace?
#@-node:ekr.20080727122007.1:Allow user to set background colors of nodes
#@+node:ekr.20080813064908.8:Find a way to limit length of lines in indented nodes
#@-node:ekr.20080813064908.8:Find a way to limit length of lines in indented nodes
#@+node:ekr.20080802070659.11:Make node attributes visible, and supported by Leo's core
#@-node:ekr.20080802070659.11:Make node attributes visible, and supported by Leo's core
#@+node:ekr.20080806054207.3:Auto scroll outline pane if headline would become invisible
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/76789df8aac08c70

When using leo as outliner, I often use only node headlines to write
down some data. If the headline string is too long, the cursor goes
beyond the visible area. When modifying a node headline, is it
possible to make leo to auto-scroll, so the cursor is always visible? 
#@-node:ekr.20080806054207.3:Auto scroll outline pane if headline would become invisible
#@+node:ekr.20070521105645:Improve api docs with epydoc?
@nocolor
http://sourceforge.net/forum/message.php?msg_id=4319363
By: ktenney

I think there is room for improvement in documenting Leo's
API, making it easier to write these kind of scripts.
I'm not sure of the best way to do that.

Epydoc seems to be the most active project in this realm.
http://epydoc.sourceforge.net/epydoc.html
#@-node:ekr.20070521105645:Improve api docs with epydoc?
#@+node:ekr.20061116054917.6:Remove blanks in calltips
#@-node:ekr.20061116054917.6:Remove blanks in calltips
#@+node:ekr.20080628095358.1:Make each Leo command a class
http://groups.google.com/group/leo-editor/browse_thread/thread/5688ed9aaa39be2e#

@nocolor

The main difficulty I see in the migration is creating the tables in the getPublicCommands methods in the various classes in leoEditCommands.py.  At present, these tables associate command names (strings) with corresponding methods.  The form of getPublicCommands is always:

def getPublicCommands (self):
  return {
    'command-name1': self.methodName1,
    'command-name2': self.methodName2,
    ...
  }

Thinking out loud, let's see whether the migration can be done easily.  We would change the entry:

    'command-name1': self.methodNameN,

to:

    'command-name1': self.classNameN(self),

That is, the table creates an instance of the class by calling the class's ctor, with self (the container object) as the ctor's only argument.  To make this work, all we need to do is give the class a __call__ method whose signature matches the signature of methodNameN, that is, the signature used to call methods previously.

Well, isn't this nice.  We can transition gradually, as needed.  No need *ever* to do a mass migration.  It should be easy to verify this scheme with one or two examples.  Please report your experiences if you decide to play around with this.

Edward

P.S.  I think it would be good style to append "Class" to the name of each command class. This makes it clear that self.myCommandClass(self) is a ctor.
#@-node:ekr.20080628095358.1:Make each Leo command a class
#@-node:ekr.20090210093316.1:Optional features
#@+node:ekr.20090714085914.5994:Optional new commands
#@+node:ekr.20071004120359.2:Do expand-region-abbrevs from
See: regionalExpandAbbrev.
#@nonl
#@-node:ekr.20071004120359.2:Do expand-region-abbrevs from
#@+node:ekr.20090402072059.2:clone-find-all-once
@

First do a normal clone-find-all for the word "clone". Then click the script
button and do it again. Notice that children of previously found nodes don't get
added again in the modified version.
#@nonl
#@+node:ekr.20090402072059.4:@@@button my clone find all
import leo.core.leoFind as leoFind 

def new_find_all(self):
    << do some initial stuff >>


    while 1:
        pos, newpos = self.findNextMatch()
        if pos is None: break

        if count % 10 == 0 and count > 0:
            g.es("still searching, matches found: ", count)

        << Skip node if it's a child of a previously found node >>

        count += 1

        s = w.getAllText()
        i,j = g.getLine(s,pos)
        line = s[i:j]
        if not self.clone_find_all:
            self.printLine(line,allFlag=True)
        if self.clone_find_all and self.p.v.t not in clones:
            # g.trace(self.p.v.t,self.p.h)
            if not clones:
                undoData = u.beforeInsertNode(c.p)
                << create the found node >>
            clones.append(self.p.v.t)
            positions.append(self.p)
            << create a clone of p under the find node >>

    if self.clone_find_all and clones:
        u.afterInsertNode(found,undoType,undoData,dirtyVnodeList=[])
        c.selectPosition(found)
        c.setChanged(True)

    self.restore(data)
    c.redraw()
    g.es("found",count,"matches")


leoFind.leoFind.findAll = new_find_all

c.executeMinibufferCommand("clone-find-all") 
#@+node:ekr.20090402072059.5:<< do some initial stuff >>
g.es("findAll..., self: ", self)

c = self.c ; w = self.s_ctrl ; u = c.undoer
undoType = 'Clone Find All'
if not self.checkArgs():
    return
self.initInHeadline()
if self.clone_find_all:
    self.p = None # Restore will select the root position.
data = self.save()
self.initBatchCommands()
count = 0 ; clones = []; positions = []
#@nonl
#@-node:ekr.20090402072059.5:<< do some initial stuff >>
#@+node:ekr.20090402072059.6:<< create the found node >>
oldRoot = c.rootPosition()
found = oldRoot.insertAfter()
found.moveToRoot(oldRoot)
c.setHeadString(found,'Found: ' + self.find_text)
c.setRootPosition(found) # New in Leo 4.5.
#@-node:ekr.20090402072059.6:<< create the found node >>
#@+node:ekr.20090402072059.7:<< create a clone of p under the find node >>
q = self.p.clone()
q.moveToLastChildOf(found)
#@-node:ekr.20090402072059.7:<< create a clone of p under the find node >>
#@+node:ekr.20090402072059.8:<< Skip node if it's a child of a previously found node >>
<< def: is a child of b >>

is_child_of_previous = False
for previously_found in positions:
    if is_a_child_of_b(self.p, previously_found):
        is_child_of_previous = True
        break

if is_child_of_previous:
    continue
#@nonl
#@+node:ekr.20090402072059.9:<< def: is a child of b >>

def is_a_child_of_b(a, b):
    for child in b.children_iter():
        if a.t == child.t:
            return True
        if is_a_child_of_b(a, child):
            return True
    return False
#@nonl
#@-node:ekr.20090402072059.9:<< def: is a child of b >>
#@-node:ekr.20090402072059.8:<< Skip node if it's a child of a previously found node >>
#@-node:ekr.20090402072059.4:@@@button my clone find all
#@-node:ekr.20090402072059.2:clone-find-all-once
#@-node:ekr.20090714085914.5994:Optional new commands
#@-node:ekr.20091005145253.6058:Features
#@-node:ekr.20100206074650.5843:4.9 Autocompletion
#@+node:ekr.20060306194040:Leo Video & slide show
@nocolor
http://sourceforge.net/forum/message.php?msg_id=3615177
By: ktenney

High on my ToLearn list is vnc2swf
http://www.unixuser.org/~euske/vnc2swf/


http://sourceforge.net/forum/message.php?msg_id=3615278
By: James

A lot of people are now using Wink for demonstrations
(http://www.debugmode.com/wink/), it's is free and seems to work well.

Check out http://murl.se/11332
At the bottom they talk about tools and techniques.
http://showmedo.com seems like it would be a good
place to host vids also.

I've listened/watched a fair number of things like this;
my recomendation is to get a good microphone and
pre-amp to record your voice, and prepare the audio
track carefully. It is so aggravating when
it's hard to discern the words being spoken.

Thanks,
Kent
#@nonl
#@+node:ekr.20060531134434:Tutorials
http://sourceforge.net/forum/message.php?msg_id=3758271

From: Rich

Tutorials would be great. I use Liberty BASIC, (http://libertybasic.conforums.com)
and it has a very good tutorial -- leads the beginner by the hand through much
of the language. Also the help file has working code snippets
to cut-n-paste-n-play-with. I'd like to see something like:

[Buttons]
...[What are Buttons good for?]
...[How do I make my own buttons?]
......[Some commands you can use with buttons]
......[Where to find button commands]
#@nonl
#@-node:ekr.20060531134434:Tutorials
#@+node:ekr.20091006063434.16252:A slide show for newbies
#@-node:ekr.20091006063434.16252:A slide show for newbies
#@+node:ekr.20060531134434.1:Screencasts
@nocolor
http://sourceforge.net/forum/message.php?msg_id=3758303
By: ktenney

My sense is that documentation/screencasts has the
greatest potential for expanding Leo's mindshare.

I really like those produced by the good folks
at Dabo;
http://leafe.com/screencasts/
http://leafe.com/screencasts/populategrid.html

The TurboGears people have taken this to the extreme;
http://www.turbogears.org/ultimate.html

Leo is different enough that it warrants a 
demonstration of it's advantages.

-------------------

https://sourceforge.net/forum/message.php?msg_id=4396251
By: ktenney

2 good screencasts on making screencasts;

http://murl.se/26296
#@-node:ekr.20060531134434.1:Screencasts
#@+node:ekr.20060829103523:Render Leo slideshows
@nocolor

http://sourceforge.net/forum/message.php?msg_id=3889246
By: terry_n_brown

Three packages that might be candidates for "rendering" slides authored in Leo:

MagicPoint: http://member.wide.ad.jp/wg/mgp/

  uses a text file format that leo could produce

Slidy: http://www.w3.org/Talks/Tools/Slidy/

  uses XHTML / canned Java script

S5: http://meyerweb.com/eric/tools/s5/

  Similar to Slidy I think, haven't looked at it
#@nonl
#@-node:ekr.20060829103523:Render Leo slideshows
#@-node:ekr.20060306194040:Leo Video & slide show
#@-all
#@nonl
#@-node:ekr.20100119205347.6015:@thin ../doc/leoToDo.txt
#@-leo
